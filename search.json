[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Sur le chemin de lâ€™enf-R",
    "section": "",
    "text": "PrÃ©face",
    "crumbs": [
      "DonnÃ©es",
      "PrÃ©face"
    ]
  },
  {
    "objectID": "index.html#lobjectif-de-ce-livre",
    "href": "index.html#lobjectif-de-ce-livre",
    "title": "Sur le chemin de lâ€™enf-R",
    "section": "Lâ€™objectif de ce livre",
    "text": "Lâ€™objectif de ce livre\nLâ€™objectif de ce livre est double :\n\nVous prÃ©senter R, un environnement interactif puissant et flexible pour le calcul et la recherche statistiques.\nVous prÃ©senter (ou vous familiariser Ã  nouveau) avec lâ€™analyse statistique effectuÃ©e dans R.\n\nR nâ€™est pas difficile Ã  apprendre en soi, mais comme pour toute nouvelle langue (parlÃ©e ou informatique), la courbe dâ€™apprentissage initiale peut Ãªtre raide et quelque peu intimidante. Lâ€™objectif nâ€™est pas de tout couvrir (ni avec R, ni avec les statistiques), mais simplement de vous aider Ã  franchir le cap (potentiellement plus rapidement) et Ã  vous fournir les compÃ©tences de base (et la confiance !) nÃ©cessaires pour commencer votre propre voyage avec R et avec des analyses spÃ©cifiques.",
    "crumbs": [
      "DonnÃ©es",
      "PrÃ©face"
    ]
  },
  {
    "objectID": "index.html#livre-multilingue",
    "href": "index.html#livre-multilingue",
    "title": "Sur le chemin de lâ€™enf-R",
    "section": "Livre multilingue",
    "text": "Livre multilingue\nLe livre est fourni comme un livre multilingue qui brise la barriÃ¨re de la langue et permet potentiellement de faciliter lâ€™apprentissage de R et de son environnement principalement anglophone. Nous sommes toujours Ã  la recherche de bÃ©nÃ©voles pour nous aider Ã  dÃ©velopper le livre et Ã  ajouter dâ€™autres langues Ã  la liste qui ne cesse de sâ€™allonger . Nâ€™hÃ©site pas Ã  Nous contacter si tu veux nous aider\nSur la page web, tu peux changer de langue via le  dans la barre de navigation. AprÃ¨s avoir changer de langue, tu peux tÃ©lÃ©charger le document en pdf ou epub pour cet langue .\nListe des langues :\n\nanglais (publiÃ© mais Ã  peaufiner)\nfranÃ§ais (en dÃ©veloppement, en attendant que lâ€™anglais soit peaufinÃ©)\nespagnol (un jour peut-Ãªtreâ€¦)\nâ€¦ des volontaires pour plus ??",
    "crumbs": [
      "DonnÃ©es",
      "PrÃ©face"
    ]
  },
  {
    "objectID": "index.html#comment-utiliser-ce-livre",
    "href": "index.html#comment-utiliser-ce-livre",
    "title": "Sur le chemin de lâ€™enf-R",
    "section": "Comment utiliser ce livre",
    "text": "Comment utiliser ce livre\nPour une meilleure expÃ©rience, nous te recommandons de lire la version web de ce livre que tu peux trouver Ã  https://biostats-uottawa.github.io/enfR.\nLa version web inclut une barre de navigation incluant des options pour faciliter la lecture , de recherche , pour changer la couleur  et pour suggÃ©rer des modifications ou reporter des problÃ¨mes . Tu peux aussi tÃ©lÃ©charger le document  au format pdf ou epub.\nNous utilisons quelques conventions typographiques tout au long de ce livre.\nLe code R et la sortie qui en rÃ©sulte sont prÃ©sentÃ©s dans des blocs de code dans notre livre.\n\n2 + 2\n\n[1] 4\n\n\nLes fonctions dans le texte sont prÃ©sentÃ©es avec des parenthÃ¨ses Ã  la fin en utilisant la police de code, câ€™est-Ã -dire mean() ou sd() etc.\nLes objets sont reprÃ©sentÃ©s Ã  lâ€™aide de la police de code sans les parenthÃ¨ses, câ€™est-Ã -dire obj1, obj2 etc.\nLes paquets R dans le texte sont indiquÃ©s en utilisant la police de code et suivis de lâ€™icone ğŸ“¦, exemple tidyverse ğŸ“¦.\nUne sÃ©rie dâ€™actions nÃ©cessaires pour accÃ©der aux commandes de menu dans RStudio ou VSCode sont identifiÃ©es comme suit File -&gt; New File -&gt; R Script ce qui se traduit par â€œclique sur le menu Fichier, puis clique sur Nouveau fichier et sÃ©lectionne R Scriptâ€.\nLorsque nous faisons rÃ©fÃ©rence Ã  IDE (Integrated Development Environment : Logiciel dâ€™Environnement de DÃ©veloppement IntÃ©grÃ©) dans la suite du texte, il sâ€™agit de RStudio ou de VScode.\nLorsque nous parlons de .[Rq]md, nous entendons par lÃ  les documents R markdown (.Rmd) ou Quarto (.qmd) et nous parlerons gÃ©nÃ©ralement des documents R markdown en faisant rÃ©fÃ©rence Ã  lâ€™un ou lâ€™autre des fichiers .Rmd ou .qmd.\nLe manuel tente de mettre en Ã©vidence certaines parties du texte Ã  lâ€™aide des encadrÃ©s et icÃ´nes suivants.\n\n\n\n\n\n\nExercices\n\n\n\nDes choses Ã  faire pour toi\n\n\n\n\n\n\n\n\nSolutions\n\n\n\nCode R et explications\n\n\n\n\n\n\n\n\nAvertissement\n\n\n\nAvertissements\n\n\n\n\n\n\n\n\nImportant\n\n\n\nPoints importants\n\n\n\n\n\n\n\n\nNote\n\n\n\nNotes",
    "crumbs": [
      "DonnÃ©es",
      "PrÃ©face"
    ]
  },
  {
    "objectID": "index.html#sec-qui",
    "href": "index.html#sec-qui",
    "title": "Sur le chemin de lâ€™enf-R",
    "section": "Qui sommes-nous ?",
    "text": "Qui sommes-nous ?\n\n\n\n\n\n\n\n\n\n\n\n\nÂ \n\n\nJulien Martin est professeur Ã  lâ€™UniversitÃ© dâ€™Ottawa en Ã‰cologie Ã©volutive. Il a dÃ©couvert le merveilleux monde R avec la version 1.8.1 et lâ€™enseigne depuis R v2.4.0.\n\n\n: uOttawa page, lab page\n\n\n: jgamartin\n\n\n: juliengamartin\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nÂ \n\n\nAugustin Birot est Ã©tudiant au doctorat Ã  lâ€™UniversitÃ© dâ€™Ottawa en Ã‰cologie Ã©volutive.\n\n\n: page du labo \n\n\n\n\n\nContribution au livre\nJM: dÃ©veloppement et Ã©criture de la premiÃ¨re version des chapitres en anglais, mise en page, traduction, maintenance\nAB: traduction en franÃ§ais et clarification de tous les chapitres.",
    "crumbs": [
      "DonnÃ©es",
      "PrÃ©face"
    ]
  },
  {
    "objectID": "index.html#remerciements",
    "href": "index.html#remerciements",
    "title": "Sur le chemin de lâ€™enf-R",
    "section": "Remerciements",
    "text": "Remerciements\nLa premiÃ¨re partie du livre sur lâ€™utilisation de R a commencÃ© comme un fork sur github Ã  partir de lâ€™excellent livre en anglais An introduction to R de Douglas, Roos, Mancini, Couto et Lusseau (Douglas 2023). Il a Ã©tÃ© forkÃ© le 23 avril 2023 Ã  partir de Alexd106 github repository puis modifiÃ© et mis Ã  jour en fonction de mes propres besoins et de ma perspective dâ€™enseignement de R. Le contenu nâ€™a pas Ã©tÃ© revu ni approuvÃ© par les dÃ©veloppeurs prÃ©cÃ©dents.\nPlusieurs parties du livre sont basÃ©es sur des manuels de laboratoire pour les cours de biostatistique Ã  lâ€™UniversitÃ© dâ€™Ottawa Ã©crits par Martin, Findlay, Morin et Rundle.\nSites ayant fourni de nombreuses informations pour le livre :\n\ndplyr introduction\nIntroduction to gam\nIntoduction to gams by Noam Ross",
    "crumbs": [
      "DonnÃ©es",
      "PrÃ©face"
    ]
  },
  {
    "objectID": "index.html#crÃ©dits-dimage",
    "href": "index.html#crÃ©dits-dimage",
    "title": "Sur le chemin de lâ€™enf-R",
    "section": "CrÃ©dits dâ€™image",
    "text": "CrÃ©dits dâ€™image\nLes photos, images et captures dâ€™Ã©cran sont de Julien Martin sauf lorsque indiquÃ© dans la lÃ©gende.\nLâ€™image de couverture a Ã©tÃ© gÃ©nÃ©rÃ©e par Nightcafe Ai Art generator. Le Favicon et lâ€™autocollant hexagonal ont Ã©tÃ© crÃ©Ã©s Ã  partir de lâ€™image de couverture.\n\n\n\n\n\n\nNote\n\n\n\nplusieurs captures dâ€™Ã©cran sont actuellement rÃ©alisÃ©es par Alex Douglas et sont en train dâ€™Ãªtre refaites pour pour se conformer Ã  la dÃ©claration prÃ©cÃ©dente",
    "crumbs": [
      "DonnÃ©es",
      "PrÃ©face"
    ]
  },
  {
    "objectID": "index.html#licence",
    "href": "index.html#licence",
    "title": "Sur le chemin de lâ€™enf-R",
    "section": "Licence",
    "text": "Licence\nJe partage cette version modifiÃ©e du livre original sous la licence Licence Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International.\n\n\nLicence Creative Commons\n\nSi tu enseignes R, nâ€™hÃ©site pas Ã  utiliser tout ou partie du contenu de ce livre pour aider tes propres Ã©lÃ¨ves. La seule chose que je te demande, câ€™est de citer la source originale et les auteurs. Si tu trouves ce livre utile ou si tu as des commentaires ou des suggestions, jâ€™aimerais beaucoup que tu me les fasses parvenir (contact info).",
    "crumbs": [
      "DonnÃ©es",
      "PrÃ©face"
    ]
  },
  {
    "objectID": "index.html#citer-le-livre",
    "href": "index.html#citer-le-livre",
    "title": "Sur le chemin de lâ€™enf-R",
    "section": "Citer le livre",
    "text": "Citer le livre\nJulien Martin. (2024). Sur le chemin de lâ€™enf-R. Un livre multilingue dâ€™introduction Ã  R. Version: 0.6.0 (2024-10-08). DOI: 10.5281/zenodo.13801265",
    "crumbs": [
      "DonnÃ©es",
      "PrÃ©face"
    ]
  },
  {
    "objectID": "index.html#chapters-to-read",
    "href": "index.html#chapters-to-read",
    "title": "Sur le chemin de lâ€™enf-R",
    "section": "Lecture associÃ©e au cours",
    "text": "Lecture associÃ©e au cours\n\n\n\nTableÂ 1: Course associated reading for biostatistical course at uOttawa\n\n\n\n\n\n\n\n\n\n\n\nChapter\nBioXx58 \nBio8940 \n\n\n\nUtiliser R\n\n\n1.-4.\nâœ…âœ…\nğŸ˜ƒ\n\n\n5. Programmation\n\nâœ…âœ…\n\n\n6. Rapports reproductibles\nâœ”ï¸\nâœ…âœ…\n\n\n7. ContrÃ´le de version\n\nâœ…âœ…\n\n\nPrincipes de statistiques\n\n\ntous les chapitres\nâœ…âœ…\nğŸ˜ƒ\n\n\nModÃ¨les linÃ©aires\n\n\ntous les chapitres\nâœ…âœ…\nğŸ˜ƒ\n\n\nModÃ¨les linÃ©aires gÃ©nÃ©ralisÃ©s\n\n\ntous les chapitres\nâœ”ï¸\nâœ…âœ…\n\n\nModÃ¨les mixtes\n\n\ntous les chapitres\n\nâœ…âœ…\n\n\nModÃ¨les additifs gÃ©nÃ©ralisÃ©s\n\n\ntous les chapitres\n\nâœ”ï¸\n\n\nAnalyses multivariÃ©es\n\n\ntous les chapitres\n\nâœ”ï¸\n\n\nApproche BayÃ©sienne\n\n\ntous les chapitres\n\nâœ…âœ…\n\n\n\nSuggÃ©rÃ© âœ”ï¸ ; Obligatoire âœ…âœ… ; connaissances attendues (pourraient avoir besoin d'une remise Ã  niveau) ğŸ˜ƒ",
    "crumbs": [
      "DonnÃ©es",
      "PrÃ©face"
    ]
  },
  {
    "objectID": "index.html#collant-hex",
    "href": "index.html#collant-hex",
    "title": "Sur le chemin de lâ€™enf-R",
    "section": "Collant Hex",
    "text": "Collant Hex\n\n\n\n\n\n\n\n\nDouglas, A. 2023. An introduction to R.",
    "crumbs": [
      "DonnÃ©es",
      "PrÃ©face"
    ]
  },
  {
    "objectID": "01-debut.html",
    "href": "01-debut.html",
    "title": "1Â  Pour commencer",
    "section": "",
    "text": "Quelques conseils sur R\nBonne chance et nâ€™oubliez pas de vous amuser.",
    "crumbs": [
      "DonnÃ©es",
      "Utiliser R",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Pour commencer</span>"
    ]
  },
  {
    "objectID": "01-debut.html#quelques-conseils-sur-r",
    "href": "01-debut.html#quelques-conseils-sur-r",
    "title": "1Â  Pour commencer",
    "section": "",
    "text": "Utilisez R souvent et rÃ©guliÃ¨rement. Cela permettra de crÃ©er et maintenir une dynamique importante.\nApprendre R nâ€™est pas un test de mÃ©moire. Lâ€™un des avantages dâ€™un langage de script est que vous aurez toujours votre code (bien annotÃ©) auquel vous pourrez vous rÃ©fÃ©rer lorsque vous oublierez comment faire quelque chose.\nIl nâ€™est pas nÃ©cessaire de tout savoir sur R pour Ãªtre productif.\nSi vous Ãªtes bloquÃ©, faites des recherches en ligne, ce nâ€™est pas de la triche et Ã©crire une bonne requÃªte de recherche est une compÃ©tence en soi.\nSi vous vous retrouvez Ã  fixer un code pendant des heures en essayant de comprendre pourquoi il ne fonctionne pas, Ã©loignez-vous quelques minutes.\nEn R, il existe de nombreuses faÃ§ons dâ€™aborder un problÃ¨me particulier. Si votre code fait ce que vous voulez quâ€™il fasse dans un temps raisonnable et de maniÃ¨re robuste, ne vous inquiÃ©tez pas.\nR nâ€™est quâ€™un outil pour vous aider Ã  rÃ©pondre Ã  vos questions intÃ©ressantes. Ne perdez pas de vue ce qui est important : vos questions de recherche et vos donnÃ©es. Aucune compÃ©tence en matiÃ¨re dâ€™utilisation de R ne sera utile si votre collecte de donnÃ©es est fondamentalement dÃ©fectueuse ou si votre question est vague.\nSoyez conscient quâ€™il y aura des moments oÃ¹ les choses deviendront un peu difficiles ou frustrantes. Essayez dâ€™accepter ces pÃ©riodes comme faisant partie du processus naturel dâ€™apprentissage dâ€™une nouvelle compÃ©tence (nous sommes tous passÃ©s par lÃ ) et rappelez-vous que le temps et lâ€™Ã©nergie que vous investissez maintenant seront largement remboursÃ©s dans un avenir pas trop lointain.",
    "crumbs": [
      "DonnÃ©es",
      "Utiliser R",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Pour commencer</span>"
    ]
  },
  {
    "objectID": "01-debut.html#installation",
    "href": "01-debut.html#installation",
    "title": "1Â  Pour commencer",
    "section": "\n1.1 Installation",
    "text": "1.1 Installation\n\n1.1.1 Installation de R\nPour dÃ©marrer, la premiÃ¨re chose Ã  faire est dâ€™installer R. R est disponible gratuitement pour les systÃ¨mes dâ€™exploitation Windows, Mac et Linux Ã  partir du site web du Comprehensive R Archive Network (CRAN) . Pour les utilisateurs de Windows et de Mac, nous vous suggÃ©rons de tÃ©lÃ©charger et dâ€™installer les versions binaires prÃ©compilÃ©es. Il existe des instructions assez complÃ¨tes pour installer R pour chaque systÃ¨me dâ€™exploitation (Windows, Mac ou linux).\nQuel que soit le systÃ¨me dâ€™exploitation que vous utilisez, une fois que vous avez installÃ© R, vous devez vÃ©rifier quâ€™il fonctionne correctement. La maniÃ¨re la plus simple de le faire est de lancer R en double-cliquant sur lâ€™icÃ´ne R (Windows ou Mac) ou en tapant R dans la console (Linux). La console R devrait sâ€™afficher et vous devriez pouvoir taper des commandes R dans la console aprÃ¨s lâ€™invite de commande &gt;. Essayez de taper le code R suivant et appuyez sur la touche EntrÃ©e :\n\nplot(1)\n\n\n\n\n\n\nFigureÂ 1.1: Le meilleur graph du monde, sert juste Ã  tester R\n\n\n\n\nUn graphique avec un seul point au centre devrait apparaÃ®tre. Si câ€™est le cas, vous pouvez commencer. Si ce nâ€™est pas le cas, nous vous suggÃ©rons de noter toutes les erreurs produites et dâ€™utiliser ensuite votre moteur de recherche prÃ©fÃ©rÃ© pour rÃ©soudre le problÃ¨me.\n\n1.1.2 Installation dâ€™un IDE\nIl est fortement recommandÃ© dâ€™utiliser un logiciel dâ€™Environnement de DÃ©veloppement IntÃ©grÃ© (IDE) pour travailler avec R. Un IDE simple et extrÃªmement populaire est RStudio . Une alternative Ã  RStudio est Visual Studio Code, ou VSCode . Un IDE peut Ãªtre considÃ©rÃ© comme un complÃ©ment Ã  R qui fournit une interface plus conviviale, intÃ©grant la console R, un Ã©diteur de scripts et dâ€™autres fonctionnalitÃ©s utiles (comme R markdown et lâ€™intÃ©gration de Git Hub).\n\n\n\n\n\n\nMise en garde\n\n\n\nVous devez installer R avant dâ€™installer un IDE (voir Section 1.1.1 pour plus de dÃ©tails).\n\n\n\n\n\n\n\n\nNote\n\n\n\nLorsque lâ€™on se rÃ©fÃ¨re Ã  un IDE dans la suite du texte, il sâ€™agit de RStudio ou de VScode.\n\n\n\n1.1.2.1 RStudio\nRStudio est disponible gratuitement pour les systÃ¨mes dâ€™exploitation Windows, Mac et Linux et peut Ãªtre tÃ©lÃ©chargÃ© Ã  partir du site RStudio. Vous devez sÃ©lectionner la version â€˜RStudio Desktopâ€™.\n\n1.1.2.2 VSCode\nVSCode est disponible gratuitement pour les systÃ¨mes dâ€™exploitation Windows, Mac et Linux et peut Ãªtre tÃ©lÃ©chargÃ© Ã  partir du site VS Code .\nEn outre, vous devez installer lâ€™extension R pour VSCode. Pour faire de VSCode une vÃ©ritable centrale pour travailler avec R, nous vous recommandons fortement dâ€™installer Ã©galement :\n\n\nradian : Une console R moderne qui corrige de nombreuses limitations du terminal R officiel et prend en charge de nombreuses fonctionnalitÃ©s telles que la coloration syntaxique et lâ€™autocomplÃ©tion.\n\nVSCode-R-Debugger : Une extension de VS Code pour supporter les capacitÃ©s de dÃ©bogage de R.\n\nhttpgd : Un paquet R ğŸ“¦ pour fournir un dispositif graphique qui sert de maniÃ¨re asynchrone des graphiques SVG via HTTP et WebSockets.\n\n1.1.2.3 Alternatives Ã  RStudio et VSCode\nPlutÃ´t que dâ€™utiliser un IDE â€œtout-en-unâ€, de nombreuses personnes choisissent dâ€™utiliser R et un Ã©diteur de script sÃ©parÃ© pour Ã©crire et exÃ©cuter du code R. Si vous ne savez pas ce quâ€™est un Ã©diteur de script, vous pouvez voir Ã§a comme un logiciel de traitement de texte, mais spÃ©cialement conÃ§u pour Ã©crire du code. Par chance, de nombreux Ã©diteurs de scripts sont disponibles gratuitement. Nâ€™hÃ©sitez donc pas Ã  les tÃ©lÃ©charger et Ã  les tester jusquâ€™Ã  ce que vous en trouviez un qui vous convienne. Certains Ã©diteurs de scripts ne sont disponibles que pour certains systÃ¨mes dâ€™exploitation et tous ne sont pas spÃ©cifiques Ã  R. Vous trouverez ci-dessous des suggestions dâ€™Ã©diteurs de scripts. Câ€™est Ã  vous de choisir celui qui vous convient le mieux : lâ€™une des grandes qualitÃ©s de R est que VOUS choisissez comment vous voulez utiliser R.\n\n1.1.2.3.1 Ã‰diteurs de texte avancÃ©s\nUn moyen lÃ©ger mais efficace de travailler avec R est dâ€™utiliser des Ã©diteurs de texte avancÃ©s tels que :\n\n\nAtom (tous les systÃ¨mes dâ€™exploitation)\n\nBBedit (Mac OS)\n\ngedit (Linux ; livrÃ© avec la plupart des distributions Linux)\n\nMacVim (Mac OS)\n\nNano (Linux)\n\nNotepad++ (en anglais) (Windows)\n\nSublime Text (tous les systÃ¨mes dâ€™exploitation)\n\nvim et son extension NVim-R (Linux)\n\n1.1.2.3.2 Environnements de dÃ©veloppement intÃ©grÃ©s\nCes environnements sont plus puissants que de simples Ã©diteurs de texte et sont similaires Ã  RStudio :\n\n\nEmacs et son extension Statistiques de Emacs Speaks (tous les systÃ¨mes dâ€™exploitation)\n\nRKWard (Linux)\n\nTinn-R (Windows)",
    "crumbs": [
      "DonnÃ©es",
      "Utiliser R",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Pour commencer</span>"
    ]
  },
  {
    "objectID": "01-debut.html#sec-orient",
    "href": "01-debut.html#sec-orient",
    "title": "1Â  Pour commencer",
    "section": "\n1.2 Orientation dans lâ€™IDE",
    "text": "1.2 Orientation dans lâ€™IDE\n\n1.2.1 RStudio\nLorsque vous ouvrez RStudio pour la premiÃ¨re fois, vous devriez voir la prÃ©sentation suivante (elle peut Ãªtre lÃ©gÃ¨rement diffÃ©rente sur un ordinateur Windows).\n\n\n\n\n\n\n\nFigureÂ 1.2: FenÃªtre principale R studio\n\n\n\n\nLa grande fenÃªtre (ou volet) de gauche est la Console. La fenÃªtre en haut Ã  droite est le volet Environnement / Historique / Connexions et la fenÃªtre en bas Ã  droite est le volet Fichiers / Graphiques / Paquets / Aide / Visiualiseur . Nous aborderons chacun de ces volets dans les paragraphes qui suivent. Vous pouvez personnaliser lâ€™emplacement de chaque volet en cliquant sur le menu â€œOutilsâ€, puis en sÃ©lectionnant Options globales â€“&gt; Disposition des volets. Vous pouvez redimensionner les volets en cliquant sur le milieu des bords de la fenÃªtre et en le faisant glisser dans la direction souhaitÃ©e. Il existe une multitude dâ€™autres faÃ§ons de personnaliser RStudio.\n\n1.2.1.1 Console\nLa console est le cheval de bataille de R. Câ€™est lÃ  que R Ã©value tout le code que vous Ã©crivez. Vous pouvez taper du code R directement dans la console Ã  lâ€™invite de la ligne de commande, &gt;. Par exemple, si vous tapez 2 + 2 dans la console, vous devriez obtenir la rÃ©ponse 4 (avec un peu de chance). Ne vous prÃ©occupez pas du [1] au dÃ©but de la ligne pour lâ€™instant.\n\n\n\n\n\n\n\nFigureÂ 1.3: Vue de la console R studio\n\n\n\n\nCependant, dÃ¨s que vous commencez Ã  Ã©crire plus de code R, cela devient plutÃ´t encombrant. Au lieu de taper le code R directement dans la console, il est prÃ©fÃ©rable de crÃ©er un script R. Un script R est un simple fichier texte portant lâ€™extension .R qui contient vos lignes de code R. Ces lignes de code sont ensuite introduites dans la console R, ligne par ligne. Pour crÃ©er un nouveau script R, cliquez sur le menu â€œFichierâ€, puis sÃ©lectionnez Nouveau fichier â€“&gt; Script R.\n\n\n\n\n\n\n\nFigureÂ 1.4: CrÃ©er un nouveau fichier script sur R studio\n\n\n\n\nVous remarquerez quâ€™une nouvelle fenÃªtre (appelÃ©e volet Source) apparaÃ®t en haut Ã  gauche de RStudio et que la console se trouve dÃ©sormais en bas Ã  gauche. La nouvelle fenÃªtre est un Ã©diteur de script et câ€™est lÃ  que vous Ã©crirez votre code.\n\n\n\n\n\n\n\nFigureÂ 1.5: FenÃªtre principale avec un nouveau script sur R studio\n\n\n\n\nPour transfÃ©rer votre code de votre Ã©diteur de script Ã  la console, placez simplement votre curseur sur la ligne de code, puis cliquez sur le bouton â€œExÃ©cuterâ€ en haut Ã  droite de la fenÃªtre de lâ€™Ã©diteur de script.\n\n\n\n\n\n\n\nFigureÂ 1.6: Bouton â€œExÃ©cuterâ€ sur R studio\n\n\n\n\nVous devriez voir le rÃ©sultat dans la fenÃªtre de la console. Si cliquer sur le bouton â€œExÃ©cuterâ€ devient fastidieux, vous pouvez utiliser le raccourci clavier â€œctrl + entrÃ©eâ€ (sous Windows et Linux) ou â€œcmd + entrÃ©eâ€ (sous Mac). Vous pouvez enregistrer vos scripts R sous la forme dâ€™un fichier .R en sÃ©lectionnant le menu â€œFichierâ€ et en cliquant sur â€œEnregistrerâ€. Notez que le nom du fichier dans lâ€™onglet devient rouge pour vous rappeler que des modifications nâ€™ont pas Ã©tÃ© enregistrÃ©es. Pour ouvrir votre script R dans RStudio, sÃ©lectionnez le menu â€œFichierâ€, puis â€œOuvrir le fichierâ€¦â€. Enfin, il convient de noter que, bien que les scripts R soient enregistrÃ©s avec un nom de fichier .R il sâ€™agit en fait de fichiers texte simples qui peuvent Ãªtre ouverts avec nâ€™importe quel Ã©diteur de texte.\n\n1.2.1.2 Environnement/Histoire/Connexions\nLa fenÃªtre Environnement / Historique / Connexions contient de nombreuses informations utiles. Vous pouvez accÃ©der Ã  chaque composant en cliquant sur lâ€™onglet appropriÃ© dans le volet.\n\nLâ€™onglet â€œEnvironnementâ€ affiche tous les objets que vous avez crÃ©Ã©s dans lâ€™environnement actuel (global). Ces objets peuvent Ãªtre des donnÃ©es que vous avez importÃ©es ou des fonctions que vous avez Ã©crites. Les objets peuvent Ãªtre affichÃ©s sous forme de liste ou de grille en sÃ©lectionnant lâ€™option dans le menu dÃ©roulant situÃ© en haut Ã  droite de la fenÃªtre. Si vous utilisez le format Grille, vous pouvez supprimer des objets de lâ€™environnement en cochant la case vide situÃ©e Ã  cÃ´tÃ© du nom de lâ€™objet, puis en cliquant sur lâ€™icÃ´ne de balai. Il existe Ã©galement un bouton â€œImporter un ensemble de donnÃ©esâ€ qui permet dâ€™importer des donnÃ©es sauvegardÃ©es dans diffÃ©rents formats de fichiers. Cependant, nous vous conseillons de ne pas utiliser cette approche pour importer vos donnÃ©es car elle nâ€™est pas reproductible et donc pas robuste (voir Chapitre 3 pour plus de dÃ©tails).\nLâ€™onglet â€œHistoriqueâ€ contient une liste de toutes les commandes que vous avez saisies dans la console R. Vous pouvez rechercher dans votre historique la ligne de code que vous avez oubliÃ©e, renvoyer le code sÃ©lectionnÃ© dans la Console ou dans la fenÃªtre Source. En gÃ©nÃ©ral, nous nâ€™utilisons jamais cette fonction car nous nous rÃ©fÃ©rons toujours Ã  notre script R.\nLâ€™onglet â€œConnexionsâ€ vous permet de vous connecter Ã  diverses sources de donnÃ©es telles que des bases de donnÃ©es externes.\n\n1.2.1.3 Fichiers/Graphiques/Paquets/Aide/Visualiseur\n\nLâ€™onglet â€œFichiersâ€ rÃ©pertorie tous les fichiers et rÃ©pertoires externes dans le rÃ©pertoire de travail actuel de votre ordinateur. Il fonctionne comme lâ€™explorateur de fichiers (Windows) ou le Finder (Mac). Vous pouvez ouvrir, copier, renommer, dÃ©placer et supprimer les fichiers rÃ©pertoriÃ©s dans la fenÃªtre.\nLâ€™onglet â€œGraphiquesâ€ est lâ€™endroit oÃ¹ tous les graphiques que vous crÃ©ez dans R sont affichÃ©s (sauf indication contraire de votre part). Vous pouvez â€œzoomerâ€ sur les graphiques pour les agrandir Ã  lâ€™aide du bouton loupe et faire dÃ©filer les graphiques crÃ©Ã©s prÃ©cÃ©demment Ã  lâ€™aide des boutons flÃ¨ches. Il est Ã©galement possible dâ€™exporter les graphiques vers un fichier externe Ã  lâ€™aide du menu dÃ©roulant â€œExportationâ€. Les graphiques peuvent Ãªtre exportÃ©s dans diffÃ©rents formats de fichiers tels que jpeg, png, pdf, tiff ou copiÃ©s dans le presse-papiers (bien quâ€™il soit probablement prÃ©fÃ©rable dâ€™utiliser les fonctions R appropriÃ©es pour ce faire - voir Chapitre 4 pour plus de dÃ©tails).\nLâ€™onglet â€œPaquetsâ€ rÃ©pertorie tous les paquets que vous avez installÃ©s sur votre ordinateur. Vous pouvez Ã©galement installer de nouveaux paquets et mettre Ã  jour les paquets existants en cliquant respectivement sur les boutons â€œInstallerâ€ et â€œMettre Ã  jourâ€.\nLâ€™onglet â€œAideâ€ affiche la documentation dâ€™aide R pour chaque fonction. Nous verrons comment consulter les fichiers dâ€™aide et comment rechercher de lâ€™aide dans le Chapitre 2).\nLâ€™onglet â€œVisualiseurâ€ affiche le contenu web local tel que les graphiques web gÃ©nÃ©rÃ©s par certains packages.\n\n1.2.2 VSCode\n\n\n\n\n\n\n\nFigureÂ 1.7: AperÃ§u de la fenÃªtre VSCode\n\n\n\n\n\n1.2.2.1 Panneau gauche\nContient :\n\nGestionnaire de fichiers et aperÃ§u des fichiers\nSupport R incluant lâ€™environnement R / la recherche R / lâ€™aide R / lâ€™installation de paquets\nInteraction avec Github\n\n\n\n\n\n\n\n\n\n\n(a) volet des fichiers\n\n\n\n\n\n\n\n\n\n(b) volet git\n\n\n\n\n\n\n\n\n\n(c) Volet R\n\n\n\n\n\n\nFigureÂ 1.8: Panneau de gauche VS Code\n\n\n\n1.2.2.2 Onglets de lâ€™Ã©diteur\nComprend :\n\nUn onglet de graphiques (avec historique et navigation)\nUn Ã©diteur de scripts\nUn panneaux de prÃ©visualisation\n\n\n\n\n\n\n\n\nFigureÂ 1.9: Onglet dâ€™Ã©dition et panneaux de prÃ©visualisation VSCode\n\n\n\n\n\n1.2.2.3 FenÃªtre du terminal\nContient :\n\nLe terminal permettant dâ€™avoir une session R ou tout autre type de terminal nÃ©cessaire (bash/tmux/). Il peut Ãªtre divisÃ© et exÃ©cuter plusieurs sessions en mÃªme temps.\nUn panneau de problÃ¨mes mettant en Ã©vidence les problÃ¨mes de grammaire et de codage\n\n\n\n\n\n\n\n\nFigureÂ 1.10: FenÃªtre du terminal VSCode",
    "crumbs": [
      "DonnÃ©es",
      "Utiliser R",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Pour commencer</span>"
    ]
  },
  {
    "objectID": "01-debut.html#sec-work-d",
    "href": "01-debut.html#sec-work-d",
    "title": "1Â  Pour commencer",
    "section": "\n1.3 RÃ©pertoires de travail",
    "text": "1.3 RÃ©pertoires de travail\nLe rÃ©pertoire de travail est lâ€™emplacement par dÃ©faut oÃ¹ R cherchera les fichiers que vous souhaitez charger et oÃ¹ il placera tous les fichiers que vous enregistrez. Lâ€™un des avantages de lâ€™utilisation des projets RStudio est que lorsque vous ouvrez un projet, il dÃ©finit automatiquement votre rÃ©pertoire de travail Ã  lâ€™emplacement appropriÃ©. Vous pouvez vÃ©rifier le chemin dâ€™accÃ¨s de votre rÃ©pertoire de travail en utilisant lâ€™une des mÃ©thodes suivantes getwd() ou here() fonctions.\n\ngetwd()\n\n[1] \"/home/julien/Documents/courses/biostats/livre/enfR\"\n\n\nDans lâ€™exemple ci-dessus, le rÃ©pertoire de travail est un dossier appelÃ© â€œR_wayâ€ qui est un sous-dossier de â€œbiostatsâ€ dans le dossier â€œcoursesâ€ qui lui-mÃªme se trouve dans un dossier â€œDocumentsâ€ situÃ© dans le dossier â€œjulienâ€ qui lui-mÃªme se trouve dans le dossier â€œhomeâ€. Sur un ordinateur fonctionnant sous Windows, notre rÃ©pertoire de travail comprendrait Ã©galement une lettre de lecteur (c.-Ã -d.Â C:\\home\\julien\\Documents\\courses\\biostats\\R_way).\nSi vous nâ€™utilisez pas dâ€™IDE, vous devez dÃ©finir votre rÃ©pertoire de travail Ã  lâ€™aide de la commande setwd() au dÃ©but de chaque script R (ce que nous avons fait pendant de nombreuses annÃ©es).\n\nsetwd(\"/home/julien/Documents/courses/biostats/R_way/\")\n\nCependant, le problÃ¨me avec setwd() est quâ€™il utilise un chemin dâ€™accÃ¨s absolue spÃ©cifique Ã  lâ€™ordinateur sur lequel vous travaillez. Si vous souhaitez envoyer votre script Ã  quelquâ€™un dâ€™autre (ou si vous travaillez sur un autre ordinateur), ce chemin dâ€™accÃ¨s absolu ne fonctionnera pas sur lâ€™ordinateur de votre ami/collÃ¨gue, car la configuration de ses rÃ©pertoires sera diffÃ©rente (il est peu probable que vous ayez une structure de rÃ©pertoires /home/julien/Documents/courses/biostats/ sur votre ordinateur). Il en rÃ©sulte un projet qui nâ€™est pas autonome et qui nâ€™est pas facilement transportable. Les IDE rÃ©solvent ce problÃ¨me en vous permettant dâ€™utiliser des fichiers relatif qui sont relatifs au chemin dâ€™accÃ¨s au fichier racine du projet. Le fichier racine du projet est simplement le rÃ©pertoire qui contient le fichier .Rproj dans Rstudio (first_project.Rproj dans notre cas) ou le dossier de base de votre espace de travail dans VScode. Si vous souhaitez partager vos analyses avec quelquâ€™un dâ€™autre, il vous suffit de copier le rÃ©pertoire complet du projet et de lâ€™envoyer Ã  votre collaborateur. Il lui suffira alors dâ€™ouvrir le fichier du projet et tous les scripts R qui contiennent des rÃ©fÃ©rences Ã  des chemins dâ€™accÃ¨s relatifs fonctionneront. Par exemple, disons que vous avez crÃ©Ã© un sous-rÃ©pertoire appelÃ© data dans votre rÃ©pertoire de projet racine, qui contient un fichier dÃ©limitÃ© au format csv appelÃ© mydata.csv (nous aborderons les structures de rÃ©pertoire plus loin dans Section 1.4). Pour importer ce fichier dans un projet RStudio Ã  lâ€™aide de la commande read.csv() (ne vous en prÃ©occupez pas pour lâ€™instant, nous aborderons cette question plus en dÃ©tail dans Chapitre 3), tout ce que vous devez inclure dans votre script R est\ndat &lt;- read.csv(\"data/mydata.csv\")\nParce que le chemin du fichier data/mydata.csv est relatif au rÃ©pertoire du projet, peu importe oÃ¹ votre collaborateur enregistre le rÃ©pertoire du projet sur son ordinateur, cela fonctionnera toujours.\nSi vous nâ€™utilisez pas un projet RStudio ou un espace de travail VScode, vous devrez soit dÃ©finir le rÃ©pertoire de travail en fournissant le chemin complet de votre rÃ©pertoire, soit spÃ©cifier le chemin complet du fichier de donnÃ©es. Aucune de ces deux options nâ€™est reproductible sur dâ€™autres ordinateurs.\nsetwd(\"/home/julien/Documents/courses/biostats/R_way\")\n\ndat &lt;- read.csv(\"data/mydata.csv\")\nou\ndat &lt;- read.csv(\"/home/julien/Documents/courses/biostats/R_way/data/mydata.csv\")\nPour ceux dâ€™entre vous qui souhaitent pousser plus loin la notion de chemins dâ€™accÃ¨s relatifs aux fichiers, jetez un coup dâ€™Å“il Ã  la fonction here() du paquet here ğŸ“¦. La fonction here() vous permet de crÃ©er des chemins dâ€™accÃ¨s pour nâ€™importe quel fichier par rapport au rÃ©pertoire racine du projet, qui ne dÃ©pendent pas du systÃ¨me dâ€™exploitation (fonctionne sur une machine Mac, Windows ou Linux). Par exemple, pour importer notre mydata.csv Ã  partir du rÃ©pertoire data il suffit dâ€™utiliser :\nlibrary(here) # il se peut que vous deviez d'abord installer le paquet 'here'\ndat &lt;- read.csv(here(\"data\", \"mydata.csv\"))",
    "crumbs": [
      "DonnÃ©es",
      "Utiliser R",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Pour commencer</span>"
    ]
  },
  {
    "objectID": "01-debut.html#sec-dir-struc",
    "href": "01-debut.html#sec-dir-struc",
    "title": "1Â  Pour commencer",
    "section": "\n1.4 Structure du rÃ©pertoire",
    "text": "1.4 Structure du rÃ©pertoire\nOutre lâ€™utilisation de RStudio Projects, il est Ã©galement conseillÃ© de structurer votre rÃ©pertoire de travail de maniÃ¨re cohÃ©rente et logique afin de vous aider, vous et vos collaborateurs. Nous utilisons frÃ©quemment la structure de rÃ©pertoire suivante dans nos projets basÃ©s sur R.\n\n\n\n\n\nroot\nracinedot01\nroot-&gt;dot01\ndot1\nroot-&gt;dot1\ndata\ndonnÃ©esdot21\ndata-&gt;dot21\nfunctions\nfonctionsdot22\nfunctions-&gt;dot22\noutputs\nsortiedot23\noutputs-&gt;dot23\nscripts\nscriptsdot24\nscripts-&gt;dot24\nwd\nvotre rÃ©pertoire de travailLOT1\nmÃ©tadonnÃ©es brutes traitÃ©eLOT2\nfonctions RLOT4\nscripts d'analyses documents R markdownLOT3\npdf html figuresdot01-&gt;wd\ndot1-&gt;data\ndot2\ndot1-&gt;dot2\ndot2-&gt;functions\ndot3\ndot2-&gt;dot3\ndot3-&gt;outputs\ndot4\ndot3-&gt;dot4\ndot4-&gt;scripts\ndot21-&gt;LOT1\ndot22-&gt;LOT2\ndot23-&gt;LOT3\ndot24-&gt;LOT4\n\n\n\n\nFigureÂ 1.11: Structure de rÃ©pertoire recommandÃ©e pour des analyses sur R\n\n\n\n\nDans notre rÃ©pertoire de travail, nous avons les rÃ©pertoires suivants :\n\nRacine - Il sâ€™agit du rÃ©pertoire de votre projet contenant votre fichier .Rproj. Nous avons tendance Ã  garder tous les scripts R ou [Rq]md nÃ©cessaires Ã  lâ€™analyse/au rapport dans ce dossier racine ou dans le dossier scripts sâ€™il y en a trop.\ndonnÃ©es - Nous stockons toutes nos donnÃ©es dans ce rÃ©pertoire. Le sous-rÃ©pertoire appelÃ© donnÃ©es contient des fichiers de donnÃ©es brutes et uniquement des fichiers de donnÃ©es brutes. Ces fichiers doivent Ãªtre traitÃ©s comme sâ€™ils Ã©taient en lecture seule et ne doivent en aucun cas Ãªtre modifiÃ©s. Si vous devez traiter/nettoyer/modifier vos donnÃ©es, faites-le dans R (et non dans MS Excel), car vous pourrez documenter (et justifier) toutes les modifications apportÃ©es. Toutes les donnÃ©es traitÃ©es doivent Ãªtre sauvegardÃ©es dans un fichier sÃ©parÃ© et stockÃ©es dans le fichier donnÃ©es_traitÃ©es . Les informations sur les mÃ©thodes de collecte des donnÃ©es, les dÃ©tails du tÃ©lÃ©chargement des donnÃ©es et toute autre mÃ©tadonnÃ©e utile doivent Ãªtre sauvegardÃ©s dans un document texte (voir les fichiers README ci-dessous) dans le sous-rÃ©pertoire meta_donnÃ©es.\nfonctions - Il sâ€™agit dâ€™un rÃ©pertoire facultatif dans lequel nous enregistrons toutes les fonctions R personnalisÃ©es que nous avons Ã©crites pour lâ€™analyse en cours. Celles-ci peuvent ensuite Ãªtre importÃ©es dans R Ã  lâ€™aide de la fonction source().\nscripts - Un rÃ©pertoire optionnel oÃ¹ nous enregistrons nos documents R markdown et/ou les principaux scripts R que nous avons Ã©crits pour le projet en cours. Ces documents ne sont pas enregistrÃ©s dans le dossier racine.\nsortie - Les rÃ©sultats de nos scripts R, tels que les graphiques, les fichiers HTML et les rÃ©sumÃ©s de donnÃ©es, sont enregistrÃ©s dans ce rÃ©pertoire. Cela nous aide, ainsi que nos collaborateurs, Ã  distinguer les fichiers qui sont des sorties de ceux qui sont des fichiers sources.\n\nBien entendu, la structure dÃ©crite ci-dessus est celle qui nous convient le mieux la plupart du temps et doit Ãªtre considÃ©rÃ©e comme un point de dÃ©part pour vos propres besoins. Nous avons tendance Ã  avoir une structure de rÃ©pertoires assez cohÃ©rente dans tous nos projets, car cela nous permet de nous orienter rapidement lorsque nous revenons Ã  un projet aprÃ¨s un certain temps. Cela dit, les besoins varient dâ€™un projet Ã  lâ€™autre et nous ajoutons ou supprimons des rÃ©pertoires en fonction des besoins.\nVous pouvez crÃ©er votre structure de rÃ©pertoire Ã  lâ€™aide de lâ€™explorateur Windows (ou Finder sur Mac) ou dans votre IDE en cliquant sur le bouton â€œNouveau dossierâ€ dans le panneau â€œFichiersâ€.\nUne autre approche est dâ€™utiliser la fonction dir.create() dans la console R.\n# crÃ©er un rÃ©pertoire appelÃ© 'donnÃ©es'\ndir.create(\"donnÃ©es\")",
    "crumbs": [
      "DonnÃ©es",
      "Utiliser R",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Pour commencer</span>"
    ]
  },
  {
    "objectID": "01-debut.html#sec-rsprojs",
    "href": "01-debut.html#sec-rsprojs",
    "title": "1Â  Pour commencer",
    "section": "\n1.5 Organisation des projets",
    "text": "1.5 Organisation des projets\nComme pour la plupart des choses de la vie, lorsquâ€™il sâ€™agit de traiter des donnÃ©es et de les analyser, les choses sont tellement plus simples si vous Ãªtes organisÃ©. Une organisation claire du projet permet Ã  la fois Ã  vous (et surtout au futur vous) et Ã  vos collaborateurs de donner un sens Ã  ce que vous avez fait. Il nâ€™y a rien de plus frustrant que de revenir Ã  un projet des mois (parfois des annÃ©es) plus tard et de devoir passer des jours (ou des semaines) Ã  comprendre oÃ¹ tout se trouve, ce que vous avez fait et pourquoi vous lâ€™avez fait. Un projet bien documentÃ©, dotÃ© dâ€™une structure cohÃ©rente et logique, augmente les chances de pouvoir reprendre le projet lÃ  oÃ¹ il sâ€™est arrÃªtÃ© sans trop de difficultÃ©s, quel que soit le temps qui sâ€™est Ã©coulÃ©. En outre, il est beaucoup plus facile dâ€™Ã©crire du code pour automatiser des tÃ¢ches lorsque les fichiers sont bien organisÃ©s et portent des noms judicieux. Cela est dâ€™autant plus vrai maintenant quâ€™il nâ€™a jamais Ã©tÃ© aussi facile de collecter de grandes quantitÃ©s de donnÃ©es qui peuvent Ãªtre sauvegardÃ©es dans des milliers, voire des centaines de milliers de fichiers de donnÃ©es distincts. Enfin, un projet bien organisÃ© rÃ©duit le risque dâ€™introduire des bogues ou des erreurs dans votre flux de travail et, sâ€™ils se produisent (ce qui est inÃ©vitable Ã  un moment ou Ã  un autre), il est plus facile de retrouver ces erreurs et de les traiter efficacement.\nIl existe Ã©galement quelques mesures simples que vous pouvez prendre dÃ¨s le dÃ©but dâ€™un projet pour aider Ã  maintenir les choses en bon Ã©tat.\nUn bon moyen de garder les choses organisÃ©es est dâ€™utiliser les projets RStudio ou les espaces de travail VSCode, dÃ©signÃ©s sous le nom de projet. Un projet conserve tous vos scripts R, vos documents R markdown, vos fonctions R et vos donnÃ©es en un seul endroit. Ce quâ€™il y a de bien avec un projet est que chacun a son propre rÃ©pertoire, son propre historique et ses propres documents sources, de sorte que les diffÃ©rentes analyses sur lesquelles vous travaillez sont complÃ¨tement sÃ©parÃ©es les unes des autres. Cela signifie que vous pouvez trÃ¨s facilement passer dâ€™un projet Ã  lâ€™autre sans craindre quâ€™ils nâ€™interfÃ¨rent lâ€™un avec lâ€™autre.\n\n1.5.1 RStudio\nPour crÃ©er un projet, ouvrez RStudio et sÃ©lectionnez Fichier â€“&gt; Nouveau projet... dans le menu. Vous pouvez crÃ©er un projet entiÃ¨rement nouveau, un projet Ã  partir dâ€™un rÃ©pertoire existant ou un projet Ã  version contrÃ´lÃ©e (voir le Chapitre 7 pour plus de dÃ©tails Ã  ce sujet). Dans ce chapitre, nous allons crÃ©er un projet dans un nouveau rÃ©pertoire.\n\n\n\n\n\n\n\nFigureÂ 1.12: CrÃ©er un Projet R Studio Ã©tape 1\n\n\n\n\nVous pouvez Ã©galement crÃ©er un nouveau projet en cliquant sur le bouton â€œProjetâ€ en haut Ã  droite de RStudio et en sÃ©lectionnant â€œNouveau projetâ€¦â€\n\n\n\n\n\n\n\nFigureÂ 1.13: CrÃ©er un Projet R Studio Ã©tape 2\n\n\n\n\nDans la fenÃªtre suivante, sÃ©lectionnez â€œNouveau projetâ€.\n\n\n\n\n\n\n\nFigureÂ 1.14: CrÃ©er un Projet R Studio Ã©tape 3\n\n\n\n\nSaisissez le nom du rÃ©pertoire que vous souhaitez crÃ©er dans le champ â€œNom du rÃ©pertoire :â€ (nous lâ€™appellerons premier_projet pour ce chapitre). Si vous souhaitez modifier lâ€™emplacement du rÃ©pertoire sur votre ordinateur, cliquez sur le bouton â€œParcourirâ€¦â€ et naviguez jusquâ€™Ã  lâ€™endroit oÃ¹ vous souhaitez crÃ©er le rÃ©pertoire. Nous cochons toujours la case â€œOuvrir dans une nouvelle sessionâ€. Enfin, cliquez sur le bouton â€œCrÃ©er un projetâ€ pour crÃ©er le nouveau projet.\n\n\n\n\n\n\n\nFigureÂ 1.15: CrÃ©er un Projet R Studio Ã©tape 4\n\n\n\n\nUne fois votre nouveau projet crÃ©Ã©, vous disposerez dâ€™un nouveau dossier sur votre ordinateur contenant un fichier de projet RStudio appelÃ© premier_projet.Rproj. Ce projet .Rproj contient diverses options de projet (mais vous ne devriez pas vraiment interagir avec lui) et peut Ã©galement Ãªtre utilisÃ© comme raccourci pour ouvrir le projet directement Ã  partir du systÃ¨me de fichiers (il suffit de double-cliquer dessus). Vous pouvez le vÃ©rifier dans lâ€™onglet â€œFichiersâ€ de RStudio (ou dans Finder si vous Ãªtes sur Mac ou dans lâ€™Explorateur de fichiers sous Windows).\n\n\n\n\n\n\n\nFigureÂ 1.16: CrÃ©er un Projet R Studio Ã©tape finale\n\n\n\n\nLa derniÃ¨re chose que nous vous suggÃ©rons de faire est de sÃ©lectionner Outils â€“&gt; Options du Project... dans le menu. Cliquez sur lâ€™onglet â€œGÃ©nÃ©ralâ€ sur le cÃ´tÃ© gauche et modifiez les valeurs pour â€œRestaurer .RData dans lâ€™espace de travail au dÃ©marrageâ€ et â€œSauvegarder lâ€™espace de travail dans .RData Ã  la sortieâ€ de â€œPar dÃ©fautâ€ Ã  â€œNonâ€. Cela garantit que chaque fois que vous ouvrez votre projet, vous dÃ©marrez avec une session R propre. Vous nâ€™Ãªtes pas obligÃ© de faire cela (beaucoup de gens ne le font pas), mais nous prÃ©fÃ©rons commencer avec un espace de travail complÃ¨tement propre chaque fois que nous ouvrons nos projets pour Ã©viter tout conflit potentiel avec des choses que nous avons faites dans des sessions prÃ©cÃ©dentes (ce qui conduit parfois Ã  des rÃ©sultats surprenants et Ã  des maux de tÃªte pour rÃ©soudre le problÃ¨me). Lâ€™inconvÃ©nient est que vous devrez rÃ©exÃ©cuter votre code R Ã  chaque fois que vous ouvrirez votre projet.\n\n\n\n\n\n\n\nFigureÂ 1.17: CrÃ©er un Projet R Studio changement dâ€™options\n\n\n\n\nMaintenant que vous avez mis en place un projet RStudio, vous pouvez commencer Ã  crÃ©er des scripts R (ou des documents R markdown /Quarto, voir Chapitre 6) ou tout ce dont vous avez besoin pour complÃ©ter votre projet. Tous les scripts R seront dÃ©sormais contenus dans le projet RStudio et enregistrÃ©s dans le dossier du projet.\n\n1.5.2 VSCode\nLes espaces de travail sont similaires aux projets RStudio. Vous devez cependant crÃ©er un nouveau dossier avec un fichier R (ou un fichier texte) et lâ€™enregistrer en tant quâ€™espace de travail.",
    "crumbs": [
      "DonnÃ©es",
      "Utiliser R",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Pour commencer</span>"
    ]
  },
  {
    "objectID": "01-debut.html#sec-file-names",
    "href": "01-debut.html#sec-file-names",
    "title": "1Â  Pour commencer",
    "section": "\n1.6 Nom des fichiers",
    "text": "1.6 Nom des fichiers\nLe nom que vous donnez Ã  vos fichiers a plus dâ€™importance que vous ne le pensez. Nommer les fichiers est Ã©galement plus difficile que vous ne le pensez. Pour quâ€™un nom de fichier soit â€œbonâ€, il faut quâ€™il soit informatif et relativement court. Ce nâ€™est pas toujours un compromis facile et il faut souvent y rÃ©flÃ©chir. Lâ€™idÃ©al est dâ€™Ã©viter les Ã©lÃ©ments suivants !\n\n\n\n\n\n\n\nFigureÂ 1.18: File renaming song (source:https://xkcd.com/1459/)\n\n\n\n\nBien quâ€™il nâ€™y ait pas vraiment dâ€™approche standard reconnue pour nommer les fichiers (en fait il y en a une mais tout le monde ne lâ€™utilise pas), il y a quelques points Ã  garder Ã  lâ€™esprit.\n\nÃ‰vitez dâ€™utiliser des espaces dans les noms de fichiers en les remplaÃ§ant par des traits de soulignement ou des tirets. Pourquoi cela est-il important ? Lâ€™une des raisons est que certains logiciels de ligne de commande (en particulier de nombreux outils bioinformatiques) ne reconnaissent pas un nom de fichier comportant un espace et que vous devez vous livrer Ã  toutes sortes de manigances en utilisant des caractÃ¨res dâ€™Ã©chappement pour vous assurer que les espaces sont traitÃ©s correctement. MÃªme si vous ne pensez pas utiliser un jour un logiciel de ligne de commande, il se peut que vous le fassiez indirectement. Prenez R markdown par exemple, si vous voulez rendre un document R markdown au format pdf en utilisant le paquet rmarkdown ğŸ“¦ vous utiliserez en fait une ligne de commande \\(\\LaTeX\\) sous le capot. Une autre bonne raison de ne pas utiliser dâ€™espaces dans les noms de fichiers est que cela rend la recherche de noms de fichiers (ou de parties de noms de fichiers) Ã  lâ€™aide dâ€™expressions rÃ©guliÃ¨res dans R (ou tout autre langage) beaucoup plus difficile.\nÃ‰vitez dâ€™utiliser des caractÃ¨res spÃ©ciaux (par exemple @Â£$%^&*(:/)) dans vos noms de fichiers.\nSi vous crÃ©ez des versions de vos fichiers Ã  lâ€™aide de nombres sÃ©quentiels (par ex. fichier1, fichier2, fichier3 â€¦). Si vous prÃ©voyez dâ€™avoir plus de 9 fichiers, vous devez utiliser 01, 02, 03, â€¦, 10 afin de garantir que les fichiers soient listÃ©s dans le bon ordre. Si vous prÃ©voyez dâ€™avoir plus de 99 fichiers, utilisez 001, 002, 003, â€¦.\nPour les dates, utilisez le format ISO 8601 AAAA-MM-JJ (ou AAAAMMJJ) afin de vous assurer que vos fichiers sont listÃ©s dans un ordre chronologique correct.\nNâ€™utilisez jamais le mot final dans un nom de fichier - il est extrÃªmement rare quâ€™il le soit !\n\nQuelle que soit la convention de dÃ©nomination des fichiers que vous dÃ©cidez dâ€™utiliser, essayez de lâ€™adopter rapidement, de vous y tenir et dâ€™Ãªtre cohÃ©rent.",
    "crumbs": [
      "DonnÃ©es",
      "Utiliser R",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Pour commencer</span>"
    ]
  },
  {
    "objectID": "01-debut.html#sec-proj-doc",
    "href": "01-debut.html#sec-proj-doc",
    "title": "1Â  Pour commencer",
    "section": "\n1.7 Documentation du script",
    "text": "1.7 Documentation du script\nUn petit mot sur lâ€™Ã©criture du code R et la crÃ©ation de scripts R. Ã€ moins que vous ne fassiez quelque chose de vraiment rapide et sale, nous vous suggÃ©rons de toujours Ã©crire votre code R sous la forme dâ€™un script R. Les scripts R sont ce qui permet Ã  R dâ€™Ãªtre plus efficace. Les scripts R sont ce qui rend R si utile. Non seulement vous disposez dâ€™un enregistrement complet de votre analyse, de la manipulation des donnÃ©es Ã  la visualisation et Ã  lâ€™analyse statistique, mais vous pouvez Ã©galement partager ce code (et ces donnÃ©es) avec vos amis, vos collÃ¨gues et, surtout, lorsque vous soumettez et publiez votre recherche dans une revue. Dans cette optique, veillez Ã  inclure dans votre script R toutes les informations nÃ©cessaires pour rendre votre travail reproductible (noms des auteurs, dates, plan dâ€™Ã©chantillonnage, etc.). Ces informations peuvent Ãªtre incluses sous la forme dâ€™une sÃ©rie de commentaires # ou, mieux encore, en mÃ©langeant code exÃ©cutable et narration dans un document R markdown (Chapitre 6). Câ€™est aussi une bonne pratique dâ€™inclure la sortie de la fonction sessionInfo() Ã  la fin de nâ€™importe quel script qui affiche la version de R, les dÃ©tails du systÃ¨me dâ€™exploitation et les paquets chargÃ©s. Une trÃ¨s bonne alternative est dâ€™utiliser la fonction session_info() du paquet xfun ğŸ“¦ pour un rÃ©sumÃ© plus concis de notre environnement de session.\nVoici un exemple dâ€™inclusion de mÃ©ta-informations au dÃ©but dâ€™un script R\n# Titre: Analyse de sÃ©ries temporelles de consommation de lasagnes\n\n# Objectif : Ce script effectue une analyse de sÃ©rie temporelle sur\n#           les plats de lasagnes que les enfants veulent manger chaque semaine.\n#           Les donnÃ©es sont des dÃ©nombrements de plats de lasagnes (rÃªvÃ©s) par semaine\n#           collectÃ©s Ã  partir de 24 enfants Ã  l'Ã©cole \"Repas-de-rÃªve\"\n#           entre 2042 et 2056.\n\n# fichier de donnÃ©es: lasagna_dreams.csv\n\n# Auteur: Un. Estomac\n# CoordonnÃ©es de contact: un.estomac@univ.repas.com\n\n# Date de crÃ©ation du script: Fri Mar 29 17:06:44 2010 -----------------\n# Date de derniÃ¨re modification du script: Wed Sep 18 12:14:18 2024 ----\n\n# paquets chargÃ©s\nlibrary(tidyverse)\nlibrary(ggplot2)\n\nprint(\"Ã©crivez votre merveilleux code R ici\")\n\n# bonne pratique pour inclure des informations sur la session\n\nxfun::session_info()\nIl ne sâ€™agit que dâ€™un exemple et il nâ€™y a pas de rÃ¨gles strictes, alors nâ€™hÃ©sitez pas Ã  dÃ©velopper un systÃ¨me qui vous convienne. Un raccourci trÃ¨s utile dans RStudio est dâ€™inclure automatiquement un horodatage dans votre script R. Pour ce faire, Ã©crivez ts Ã  lâ€™endroit oÃ¹ vous souhaitez insÃ©rer votre horodatage dans votre script R, puis appuyez sur les touches â€˜shift + tabâ€™. RStudio convertira ts en date et heure actuelles et commentera automatiquement cette ligne avec un #. Un autre raccourci trÃ¨s utile de RStudio consiste Ã  commenter plusieurs lignes de votre script avec le symbole #. Pour ce faire, sÃ©lectionnez les lignes de texte que vous souhaitez commenter et appuyez sur â€˜ctrl + shift + câ€™ (ou â€˜cmd + shift + câ€™ sur un mac). Pour dÃ©commenter les lignes, utilisez Ã  nouveau â€˜ctrl + shift + câ€™.\nEn plus dâ€™inclure des mÃ©tadonnÃ©es dans vos scripts R, il est Ã©galement courant de crÃ©er un fichier texte sÃ©parÃ© pour enregistrer les informations importantes. Par convention, ces fichiers texte sont nommÃ©s README. Nous incluons souvent un fichier README dans le rÃ©pertoire oÃ¹ nous conservons nos donnÃ©es brutes. Dans ce fichier, nous indiquons la date Ã  laquelle les donnÃ©es ont Ã©tÃ© collectÃ©es (ou tÃ©lÃ©chargÃ©es), la maniÃ¨re dont elles ont Ã©tÃ© collectÃ©es, des informations sur lâ€™Ã©quipement spÃ©cialisÃ©, les mÃ©thodes de conservation, le type et la version des machines utilisÃ©es (câ€™est-Ã -dire lâ€™Ã©quipement de sÃ©quenÃ§age), etc. Vous pouvez crÃ©er un fichier README pour votre projet dans RStudio en cliquant sur le menu Fichier â€“&gt; Nouveau fichier â€“&gt; Fichier texte.",
    "crumbs": [
      "DonnÃ©es",
      "Utiliser R",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Pour commencer</span>"
    ]
  },
  {
    "objectID": "01-debut.html#guide-de-style-r",
    "href": "01-debut.html#guide-de-style-r",
    "title": "1Â  Pour commencer",
    "section": "\n1.8 Guide de style R",
    "text": "1.8 Guide de style R\nLa faÃ§on dont vous Ã©crivez votre code dÃ©pend plus ou moins de vous, bien que votre objectif soit de le rendre aussi facile Ã  lire que possible (pour vous et pour les autres). Bien quâ€™il nâ€™y ait pas de rÃ¨gles (ni de police du code), nous vous encourageons Ã  prendre lâ€™habitude dâ€™Ã©crire un code R lisible en adoptant un style particulier. Nous vous suggÃ©rons de suivre le R style guide de Google dans la mesure du possible. Ce guide de style vous aidera Ã  dÃ©cider oÃ¹ utiliser les espaces, comment indenter le code et comment utiliser les crochets [ ] et les parenthÃ¨ses bouclÃ©es { }, entre autres choses.\nPour vous aider Ã  formater le code :\n\nVSCode il y a un formateur intÃ©grÃ© dans lâ€™extension R pour VSCode. Il vous suffit dâ€™utiliser le raccourci clavier pour reformater le code de maniÃ¨re agrÃ©able et automatique.\nPour RStudio, vous pouvez installer le paquet styler ğŸ“¦ qui inclut une extension RStudio vous permettant de reformater automatiquement le code sÃ©lectionnÃ© (ou des fichiers et projets entiers) dâ€™un simple clic de souris. Vous pouvez trouver plus dâ€™informations sur le paquet styler ğŸ“¦, y compris comment lâ€™installer ici . Une fois installÃ©, vous pouvez sÃ©lectionner le code que vous souhaitez remodeler, cliquer sur le bouton â€œExtensionâ€ en haut de RStudio et sÃ©lectionner lâ€™option â€œStyle Selectionâ€. Voici un exemple de code R mal formatÃ©\n\n\n\n\n\n\n\n\nFigureÂ 1.19: Code mal formatÃ©\n\n\n\n\nMettez maintenant le code en surbrillance et utilisez le paquet styler ğŸ“¦ pour reformater\n\n\n\n\n\n\n\nFigureÂ 1.20: Structurer le code avec styler\n\n\n\n\nPour produire un code joliment formatÃ©\n\n\n\n\n\n\n\nFigureÂ 1.21: Code bien structurÃ©",
    "crumbs": [
      "DonnÃ©es",
      "Utiliser R",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Pour commencer</span>"
    ]
  },
  {
    "objectID": "01-debut.html#sauvegarde-des-projets",
    "href": "01-debut.html#sauvegarde-des-projets",
    "title": "1Â  Pour commencer",
    "section": "\n1.9 Sauvegarde des projets",
    "text": "1.9 Sauvegarde des projets\nNe soyez pas la personne qui perd des donnÃ©es et des analyses durement acquises (et souvent coÃ»teuses). Ne soyez pas cette personne qui pense que cela ne mâ€™arrivera jamais - Ã§a vous arrivera ! Pensez toujours au pire scÃ©nario, Ã  quelque chose qui vous donnera des sueurs froides la nuit, et faites tout ce qui est en votre pouvoir pour que cela nâ€™arrive jamais. Pour Ãªtre clair, si vous comptez copier vos prÃ©cieux fichiers sur un disque dur externe ou une clÃ© USB, ce nâ€™est PAS une stratÃ©gie de sauvegarde efficace. Ces objets tombent souvent en panne lorsque vous les glissez dans votre sac Ã  dos ou votre â€œsac de tous les joursâ€ et que vous les trimballez entre votre bureau et votre domicile. MÃªme si vous les laissez branchÃ©s sur votre ordinateur, que se passe-t-il lorsque le bÃ¢timent brÃ»le (nous avons bien dit le pire des cas !)?\nIdÃ©alement, vos sauvegardes devraient Ãªtre hors site et incrÃ©mentielles. Heureusement, il existe de nombreuses options pour sauvegarder vos fichiers. La premiÃ¨re chose Ã  faire est de chercher dans votre propre institut. La plupart (toutes ?) des universitÃ©s disposent dâ€™une forme de stockage en rÃ©seau qui devrait Ãªtre facilement accessible et qui est Ã©galement Ã©tayÃ©e par un plan complet de reprise aprÃ¨s sinistre. Dâ€™autres options incluent des services basÃ©s sur le cloud tels que Google Drive et Dropbox (pour nâ€™en citer que quelques-uns), mais assurez-vous que vous ne stockez pas de donnÃ©es sensibles sur ces services et que vous Ãªtes Ã  lâ€™aise avec les politiques de confidentialitÃ© souvent exorbitantes.\nSi ces services sont trÃ¨s efficaces pour stocker des fichiers, ils ne sont pas vraiment utiles pour les sauvegardes incrÃ©mentielles. Pour retrouver les versions prÃ©cÃ©dentes des fichiers, il faut souvent passer un temps fou Ã  parcourir plusieurs fichiers nommÃ©s â€˜final.docâ€™, â€˜final_v2.docâ€™ et â€˜final_utiliseceluila.docâ€™ etc. jusquâ€™Ã  ce que vous trouviez celui que vous cherchiez. Le meilleur moyen que nous connaissons pour sauvegarder des fichiers et gÃ©rer diffÃ©rentes versions de fichiers est dâ€™utiliser Git et GitHub. Pour en savoir plus sur la faÃ§on dont vous pouvez utiliser RStudio, Git et GitHub ensemble, consultez Chapitre 7.",
    "crumbs": [
      "DonnÃ©es",
      "Utiliser R",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Pour commencer</span>"
    ]
  },
  {
    "objectID": "01-debut.html#citer-r-et-les-paquets-r",
    "href": "01-debut.html#citer-r-et-les-paquets-r",
    "title": "1Â  Pour commencer",
    "section": "\n1.10 Citer R et les paquets R",
    "text": "1.10 Citer R et les paquets R\nDe nombreuses personnes ont investi Ã©normÃ©ment de temps et dâ€™Ã©nergie pour faire de R lâ€™excellent logiciel que vous utilisez aujourdâ€™hui. Si vous utilisez R dans votre travail (et nous espÃ©rons que vous le ferez), nâ€™oubliez pas de citer non seulement R, mais aussi tous les paquets que vous avez utilisÃ©s. Pour obtenir la citation la plus rÃ©cente pour R, vous pouvez utiliser la fonction citation().\n\ncitation()\n\nTo cite R in publications use:\n\n  R Core Team (2024). _R: A Language and Environment for Statistical\n  Computing_. R Foundation for Statistical Computing, Vienna, Austria.\n  &lt;https://www.R-project.org/&gt;.\n\nA BibTeX entry for LaTeX users is\n\n  @Manual{,\n    title = {R: A Language and Environment for Statistical Computing},\n    author = {{R Core Team}},\n    organization = {R Foundation for Statistical Computing},\n    address = {Vienna, Austria},\n    year = {2024},\n    url = {https://www.R-project.org/},\n  }\n\nWe have invested a lot of time and effort in creating R, please cite it\nwhen using it for data analysis. See also 'citation(\"pkgname\")' for\nciting R packages.\n\n\nSi vous souhaitez citer un package particulier que vous avez utilisÃ© pour votre analyse de donnÃ©es, vous pouvez Ã©galement utiliser la fonction citation() pour obtenir lâ€™information.\n\ncitation(package = \"here\")\n\nTo cite package 'here' in publications use:\n\n  MÃ¼ller K (2020). _here: A Simpler Way to Find Your Files_. R package\n  version 1.0.1, &lt;https://CRAN.R-project.org/package=here&gt;.\n\nA BibTeX entry for LaTeX users is\n\n  @Manual{,\n    title = {here: A Simpler Way to Find Your Files},\n    author = {Kirill MÃ¼ller},\n    year = {2020},\n    note = {R package version 1.0.1},\n    url = {https://CRAN.R-project.org/package=here},\n  }\n\n\nSelon nous, lâ€™outil le plus utile pour la citation est le paquet grateful ğŸ“¦ qui vous permet de gÃ©nÃ©rer les informations de citation dans un fichier, ainsi que de crÃ©er une phrase ou un tableau citant tous les paquets utilisÃ©s. Cela devrait devenir la norme dans tout manuscrit honnÃªtement. Voir TableÂ 1 pour un exemple de rÃ©sultat produit avec grateful.",
    "crumbs": [
      "DonnÃ©es",
      "Utiliser R",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Pour commencer</span>"
    ]
  },
  {
    "objectID": "02-base.html",
    "href": "02-base.html",
    "title": "2Â  Quelques notions de base sur R",
    "section": "",
    "text": "2.1 ConsidÃ©rations importantes\nLes captures dâ€™Ã©crans prÃ©sentÃ©es proviennent de RStudio mais tout est trÃ¨s similaire sur VSCode.\nAvant de poursuivre, quelques points Ã  garder Ã  lâ€™esprit tout au long de ce chapitre :",
    "crumbs": [
      "DonnÃ©es",
      "Utiliser R",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Quelques notions de base sur R</span>"
    ]
  },
  {
    "objectID": "02-base.html#considÃ©rations-importantes",
    "href": "02-base.html#considÃ©rations-importantes",
    "title": "2Â  Quelques notions de base sur R",
    "section": "",
    "text": "R est sensible Ã  la casse, câ€™est-Ã -dire que A nâ€™est pas la mÃªme chose que a et anova, ce nâ€™est pas Anova.\nTout ce qui suit un # est interprÃ©tÃ© comme un commentaire et ignorÃ© par R. Ces commentaires doivent Ãªtre utilisÃ©s librement dans votre code, Ã  la fois pour votre propre information et pour aider vos collaborateurs. Lâ€™Ã©criture de commentaires est un peu un art que vous maÃ®triserez de mieux en mieux avec lâ€™expÃ©rience.\nDans R, les commandes sont gÃ©nÃ©ralement sÃ©parÃ©es par une nouvelle ligne. Vous pouvez Ã©galement utiliser un point-virgule ; pour sÃ©parer vos commandes, mais nous vous le dÃ©conseillons fortement (rend le code trÃ¨s difficilement lisible).\nSi une invite de continuation + apparaÃ®t dans la console aprÃ¨s lâ€™exÃ©cution de votre code, cela signifie que vous nâ€™avez pas terminÃ© votre code correctement. Cela se produit souvent lorsque vous oubliez de fermer une parenthÃ¨se, ce qui est particuliÃ¨rement frÃ©quent lors que lâ€™on utilise des parenthÃ¨ses imbriquÃ©es ((((commande quelconque))). Terminez simplement la commande sur la nouvelle ligne ou appuyez sur la touche â€œescapeâ€ de votre clavier (voir le point ci-dessous) et corrigez la faute de frappe.\nEn gÃ©nÃ©ral, R est assez tolÃ©rant vis-Ã -vis des espaces supplÃ©mentaires insÃ©rÃ©s dans votre code, en fait lâ€™utilisation dâ€™espaces est activement encouragÃ©e. Cependant, les espaces ne doivent pas Ãªtre insÃ©rÃ©s dans les opÃ©rateurs, câ€™est-Ã -dire &lt;- ne peut pas sâ€™Ã©crire &lt; - (notez lâ€™espace). Voir le guide de style pour savoir oÃ¹ placer les espaces afin de rendre votre code plus lisible.\nSi votre console se bloque et ne rÃ©pond plus aprÃ¨s lâ€™exÃ©cution dâ€™une commande, vous pouvez souvent vous sortir dâ€™affaire en appuyant sur la touche â€œescapeâ€ (esc) de votre clavier ou en cliquant sur lâ€™icÃ´ne dâ€™arrÃªt/stop en haut Ã  droite de votre console. Cela mettra fin Ã  la plupart des opÃ©rations en cours.",
    "crumbs": [
      "DonnÃ©es",
      "Utiliser R",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Quelques notions de base sur R</span>"
    ]
  },
  {
    "objectID": "02-base.html#premiÃ¨re-Ã©tape-dans-la-console",
    "href": "02-base.html#premiÃ¨re-Ã©tape-dans-la-console",
    "title": "2Â  Quelques notions de base sur R",
    "section": "\n2.2 PremiÃ¨re Ã©tape dans la console",
    "text": "2.2 PremiÃ¨re Ã©tape dans la console\nDans le Chapitre 1, nous avons appris ce quâ€™Ã©tait la console R la crÃ©ation de scripts et de Projets. Nous avons Ã©galement vu comment Ã©crire votre code R dans un script, puis comment insÃ©rer ce code dans la console pour quâ€™il sâ€™exÃ©cute (si vous avez oubliÃ© comment faire, revenez Ã  la section sur la console (-Section 1.2.1.1) pour vous rafraÃ®chir la mÃ©moire). Le fait dâ€™Ã©crire votre code dans un script signifie que vous aurez un enregistrement permanent de tout ce que vous avez fait (Ã  condition de sauvegarder votre script) et vous permet Ã©galement de faire de nombreux commentaires pour vous rappeler ce que vous aviez fait (ou voulu faire) quand vous retournerez si votre code Ã  lâ€™avenir. Ainsi, pendant que vous travaillez sur ce chapitre, nous vous suggÃ©rons de crÃ©er un nouveau script (ou un Projet Rstudio) pour Ã©crire votre code au fur et Ã  mesure.\nComme nous lâ€™avons vu au Chapitre 1, nous pouvons utiliser R de la mÃªme maniÃ¨re quâ€™une calculatrice. Nous pouvons saisir une expression arithmÃ©tique dans notre script, puis lâ€™envoyer dans la console et recevoir un rÃ©sultat. Par exemple, si nous tapons lâ€™expression 1 + 1 et que lâ€™on exÃ©cute cette ligne de code dans la console, on obtient la rÃ©ponse 2 (ğŸ˜ƒ !)\n\n1 + 1\n\n[1] 2\n\n\nLe [1] devant le rÃ©sultat indique que lâ€™observation au dÃ©but de la ligne est la premiÃ¨re. Cela nâ€™est pas trÃ¨s utile dans cet exemple, mais peut lâ€™Ãªtre lors de lâ€™impression de rÃ©sultats sur plusieurs lignes (nous en verrons un exemple ci-dessous). Les autres opÃ©rateurs arithmÃ©tiques Ã©vidents sont -, *, / pour la soustraction, la multiplication et la division respectivement. Pour la multiplication de la matrice, lâ€™opÃ©rateur est %*%.\nR suit la convention mathÃ©matique habituelle de lâ€™ordre des opÃ©rations. Par exemple, lâ€™expression 2 + 3 * 4 est interprÃ©tÃ©e comme ayant la valeur 2 + (3 * 4) = 14 et non (2 + 3) * 4 = 20. Il existe un grand nombre de fonctions mathÃ©matiques dans R, dont les plus utiles sont les suivantes : log(), log10(), exp(), sqrt().\n\nlog(1) # logarithme en base e\n\n[1] 0\n\nlog10(1) # logarithme en base 10\n\n[1] 0\n\nexp(1) # antilog naturel, fonction exponentielle\n\n[1] 2.718282\n\nsqrt(4) # racine carrÃ©e\n\n[1] 2\n\n4^2 # 4 puissance 2\n\n[1] 16\n\npi # pas une fonction mais utile\n\n[1] 3.141593\n\n\nIl est important de comprendre que lorsque vous exÃ©cutez un code comme nous lâ€™avons fait ci-dessus, le rÃ©sultat du code (ou valeur) nâ€™est affichÃ© que dans la console. Bien que cela puisse parfois Ãªtre utile, il est gÃ©nÃ©ralement beaucoup plus pratique de stocker la ou les valeurs dans un objet.",
    "crumbs": [
      "DonnÃ©es",
      "Utiliser R",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Quelques notions de base sur R</span>"
    ]
  },
  {
    "objectID": "02-base.html#objets-en-r",
    "href": "02-base.html#objets-en-r",
    "title": "2Â  Quelques notions de base sur R",
    "section": "\n2.3 Objets en R",
    "text": "2.3 Objets en R\nAu cÅ“ur de presque tout ce que vous ferez (ou ferez probablement) en R se trouve le concept selon lequel tout en R est un objet. Ces objets peuvent Ãªtre pratiquement nâ€™importe quoi, dâ€™un simple nombre ou dâ€™une chaÃ®ne de caractÃ¨res (comme un mot) Ã  des structures trÃ¨s complexes comme la sortie dâ€™un graphique, un rÃ©sumÃ© de votre analyse statistique ou un ensemble de commandes R effectuant une tÃ¢che spÃ©cifique. Pour comprendre R, il est essentiel de savoir comment crÃ©er des objets et leur attribuer des valeurs.\n\n2.3.1 CrÃ©ation dâ€™objets\nPour crÃ©er un objet, il suffit de lui donner un nom. Nous pouvons ensuite attribuer une valeur Ã  cet objet Ã  lâ€™aide dâ€™un opÃ©rateur dâ€™affectation &lt;- (parfois appelÃ© opÃ©rateur dâ€™obtention). Lâ€™opÃ©rateur dâ€™affectation est un symbole composite composÃ© dâ€™un symbole â€œmoins queâ€ &lt; et dâ€™un trait dâ€™union -\n\nraccourci clavier : â€œoptionâ€ + â€œ-â€ sur Mac ; â€œaltâ€ + â€œ-â€ sur Windows.\n\n\nmon_obj &lt;- 32\n\nDans le code ci-dessus, nous avons crÃ©Ã© un objet appelÃ© mon_obj et lui avons attribuÃ© la valeur numÃ©rique 32 Ã  lâ€™aide de lâ€™opÃ©rateur dâ€™affectation (dans notre tÃªte, nous lisons toujours cela comme â€˜mon_obj est 32â€™). Vous pouvez Ã©galement utiliser = Ã  la place de &lt;- pour assigner des valeurs, mais câ€™est une mauvaise pratique car cela peut entraÃ®ner des confusions plus tard quand vous programmerez en R (voir Chapitre 5) donc nous vous dÃ©conseillons dâ€™utiliser cette notation.\nPour afficher la valeur de lâ€™objet, il suffit de taper son nom.\n\nmon_obj\n\n[1] 32\n\n\nMaintenant que nous avons crÃ©Ã© cet objet, R le connaÃ®t et en gardera la trace pendant la session R en cours. Tous les objets que vous crÃ©ez sont stockÃ©s dans lâ€™espace de travail actuel et vous pouvez visualiser tous les objets de votre espace de travail dans RStudio en cliquant sur lâ€™onglet â€œEnvironnementâ€ dans le volet supÃ©rieur droit.\n\n\n\n\n\n\n\nFigureÂ 2.1: Onglet Environnement RStudio\n\n\n\n\nSi vous cliquez sur la flÃ¨che vers le bas de lâ€™icÃ´ne â€œListâ€ (Liste) dans le mÃªme volet et que vous passez Ã  lâ€™affichage â€œGridâ€ (Grille), RStudio vous prÃ©sentera un rÃ©sumÃ© des objets, y compris le type (â€œnumericâ€ (numÃ©rique) - câ€™est un nombre), la longueur (une seule valeur dans cet objet), sa taille â€œphysiqueâ€ et sa valeur (32 dans ce cas). Dans VSCode, allez sur le panneau dâ€™extension R et vous obtiendrez les mÃªmes informations.\n\n\n\n\n\n\n\nFigureÂ 2.2: Onglet Environnement RStudio au format grille\n\n\n\n\nIl existe de nombreux types de valeurs que vous pouvez attribuer Ã  un objet. Par exemple\n\nmon_obj2 &lt;- \"R c'est trop bien\"\n\nNous avons crÃ©Ã© un objet appelÃ© mon_obj2 et lui avons attribuÃ© la valeur R c'est trop bien qui est une chaÃ®ne de caractÃ¨res. Remarquez que nous avons mis la chaÃ®ne de caractÃ¨res entre guillemets. Si vous oubliez dâ€™utiliser les guillemets, vous recevrez un message dâ€™erreur.\nNotre espace de travail contient maintenant les deux objets que nous avons crÃ©Ã©s jusquâ€™Ã  prÃ©sent avec mon_obj2 de type â€œcharacterâ€ (caractÃ¨re).\n\n\n\n\n\n\n\nFigureÂ 2.3: Onglet Environnement RStudio avec mon_obj2 de type caractÃ¨re\n\n\n\n\nPour modifier la valeur dâ€™un objet existant, il suffit de lui rÃ©attribuer une nouvelle valeur. Par exemple, pour modifier la valeur de mon_obj2 de \"R c'est trop bien\" au nombre 1024\n\nmon_obj2 &lt;- 1024\n\nRemarquez que le type est devenu numÃ©rique et que la valeur est passÃ©e Ã  1024 dans lâ€™environnement.\n\n\n\n\n\n\n\nFigureÂ 2.4: Onglet Environnement RStudio avec mon_obj2 mis-Ã -jours en numÃ©rique\n\n\n\n\nUne fois que nous avons crÃ©Ã© plusieurs objets, nous pouvons faire des choses avec. Par exemple, le code suivant crÃ©e un nouvel objet mon_obj3 et lui assigne la valeur de mon_obj ajoutÃ© Ã  mon_obj2 soit 1056 (32 + 1024 = 1056).\n\nmon_obj3 &lt;- mon_obj + mon_obj2\nmon_obj3\n\n[1] 1056\n\n\nRemarquez que pour afficher la valeur de mon_obj3 nous devons Ã©galement Ã©crire le nom de lâ€™objet. Le code ci-dessus fonctionne parce que les valeurs de mon_obj et mon_obj2 sont numÃ©riques (donc des nombres). Si vous essayez de faire Ã§a avec des objets dont les valeurs sont des caractÃ¨res (classe character), vous recevrez une erreur\n\nchar_obj &lt;- \"hello\"\nchar_obj2 &lt;- \"world!\"\nchar_obj3 &lt;- char_obj + char_obj2\n# Error in char_obj+char_obj2:non-numeric argument to binary operator\n\nLe message dâ€™erreur vous indique que lâ€™un ou les deux objets char_obj et char_obj2 nâ€™est pas un nombre et ne peut donc pas Ãªtre additionnÃ©.\nLorsque vous commencez Ã  apprendre R, la gestion des erreurs et des avertissements peut Ãªtre frustrante car ils sont souvent difficiles Ã  comprendre (quâ€™est-ce quâ€™un argument ? quâ€™est-ce quâ€™un opÃ©rateur binaire ?). Une faÃ§on de trouver plus dâ€™informations sur une erreur particuliÃ¨re est de rechercher une version gÃ©nÃ©ralisÃ©e du message dâ€™erreur. Pour lâ€™erreur ci-dessus, essayez de rechercher â€˜non-numeric argument to binary operator error + râ€™ ou mÃªme â€˜common r error messagesâ€™.\nUn autre message dâ€™erreur que vous obtiendrez assez souvent lorsque vous commencerez Ã  utiliser R est Error : object 'XXX' not found (erreur : objet â€˜XXXâ€™ non trouvÃ©). A titre dâ€™exemple, regardez le code ci-dessous\nmon_obj &lt;- 48\nmon_obj4 &lt;- mon_obj + no_obj\n# Error: object 'no_obj' not found\nR renvoie un message dâ€™erreur parce que nous nâ€™avons pas encore crÃ©Ã© (dÃ©fini) lâ€™objet no_obj. Un autre indice quâ€™il y a un problÃ¨me avec ce code est que, si vous vÃ©rifiez votre environnement, vous verrez que lâ€™objet mon_obj4 nâ€™a pas Ã©tÃ© crÃ©Ã©.\n\n2.3.2 Nommer les objets\nNommer vos objets est lâ€™une des choses les plus difficiles que vous ferez dans R. IdÃ©alement, les noms de vos objets devraient Ãªtre courts et informatifs, ce qui nâ€™est pas toujours facile. Si vous devez crÃ©er des objets avec plusieurs mots dans leur nom, utilisez un trait de soulignement _ ou un point . entre les mots ou mettez les diffÃ©rents mots en majuscules. Nous prÃ©fÃ©rons le format soulignÃ© _ et nâ€™incluons jamais de majuscules dans les noms (appelÃ© snake_case).\nresume_sortie &lt;- \"mon analyse\" # recommandÃ© #\nresume.sortie &lt;- \"mon analyse\"\nresumeSortie &lt;- \"mon analyse\"\nIl y a Ã©galement quelques limitations lorsquâ€™il sâ€™agit de donner des noms aux objets. Un nom dâ€™objet ne peut pas commencer par un chiffre ou un point suivi dâ€™un chiffre (ex. 2ma_variable ou .2ma_variable). Vous devez Ã©galement Ã©viter dâ€™utiliser des caractÃ¨res non alphanumÃ©riques ou des accents dans vos noms dâ€™objets (i.e.Â &, ^, /, !, Ã©, Ã¨, etc). De plus, assurez-vous de ne pas nommer vos objets avec des mots rÃ©servÃ©s (i.e.Â TRUE, NA) et ce nâ€™est jamais une bonne idÃ©e de donner Ã  votre objet le mÃªme nom quâ€™une fonction intÃ©grÃ©e. Une fonction qui revient plus souvent quâ€™on ne peut sâ€™en souvenir est :\ndata &lt;- read.table(\"monfichierdedonees\", header = TRUE)\nOui, data() est une fonction de R qui permet de charger ou de lister les ensembles de donnÃ©es disponibles dans les paquets.",
    "crumbs": [
      "DonnÃ©es",
      "Utiliser R",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Quelques notions de base sur R</span>"
    ]
  },
  {
    "objectID": "02-base.html#sec-funcs",
    "href": "02-base.html#sec-funcs",
    "title": "2Â  Quelques notions de base sur R",
    "section": "\n2.4 Utilisation de fonctions dans R",
    "text": "2.4 Utilisation de fonctions dans R\nJusquâ€™Ã  prÃ©sent, nous avons crÃ©Ã© des objets simples en assignant directement une valeur unique Ã  un objet. Il est trÃ¨s probable que vous souhaitiez bientÃ´t crÃ©er des objets plus compliquÃ©s au fur et Ã  mesure que vous aurez de lâ€™expÃ©rience sur R et que la complexitÃ© de vos tÃ¢ches augmente. Heureusement, R dispose dâ€™une multitude de fonctions pour vous aider Ã  le faire. Vous pouvez considÃ©rer une fonction comme un objet qui contient une sÃ©rie dâ€™instructions pour effectuer une tÃ¢che spÃ©cifique. Lâ€™installation de base de R est livrÃ©e avec de nombreuses fonctions dÃ©jÃ  dÃ©finies ou vous pouvez augmenter la puissance de R en installant lâ€™un des 10 000 paquets actuellement disponibles. Une fois que vous aurez acquis un peu plus dâ€™expÃ©rience dans lâ€™utilisation de R, vous voudrez peut-Ãªtre dÃ©finir vos propres fonctions pour effectuer des tÃ¢ches spÃ©cifiques Ã  vos objectifs (plus dâ€™informations Ã  ce sujet dans Chapitre 5).\nLa premiÃ¨re fonction que nous allons dÃ©couvrir est la fonction c(). La fonction c() est lâ€™abrÃ©viation de concatÃ©ner et nous lâ€™utilisons pour joindre une sÃ©rie de valeurs et les stocker dans une structure de donnÃ©es appelÃ©e vecteur (plus dâ€™informations sur les vecteurs dans Chapitre 3).\n\nmon_vec &lt;- c(2, 3, 1, 6, 4, 3, 3, 7)\n\nDans le code ci-dessus, nous avons crÃ©Ã© un objet appelÃ© mon_vec et lui avons assignÃ© une valeur en utilisant la fonction c(). Il y a quelques points trÃ¨s importants Ã  noter ici. PremiÃ¨rement, lorsque vous utilisez une fonction dans R, le nom de la fonction est toujours suivi dâ€™une paire de parenthÃ¨ses rondes (), mÃªme sâ€™il nâ€™y a rien entre les parenthÃ¨ses. DeuxiÃ¨mement, les arguments dâ€™une fonction sont placÃ©s Ã  lâ€™intÃ©rieur des parenthÃ¨ses rondes () et sont sÃ©parÃ©s par des virgules ,. Vous pouvez considÃ©rer un argument comme un moyen de personnaliser lâ€™utilisation ou le comportement dâ€™une fonction. Dans lâ€™exemple ci-dessus, les arguments sont les nombres que nous voulons concatÃ©ner. Enfin, lâ€™une des choses les plus dÃ©licates lorsque vous commencez Ã  utiliser R est de savoir quelle fonction utiliser pour une tÃ¢che particuliÃ¨re et comment lâ€™utiliser. Heureusement, chaque fonction est toujours associÃ©e Ã  un document dâ€™aide qui explique comment utiliser la fonction (plus dâ€™informations Ã  ce sujet plus tard Section 2.6) et une recherche rapide sur le web peut Ã©galement vous aider.\nPour examiner la valeur de notre nouvel objet, nous pouvons simplement taper le nom de lâ€™objet comme nous lâ€™avons fait prÃ©cÃ©demment\n\nmon_vec\n\n[1] 2 3 1 6 4 3 3 7\n\n\nMaintenant que nous avons crÃ©Ã© un vecteur, nous pouvons utiliser dâ€™autres fonctions pour faire des choses utiles avec cet objet. Par exemple, nous pouvons calculer la moyenne, la variance, lâ€™Ã©cart-type et le nombre dâ€™Ã©lÃ©ments de notre vecteur en utilisant les fonctions mean(), var(), sd() et length().\n\nmean(mon_vec) # renvoie la moyenne de mon_vec\n\n[1] 3.625\n\nvar(mon_vec) # renvoie la variance de mon_vec\n\n[1] 3.982143\n\nsd(mon_vec) # renvoie l'Ã©cart-type de mon_vec\n\n[1] 1.995531\n\nlength(mon_vec) # renvoie le nombre d'Ã©lÃ©ments dnas mon_vec\n\n[1] 8\n\n\nSi nous voulons utiliser lâ€™une de ces valeurs plus tard dans notre analyse, il nous suffit dâ€™affecter la valeur obtenue Ã  un autre objet.\n\nmoyenne_vec &lt;- mean(mon_vec) # renvoie la moyenne de mon_vec\nmoyenne_vec\n\n[1] 3.625\n\n\nIl peut parfois Ãªtre utile de crÃ©er un vecteur contenant une sÃ©quence rÃ©guliÃ¨re de valeurs par pas de un. Dans ce cas, nous pouvons utiliser un raccourci en utilisant le symbole :.\n\nma_seq &lt;- 1:10 # crÃ©er une sÃ©quence rÃ©guliÃ¨re\nma_seq\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\nma_seq2 &lt;- 10:1 # en ordre dÃ©croissant\nma_seq2\n\n [1] 10  9  8  7  6  5  4  3  2  1\n\n\nDâ€™autres fonctions utiles pour gÃ©nÃ©rer des vecteurs de sÃ©quences sont seq() et rep(). Par exemple, pour gÃ©nÃ©rer une sÃ©quence de 1 Ã  5 par pas de 0,5 :\n\nma_seq2 &lt;- seq(from = 1, to = 5, by = 0.5)\nma_seq2\n\n[1] 1.0 1.5 2.0 2.5 3.0 3.5 4.0 4.5 5.0\n\n\nIci, nous avons utilisÃ© les arguments from = et to = pour dÃ©finir les limites de la sÃ©quence et lâ€™argument by = pour spÃ©cifier lâ€™incrÃ©ment (les pas) de la sÃ©quence. Jouez avec dâ€™autres valeurs pour ces arguments afin de voir leur effet.\nLâ€™argument rep() vous permet de rÃ©pliquer (rÃ©pÃ©ter) des valeurs un certain nombre de fois. Pour rÃ©pÃ©ter la valeur â€˜2â€™, 10 fois :\n\nma_seq3 &lt;- rep(2, times = 10) # rÃ©pÃ¨te '2', 10 fois\nma_seq3\n\n [1] 2 2 2 2 2 2 2 2 2 2\n\n\nVous pouvez Ã©galement rÃ©pÃ©ter des valeurs non numÃ©riques :\n\nma_seq4 &lt;- rep(\"abc\", times = 3) # rÃ©pÃ¨te â€˜abc' 3 fois\nma_seq4\n\n[1] \"abc\" \"abc\" \"abc\"\n\n\nou chaque Ã©lÃ©ment dâ€™une sÃ©rie :\n\nma_seq5 &lt;- rep(1:5, times = 3) # rÃ©pÃ¨te la sÃ©rie de '1' Ã  '5', 3 fois\nma_seq5\n\n [1] 1 2 3 4 5 1 2 3 4 5 1 2 3 4 5\n\n\nou des Ã©lÃ©ments dâ€™une sÃ©rie :\n\nma_seq6 &lt;- rep(1:5, each = 3) # rÃ©pÃ¨te chaque Ã©lÃ©ment de la sÃ©rie 3 fois\nma_seq6\n\n [1] 1 1 1 2 2 2 3 3 3 4 4 4 5 5 5\n\n\nOn peut aussi rÃ©pÃ©ter une sÃ©rie non sÃ©quentielle :\n\nma_seq7 &lt;- rep(c(3, 1, 10, 7), each = 3) # rÃ©pÃ¨te chaque Ã©lÃ©ment de la sÃ©rie 3 fois\nma_seq7\n\n [1]  3  3  3  1  1  1 10 10 10  7  7  7\n\n\nNotez dans le code ci-dessus comment nous avons utilisÃ© la fonction c() Ã  lâ€™intÃ©rieur de la fonction rep(). Lâ€™imbrication de fonctions nous permet de construire des commandes assez complexes Ã  lâ€™intÃ©rieur dâ€™une seule ligne de code et est une pratique trÃ¨s courante dans lâ€™utilisation de R. Cependant, il faut faire attention car trop de fonctions imbriquÃ©es peuvent rendre votre code difficile Ã  comprendre pour les autres (et pour vous-mÃªme dans le futur !). Nous pourrions rÃ©Ã©crire le code ci-dessus pour sÃ©parer explicitement les deux Ã©tapes de la gÃ©nÃ©ration de notre vecteur. Lâ€™une ou lâ€™autre approche donnera le mÃªme rÃ©sultat, il vous suffit dâ€™utiliser votre propre jugement pour dÃ©terminer laquelle est la plus lisible.\n\nvec_int &lt;- c(3, 1, 10, 7)\nma_seq7 &lt;- rep(vec_int, each = 3) # rÃ©pÃ¨te chaque Ã©lÃ©ment de la sÃ©rie, 3 fois\nma_seq7\n\n [1]  3  3  3  1  1  1 10 10 10  7  7  7",
    "crumbs": [
      "DonnÃ©es",
      "Utiliser R",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Quelques notions de base sur R</span>"
    ]
  },
  {
    "objectID": "02-base.html#sec-vectors",
    "href": "02-base.html#sec-vectors",
    "title": "2Â  Quelques notions de base sur R",
    "section": "\n2.5 Travailler avec des vecteurs",
    "text": "2.5 Travailler avec des vecteurs\nManipuler, rÃ©sumer et trier des donnÃ©es Ã  lâ€™aide de R est une compÃ©tence importante Ã  maÃ®triser, mais que de nombreuses personnes trouvent un peu dÃ©routante au dÃ©but. Nous allons voir ici quelques exemples simples utilisant des vecteurs pour illustrer certains concepts importants, mais nous dÃ©velopperons cela plus en dÃ©tail dans Chapitre 3 oÃ¹ nous verrons des structures de donnÃ©es plus compliquÃ©es (et plus utiles).\n\n2.5.1 Extraction dâ€™Ã©lÃ©ments\nPour extraire (ou indexer ou souscrire) une ou plusieurs valeurs (plus gÃ©nÃ©ralement appelÃ©es Ã©lÃ©ments) dâ€™un vecteur, nous utilisons les crochets [ ]. Lâ€™approche gÃ©nÃ©rale consiste Ã  nommer lâ€™objet Ã  extraire, puis Ã©crire lâ€™indice de lâ€™Ã©lÃ©ment Ã  extraire dans les crochets. Cet indice peut Ãªtre une position ou le rÃ©sultat dâ€™un test logique.\nIndice de position\nPour extraire des Ã©lÃ©ments en fonction de leur position, il suffit dâ€™Ã©crire la position Ã  lâ€™intÃ©rieur des crochets [ ]. Par exemple, pour extraire la 3e valeur de mon_vec :\n\nmon_vec # rappelons-nous Ã  quoi mon_vec ressemble\n\n[1] 2 3 1 6 4 3 3 7\n\nmon_vec[3] # extrait la 3e valeur\n\n[1] 1\n\n# si vous voulez stocker cette valeur dans un autre objet\nval_3 &lt;- mon_vec[3]\nval_3\n\n[1] 1\n\n\nNotez que lâ€™indice de position commence Ã  1 et non Ã  0 comme dans dâ€™autres langages de programmation (i.e.Â Python).\nNous pouvons Ã©galement extraire plusieurs valeurs en utilisant la fonction c() Ã  lâ€™intÃ©rieur des crochets. Ici, nous extrayons le 1er, le 5e, le 6e et le 8e Ã©lÃ©ment de lâ€™objet mon_vec :\n\nmon_vec[c(1, 5, 6, 8)]\n\n[1] 2 4 3 7\n\n\nNous pouvons Ã©galement extraire une plage de valeurs Ã  lâ€™aide de la fonction :. Pour extraire du 3e au 8e Ã©lÃ©ment :\n\nmon_vec[3:8]\n\n[1] 1 6 4 3 3 7\n\n\n\n2.5.1.1 Indice logique\nUne autre faÃ§on trÃ¨s utile dâ€™extraire des donnÃ©es dâ€™un vecteur est dâ€™utiliser une expression logique comme indice. Par exemple, pour extraire tous les Ã©lÃ©ments dont la valeur est supÃ©rieure Ã  4 dans le vecteur mon_vec :\n\nmon_vec[mon_vec &gt; 4]\n\n[1] 6 7\n\n\nIci, lâ€™expression logique est mon_vec &gt; 4 et R nâ€™extraira que les Ã©lÃ©ments qui satisfont Ã  cette condition logique. Comment cela fonctionne-t-il rÃ©ellement ? Si nous regardons la sortie de lâ€™expression logique sans les crochets, vous pouvez voir que R renvoie un vecteur contenant soit TRUE soit FALSE qui indique si la condition logique est remplie pour chaque Ã©lÃ©ment. Dans ce cas, seuls les Ã©lÃ©ments en 4e et 8e position renvoient un TRUE car leur valeur est supÃ©rieure Ã  4.\n\nmon_vec &gt; 4\n\n[1] FALSE FALSE FALSE  TRUE FALSE FALSE FALSE  TRUE\n\n\nAinsi, ce que R fait en rÃ©alitÃ© sous le capot est Ã©quivalent Ã  :\n\nmon_vec[c(FALSE, FALSE, FALSE, TRUE, FALSE, FALSE, FALSE, TRUE)]\n\n[1] 6 7\n\n\net seuls les Ã©lÃ©ments qui sont TRUE seront extraits.\nEn plus de &lt; et &gt; vous pouvez Ã©galement utiliser des opÃ©rateurs composites pour augmenter la complexitÃ© de vos expressions. Par exemple, lâ€™expression â€œsupÃ©rieur ou Ã©gal Ã â€ est : &gt;=. Pour vÃ©rifier si une valeur est Ã©gale Ã  une autre, nous devons utiliser un double symbole Ã©gal == et pour vÃ©rifier si une valeur est diffÃ©rente de, nous utilisons le symbole != (le symbole ! signifie â€œpasâ€).\n\nmon_vec[mon_vec &gt;= 4] # valeurs supÃ©rieures ou Ã©gales Ã  4\n\n[1] 6 4 7\n\nmon_vec[mon_vec &lt; 4] # valeurs infÃ©rieures Ã  4\n\n[1] 2 3 1 3 3\n\nmon_vec[mon_vec &lt;= 4] # valeurs infÃ©rieures ou Ã©gales Ã  4\n\n[1] 2 3 1 4 3 3\n\nmon_vec[mon_vec == 4] # valeurs Ã©gales Ã  4\n\n[1] 4\n\nmon_vec[mon_vec != 4] # valeurs pas Ã©gales Ã  4\n\n[1] 2 3 1 6 3 3 7\n\n\nNous pouvons Ã©galement combiner plusieurs expressions logiques Ã  lâ€™aide dâ€™expressions boolÃ©ennes. Dans R, lâ€™Ã©lÃ©ment & signifie ET et le symbole | signifie OU. Par exemple, pour extraire des valeurs dans mon_vec qui sont infÃ©rieures Ã  6 ET supÃ©rieures Ã  2 :\n\nval26 &lt;- mon_vec[mon_vec &lt; 6 & mon_vec &gt; 2]\nval26\n\n[1] 3 4 3 3\n\n\nou extraire des valeurs dans mon_vec qui sont supÃ©rieures Ã  6 OU infÃ©rieures Ã  3 :\n\nval63 &lt;- mon_vec[mon_vec &gt; 6 | mon_vec &lt; 3]\nval63\n\n[1] 2 1 7\n\n\n\n2.5.2 Remplacement dâ€™Ã©lÃ©ments\nNous pouvons modifier les valeurs de certains Ã©lÃ©ments dâ€™un vecteur Ã  lâ€™aide des crochets [ ] en combinaison avec lâ€™opÃ©rateur dâ€™affectation &lt;-. Par exemple, pour remplacer la 4e valeur de mon_vec de 6 Ã  500 :\n\nmon_vec[4] &lt;- 500\nmon_vec\n\n[1]   2   3   1 500   4   3   3   7\n\n\nNous pouvons Ã©galement remplacer plusieurs valeurs ou mÃªme remplacer des valeurs sur la base dâ€™une expression logique :\n\n# remplacer les 6e et 7e Ã©lÃ©ments par 100\nmon_vec[c(6, 7)] &lt;- 100\nmon_vec\n\n[1]   2   3   1 500   4 100 100   7\n\n# remplacer les Ã©lÃ©ments infÃ©rieurs ou Ã©gaux Ã  4 par 1000\nmon_vec[mon_vec &lt;= 4] &lt;- 1000\nmon_vec\n\n[1] 1000 1000 1000  500 1000  100  100    7\n\n\n\n2.5.3 Ordonner les Ã©lÃ©ments\nOutre lâ€™extraction dâ€™Ã©lÃ©ments particuliers dâ€™un vecteur, il est Ã©galement possible dâ€™ordonner les valeurs contenues dans un vecteur. Pour trier les valeurs de la plus petite Ã  la plus grande, nous pouvons utiliser la fonction sort() :\n\nvec_trie &lt;- sort(mon_vec)\nvec_trie\n\n[1]    7  100  100  500 1000 1000 1000 1000\n\n\nPour inverser le tri, du plus Ã©levÃ© au plus bas, nous pouvons soit inclure lâ€™option decreasing = TRUE lors de lâ€™utilisation de la fonction sort() :\n\nvec_trie2 &lt;- sort(mon_vec, decreasing = TRUE)\nvec_trie2\n\n[1] 1000 1000 1000 1000  500  100  100    7\n\n\nsoit trier dâ€™abord le vecteur Ã  lâ€™aide de la fonction sort() puis lâ€™inverser Ã  lâ€™aide de la fonction rev(). Il sâ€™agit lÃ  dâ€™un autre exemple dâ€™imbrication dâ€™une fonction dans une autre fonction :\n\nvec_trie3 &lt;- rev(sort(mon_vec))\nvec_trie3\n\n[1] 1000 1000 1000 1000  500  100  100    7\n\n\nBien quâ€™il soit amusant de trier un seul vecteur, il serait peut-Ãªtre plus utile de trier un vecteur en fonction des valeurs dâ€™un autre vecteur. Pour ce faire, nous devons utiliser la fonction order() en combinaison avec [ ]. Pour le dÃ©montrer, crÃ©ons un vecteur appelÃ© taille contenant la taille de 5 personnes diffÃ©rentes et un autre vecteur appelÃ© p_noms contenant les noms de ces personnes (Joanna mesure 180 cm, Charlotte mesure 155 cm, etc.)\n\ntaille &lt;- c(180, 155, 160, 167, 181)\ntaille\n\n[1] 180 155 160 167 181\n\np_noms &lt;- c(\"Joanna\", \"Charlotte\", \"Helen\", \"Karen\", \"Amy\")\np_noms\n\n[1] \"Joanna\"    \"Charlotte\" \"Helen\"     \"Karen\"     \"Amy\"      \n\n\nNotre objectif est de classer les personnes dans p_noms dans lâ€™ordre croissant de leur taille. La premiÃ¨re chose que nous allons faire est dâ€™utiliser la fonction order() avec le vecteur taille pour crÃ©er un vecteur appelÃ© taille_ord\n\ntaille_ord &lt;- order(taille)\ntaille_ord\n\n[1] 2 3 4 1 5\n\n\nOK, que se passe-t-il ici ? La premiÃ¨re valeur, 2(nâ€™oubliez pas dâ€™ignorer [1]) doit Ãªtre lue comme â€œla plus petite valeur de taille est le deuxiÃ¨me Ã©lÃ©ment du vecteur tailleâ€. Si nous le vÃ©rifions en regardant le vecteur taille ci-dessus, nous pouvons voir que le 2e Ã©lÃ©ment a une valeur de 155, ce qui est la plus petite valeur. La deuxiÃ¨me valeur la plus petite du vecteur taille est la 3e ce qui, aprÃ¨s vÃ©rification, donne 160 et ainsi de suite. La plus grande valeur de taille est la 5e qui vaut 181. Maintenant que nous avons le vecteur des indices de position des tailles par ordre croissant (taille_ord), nous pouvons extraire ces valeurs de notre vecteur p_noms dans cet ordre\n\nnoms_ord &lt;- p_noms[taille_ord]\nnoms_ord\n\n[1] \"Charlotte\" \"Helen\"     \"Karen\"     \"Joanna\"    \"Amy\"      \n\n\nVous vous demandez probablement Ã  quoi cela peut bien servir. Imaginons que vous disposiez dâ€™un jeu de donnÃ©es contenant deux colonnes et que vous souhaitiez trier chacune dâ€™entre elles. Si vous utilisez simplement sort() pour trier chaque colonne sÃ©parÃ©ment, les valeurs de chaque colonne seront dissociÃ©es les unes des autres. En utilisant order() sur une colonne, un vecteur dâ€™indices de position est crÃ©Ã© Ã  partir des valeurs de la colonne dans lâ€™ordre croissant. Ce vecteur peut Ãªtre utilisÃ© sur la deuxiÃ¨me colonne, en tant quâ€™indice dâ€™Ã©lÃ©ments qui renverront un vecteur de valeurs basÃ© sur la premiÃ¨re colonne. En toute honnÃªtetÃ©, lorsque vous avez plusieurs vecteurs liÃ©s, vous devez utiliser un objet de type data.frame (voir Chapitre 3) au lieu de plusieurs vecteurs indÃ©pendants.\n\n2.5.4 Vectorisation\nLâ€™un des avantages des fonctions R est que la plupart dâ€™entre elles sont vectorisÃ©es. Cela signifie que la fonction opÃ¨re sur tous les Ã©lÃ©ments dâ€™un vecteur sans quâ€™il soit nÃ©cessaire dâ€™appliquer la fonction Ã  chaque Ã©lÃ©ment sÃ©parÃ©ment. Par exemple, pour multiplier chaque Ã©lÃ©ment dâ€™un vecteur par 5, il suffit dâ€™utiliser la fonction :\n\n# crÃ©er un vecteur\nmon_vec2 &lt;- c(3, 5, 7, 1, 9, 20)\n\n# multiplier chaque Ã©lÃ©ment par 5\nmon_vec2 * 5\n\n[1]  15  25  35   5  45 100\n\n\nOu nous pouvons additionner les Ã©lÃ©ments de deux vecteurs ou plus :\n\n# crÃ©er un deuxiÃ¨me vecteur\nmon_vec3 &lt;- c(17, 15, 13, 19, 11, 0)\n\n# additionner les 2 vecteurs\nmon_vec2 + mon_vec3\n\n[1] 20 20 20 20 20 20\n\n# multiplier les 2 vecteurs\nmon_vec2 * mon_vec3\n\n[1] 51 75 91 19 99  0\n\n\nCependant, vous devez faire attention lorsque vous utilisez la vectorisation avec des vecteurs de longueurs diffÃ©rentes, car R recyclera tranquillement les Ã©lÃ©ments du vecteur le plus court plutÃ´t que de signaler une erreur.\n\n# crÃ©er un troisiÃ¨me vecteur\nmon_vec4 &lt;- c(1, 2)\n\n# additionner les 2 vecteurs - recyclage tranquille!\nmon_vec2 + mon_vec4\n\n[1]  4  7  8  3 10 22\n\n\n\n2.5.5 DonnÃ©es manquantes\nDans R, les donnÃ©es manquantes sont gÃ©nÃ©ralement reprÃ©sentÃ©es par un NA qui signifie â€œNot Availableâ€ (Non disponible). Les donnÃ©es peuvent Ãªtre manquantes pour toute une sÃ©rie de raisons : votre machine est peut-Ãªtre tombÃ©e en panne, vous Ãªtes peut-Ãªtre tombÃ© en panne, le temps Ã©tait peut-Ãªtre trop mauvais pour collecter des donnÃ©es un jour donnÃ©, etc. Les donnÃ©es manquantes peuvent Ãªtre une vÃ©ritable plaie, tant du point de vue de R que du point de vue statistique. Du point de vue de R, les donnÃ©es manquantes peuvent Ãªtre problÃ©matiques car diffÃ©rentes fonctions traitent les donnÃ©es manquantes de diffÃ©rentes maniÃ¨res. Par exemple, supposons que nous ayons recueilli des relevÃ©s de tempÃ©rature de lâ€™air pendant 10 jours, mais que notre thermomÃ¨tre se soit cassÃ© le deuxiÃ¨me et le neuviÃ¨me jour, de sorte que nous nâ€™avons pas de donnÃ©es pour ces jours-lÃ  :\n\ntemp &lt;- c(7.2, NA, 7.1, 6.9, 6.5, 5.8, 5.8, 5.5, NA, 5.5)\ntemp\n\n [1] 7.2  NA 7.1 6.9 6.5 5.8 5.8 5.5  NA 5.5\n\n\nNous voulons maintenant calculer la tempÃ©rature moyenne sur ces jours Ã  lâ€™aide de la fonction mean() :\n\ntemp_moyenne &lt;- mean(temp)\ntemp_moyenne\n\n[1] NA\n\n\nSi un vecteur a une valeur manquante, la seule valeur possible Ã  renvoyer lors du calcul dâ€™une moyenne est NA. R ne sait pas que vous souhaitez peut-Ãªtre ignorer la valeur NA (R ne peut pas lire dans vos pensÃ©es - pour lâ€™instant !). Si nous regardons le fichier dâ€™aide (en utilisant ?mean - voir la section suivante Section 2.6 pour plus de dÃ©tails) associÃ© Ã  la fonction mean() nous pouvons voir quâ€™il y a un argument na.rm = qui prend la valeur FALSE par dÃ©faut.\n\nna.rm - une valeur logique indiquant si les valeurs NA doivent Ãªtre supprimÃ©es avant le calcul (â€œna removeâ€).\n\nSi nous remplaÃ§ons cet argument par na.rm = TRUE lorsque nous utilisons la fonction mean() cela nous permettra dâ€™ignorer les NA lors du calcul de la moyenne :\n\ntemp_moyenne &lt;- mean(temp, na.rm = TRUE)\ntemp_moyenne\n\n[1] 6.2875\n\n\nIl est important de noter que les NA nâ€™ont pas Ã©tÃ© retirÃ©s du vecteur temp (ce serait une mauvaise pratique), mais que lâ€™objet mean() les a simplement ignorÃ©es. Le but de ce qui prÃ©cÃ¨de est de souligner comment nous pouvons modifier le comportement par dÃ©faut dâ€™une fonction Ã  lâ€™aide dâ€™un argument appropriÃ©. Le problÃ¨me est que toutes les fonctions nâ€™ont pas dâ€™argument na.rm = elles peuvent gÃ©rer les NA diffÃ©remment. Cependant, la bonne nouvelle est que chaque fichier dâ€™aide associÃ© Ã  une fonction vous indiquera toujours comment les donnÃ©es manquantes sont traitÃ©es par dÃ©faut.",
    "crumbs": [
      "DonnÃ©es",
      "Utiliser R",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Quelques notions de base sur R</span>"
    ]
  },
  {
    "objectID": "02-base.html#sec-help",
    "href": "02-base.html#sec-help",
    "title": "2Â  Quelques notions de base sur R",
    "section": "\n2.6 Obtenir de lâ€™aide",
    "text": "2.6 Obtenir de lâ€™aide\nCe livre est conÃ§u comme une introduction relativement brÃ¨ve Ã  R et, en tant que tel, vous utiliserez bientÃ´t des fonctions et des paquets qui dÃ©passent le cadre de ce texte dâ€™introduction. Heureusement, lâ€™une des forces de R est son systÃ¨me dâ€™aide complet et facilement accessible, ainsi que la richesse des ressources en ligne oÃ¹ vous pouvez obtenir de plus amples informations.\n\n2.6.1 Aide R\nPour accÃ©der Ã  lâ€™aide intÃ©grÃ©e de R et obtenir des informations sur nâ€™importe quelle fonction, il suffit dâ€™utiliser la fonction help(). Par exemple, pour ouvrir la page dâ€™aide de notre amie, la fonction mean() :\nhelp(\"mean\")\nou vous pouvez utiliser le raccourci ? devant la fonction :\n?mean\nla page dâ€™aide est affichÃ©e dans lâ€™onglet â€œAideâ€(gÃ©nÃ©ralement en bas Ã  droite sur RStudio)\n\n\n\n\n\n\n\nFigureÂ 2.5: Page dâ€™aide pour la fonction mean() dans le panneau Aide sur Rstudio\n\n\n\n\nIl est vrai que les fichiers dâ€™aide peuvent sembler tout sauf utiles lorsque vous commencez Ã  utiliser R. Cela est probablement dÃ» au fait quâ€™ils sont Ã©crits de maniÃ¨re trÃ¨s concise et que le langage utilisÃ© est souvent assez technique et plein de jargon. Cela dit, on sâ€™y habitue et, avec le temps, on finit mÃªme par apprÃ©cier une certaine beautÃ© dans cette briÃ¨vetÃ© (honnÃªtement !). Lâ€™un des aspects les plus intÃ©ressants des fichiers dâ€™aide est quâ€™ils ont tous une structure trÃ¨s similaire, quelle que soit la fonction. Il est donc facile de naviguer dans le fichier pour trouver exactement ce dont vous avez besoin.\nLa premiÃ¨re ligne du document dâ€™aide contient des informations telles que le nom de la fonction et le paquet dâ€™oÃ¹ elle provient (entre les accolades {}, ici {base} signifie que la fonction mean() fait partie des fonctions de base de R). Dâ€™autres rubriques fournissent des informations plus spÃ©cifiques, telles que\n\n\n\n\n\n\nRubriques\nDescription de la rubrique\n\n\n\nDescription :\ndonne une brÃ¨ve description de la fonction et de ce quâ€™elle fait.\n\n\nUsage :\ndonne le nom des arguments associÃ©s Ã  la fonction et les Ã©ventuelles valeurs par dÃ©faut.\n\n\nArguments :\nfournit plus de dÃ©tails sur chaque argument et sur ce quâ€™il fait.\n\n\nDetails :\ndonne des dÃ©tails supplÃ©mentaires sur la fonction si nÃ©cessaire.\n\n\nValue :\nle cas Ã©chÃ©ant, indique le type et la structure de lâ€™objet renvoyÃ© par la fonction ou lâ€™opÃ©rateur.\n\n\nSee also :\nfournit des informations sur dâ€™autres pages dâ€™aide au contenu similaire ou connexe.\n\n\nExamples :\ndonne quelques exemples dâ€™utilisation de la fonction.\n\n\n\nLes Examples (Exemples dâ€™application) sont trÃ¨s utiles, il suffit de les copier et de les coller dans la console pour voir ce qui se passe. Vous pouvez Ã©galement accÃ©der aux exemples Ã  tout moment en utilisant la fonction example() (câ€™est-Ã -dire example(\"mean\"))\nLa fonction help() est utile si vous connaissez le nom de la fonction. Si vous nâ€™Ãªtes pas sÃ»r du nom, mais que vous vous souvenez dâ€™un mot clÃ©, vous pouvez faire une recherche dans le systÃ¨me dâ€™aide de R Ã  lâ€™aide de la fonction help.search().\nhelp.search(\"mean\")\nou vous pouvez utiliser le raccourci Ã©quivalent ?? :\n??mean\nLes rÃ©sultats de la recherche seront affichÃ©s dans RStudio sous lâ€™onglet â€œAideâ€ comme prÃ©cÃ©demment. help.search() recherche dans la documentation dâ€™aide, les dÃ©monstrations de code et les vignettes de paquet et affiche les rÃ©sultats sous forme de liens cliquables pour une exploration plus approfondie.\n\n\n\n\n\n\n\nFigureÂ 2.6: Sortie de la fonction help.search() dans Rstudio\n\n\n\n\nUne autre fonction utile est apropos(). Cette fonction peut Ãªtre utilisÃ©e pour dresser la liste de toutes les fonctions contenant une chaÃ®ne de caractÃ¨res spÃ©cifiÃ©e. Par exemple, pour trouver toutes les fonctions avec mean dans leur nom :\n\napropos(\"mean\")\n\n [1] \".colMeans\"     \".rowMeans\"     \"colMeans\"      \"kmeans\"       \n [5] \"mean\"          \"mean_temp\"     \"mean.Date\"     \"mean.default\" \n [9] \"mean.difftime\" \"mean.POSIXct\"  \"mean.POSIXlt\"  \"rowMeans\"     \n[13] \"vec_mean\"      \"weighted.mean\"\n\n\nVous pouvez alors afficher le fichier dâ€™aide de la fonction concernÃ©e.\nhelp(\"kmeans\")\nUne autre fonction est RSiteSearch() qui vous permet de rechercher des mots-clÃ©s et des phrases dans les pages dâ€™aide des fonctions et les vignettes de tous les paquets CRAN. Cette fonction vous permet dâ€™accÃ©der au moteur de recherche du site web de R https://www.r-project.org/search.html directement Ã  partir de la console et dâ€™afficher les rÃ©sultats dans votre navigateur web.\nRSiteSearch(\"regression\")\n\n2.6.2 Autres sources dâ€™aide\nIl nâ€™y a jamais eu de meilleur moment pour commencer Ã  apprendre R. Il existe plÃ©thore de ressources en ligne disponibles gratuitement, allant de cours complets Ã  des tutoriels et des listes de diffusion spÃ©cifiques Ã  un sujet. Il existe Ã©galement de nombreuses options payantes si câ€™est votre truc, mais Ã  moins que vous nâ€™ayez de lâ€™argent Ã  brÃ»ler, il nâ€™est vraiment pas nÃ©cessaire de dÃ©penser votre argent durement gagnÃ©. Vous trouverez ci-dessous quelques ressources que nous avons trouvÃ©es utiles.\n\n2.6.2.1 Ressources gÃ©nÃ©rales sur les R\n\n\nProjet R: Documentation fournie par lâ€™utilisateur\n\nLe journal R: Journal du projet R pour le calcul statistique\n\nTourbillon: Un paquet R qui vous enseigne R de lâ€™intÃ©rieur\nLes antisÃ¨ches imprimables de RStudio\n\nRseek Une recherche Google personnalisÃ©e pour les sites liÃ©s Ã  R\n\n2.6.2.2 Obtenir de lâ€™aide\n\nCherchez sur internet: utiliser votre moteur de recherche prÃ©fÃ©rÃ© pour chercher les messages dâ€™erreur que vous obtenez. Ce nâ€™est pas de la triche et tout le monde le fait ! Vous serez surpris du nombre de personnes qui ont probablement rencontrÃ© le mÃªme problÃ¨me et lâ€™ont rÃ©solu.\n\nStack Overflow: Il y a plusieurs milliers de questions relatives Ã  R sur Stack Overflow. Ici sont les plus populaires, classÃ©es par vote. Veillez Ã  rechercher des questions similaires avant de poser la vÃ´tre et Ã  inclure un exemple reproductible afin dâ€™obtenir les conseils les plus utiles. Un exemple reproductible est un exemple minimal qui permet aux personnes qui essaient de vous aider de voir lâ€™erreur elles-mÃªmes.\n\n2.6.2.3 Ressources R markdown\n\nRÃ©fÃ©rence de base pour markdown et markdown R\nUne bonne rÃ©fÃ©rence en markdown\nUn bon tutoriel de 10 minutes sur le markdown\nFeuille de contrÃ´le de RStudio sur le format R markdown\nFeuille de rÃ©fÃ©rence pour R markdown\n\nLa documentation R markdown incluant un guide de dÃ©marrage , a galerie de dÃ©monstrations et plusieurs articles pour une utilisation plus avancÃ©e.\n\nLe site web de knitr contient de nombreux documents de rÃ©fÃ©rence utiles sur le fonctionnement de knitr.\n\n2.6.2.4 Ressources Git et GitHub\n\n\nHappy Git: Excellente ressource pour lâ€™utilisation de Git et GitHub\n\nContrÃ´le de version avec RStudio: Document RStudio pour lâ€™utilisation du contrÃ´le de version\n\nUtiliser Git depuis RStudio: Un bon guide en 10 minutes\n\nLa classe R: Guide approfondi de lâ€™utilisation de Git et GitHub avec RStudio\n\n2.6.2.5 Programmation R\n\n\nProgrammation R pour la science des donnÃ©es: Guide approfondi de la programmation R\n\nR pour la science des donnÃ©es: Livre fantastique, orientÃ© tidyverse",
    "crumbs": [
      "DonnÃ©es",
      "Utiliser R",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Quelques notions de base sur R</span>"
    ]
  },
  {
    "objectID": "02-base.html#sauvegarder-des-donnÃ©es-dans-r",
    "href": "02-base.html#sauvegarder-des-donnÃ©es-dans-r",
    "title": "2Â  Quelques notions de base sur R",
    "section": "\n2.7 Sauvegarder des donnÃ©es dans R",
    "text": "2.7 Sauvegarder des donnÃ©es dans R\nVotre approche de lâ€™enregistrement du travail dans R et RStudio dÃ©pend de ce que vous voulez enregistrer. La plupart du temps, la seule chose que vous devrez sauvegarder est le code R de vos scripts. Nâ€™oubliez pas que votre script est un enregistrement reproductible de tout ce que vous avez fait. Il vous suffit donc dâ€™ouvrir votre script dans une nouvelle session RStudio et de lâ€™exÃ©cuter dans la console R pour revenir Ã  lâ€™endroit oÃ¹ vous vous Ã©tiez arrÃªtÃ©.\nÃ€ moins que vous nâ€™ayez suivi notre suggestion de modifier les paramÃ¨tres par dÃ©faut des projets RStudio (voir Section 1.5), il vous sera demandÃ© si vous souhaitez sauvegarder lâ€™image de votre espace de travail Ã  chaque fois que vous quitterez RStudio. Nous pensons que dans 99,9 % des cas, vous ne souhaitez pas le faire. En commenÃ§ant avec une session RStudio propre chaque fois que nous revenons Ã  notre analyse, nous pouvons Ãªtre sÃ»rs dâ€™Ã©viter tout conflit potentiel avec les choses que nous avons faites dans les sessions prÃ©cÃ©dentes.\nCependant, il est parfois utile de sauvegarder les objets que vous avez crÃ©Ã©s dans R. Par exemple, imaginons que vous crÃ©iez un objet dont la gÃ©nÃ©ration nÃ©cessite des heures (voire des jours) de temps de calcul. Il serait extrÃªmement gÃªnant de devoir attendre tout ce temps Ã  chaque fois que vous revenez sur votre analyse. Cependant, dans ce cas, nous pouvons enregistrer cet objet en tant que fichier externe, .RData que nous pourrons charger dans RStudio la prochaine fois que nous voudrons lâ€™utiliser. Pour enregistrer un objet dans un fichier .RData vous pouvez utiliser la fonction save() (remarquez que nous nâ€™avons pas besoin dâ€™utiliser lâ€™opÃ©rateur dâ€™affectation ici) :\nsave(nomDelObjet, file = \"nom_du_fichier.RData\")\nou si vous souhaitez sauvegarder tous les objets de votre espace de travail dans un seul fichier .RData utilisez la fonction save.image() :\nsave.image(file = \"nom_du_fichier.RData\")\nPour charger votre .RData dans RStudio, utilisez la fonction load() :\nload(file = \"nom_du_fichier.RData\")",
    "crumbs": [
      "DonnÃ©es",
      "Utiliser R",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Quelques notions de base sur R</span>"
    ]
  },
  {
    "objectID": "02-base.html#sec-packages",
    "href": "02-base.html#sec-packages",
    "title": "2Â  Quelques notions de base sur R",
    "section": "\n2.8 Paquets R",
    "text": "2.8 Paquets R\nLâ€™installation de base de R est livrÃ©e avec de nombreux paquets utiles. Ces paquets contiennent de nombreuses fonctions que vous utiliserez quotidiennement. Cependant, lorsque vous commencerez Ã  utiliser R pour des projets plus variÃ©s (et que votre propre utilisation de R Ã©voluera), vous constaterez quâ€™il y a un moment oÃ¹ vous aurez besoin dâ€™Ã©tendre les capacitÃ©s de R. Heureusement, des milliers dâ€™utilisateurs de R ont dÃ©veloppÃ© du code utile et lâ€™ont partagÃ© sous forme de paquets installables. Vous pouvez considÃ©rer un paquet comme une collection de fonctions, de donnÃ©es et de fichiers dâ€™aide rassemblÃ©s dans une structure standard bien dÃ©finie que vous pouvez tÃ©lÃ©charger et installer dans R. Ces paquets peuvent Ãªtre tÃ©lÃ©chargÃ©s Ã  partir de diverses sources, mais les plus populaires sont les suivantes CRAN, Bioconductor et GitHub . Actuellement, le CRAN hÃ©berge plus de 15 000 paquets et est le dÃ©pÃ´t officiel des paquets R fournis par les utilisateurs. Bioconductor fournit des logiciels libres orientÃ©s vers la bioinformatique et hÃ©berge plus de 1800 paquets R. GitHub est un site web qui hÃ©berge des dÃ©pÃ´ts git pour toutes sortes de logiciels et de projets (pas seulement R). Souvent, les versions de dÃ©veloppement de pointe des paquets R sont hÃ©bergÃ©es sur GitHub, donc si vous avez besoin de toutes les nouvelles fonctionnalitÃ©s, cela peut Ãªtre une option. Cependant, lâ€™inconvÃ©nient potentiel de lâ€™utilisation de la version de dÃ©veloppement dâ€™un paquet R est quâ€™elle peut ne pas Ãªtre aussi stable que la version hÃ©bergÃ©e sur CRAN (elle est en cours de dÃ©veloppement !) et que la mise Ã  jour des paquets ne sera pas automatique.\n\n2.8.1 Utilisation des paquets\nUne fois que vous avez installÃ© un paquet sur votre ordinateur, vous ne pouvez pas lâ€™utiliser immÃ©diatement. Pour utiliser un paquet, vous devez dâ€™abord le charger Ã  lâ€™aide de la fonction library(). Par exemple, pour charger le paquet remotes ğŸ“¦ que vous avez installÃ© prÃ©cÃ©demment :\nlibrary(remotes)\nLa fonction library() chargera Ã©galement tous les paquets supplÃ©mentaires nÃ©cessaires et pourra afficher des informations supplÃ©mentaires sur les paquets dans la console. Il est important de savoir que chaque fois que vous dÃ©marrez une nouvelle session R (ou que vous restaurez une session prÃ©cÃ©demment sauvegardÃ©e), vous devez charger les paquets que vous utiliserez. Nous avons tendance Ã  mettre tous nos library() nÃ©cessaires Ã  notre analyse en tÃªte de nos scripts R afin de les rendre facilement accessibles et de pouvoir les complÃ©ter au fur et Ã  mesure du dÃ©veloppement de notre code. Si vous essayez dâ€™utiliser une fonction sans avoir prÃ©alablement chargÃ© le paquet R correspondant, vous recevrez un message dâ€™erreur indiquant que R nâ€™a pas pu trouver la fonction. Par exemple, si vous essayez dâ€™utiliser la fonction install_github() sans charger le paquet remotes ğŸ“¦ en premier lieu, vous obtiendrez lâ€™erreur suivante :\ninstall_github(\"tidyverse/dplyr\")\n\n# Error in install_github(\"tidyverse/dplyr\") :\n#  could not find function \"install_github\"\nIl peut parfois Ãªtre utile dâ€™utiliser une fonction sans utiliser au prÃ©alable la fonctionlibrary(). Si, par exemple, vous nâ€™utilisez quâ€™une ou deux fonctions dans votre script et que vous ne souhaitez pas charger toutes les autres fonctions dâ€™un paquet, vous pouvez accÃ©der directement Ã  la fonction en spÃ©cifiant le nom du paquet, suivi de deux points (2 fois) ::, puis du nom de la fonction :\nremotes::install_github(\"tidyverse/dplyr\")\nCâ€™est ainsi que nous avons pu utiliser la fonction install() et install_github() ci-dessous sans charger les paquets au prÃ©alableBiocManager ğŸ“¦ et remotes ğŸ“¦ . La plupart du temps, nous recommandons dâ€™utiliser la fonction library().\n\n2.8.2 Installation des paquets R\n\n2.8.2.1 Paquets CRAN\nPour installer un paquet Ã  partir du CRAN, vous pouvez utiliser la fonction install.packages(). Par exemple, si vous voulez installer le paquet remotes ğŸ“¦ entrez le code suivant dans la Console (note : vous aurez besoin dâ€™une connexion internet fonctionnelle pour effectuer cette opÃ©ration) :\ninstall.packages(\"remotes\", dependencies = TRUE)\nIl vous sera peut-Ãªtre demandÃ© de choisir un miroir CRAN, sÃ©lectionnez simplement â€˜0-cloudâ€™ ou un miroir proche de votre localisation. Lâ€™argument dependencies = TRUE permet de sâ€™assurer que les paquets supplÃ©mentaires nÃ©cessaires seront Ã©galement installÃ©s.\nIl est conseillÃ© de mettre rÃ©guliÃ¨rement Ã  jour les paquets dÃ©jÃ  installÃ©s afin de bÃ©nÃ©ficier des nouvelles fonctionnalitÃ©s et des corrections de bogues. Pour mettre Ã  jour les paquets CRAN, vous pouvez utiliser la commande update.packages() (vous aurez besoin dâ€™une connexion internet pour cela) :\nupdate.packages(ask = FALSE)\nLâ€™argument ask = FALSE Ã©vite dâ€™avoir Ã  confirmer chaque tÃ©lÃ©chargement de paquet, ce qui peut Ãªtre fastidieux si de nombreux paquets sont installÃ©s.\n\n2.8.2.2 Paquets Bioconductor\nPour installer des paquets de Bioconductor, le processus est un peu diffÃ©rent. Vous devez dâ€™abord installer le paquet BiocManager ğŸ“¦. Vous ne devez le faire quâ€™une seule fois, sauf si vous rÃ©installez ou mettez Ã  jour R.\ninstall.packages(\"BiocManager\", dependencies = TRUE)\nUne fois que BiocManager a Ã©tÃ© installÃ©, vous pouvez soit installer tous les paquets â€œde baseâ€ de Bioconductor avec la commande :\nBiocManager::install()\nou installer des paquets spÃ©cifiques tels que le GenomicRanges ğŸ“¦ et edgeR ğŸ“¦ :\nBiocManager::install(c(\"GenomicRanges\", \"edgeR\"))\nPour mettre Ã  jour les paquets de Bioconductor, il suffit dâ€™utiliser la commande BiocManager::install() Ã  nouveau :\nBiocManager::install(ask = FALSE)\nLÃ  encore, vous pouvez utiliser lâ€™argument ask = FALSE pour Ã©viter dâ€™avoir Ã  confirmer chaque tÃ©lÃ©chargement de paquet.\n\n2.8.2.3 Paquets GitHub\nIl existe plusieurs options pour installer les paquets hÃ©bergÃ©s sur GitHub. La mÃ©thode la plus efficace est sans doute dâ€™utiliser la fonction install_github() du paquet remotes ğŸ“¦ (vous avez installÃ© ce paquet prÃ©cÃ©demment, Section 2.8.2.1). Avant dâ€™utiliser la fonction, vous devez connaÃ®tre le nom dâ€™utilisateur GitHub du propriÃ©taire du rÃ©pertoire ainsi que le nom du rÃ©pertoire. Par exemple, la version de dÃ©veloppement de dplyr ğŸ“¦ de Hadley Wickham est hÃ©bergÃ©e sur le compte GitHub de tidyverse et porte le nom de rÃ©pertoire â€œdplyrâ€ (recherchez simplement â€œgithub dplyrâ€). Pour installer cette version depuis GitHub, utilisez :\nremotes::install_github(\"tidyverse/dplyr\")\nLe moyen le plus sÃ»r (Ã  notre connaissance) de mettre Ã  jour un paquet installÃ© depuis GitHub est de le rÃ©installer en utilisant la commande ci-dessus.",
    "crumbs": [
      "DonnÃ©es",
      "Utiliser R",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Quelques notions de base sur R</span>"
    ]
  },
  {
    "objectID": "03-donnees.html",
    "href": "03-donnees.html",
    "title": "3Â  DonnÃ©es",
    "section": "",
    "text": "3.1 Types de donnÃ©es\nIl est important de comprendre les diffÃ©rents types de donnÃ©es et la maniÃ¨re dont R traite ces donnÃ©es. La tentation est grande dâ€™ignorer ces dÃ©tails techniques, mais attention, cela peut se retourner contre vous trÃ¨s vite si vous ne faites pas attention. Nous avons dÃ©jÃ  vu un exemple (Section 2.3.1) de cela lorsque nous avons essayÃ© (et Ã©chouÃ©) dâ€™ajouter deux objets de type caractÃ¨res ensemble en utilisant lâ€™opÃ©rateur +.\nR dispose de six types de donnÃ©es de base : numÃ©rique (numeric), entier (integer), logique (logical), complexe (complex) et caractÃ¨re (character). Les plus attentifs dâ€™entre vous remarqueront que nous nâ€™avons listÃ© ici que cinq types de donnÃ©es, le dernier Ã©tant le type de donnÃ©es brut (raw), que nous nâ€™aborderons pas car il nâ€™est pas utile dans 99,99 % des cas. Nous nâ€™aborderons pas non plus les nombres complexes, mais nous vous laisserons imaginer cette partie !\nR est (gÃ©nÃ©ralement) capable de distinguer automatiquement les diffÃ©rentes classes de donnÃ©es en fonction de leur nature et du contexte dans lequel elles sont utilisÃ©es, bien que vous deviez garder Ã  lâ€™esprit que R ne peut pas vraiment lire dans vos pensÃ©es et que vous devrez peut-Ãªtre lui indiquer explicitement comment vous souhaitez traiter un type de donnÃ©es. Vous pouvez connaÃ®tre le type (ou la classe) de nâ€™importe quel objet en utilisant la fonction class() pour connaÃ®tre le type (ou la classe) dâ€™un objet.\nnum &lt;- 2.2\nclass(num)\n\n[1] \"numeric\"\n\nchar &lt;- \"hello\"\nclass(char)\n\n[1] \"character\"\n\nlogi &lt;- TRUE\nclass(logi)\n\n[1] \"logical\"\nVous pouvez Ã©galement demander si un objet appartient Ã  une classe spÃ©cifique Ã  lâ€™aide dâ€™un test logique. Le test is.[classOfData]() renvoie soit un TRUE ou un FALSE.\nis.numeric(num)\n\n[1] TRUE\n\nis.character(num)\n\n[1] FALSE\n\nis.character(char)\n\n[1] TRUE\n\nis.logical(logi)\n\n[1] TRUE\nIl peut parfois Ãªtre utile de pouvoir changer la classe dâ€™une variable Ã  lâ€™aide de la fonction as.[className]() bien quâ€™il faille Ãªtre prudent car vous pourriez obtenir des rÃ©sultats inattendus (voir ce qui se passe ci-dessous lorsque nous essayons de convertir une chaÃ®ne de caractÃ¨res en une chaÃ®ne numÃ©rique).\n# convertir un objet numÃ©rique en caractÃ¨re\nclass(num)\n\n[1] \"numeric\"\n\nnum_char &lt;- as.character(num)\nnum_char\n\n[1] \"2.2\"\n\nclass(num_char)\n\n[1] \"character\"\n\n# convertir un objet caractÃ¨re en numÃ©rique !\nclass(char)\n\n[1] \"character\"\n\nchar_num &lt;- as.numeric(char)\n\nWarning: NAs introduced by coercion\nVoici un tableau rÃ©capitulatif de certaines des fonctions de test logique et de coercion Ã  votre disposition.",
    "crumbs": [
      "DonnÃ©es",
      "Utiliser R",
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>DonnÃ©es</span>"
    ]
  },
  {
    "objectID": "03-donnees.html#types-de-donnÃ©es",
    "href": "03-donnees.html#types-de-donnÃ©es",
    "title": "3Â  DonnÃ©es",
    "section": "",
    "text": "NumÃ©rique sont des nombres contenant une dÃ©cimale. En fait, il peut Ã©galement sâ€™agir de nombres entiers, mais nous nâ€™y reviendrons pas.\nEntiers (integer) sont des nombres entiers (sans virgule).\nLogique prennent la valeur de TRUE ou FALSE. Il existe Ã©galement un autre type de logique appelÃ© NA pour reprÃ©senter les valeurs manquantes.\nCaractÃ¨re sont des chaÃ®nes de caractÃ¨res comme un (ou plusieurs) mot(s). Un type particulier de chaÃ®ne de caractÃ¨res est le facteur qui a des attributs supplÃ©mentaires (comme des niveaux ou un ordre). Nous reviendrons sur les facteurs plus tard.\n\n\n\n\n\n\n\n\n\n\nType de test\nTest logique\nCoercition\n\n\n\nCaractÃ¨re\nis.character\nas.character\n\n\nNumÃ©rique\nis.numeric\nas.numeric\n\n\nLogique\nis.logical\nas.logical\n\n\nFacteur\nis.factor\nas.factor\n\n\nComplexe\nis.complex\nas.complex",
    "crumbs": [
      "DonnÃ©es",
      "Utiliser R",
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>DonnÃ©es</span>"
    ]
  },
  {
    "objectID": "03-donnees.html#structures-de-donnÃ©es",
    "href": "03-donnees.html#structures-de-donnÃ©es",
    "title": "3Â  DonnÃ©es",
    "section": "\n3.2 Structures de donnÃ©es",
    "text": "3.2 Structures de donnÃ©es\nMaintenant que vous connaissez certaines des classes de donnÃ©es les plus importantes de R, examinons quelques-unes des principales structures dont nous disposons pour stocker ces donnÃ©es.\n\n3.2.1 Scalaires et vecteurs\nLe type de structure de donnÃ©es le plus simple est sans doute le vecteur. Vous avez dÃ©jÃ  Ã©tÃ© initiÃ© aux vecteurs dans la Section 2.4, certains des vecteurs que vous avez crÃ©Ã©s ne contenaient quâ€™une seule valeur (longueur 1) on. appelle Ã§a un scalaires. Les vecteurs peuvent contenir des nombres, des caractÃ¨res, des facteurs ou des logiques, mais la chose essentielle Ã  retenir est que tous les Ã©lÃ©ments Ã  lâ€™intÃ©rieur dâ€™un vecteur doivent Ãªtre de la mÃªme classe. En dâ€™autres termes, les vecteurs peuvent contenir des nombres, des caractÃ¨res ou des logiques, mais pas des mÃ©langes de ces types de donnÃ©es. Il existe une exception importante Ã  cette rÃ¨gle : vous pouvez inclure des NA (rappelez-vous quâ€™il sâ€™agit dâ€™un type spÃ©cial de logique) pour indiquer les donnÃ©es manquantes dans les vecteurs contenant dâ€™autres types de donnÃ©es.\n\n\n\n\n\n\n\nFigureÂ 3.1: Structure de donnÃ©es scalaires et vecteurs\n\n\n\n\n\n3.2.2 Matrices et tableaux (array)\nLa matrice est une autre structure de donnÃ©es utile, utilisÃ©e dans de nombreuses disciplines telles que lâ€™Ã©cologie des populations et les statistiques thÃ©oriques et appliquÃ©es. Une matrice est simplement un vecteur dotÃ© dâ€™attributs supplÃ©mentaires appelÃ©s dimensions. Les tableaux (array) ne sont que des matrices multidimensionnelles. LÃ  encore, les matrices et les tableaux doivent contenir des Ã©lÃ©ments appartenant tous Ã  la mÃªme classe de donnÃ©es.\n\n\n\n\n\n\n\nFigureÂ 3.2: Structure de donnÃ©es matrices et tableaux (array)\n\n\n\n\nUn moyen pratique de crÃ©er une matrice ou un tableau est dâ€™utiliser la fonction matrix() et array() respectivement. Ci-dessous, nous allons crÃ©er une matrice Ã  partir dâ€™une sÃ©quence de 1 Ã  16 en quatre lignes (nrow = 4) et la remplir par rangÃ©e (byrow = TRUE) plutÃ´t que par colonne, comme câ€™est le cas par dÃ©faut. Lors de lâ€™utilisation de lâ€™option array() il faut dÃ©finir les dimensions Ã  lâ€™aide de la fonction dim = dans notre cas, 2 lignes, 4 colonnes dans 2 matrices diffÃ©rentes :\n\nma_mat &lt;- matrix(1:16, nrow = 4, byrow = TRUE)\nma_mat\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    2    3    4\n[2,]    5    6    7    8\n[3,]    9   10   11   12\n[4,]   13   14   15   16\n\nmon_tabl &lt;- array(1:16, dim = c(2, 4, 2))\nmon_tabl\n\n, , 1\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    3    5    7\n[2,]    2    4    6    8\n\n, , 2\n\n     [,1] [,2] [,3] [,4]\n[1,]    9   11   13   15\n[2,]   10   12   14   16\n\n\nIl est parfois utile de dÃ©finir les noms des lignes et des colonnes de votre matrice, mais ce nâ€™est pas obligatoire. Pour ce faire, utilisez la fonction rownames() et colnames() :\n\nrownames(ma_mat) &lt;- c(\"A\", \"B\", \"C\", \"D\")\ncolnames(ma_mat) &lt;- c(\"a\", \"b\", \"c\", \"d\")\nma_mat\n\n   a  b  c  d\nA  1  2  3  4\nB  5  6  7  8\nC  9 10 11 12\nD 13 14 15 16\n\n\nUne fois que vous avez crÃ©Ã© vos matrices, vous pouvez faire des choses utiles avec elles et, comme vous pouvez vous y attendre, R dispose de nombreuses fonctions intÃ©grÃ©es pour effectuer des opÃ©rations sur les matrices. Certaines des plus courantes sont prÃ©sentÃ©es ci-dessous. Par exemple, pour transposer une matrice, nous utilisons la fonction de transposition t() :\n\nma_mat_t &lt;- t(ma_mat)\nma_mat_t\n\n  A B  C  D\na 1 5  9 13\nb 2 6 10 14\nc 3 7 11 15\nd 4 8 12 16\n\n\nPour extraire les Ã©lÃ©ments diagonaux dâ€™une matrice et les stocker sous forme de vecteur, nous pouvons utiliser la fonction diag() :\n\nma_mat_diag &lt;- diag(ma_mat)\nma_mat_diag\n\n[1]  1  6 11 16\n\n\nLes opÃ©rations habituelles dâ€™addition, de multiplication, etc. de matrices peuvent Ãªtre effectuÃ©es. Notez lâ€™utilisation de la fonction %*% pour effectuer une multiplication matricielle.\n\nmat.1 &lt;- matrix(c(2, 0, 1, 1), nrow = 2)\nmat.1 # Notez que la matrice Ã  Ã©tÃ© remplie par colonne par dÃ©faut\n\n     [,1] [,2]\n[1,]    2    1\n[2,]    0    1\n\nmat.2 &lt;- matrix(c(1, 1, 0, 2), nrow = 2)\nmat.2\n\n     [,1] [,2]\n[1,]    1    0\n[2,]    1    2\n\nmat.1 + mat.2 # Addition de matrices\n\n     [,1] [,2]\n[1,]    3    1\n[2,]    1    3\n\nmat.1 * mat.2 # Produit Ã©lÃ©ment par Ã©lÃ©ment\n\n     [,1] [,2]\n[1,]    2    0\n[2,]    0    2\n\nmat.1 %*% mat.2 # Multiplication de matrice\n\n     [,1] [,2]\n[1,]    3    2\n[2,]    1    2\n\n\n\n3.2.3 Listes\nLa prochaine structure de donnÃ©es que nous examinerons rapidement est la liste. Alors que les vecteurs et les matrices sont contraints de contenir des donnÃ©es du mÃªme type, les listes peuvent stocker des mÃ©langes de types de donnÃ©es. En fait, nous pouvons mÃªme stocker dâ€™autres structures de donnÃ©es telles que des vecteurs et des tableaux Ã  lâ€™intÃ©rieur dâ€™une liste ou mÃªme avoir une liste de liste. Il sâ€™agit donc dâ€™une structure de donnÃ©es trÃ¨s flexible, idÃ©ale pour stocker des donnÃ©es irrÃ©guliÃ¨res ou non rectangulaires (voir Chapitre 5 pour un exemple).\nPour crÃ©er une liste, nous pouvons utiliser la fonction list(). Notez que les trois Ã©lÃ©ments de la liste sont de classes diffÃ©rentes (caractÃ¨re, logique et numÃ©rique) et de longueurs diffÃ©rentes.\n\nlist_1 &lt;- list(\n  c(\"black\", \"yellow\", \"orange\"),\n  c(TRUE, TRUE, FALSE, TRUE, FALSE, FALSE),\n  matrix(1:6, nrow = 3)\n)\nlist_1\n\n[[1]]\n[1] \"black\"  \"yellow\" \"orange\"\n\n[[2]]\n[1]  TRUE  TRUE FALSE  TRUE FALSE FALSE\n\n[[3]]\n     [,1] [,2]\n[1,]    1    4\n[2,]    2    5\n[3,]    3    6\n\n\nLes Ã©lÃ©ments de la liste peuvent Ãªtre nommÃ©s lors de la construction de la liste :\n\nlist_2 &lt;- list(\n  couleurs = c(\"black\", \"yellow\", \"orange\"),\n  evaluation = c(TRUE, TRUE, FALSE, TRUE, FALSE, FALSE),\n  temps = matrix(1:6, nrow = 3)\n)\nlist_2\n\n$couleurs\n[1] \"black\"  \"yellow\" \"orange\"\n\n$evaluation\n[1]  TRUE  TRUE FALSE  TRUE FALSE FALSE\n\n$temps\n     [,1] [,2]\n[1,]    1    4\n[2,]    2    5\n[3,]    3    6\n\n\nou aprÃ¨s la crÃ©ation de la liste Ã  lâ€™aide de la fonction names() :\n\nnames(list_1) &lt;- c(\"couleurs\", \"evaluation\", \"temps\")\nlist_1\n\n$couleurs\n[1] \"black\"  \"yellow\" \"orange\"\n\n$evaluation\n[1]  TRUE  TRUE FALSE  TRUE FALSE FALSE\n\n$temps\n     [,1] [,2]\n[1,]    1    4\n[2,]    2    5\n[3,]    3    6\n\n\n\n3.2.4 Jeu de donnÃ©es\nDe loin la structure de donnÃ©es la plus couramment utilisÃ©e : le jeu de donnÃ©es (data frame). Un jeu de donnÃ©es est un objet bidimensionnel puissant composÃ© de lignes et de colonnes qui ressemble superficiellement Ã  une matrice. Toutefois, alors que les matrices ne peuvent contenir que des donnÃ©es du mÃªme type, les jeux de donnÃ©es peuvent contenir un mÃ©lange de diffÃ©rents types de donnÃ©es. En rÃ¨gle gÃ©nÃ©rale, dans un jeu de donnÃ©es, chaque ligne correspond Ã  une observation individuelle et chaque colonne correspond Ã  une variable mesurÃ©e ou enregistrÃ©e diffÃ©rente. Cette configuration est peut-Ãªtre familiÃ¨re Ã  ceux dâ€™entre vous qui utilisent LibreOffice Calc ou Microsoft Excel pour gÃ©rer et stocker leurs donnÃ©es. Il peut Ãªtre utile de penser que les jeux de donnÃ©es sont essentiellement constituÃ©s dâ€™un ensemble de vecteurs (colonnes), chaque vecteur contenant son propre type de donnÃ©es, mais le type de donnÃ©es peut Ãªtre diffÃ©rent dâ€™un vecteur Ã  lâ€™autre.\nPar exemple, le jeu de donnÃ©es ci-dessous contient les rÃ©sultats dâ€™une expÃ©rience visant Ã  dÃ©terminer lâ€™effet des soins parentaux (avec ou sans) chez les licornes (Unicornus magnificens) sur la croissance des petits sous trois rÃ©gimes de disponibilitÃ© alimentaire diffÃ©rents. Le jeu de donnÃ©es contient 8 variables (colonnes) et chaque ligne reprÃ©sente une licorne individuelle. Les variables p_care et food sont des facteurs (variables catÃ©goriques). La variable p_care a 2 niveaux (care et no_care) et la variable food a 3 niveaux (low, medium et high). Les variables height, weight, mane_size et fluffyness sont numÃ©riques et la variable horn_rings est un nombre entier reprÃ©sentant le nombre dâ€™anneaux sur la corne. Bien que la variable block possÃ¨de des valeurs numÃ©riques, celles-ci nâ€™ont pas vraiment dâ€™ordre et pourraient Ã©galement Ãªtre traitÃ©es comme un facteur (i.e. elles auraient Ã©galement pu Ãªtre appelÃ©es A et B).\n\n\n\nTableÂ 3.1: DonnÃ©es importÃ©es sur les licornes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\np_care\nfood\nblock\nheight\nweight\nmane_size\nfluffyness\nhorn_rings\n\n\n\ncare\nmedium\n1\n7.5\n7.62\n11.7\n31.9\n1\n\n\ncare\nmedium\n1\n10.7\n12.14\n14.1\n46.0\n10\n\n\ncare\nmedium\n1\n11.2\n12.76\n7.1\n66.7\n10\n\n\ncare\nmedium\n1\n10.4\n8.78\n11.9\n20.3\n1\n\n\ncare\nmedium\n1\n10.4\n13.58\n14.5\n26.9\n4\n\n\ncare\nmedium\n1\n9.8\n10.08\n12.2\n72.7\n9\n\n\nno_care\nlow\n2\n3.7\n8.10\n10.5\n60.5\n6\n\n\nno_care\nlow\n2\n3.2\n7.45\n14.1\n38.1\n4\n\n\nno_care\nlow\n2\n3.9\n9.19\n12.4\n52.6\n9\n\n\nno_care\nlow\n2\n3.3\n8.92\n11.6\n55.2\n6\n\n\nno_care\nlow\n2\n5.5\n8.44\n13.5\n77.6\n9\n\n\nno_care\nlow\n2\n4.4\n10.60\n16.2\n63.3\n6\n\n\n\n\n\n\n\n\nIl y a deux choses importantes Ã  garder Ã  lâ€™esprit Ã  propos des jeux de donnÃ©es. Ces types dâ€™objets sont connus sous le nom de donnÃ©es rectangulaires (ou donnÃ©es ordonnÃ©es), car chaque colonne doit comporter le mÃªme nombre dâ€™observations. Aussi, toute donnÃ©e manquante doit Ãªtre enregistrÃ©e sous la forme dâ€™un NA comme nous lâ€™avons fait pour nos vecteurs.\nNous pouvons construire un jeu de donnÃ©es Ã  partir dâ€™objets de donnÃ©es existants, tels que des vecteurs, Ã  lâ€™aide de la fonction data.frame(). Ã€ titre dâ€™exemple, crÃ©ons trois vecteurs p_taille, p_poids et p_noms et incluons tous ces vecteurs dans un jeu de donnÃ©es appelÃ© dataf.\n\np_taille &lt;- c(180, 155, 160, 167, 181)\np_poids &lt;- c(65, 50, 52, 58, 70)\np_noms &lt;- c(\"Joanna\", \"Charlotte\", \"Helen\", \"Karen\", \"Amy\")\n\ndataf &lt;- data.frame(taille = p_taille, \n                    poids = p_poids, \n                    noms = p_noms)\ndataf\n\n  taille poids      noms\n1    180    65    Joanna\n2    155    50 Charlotte\n3    160    52     Helen\n4    167    58     Karen\n5    181    70       Amy\n\n\nVous remarquerez que chacune des colonnes est nommÃ©e avec le nom de la variable que nous avons fourni lorsque nous avons utilisÃ© la fonction data.frame() lorsque nous avons utilisÃ© la fonction. Il semble Ã©galement que la premiÃ¨re colonne du cadre de donnÃ©es soit une sÃ©rie de nombres allant de 1 Ã  5. En fait, il ne sâ€™agit pas vraiment dâ€™une colonne, mais du nom de chaque ligne. Nous pouvons le vÃ©rifier en demandant Ã  R de renvoyer les dimensions du jeu de donnÃ©es dataf Ã  lâ€™aide de la fonction dim(). Nous constatons quâ€™il y a 5 lignes et 3 colonnes.\n\ndim(dataf) # 5 lignes et 3 colonnes\n\n[1] 5 3\n\n\nUne autre fonction trÃ¨s utile que nous utilisons en permanence est str() qui renvoie un rÃ©sumÃ© compact de la structure de lâ€™objet data frame (ou de tout autre objet).\n\nstr(dataf)\n\n'data.frame':   5 obs. of  3 variables:\n $ height: num  180 155 160 167 181\n $ weight: num  65 50 52 58 70\n $ names : chr  \"Joanna\" \"Charlotte\" \"Helen\" \"Karen\" ...\n\n\nLa fonction str() nous donne les dimensions du jeu de donnÃ©es et nous rappelle que dataf est un data.frame. Il Ã©numÃ¨re Ã©galement toutes les variables (colonnes) contenues dans le jeu de donnÃ©es, nous indique le type de donnÃ©es quâ€™elles contiennent et leurs 5 premiÃ¨res valeurs. Nous copions souvent ce rÃ©sumÃ© pour le mettre dans le scripts R avec des commentaires au dÃ©but de chaque ligne afin de pouvoir nous y rÃ©fÃ©rer facilement lors de lâ€™Ã©criture du code. Nous vous avons montrÃ© comment commenter les blocs dans RStudio dans la Section 1.7.\nNotez Ã©galement que R a automatiquement dÃ©cidÃ© que notre p_noms doit Ãªtre un caractÃ¨re (chr) lors de la crÃ©ation du jeu de donnÃ©es. La question de savoir si câ€™est une bonne idÃ©e ou non dÃ©pendra de la maniÃ¨re dont vous souhaitez utiliser cette variable dans des analyses ultÃ©rieures. Si nous dÃ©cidons que ce nâ€™est pas une bonne idÃ©e, nous pouvons modifier le comportement par dÃ©faut du data.frame() en incluant lâ€™argument stringsAsFactors = TRUE. Nos chaÃ®nes de caractÃ¨res seront maintenant automatiquement converties en facteurs.\n\np_taille &lt;- c(180, 155, 160, 167, 181)\np_poids &lt;- c(65, 50, 52, 58, 70)\np_noms &lt;- c(\"Joanna\", \"Charlotte\", \"Helen\", \"Karen\", \"Amy\")\n\ndataf &lt;- data.frame(\n  taille = p_taille, poids = p_poids, noms = p_noms,\n  stringsAsFactors = TRUE\n)\nstr(dataf)\n\n'data.frame':   5 obs. of  3 variables:\n $ taille: num  180 155 160 167 181\n $ poids : num  65 50 52 58 70\n $ noms  : Factor w/ 5 levels \"Amy\",\"Charlotte\",..: 4 2 3 5 1",
    "crumbs": [
      "DonnÃ©es",
      "Utiliser R",
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>DonnÃ©es</span>"
    ]
  },
  {
    "objectID": "03-donnees.html#importer-des-donnÃ©es",
    "href": "03-donnees.html#importer-des-donnÃ©es",
    "title": "3Â  DonnÃ©es",
    "section": "\n3.3 Importer des donnÃ©es",
    "text": "3.3 Importer des donnÃ©es\nBien que la crÃ©ation de jeux de donnÃ©es Ã  partir de structures de donnÃ©es existantes soit extrÃªmement utile, lâ€™approche de loin la plus courante consiste Ã  crÃ©er un jeu de donnÃ©es en important des donnÃ©es Ã  partir dâ€™un fichier externe. Pour ce faire, vos donnÃ©es doivent Ãªtre correctement formatÃ©es et enregistrÃ©es dans un format de fichier que R est capable de reconnaÃ®tre. Heureusement pour nous, R est capable de reconnaÃ®tre une grande variÃ©tÃ© de formats de fichiers, mÃªme si, en rÃ©alitÃ©, vous nâ€™en utiliserez probablement que deux ou trois rÃ©guliÃ¨rement.\n\n3.3.1 Enregistrement de fichiers Ã  importer\nLa mÃ©thode la plus simple pour crÃ©er un fichier de donnÃ©es Ã  importer dans R consiste Ã  saisir vos donnÃ©es dans une feuille de calcul Ã  lâ€™aide de Microsoft Excel ou LibreOffice Calc et Ã  lâ€™enregistrer sous la forme dâ€™un fichier dÃ©limitÃ© par des virgules. Nous prÃ©fÃ©rons LibreOffice Calc car câ€™est un logiciel libre, indÃ©pendant de plate-forme et gratuit, mais MS Excel convient Ã©galement (mais voir ici pour quelques problÃ¨mes). Voici les donnÃ©es de lâ€™expÃ©rience sur les licornes dont nous avons parlÃ© prÃ©cÃ©demment, affichÃ©es dans LibreOffice. Si vous souhaitez suivre en mÃªme temps que le livre, vous pouvez tÃ©lÃ©charger le fichier de donnÃ©es (â€˜unicorn.xlsxâ€™) Ã  partir de lâ€™Annexe A.\n\n\n\n\n\n\n\nFigureÂ 3.3: DonnÃ©es Licornes (Unicorn) dans LibreOffice Calc\n\n\n\n\nPour ceux dâ€™entre vous qui ne connaissent pas le format de fichier dÃ©limitÃ© par des virgules, cela signifie simplement que les donnÃ©es des diffÃ©rentes colonnes sont sÃ©parÃ©es par le caractÃ¨re â€œ,â€ et sont gÃ©nÃ©ralement enregistrÃ©es dans un fichier portant lâ€™extension â€œ.csvâ€ (Comma-Separated Values).\nPour enregistrer une feuille de calcul en tant que fichier dÃ©limitÃ© par des virgules (CSV) dans LibreOffice Calc, sÃ©lectionnez Fichier -&gt; Enregistrer sous... dans le menu principal. Vous devrez spÃ©cifier lâ€™emplacement oÃ¹ vous souhaitez enregistrer votre fichier dans lâ€™option â€œEnregistrer dans le dossierâ€ et le nom du fichier dans lâ€™option â€œNomâ€. Dans le menu dÃ©roulant situÃ© au-dessus du bouton â€œEnregistrerâ€, remplacez lâ€™option par dÃ©faut â€œTous les formatsâ€ par â€œTexte CSV (.csv)â€.\n\n\n\n\n\n\n\nFigureÂ 3.4: Choisir le format csv lors de lâ€™enregistrement avec LibreOffice Calc\n\n\n\n\nCliquez sur le bouton Enregistrer, puis sÃ©lectionnez lâ€™option â€œUtiliser le format CSV texteâ€. Cliquez sur OK pour enregistrer le fichier.\nIl y a quelques points Ã  prendre en compte lors de lâ€™enregistrement des fichiers Ã  importer dans R, qui vous faciliteront la vie Ã  long terme. Les titres de vos colonnes (si vous en avez) doivent Ãªtre courts et informatifs. Ã‰vitez Ã©galement les espaces dans vos titres de colonnes en les remplaÃ§ant par un trait de soulignement _ ou un point . (câ€™est-Ã -dire remplacer taille de la criniere par taille_de_la_criniere ou taille.de.la.criniere) et dâ€™Ã©viter dâ€™utiliser des caractÃ¨res spÃ©ciaux (par ex. aire (mm^2)), des accents (par ex. Ã©crire criniere au lieu de criniÃ¨re) ou des majuscules pour vous simplifier la vie. Nâ€™oubliez pas que si vous avez des donnÃ©es manquantes dans votre cadre de donnÃ©es (cellules vides), vous devez utiliser un champ NA pour les reprÃ©senter. Cela permettra de conserver un cadre de donnÃ©es ordonnÃ©.\n\n3.3.2 Fonctions dâ€™importation\nUne fois que vous avez enregistrÃ© votre fichier de donnÃ©es dans un format appropriÃ©, nous pouvons maintenant lire ce fichier dans R. La fonction la plus utilisÃ©e pour importer des donnÃ©es dans R est la fonction read.table() (nous examinerons dâ€™autres solutions plus loin dans ce chapitre). La fonction read.table() est une fonction trÃ¨s flexible qui dispose dâ€™un grand nombre dâ€™arguments (voir ?read.table), mais elle est assez simple Ã  utiliser. Importons le fichier dÃ©limitÃ© par des virgules appelÃ© unicorns.csv qui contient les donnÃ©es que nous avons vues prÃ©cÃ©demment dans ce chapitre (Section 3.2.4) que lâ€™on va assigner Ã  un objet appelÃ© licornes. Le fichier est situÃ© dans un dossier data (â€œdonnÃ©esâ€) qui est lui-mÃªme situÃ© dans notre rÃ©pertoire racine (Section 1.4). La premiÃ¨re ligne des donnÃ©es contient les noms des variables (colonnes). Pour utiliser les read.table() pour importer ce fichier\n\nlicornes &lt;- read.table(\n  file = \"data/unicorns.csv\", header = TRUE, sep = \",\", dec = \".\",\n  stringsAsFactors = TRUE\n)\n\nIl y a quelques points Ã  noter Ã  propos de la commande ci-dessus. Tout dâ€™abord, le chemin dâ€™accÃ¨s au fichier et le nom du fichier (y compris lâ€™extension) doivent Ãªtre placÃ©s entre guillemets simples ou doubles (c-Ã -d. le data/unicorns.csv), car la fonction read.table() attend une chaÃ®ne de caractÃ¨res. Si votre rÃ©pertoire de travail est dÃ©jÃ  le rÃ©pertoire qui contient le fichier, il nâ€™est pas nÃ©cessaire dâ€™inclure le chemin dâ€™accÃ¨s complet au fichier, mais seulement le nom du fichier. Dans lâ€™exemple ci-dessus, le chemin dâ€™accÃ¨s au fichier est sÃ©parÃ© par une simple barre oblique. /. Cela fonctionne quel que soit le systÃ¨me dâ€™exploitation que vous utilisez et nous vous recommandons de vous en tenir Ã  cela. Cependant, les utilisateurs de Windows peuvent Ãªtre plus familiers avec la notation de la barre oblique inverse simple et si vous voulez continuer Ã  lâ€™utiliser, vous devrez lâ€™inclure en tant que barre oblique inverse double.\n\n\n\n\n\n\nAvertissement\n\n\n\nNotez cependant que la notation de la double barre oblique inverse fonctionnera pas sur les ordinateurs utilisant les systÃ¨mes dâ€™exploitation Mac OSX ou Linux. Nous le dÃ©conseillons donc fortement car il nâ€™est pas reproductible\n\n\nLes header = TRUE spÃ©cifie que la premiÃ¨re ligne de vos donnÃ©es contient les noms des variables (c.-Ã -d. food, block etc.) Si ce nâ€™est pas le cas, vous pouvez spÃ©cifier header = FALSE (en fait, câ€™est la valeur par dÃ©faut, vous pouvez donc omettre complÃ¨tement cet argument). Lâ€™argument sep = \",\" indique Ã  R quel est le dÃ©limiteur de fichier.\nDâ€™autres arguments utiles sont dec = et na.strings =. Les dec = permet de modifier le caractÃ¨re par dÃ©faut (.) utilisÃ© par dÃ©faut pour le point dÃ©cimal. Ceci est utile si vous Ãªtes dans un pays oÃ¹ les dÃ©cimales sont gÃ©nÃ©ralement reprÃ©sentÃ©es par une virgule (c.-Ã -d. dec = \",\"). Lâ€™argument na.strings = vous permet dâ€™importer des donnÃ©es oÃ¹ les valeurs manquantes sont reprÃ©sentÃ©es par un symbole autre que NA. Cela peut Ãªtre assez courant si vous importez des donnÃ©es Ã  partir dâ€™un autre logiciel statistique tel que Minitab, qui reprÃ©sente les valeurs manquantes avec le symbole * (na.strings = \"*\").\nUne sÃ©rie de fonctions prÃ©dÃ©finies sont disponibles dans read.table() pour dÃ©finire des options spÃ©cifiques au format. Mais nous pouvons aussi simplement utiliser read.csv()pour lire un fichier csv, avec la sÃ©paration â€œ,â€ et â€œ.â€ pour les dÃ©cimales. Dans les pays oÃ¹ â€œ,â€ est utilisÃ© pour les dÃ©cimales, les fichiers csv utilisent â€œ;â€ comme sÃ©parateur. Dans ce cas, lâ€™utilisation de read.csv2() serait nÃ©cessaire. Lorsque lâ€™on travaille avec des fichiers dÃ©limitÃ©s par des tabulations, les fonctions read.delim() et read.delim2() peuvent Ãªtre utilisÃ©es avec â€œ.â€ et â€œ,â€ comme dÃ©cimales respectivement.\nAprÃ¨s avoir importÃ© nos donnÃ©es dans R, pour voir le contenu du jeu de donnÃ©es, il suffit de taper le nom de lâ€™objet comme nous lâ€™avons fait prÃ©cÃ©demment. MAIS avant de faire cela, rÃ©flÃ©chissez Ã  la raison pour laquelle vous faites cela. Si votre jeu de donnÃ©es est autre chose que minuscule, tout ce que vous allez faire, câ€™est remplir votre Console de donnÃ©es. Ce nâ€™est pas comme si vous pouviez facilement vÃ©rifier sâ€™il y a des erreurs ou si vos donnÃ©es ont Ã©tÃ© importÃ©es correctement. Une bien meilleure solution consiste Ã  utiliser notre vieil ami, la fonction str() pour obtenir un rÃ©sumÃ© compact et informatif de votre base de donnÃ©es.\n\nstr(licornes)\n\n'data.frame':   96 obs. of  8 variables:\n $ p_care    : Factor w/ 2 levels \"care\",\"no_care\": 1 1 1 1 1 1 1 1 1 1 ...\n $ food      : Factor w/ 3 levels \"high\",\"low\",\"medium\": 3 3 3 3 3 3 3 3 3 3 ...\n $ block     : int  1 1 1 1 1 1 1 1 2 2 ...\n $ height    : num  7.5 10.7 11.2 10.4 10.4 9.8 6.9 9.4 10.4 12.3 ...\n $ weight    : num  7.62 12.14 12.76 8.78 13.58 ...\n $ mane_size : num  11.7 14.1 7.1 11.9 14.5 12.2 13.2 14 10.5 16.1 ...\n $ fluffyness: num  31.9 46 66.7 20.3 26.9 72.7 43.1 28.5 57.8 36.9 ...\n $ horn_rings: int  1 10 10 1 4 9 7 6 5 8 ...\n\n\nIci, nous voyons que licornes est un objet â€œdata.frameâ€ qui contient 96 lignes et 8 variables (colonnes). Chacune des variables est rÃ©pertoriÃ©e avec sa classe de donnÃ©es et les 10 premiÃ¨res valeurs. Comme nous lâ€™avons mentionnÃ© prÃ©cÃ©demment dans ce chapitre, il peut Ãªtre trÃ¨s pratique de copier/coller ces donnÃ©es dans votre script R sous la forme dâ€™un bloc de commentaires afin de pouvoir sâ€™y rÃ©fÃ©rer ultÃ©rieurement.\nNotez Ã©galement que vos variables de type chaÃ®ne de caractÃ¨res (care et food) ont Ã©tÃ© importÃ©es en tant que facteurs parce que nous avons utilisÃ© lâ€™argument stringsAsFactors = TRUE. Si ce nâ€™est pas ce que vous voulez, vous pouvez utiliser lâ€™argument stringsAsFactors = FALSE ou Ã  partir de la version 4.0.0 de R, vous pouvez simplement ne pas utiliser cet argument car stringsAsFactors = FALSE est la valeur par dÃ©faut.\nNous pouvons donc aussi extraire le jeu de donnÃ©es depuis un fichier texte (.txt) grÃ¢ce Ã  la fonction read.delim() :\n\nlicornes &lt;- read.delim(file = \"data/unicorns.txt\")\nstr(licornes)\n\n'data.frame':   96 obs. of  8 variables:\n $ p_care    : chr  \"care\" \"care\" \"care\" \"care\" ...\n $ food      : chr  \"medium\" \"medium\" \"medium\" \"medium\" ...\n $ block     : int  1 1 1 1 1 1 1 1 2 2 ...\n $ height    : num  7.5 10.7 11.2 10.4 10.4 9.8 6.9 9.4 10.4 12.3 ...\n $ weight    : num  7.62 12.14 12.76 8.78 13.58 ...\n $ mane_size : num  11.7 14.1 7.1 11.9 14.5 12.2 13.2 14 10.5 16.1 ...\n $ fluffyness: num  31.9 46 66.7 20.3 26.9 72.7 43.1 28.5 57.8 36.9 ...\n $ horn_rings: int  1 10 10 1 4 9 7 6 5 8 ...\n\n\nSi nous voulons simplement voir les noms de nos variables (colonnes) dans le jeu de donnÃ©es, nous pouvons utiliser lâ€™argument names() qui renverra un vecteur de caractÃ¨res contenant les noms des variables.\n\nnames(licornes)\n\n[1] \"p_care\"     \"food\"       \"block\"      \"height\"     \"weight\"    \n[6] \"mane_size\"  \"fluffyness\" \"horn_rings\"\n\n\nVous pouvez mÃªme importer des feuilles de calcul de MS Excel ou dâ€™autres logiciels de statistiques directement dans R, mais nous vous conseillons dâ€™Ã©viter cette mÃ©thode dans la mesure du possible, car elle ne fait quâ€™ajouter une couche dâ€™incertitude entre vous et vos donnÃ©es. Ã€ notre avis, il est presque toujours prÃ©fÃ©rable dâ€™exporter vos feuilles de calcul sous forme de fichiers dÃ©limitÃ©s par des tabulations (.txt) ou des virgules (.csv), puis de les importer dans R Ã  lâ€™aide de lâ€™un des fonctions dÃ©rivÃ©es de read.table() (c-Ã -d.Â read.delim(), read.csv(), etc.). Si vous tenez absolument Ã  importer directement des donnÃ©es Ã  partir dâ€™un autre logiciel, vous devrez installer le paquet foreign ğŸ“¦ qui contient des fonctions permettant dâ€™importer des fichiers Minitab, SPSS, Stata et SAS. Pour les feuilles de calcul MS Excel et LO Calc, quelques paquets peuvent Ãªtre utilisÃ©s.\n\n3.3.3 Frustrations courantes liÃ©es Ã  lâ€™importation\nIl est assez courant dâ€™obtenir un tas de messages dâ€™erreur vraiment frustrants lorsque lâ€™on commence Ã  importer des donnÃ©es dans R. Le plus courant est sans doute\nError in file(file, \"rt\") : cannot open the connection\nIn addition: Warning message:\nIn file(file, \"rt\") :\n  cannot open file 'unicorns.txt': No such file or directory\nCe message dâ€™erreur vous indique que R ne peut pas trouver le fichier que vous essayez dâ€™importer. Il apparaÃ®t gÃ©nÃ©ralement pour lâ€™une ou lâ€™autre des raisons suivantes (ou pour toutes !). La premiÃ¨re est que vous avez fait une erreur dans lâ€™orthographe du nom de fichier ou du chemin dâ€™accÃ¨s au fichier. Une autre erreur frÃ©quente est dâ€™avoir oubliÃ© dâ€™inclure lâ€™extension du fichier dans le nom du fichier (par ex. .txt). Enfin, le fichier ne se trouve pas Ã  lâ€™endroit indiquÃ© ou vous avez utilisÃ© un chemin dâ€™accÃ¨s incorrect. Lâ€™utilisation de projets RStudio (Section 1.5) et dâ€™une structure de rÃ©pertoire logique (Section 1.4) permet dâ€™Ã©viter (limiter) ce type dâ€™erreurs.\nUne autre erreur trÃ¨s frÃ©quente est dâ€™oublier dâ€™inclure lâ€™Ã©lÃ©ment header = TRUE lorsque la premiÃ¨re ligne des donnÃ©es contient des noms de variables. Par exemple, si nous omettons cet argument lorsque nous importons notre fichier unicorns.txt tout semble correct au dÃ©but (pas de message dâ€™erreur au moins).\n\nlicornes_erreur &lt;- read.table(file = \"data/unicorns.txt\", sep = \"\\t\")\n\nmais lorsque nous jetons un coup dâ€™Å“il Ã  notre jeu de donnÃ©es en utilisant str()\n\nstr(licornes_erreur)\n\n'data.frame':   97 obs. of  8 variables:\n $ V1: chr  \"p_care\" \"care\" \"care\" \"care\" ...\n $ V2: chr  \"food\" \"medium\" \"medium\" \"medium\" ...\n $ V3: chr  \"block\" \"1\" \"1\" \"1\" ...\n $ V4: chr  \"height\" \"7.5\" \"10.7\" \"11.2\" ...\n $ V5: chr  \"weight\" \"7.62\" \"12.14\" \"12.76\" ...\n $ V6: chr  \"mane_size\" \"11.7\" \"14.1\" \"7.1\" ...\n $ V7: chr  \"fluffyness\" \"31.9\" \"46\" \"66.7\" ...\n $ V8: chr  \"horn_rings\" \"1\" \"10\" \"10\" ...\n\n\nNous constatons un problÃ¨me Ã©vident, toutes nos variables ont Ã©tÃ© importÃ©es en tant que facteurs et sont nommÃ©es V1, V2, V3 â€¦ V8. Le problÃ¨me vient du fait que nous nâ€™avons pas dit au read.table() que la premiÃ¨re ligne contient les noms des variables et donc elle les traite comme des donnÃ©es. DÃ¨s que nous avons une chaÃ®ne de caractÃ¨res dans lâ€™une de nos variable, R les traite comme des donnÃ©es de type caractÃ¨re (rappelez-vous que tous les Ã©lÃ©ments dâ€™un vecteur doivent contenir le mÃªme type de donnÃ©es (Section 3.2.1)).\nCe nâ€™est quâ€™un argument de plus pour utiliser read.csv() ou read.delim() avec des valeurs par dÃ©faut appropriÃ©es pour les arguments.\n\n3.3.4 Autres options dâ€™importation\nIl existe de nombreuses autres fonctions permettant dâ€™importer des donnÃ©es Ã  partir dâ€™une variÃ©tÃ© de sources et de formats. La plupart de ces fonctions sont contenues dans des paquets que vous devez installer avant de les utiliser. Vous trouverez ci-dessous une liste des paquets et des fonctions les plus utiles.\nLes paquets fread() du paquet data.table ğŸ“¦ est idÃ©ale pour importer rapidement et efficacement de grands fichiers de donnÃ©es (beaucoup plus rapidement que la fonction read.table()). Lâ€™un des aspects les plus intÃ©ressants de la fonction fread() est quâ€™elle dÃ©tecte automatiquement la plupart des arguments que vous devriez normalement spÃ©cifier (comme sep = etc.) Une choses Ã  prendre en compte cependant est que la fonction fread() renverra un objet de type data.table et non data.frame comme ce serait le cas avec la fonction read.table(). Ce nâ€™est gÃ©nÃ©ralement pas un problÃ¨me, car vous pouvez passer un objet data.table Ã  nâ€™importe quelle fonction nâ€™acceptant normalement que des objets data.frame. Pour en savoir plus sur les diffÃ©rences entre data.table et data.frame voir ici .\n\nlibrary(data.table)\ntoutes_donnees &lt;- fread(file = \"data/unicorns.txt\")\n\nDiverses fonctions du paquet readr ğŸ“¦ sont Ã©galement trÃ¨s efficaces pour lire des fichiers de donnÃ©es volumineux. Le paquet readr ğŸ“¦ fait partie de la collection de paquet â€˜tidyverseâ€™ et fournit de nombreuses fonctions Ã©quivalentes Ã  celles de la version de base de R pour lâ€™importation de donnÃ©es. Les fonctions de readr sont utilisÃ©es de la mÃªme maniÃ¨re que les fonctions read.table() ou read.csv() et la plupart des arguments sont les mÃªmes (voir ?readr::read_table pour plus de dÃ©tails). Il existe cependant quelques diffÃ©rences. Par exemple, lors de lâ€™utilisation de lâ€™option read_table() lâ€™argument header = TRUE est remplacÃ© par col_names = TRUE et la fonction renvoie un objet de classe tibble qui est lâ€™Ã©quivalent dans le tidyverse dâ€™un objet de classe data.frame (voir ici pour les diffÃ©rences).\n\n\n\n\n\n\nAvertissement\n\n\n\nAttention ! certain.e.s de vos modÃ¨les ou fonctions, etc. peuvent ne pas fonctionner ou fonctionner diffÃ©rement Ã  cause de Ã§a (vÃ©rifier/reconvertir votre jeu de donnÃ©es au format data.frame peut vous Ã©conomiser du temps de dÃ©beugage).\n\n\n\nlibrary(readr)\n# importation de fichiers dÃ©limitÃ©s par des espaces blancs\ntoutes_donnees &lt;- read_table(file = \"data/unicorns.txt\", col_names = TRUE)\n\n# importation de fichiers dÃ©limitÃ©s par des virgules\ntoutes_donnees &lt;- read_csv(file = \"data/unicorns.csv\")\n\n# importation de fichiers dÃ©limitÃ©s par des tabulations\ntoutes_donnees &lt;- read_delim(file = \"data/unicorns.txt\", delim = \"\\t\")\n\n# ou utilisez\ntoutes_donnees &lt;- read_tsv(file = \"data/unicorns.txt\")\n\nSi votre fichier de donnÃ©es est Ã©norme, les paquets ff ğŸ“¦ et bigmemory ğŸ“¦ peuvent Ãªtre utiles car ils contiennent tous deux des fonctions dâ€™importation capables de stocker des donnÃ©es volumineuses de maniÃ¨re efficace en termes de mÃ©moire. Pour en savoir plus sur ces fonctions ici et ici .",
    "crumbs": [
      "DonnÃ©es",
      "Utiliser R",
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>DonnÃ©es</span>"
    ]
  },
  {
    "objectID": "03-donnees.html#manipuler-des-jeux-de-donnÃ©es",
    "href": "03-donnees.html#manipuler-des-jeux-de-donnÃ©es",
    "title": "3Â  DonnÃ©es",
    "section": "\n3.4 Manipuler des jeux de donnÃ©es",
    "text": "3.4 Manipuler des jeux de donnÃ©es\nMaintenant que vous avez rÃ©ussi Ã  importer vos donnÃ©es dans R depuis un fichier externe, la prochaine Ã©tape est de faire quelque chose dâ€™utile avec nos donnÃ©es. La manipulation de donnÃ©es est une compÃ©tence fondamentale que vous devrez dÃ©velopper et avec laquelle vous devrez vous sentir Ã  lâ€™aise, car vous en ferez probablement beaucoup au cours de nâ€™importe quel projet. La bonne nouvelle, câ€™est que R est particuliÃ¨rement efficace pour manipuler, rÃ©sumer et visualiser les donnÃ©es. La manipulation de donnÃ©es (souvent connue sous le nom de â€œdata wranglingâ€ ou â€œmungingâ€) en R peut sembler un peu intimidante au dÃ©but pour un nouvel utilisateur, mais si vous suivez quelques rÃ¨gles logiques simples, vous prendrez rapidement le coup de main, surtout avec un peu de pratique.\nRappelons la structure du jeu de donnÃ©es licornes que nous avons importÃ©e dans la section prÃ©cÃ©dente :\n\nlicornes &lt;- read.table(file = \"data/unicorns.txt\", header = TRUE, sep = \"\\t\")\nstr(licornes)\n\n'data.frame':   96 obs. of  8 variables:\n $ p_care    : chr  \"care\" \"care\" \"care\" \"care\" ...\n $ food      : chr  \"medium\" \"medium\" \"medium\" \"medium\" ...\n $ block     : int  1 1 1 1 1 1 1 1 2 2 ...\n $ height    : num  7.5 10.7 11.2 10.4 10.4 9.8 6.9 9.4 10.4 12.3 ...\n $ weight    : num  7.62 12.14 12.76 8.78 13.58 ...\n $ mane_size : num  11.7 14.1 7.1 11.9 14.5 12.2 13.2 14 10.5 16.1 ...\n $ fluffyness: num  31.9 46 66.7 20.3 26.9 72.7 43.1 28.5 57.8 36.9 ...\n $ horn_rings: int  1 10 10 1 4 9 7 6 5 8 ...\n\n\nPour accÃ©der aux donnÃ©es de nâ€™importe quelle variable (colonne) de notre jeu de donnÃ©es, nous pouvons utiliser la notation $. Par exemple, pour accÃ©der Ã  la variable height dans le jeu de donnÃ©es licornes on Ã©crit licornes$height. Cela indique Ã  R que la variable height est contenue dans le jeu de donnÃ©es licornes.\n\nlicornes$height\n\n [1]  7.5 10.7 11.2 10.4 10.4  9.8  6.9  9.4 10.4 12.3 10.4 11.0  7.1  6.0  9.0\n[16]  4.5 12.6 10.0 10.0  8.5 14.1 10.1  8.5  6.5 11.5  7.7  6.4  8.8  9.2  6.2\n[31]  6.3 17.2  8.0  8.0  6.4  7.6  9.7 12.3  9.1  8.9  7.4  3.1  7.9  8.8  8.5\n[46]  5.6 11.5  5.8  5.6  5.3  7.5  4.1  3.5  8.5  4.9  2.5  5.4  3.9  5.8  4.5\n[61]  8.0  1.8  2.2  3.9  8.5  8.5  6.4  1.2  2.6 10.9  7.2  2.1  4.7  5.0  6.5\n[76]  2.6  6.0  9.3  4.6  5.2  3.9  2.3  5.2  2.2  4.5  1.8  3.0  3.7  2.4  5.7\n[91]  3.7  3.2  3.9  3.3  5.5  4.4\n\n\nCette opÃ©ration renvoie un vecteur des donnÃ©es de la variable height. Si nous le souhaitons, nous pouvons assigner ce vecteur Ã  un autre objet et faire dâ€™autres choses avec, comme calculer une moyenne ou obtenir un rÃ©sumÃ© de la variable Ã  lâ€™aide de la fonction summary() :\n\nf_taille &lt;- licornes$height\nmean(f_taille)\n\n[1] 6.839583\n\nsummary(f_taille)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  1.200   4.475   6.450   6.840   9.025  17.200 \n\n\nOu si nous ne voulons pas crÃ©er un objet supplÃ©mentaire, nous pouvons utiliser des fonctions â€œÃ  la volÃ©eâ€ pour afficher uniquement la valeur dans la console.\n\nmean(licornes$height)\n\n[1] 6.839583\n\nsummary(licornes$height)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  1.200   4.475   6.450   6.840   9.025  17.200 \n\n\nTout comme nous lâ€™avons fait avec les vecteurs (Section 2.5), nous pouvons Ã©galement accÃ©der aux donnÃ©es contenues dans le jeu de donnÃ©es en utilisant les crochets [ ]. Cependant, au lieu dâ€™utiliser un seul index, nous devons maintenant utiliser deux index, lâ€™un pour spÃ©cifier les lignes et lâ€™autre pour les colonnes. Pour ce faire, nous pouvons utiliser la notation mes_donnees[ligne, colonne] oÃ¹ ligne et colonne sont des indices et mes_donnees est le nom du jeu de donnÃ©es. Une fois encore, comme pour nos vecteurs, nos index peuvent Ãªtre positionnels ou rÃ©sulter dâ€™un test logique.\n\n3.4.1 Index positionnels\nPour utiliser les index positionnels, il suffit dâ€™Ã©crire la position des lignes et des colonnes que lâ€™on veut extraire Ã  lâ€™intÃ©rieur des crochets [ ]. Par exemple, si, pour une raison quelconque, nous voulons extraire la premiÃ¨re valeur (1Ã¨re ligne) de la variable height (4e colonne) :\n\nlicornes[1, 4]\n\n[1] 7.5\n\n# on peut obtenir le mÃªme rÃ©sultat avec cette notation :\nlicornes$height[1]\n\n[1] 7.5\n\n\nNous pouvons Ã©galement extraire les valeurs de plusieurs lignes ou colonnes en spÃ©cifiant ces index sous forme de vecteurs Ã  lâ€™intÃ©rieur des crochets [ ]. Pour extraire les 10 premiÃ¨res lignes et les 4 premiÃ¨res colonnes, il suffit de fournir un vecteur contenant une sÃ©quence de 1 Ã  10 pour lâ€™index des lignes (1:10) et un vecteur de 1 Ã  4 pour lâ€™index des colonnes (1:4) :\n\nlicornes[1:10, 1:4]\n\n   p_care   food block height\n1    care medium     1    7.5\n2    care medium     1   10.7\n3    care medium     1   11.2\n4    care medium     1   10.4\n5    care medium     1   10.4\n6    care medium     1    9.8\n7    care medium     1    6.9\n8    care medium     1    9.4\n9    care medium     2   10.4\n10   care medium     2   12.3\n\n\nSi les lignes et les colonnes ne sont pas sÃ©quentielles, nous pouvons fournir des vecteurs de positions Ã  lâ€™aide de la fonction c(). Pour extraire les 1Ã¨re, 5e, 12e et 30e lignes des 1Ã¨re, 3e, 6e et 8e colonnes :\n\nlicornes[c(1, 5, 12, 30), c(1, 3, 6, 8)]\n\n   p_care block mane_size horn_rings\n1    care     1      11.7          1\n5    care     1      14.5          4\n12   care     2      12.6          6\n30   care     2      11.6          5\n\n\nTout ce que nous faisons dans les deux exemples ci-dessus est de crÃ©er des vecteurs de positions pour les lignes et les colonnes que nous voulons extraire. Pour ce faire, nous avons utilisÃ© les compÃ©tences que nous avons dÃ©veloppÃ©es dans la Section 2.4 lorsque nous avons gÃ©nÃ©rÃ© des vecteurs Ã  lâ€™aide de la fonction c() ou en utilisant la notation :.\nMais quâ€™en est-il si nous voulons extraire toutes les lignes ou toutes les colonnes ? Il serait extrÃªmement fastidieux de devoir gÃ©nÃ©rer des vecteurs pour toutes les lignes ou pour toutes les colonnes. Heureusement, R dispose dâ€™un raccourci. Si vous ne spÃ©cifiez pas dâ€™index de ligne ou de colonne dans les crochets [ ] R interprÃ¨te cela comme signifiant que vous voulez toutes les lignes ou toutes les colonnes. Par exemple, pour extraire les 4 premiÃ¨res lignes et toutes les colonnes du jeu de donnÃ©es licornes :\n\nlicornes[1:4, ]\n\n  p_care   food block height weight mane_size fluffyness horn_rings\n1   care medium     1    7.5   7.62      11.7       31.9          1\n2   care medium     1   10.7  12.14      14.1       46.0         10\n3   care medium     1   11.2  12.76       7.1       66.7         10\n4   care medium     1   10.4   8.78      11.9       20.3          1\n\n\nou toutes les lignes et les 3 premiÃ¨res colonnes 1 .\nunicorns[, 1:3]\n\n\n    p_care   food block\n1     care medium     1\n2     care medium     1\n3     care medium     1\n4     care medium     1\n5     care medium     1\n92 no_care    low     2\n93 no_care    low     2\n94 no_care    low     2\n95 no_care    low     2\n96 no_care    low     2\n\n\nNous pouvons mÃªme utiliser des index de position nÃ©gatifs pour exclure certaines lignes et colonnes. Par exemple, extrayons toutes les lignes Ã  lâ€™exception des 85 premiÃ¨res et toutes les colonnes Ã  lâ€™exception de la 4e, 7e et 8e. Remarquez que nous devons utiliser -() lorsque nous gÃ©nÃ©rons nos vecteurs de position de ligne. Si nous avions simplement utilisÃ© -1:85 cela gÃ©nÃ©rerait en fait une sÃ©quence rÃ©guliÃ¨re de -1 Ã  85, ce qui nâ€™est pas ce que nous voulons (nous pouvons bien sÃ»r utiliser -1:-85).\n\nlicornes[-(1:85), -c(4, 7, 8)]\n\n    p_care food block weight mane_size\n86 no_care  low     1   6.01      17.6\n87 no_care  low     1   9.93      12.0\n88 no_care  low     1   7.03       7.9\n89 no_care  low     2   9.10      14.5\n90 no_care  low     2   9.05       9.6\n91 no_care  low     2   8.10      10.5\n92 no_care  low     2   7.45      14.1\n93 no_care  low     2   9.19      12.4\n94 no_care  low     2   8.92      11.6\n95 no_care  low     2   8.44      13.5\n96 no_care  low     2  10.60      16.2\n\n\nOutre lâ€™utilisation dâ€™un index de position pour extraire des colonnes (variables) particuliÃ¨res, nous pouvons Ã©galement nommer les variables directement en utilisant les crochet [ ]. Par exemple, extrayons les 5 premiÃ¨res lignes des variables care, food et mane_size. Au lieu dâ€™utiliser licornes[1:5, c(1, 2, 6)] nous pouvons utiliser :\n\nlicornes[1:5, c(\"p_care\", \"food\", \"mane_size\")]\n\n  p_care   food mane_size\n1   care medium      11.7\n2   care medium      14.1\n3   care medium       7.1\n4   care medium      11.9\n5   care medium      14.5\n\n\nEn gÃ©nÃ©ral, on prÃ©fÃ©rera utiliser cette mÃ©thode plutÃ´t que lâ€™index positionnel pour sÃ©lectionner les colonnes, car elle nous donnera toujours ce que nous voulons mÃªme si nous avons changÃ© lâ€™ordre des colonnes dans notre jeu de donnÃ©es pour une raison quelconque.\n\n3.4.2 Index logiques\nTout comme nous lâ€™avons fait avec les vecteurs, nous pouvons Ã©galement extraire des donnÃ©es de notre jeu de donnÃ©es sur la base dâ€™un test logique. Nous pouvons utiliser tous les opÃ©rateurs logiques que nous avons utilisÃ©s dans les exemples des vecteurs. Si ceux-ci vous ont Ã©chappÃ©, jetez un coup dâ€™Å“il Ã  la Section 2.5.1.1 pour vous rafraÃ®chir la mÃ©moire. Extrayons toutes les lignes pour lesquelles la variable height a une valeur supÃ©rieure Ã  12 et extrayons toutes les colonnes par dÃ©faut (rappelez-vous, si vous nâ€™incluez pas dâ€™index de colonne aprÃ¨s la virgule, cela signifie toutes les colonnes).\n\ngrandes_cornes &lt;- licornes[licornes$height &gt; 12, ]\ngrandes_cornes\n\n   p_care   food block height weight mane_size fluffyness horn_rings\n10   care medium     2   12.3  13.48      16.1       36.9          8\n17   care   high     1   12.6  18.66      18.6       54.0          9\n21   care   high     1   14.1  19.12      13.1      113.2         13\n32   care   high     2   17.2  19.20      10.9       89.9         14\n38   care    low     1   12.3  11.27      13.7       28.7          5\n\n\nRemarquez dans le code ci-dessus quâ€™il faut utiliser lâ€™Ã©lÃ©ment licornes$height pour le test logique. Si nous nommions simplement la variable height sans le nom du jeu de donnÃ©es, nous recevrions une erreur nous indiquant que R ne peut pas trouver la variable height. La raison en est que la variable height nâ€™existe quâ€™Ã  lâ€™intÃ©rieur du jeu de donnÃ©es licornes vous devez donc indiquer Ã  R oÃ¹ elle se trouve exactement.\ngrandes_cornes &lt;- licornes[height &gt; 12, ]\nError in `[.data.frame`(licornes, height &gt; 12, ) : \n  object 'height' not found\nComment cela fonctionne-t-il ? Le test logique est le suivant licornes$height &gt; 12 et R nâ€™extraira que les lignes qui satisfont Ã  cette condition logique. Si nous regardons la sortie de la seule condition logique, vous pouvez voir quâ€™elle renvoie un vecteur contenant TRUE si height est supÃ©rieur Ã  12 et FALSE si height nâ€™est pas supÃ©rieur Ã  12.\n\nlicornes$height &gt; 12\n\n [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE\n[13] FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE\n[25] FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE\n[37] FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[49] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[61] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[73] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[85] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n\n\nNotre indice de ligne est donc un vecteur contenant soit TRUE ou FALSE et seulement les lignes qui sont TRUE sont sÃ©lectionnÃ©es.\nDâ€™autres opÃ©rateurs couramment utilisÃ©s sont prÃ©sentÃ©s ci-dessous :\n\nlicornes[licornes$height &gt;= 6, ] # valeurs supÃ©rieures ou Ã©gales Ã  6\n\nlicornes[licornes$height &lt;= 6, ] # valeurs infÃ©rieures ou Ã©gales Ã  6\n\nlicornes[licornes$height == 8, ] # valeurs Ã©gales Ã  8\n\nlicornes[licornes$height != 8, ] # valeurs diffÃ©rentes de 8\n\nNous pouvons Ã©galement extraire des lignes en fonction de la valeur dâ€™une chaÃ®ne de caractÃ¨res ou dâ€™un niveau de facteur. Extrayons toutes les lignes pour lesquelles la valeur de la variable food est Ã©gal Ã  high (lÃ  encore, nous extrairons toutes les colonnes). Remarquez que la double Ã©galitÃ© == doit Ãªtre utilisÃ© pour un test logique et que la chaÃ®ne de caractÃ¨res doit Ãªtre placÃ©e entre guillemets simples ou doubles (c.-Ã -d. \"high\").\n\nnourriture_bcp &lt;- licornes[licornes$food == \"high\", ]\nrbind(head(nourriture_bcp, n = 10), tail(nourriture_bcp, n = 10))\n\n    p_care food block height weight mane_size fluffyness horn_rings\n17    care high     1   12.6  18.66      18.6       54.0          9\n18    care high     1   10.0  18.07      16.9       90.5          3\n19    care high     1   10.0  13.29      15.8      142.7         12\n20    care high     1    8.5  14.33      13.2       91.4          5\n21    care high     1   14.1  19.12      13.1      113.2         13\n22    care high     1   10.1  15.49      12.6       77.2         12\n23    care high     1    8.5  17.82      20.5       54.4          3\n24    care high     1    6.5  17.13      24.1      147.4          6\n25    care high     2   11.5  23.89      14.3      101.5         12\n26    care high     2    7.7  14.77      17.2      104.5          4\n71 no_care high     1    7.2  15.21      15.9      135.0         14\n72 no_care high     1    2.1  19.15      15.6      176.7          6\n73 no_care high     2    4.7  13.42      19.8      124.7          5\n74 no_care high     2    5.0  16.82      17.3      182.5         15\n75 no_care high     2    6.5  14.00      10.1      126.5          7\n76 no_care high     2    2.6  18.88      16.4      181.5         14\n77 no_care high     2    6.0  13.68      16.2      133.7          2\n78 no_care high     2    9.3  18.75      18.4      181.1         16\n79 no_care high     2    4.6  14.65      16.7       91.7         11\n80 no_care high     2    5.2  17.70      19.1      181.1          8\n\n\nOu nous pouvons extraire toutes les lignes oÃ¹ food est diffÃ©rent de medium (en utilisant !=) et ne sÃ©lectionner que les colonnes 1 Ã  4.\n\nnourriture_pas_moyenne &lt;- licornes[licornes$food != \"medium\", 1:4]\nrbind(head(nourriture_pas_moyenne, n = 10), tail(nourriture_pas_moyenne, n = 10))\n\n    p_care food block height\n17    care high     1   12.6\n18    care high     1   10.0\n19    care high     1   10.0\n20    care high     1    8.5\n21    care high     1   14.1\n22    care high     1   10.1\n23    care high     1    8.5\n24    care high     1    6.5\n25    care high     2   11.5\n26    care high     2    7.7\n87 no_care  low     1    3.0\n88 no_care  low     1    3.7\n89 no_care  low     2    2.4\n90 no_care  low     2    5.7\n91 no_care  low     2    3.7\n92 no_care  low     2    3.2\n93 no_care  low     2    3.9\n94 no_care  low     2    3.3\n95 no_care  low     2    5.5\n96 no_care  low     2    4.4\n\n\nNous pouvons accroÃ®tre la complexitÃ© de nos tests logiques en les combinant avec des des expressions boolÃ©ennes comme nous lâ€™avons fait pour les objets vectoriels. Par exemple, pour extraire toutes les lignes oÃ¹ la taille (height) est supÃ©rieure ou Ã©gale Ã  6 ET food est Ã©gal Ã  medium ET care est Ã©gal Ã  no_care nous combinons une sÃ©rie dâ€™expressions logiques avec le symbole & :\n\nfaible_soins_non_taille6 &lt;- licornes[licornes$height &gt;= 6 &\n                                       licornes$food == \"medium\" &\n                                       licornes$p_care == \"no_care\", ]\nfaible_soins_non_taille6\n\n    p_care   food block height weight mane_size fluffyness horn_rings\n51 no_care medium     1    7.5  13.60      13.6      122.2         11\n54 no_care medium     1    8.5  10.04      12.3      113.6          4\n61 no_care medium     2    8.0  11.43      12.6       43.2         14\n\n\nPour extraire des lignes sur la base dâ€™une expression boolÃ©enne â€œORâ€ (â€œOUâ€), nous pouvons utiliser le symbole |. Extrayons toutes les lignes oÃ¹ la taille (height) est supÃ©rieure Ã  12,3 OU infÃ©rieure Ã  2,2.\n\ntaille2.2_12.3 &lt;- licornes[licornes$height &gt; 12.3 | licornes$height &lt; 2.2, ]\ntaille2.2_12.3\n\n    p_care   food block height weight mane_size fluffyness horn_rings\n17    care   high     1   12.6  18.66      18.6       54.0          9\n21    care   high     1   14.1  19.12      13.1      113.2         13\n32    care   high     2   17.2  19.20      10.9       89.9         14\n62 no_care medium     2    1.8  10.47      11.8      120.8          9\n68 no_care   high     1    1.2  18.24      16.6      148.1          7\n72 no_care   high     1    2.1  19.15      15.6      176.7          6\n86 no_care    low     1    1.8   6.01      17.6       46.2          4\n\n\nUne autre mÃ©thode pour sÃ©lectionner des parties dâ€™un jeu de donnÃ©es sur la base dâ€™une expression logique consiste Ã  utiliser la fonction subset() au lieu des crochets [ ]. Lâ€™avantage dâ€™utiliser subset() est quâ€™il nâ€™est plus nÃ©cessaire dâ€™utiliser le symbole $ pour spÃ©cifier des variables Ã  lâ€™intÃ©rieur du jeu de donnÃ©es, car le premier argument de la fonction est le nom du jeu de donnÃ©es Ã  subdiviser. Lâ€™inconvÃ©nient est que subset() est moins flexible que la notation [ ].\n\nsoins_moy_2 &lt;- subset(licornes, p_care == \"care\" & food == \"medium\" & block == 2)\nsoins_moy_2\n\n   p_care   food block height weight mane_size fluffyness horn_rings\n9    care medium     2   10.4  10.48      10.5       57.8          5\n10   care medium     2   12.3  13.48      16.1       36.9          8\n11   care medium     2   10.4  13.18      11.1       56.8         12\n12   care medium     2   11.0  11.56      12.6       31.3          6\n13   care medium     2    7.1   8.16      29.6        9.7          2\n14   care medium     2    6.0  11.22      13.0       16.4          3\n15   care medium     2    9.0  10.20      10.8       90.1          6\n16   care medium     2    4.5  12.55      13.4       14.4          6\n\n\nEt si vous ne voulez que certaines colonnes, vous pouvez utiliser lâ€™arguement select = :\n\nuni_p_care &lt;- subset(licornes, p_care == \"care\" & food == \"medium\" & block == 2,\n  select = c(\"p_care\", \"food\", \"mane_size\")\n)\nuni_p_care\n\n   p_care   food mane_size\n9    care medium      10.5\n10   care medium      16.1\n11   care medium      11.1\n12   care medium      12.6\n13   care medium      29.6\n14   care medium      13.0\n15   care medium      10.8\n16   care medium      13.4\n\n\n\n3.4.3 Ordonner un jeu de donnÃ©es\nRappelez-vous lorsque nous avons utilisÃ© la fonction order() pour ordonner un vecteur en fonction de lâ€™ordre dâ€™un autre vecteur (dans la Section 2.5.3). Cette fonction est trÃ¨s utile si vous souhaitez rÃ©organiser les lignes de votre jeu de donnÃ©es. Par exemple, si nous voulons que toutes les lignes du jeu de donnÃ©es licornes soient classÃ©es par ordre croissant en fonction de la variable height et Ã©diter toutes les colonnes par dÃ©faut :\n\ntaille_ord &lt;- licornes[order(licornes$height), ]\nhead(taille_ord, n = 10)\n\n    p_care   food block height weight mane_size fluffyness horn_rings\n68 no_care   high     1    1.2  18.24      16.6      148.1          7\n62 no_care medium     2    1.8  10.47      11.8      120.8          9\n86 no_care    low     1    1.8   6.01      17.6       46.2          4\n72 no_care   high     1    2.1  19.15      15.6      176.7          6\n63 no_care medium     2    2.2  10.70      15.3       97.1          7\n84 no_care    low     1    2.2   9.97       9.6       63.1          2\n82 no_care    low     1    2.3   7.28      13.8       32.8          6\n89 no_care    low     2    2.4   9.10      14.5       78.7          8\n56 no_care medium     1    2.5  14.85      17.5       77.8         10\n69 no_care   high     1    2.6  16.57      17.1      141.1          3\n\n\nNous pouvons Ã©galement ordonner par ordre dÃ©croissant dâ€™une variable (i.e. mane_size) en utilisant lâ€™argument decreasing = TRUE :\n\ntaille_criniere_ord &lt;- licornes[order(licornes$mane_size, decreasing = TRUE), ]\nhead(taille_criniere_ord, n = 10)\n\n    p_care   food block height weight mane_size fluffyness horn_rings\n70 no_care   high     1   10.9  17.22      49.2      189.6         17\n13    care medium     2    7.1   8.16      29.6        9.7          2\n24    care   high     1    6.5  17.13      24.1      147.4          6\n65 no_care   high     1    8.5  22.53      20.8      166.9         16\n23    care   high     1    8.5  17.82      20.5       54.4          3\n66 no_care   high     1    8.5  17.33      19.8      184.4         12\n73 no_care   high     2    4.7  13.42      19.8      124.7          5\n80 no_care   high     2    5.2  17.70      19.1      181.1          8\n17    care   high     1   12.6  18.66      18.6       54.0          9\n49 no_care medium     1    5.6  11.03      18.6       49.9          8\n\n\nNous pouvons mÃªme ordonner des jeux de donnÃ©es sur la base de plusieurs variables. Par exemple, pour ordonner le jeu de donnÃ©es licornes dans lâ€™ordre croissant des deux variables block et height :\n\nbloc_taille_ord &lt;- licornes[order(licornes$block, licornes$height), ]\nhead(bloc_taille_ord, n = 10)\n\n    p_care   food block height weight mane_size fluffyness horn_rings\n68 no_care   high     1    1.2  18.24      16.6      148.1          7\n86 no_care    low     1    1.8   6.01      17.6       46.2          4\n72 no_care   high     1    2.1  19.15      15.6      176.7          6\n84 no_care    low     1    2.2   9.97       9.6       63.1          2\n82 no_care    low     1    2.3   7.28      13.8       32.8          6\n56 no_care medium     1    2.5  14.85      17.5       77.8         10\n69 no_care   high     1    2.6  16.57      17.1      141.1          3\n87 no_care    low     1    3.0   9.93      12.0       56.6          6\n53 no_care medium     1    3.5  12.93      16.6      109.3          3\n88 no_care    low     1    3.7   7.03       7.9       36.7          5\n\n\nEt si nous voulions ordonner licornes par ordre croissant selon la variable block mais par ordre dÃ©croissant de height? Nous pouvons utiliser une astuce simple en ajoutant un - avant lâ€™argument licornes$height lorsque nous utilisons la fonction order(). Cela transformera essentiellement toutes les valeurs de height en nÃ©gatives, ce qui aura pour effet dâ€™inverser lâ€™ordre. Notez que cette astuce ne fonctionne quâ€™avec des variables numÃ©riques.\n\nbloc_invtaille_ord &lt;- licornes[order(licornes$block, -licornes$height), ]\nrbind(head(bloc_invtaille_ord, n = 10), tail(bloc_invtaille_ord, n = 10))\n\n    p_care   food block height weight mane_size fluffyness horn_rings\n21    care   high     1   14.1  19.12      13.1      113.2         13\n17    care   high     1   12.6  18.66      18.6       54.0          9\n38    care    low     1   12.3  11.27      13.7       28.7          5\n3     care medium     1   11.2  12.76       7.1       66.7         10\n70 no_care   high     1   10.9  17.22      49.2      189.6         17\n2     care medium     1   10.7  12.14      14.1       46.0         10\n4     care medium     1   10.4   8.78      11.9       20.3          1\n5     care medium     1   10.4  13.58      14.5       26.9          4\n22    care   high     1   10.1  15.49      12.6       77.2         12\n18    care   high     1   10.0  18.07      16.9       90.5          3\n64 no_care medium     2    3.9  12.97      17.0       97.5          5\n93 no_care    low     2    3.9   9.19      12.4       52.6          9\n91 no_care    low     2    3.7   8.10      10.5       60.5          6\n94 no_care    low     2    3.3   8.92      11.6       55.2          6\n92 no_care    low     2    3.2   7.45      14.1       38.1          4\n42    care    low     2    3.1   8.74      16.1       39.1          3\n76 no_care   high     2    2.6  18.88      16.4      181.5         14\n89 no_care    low     2    2.4   9.10      14.5       78.7          8\n63 no_care medium     2    2.2  10.70      15.3       97.1          7\n62 no_care medium     2    1.8  10.47      11.8      120.8          9\n\n\nSi nous voulons faire la mÃªme chose avec une variable de type facteur (ou caractÃ¨re) comme food il faut utiliser la fonction xtfrm() sur cette variable, Ã  lâ€™intÃ©rieur de notre fonction order() :\n\ninvnourriture_taille_ord &lt;- licornes[order(-xtfrm(licornes$food), licornes$height), ]\nrbind(head(invnourriture_taille_ord, n = 10), tail(invnourriture_taille_ord, n = 10))\n\n    p_care   food block height weight mane_size fluffyness horn_rings\n62 no_care medium     2    1.8  10.47      11.8      120.8          9\n63 no_care medium     2    2.2  10.70      15.3       97.1          7\n56 no_care medium     1    2.5  14.85      17.5       77.8         10\n53 no_care medium     1    3.5  12.93      16.6      109.3          3\n58 no_care medium     2    3.9   9.07       9.6       90.4          7\n64 no_care medium     2    3.9  12.97      17.0       97.5          5\n52 no_care medium     1    4.1  12.58      13.9      136.6         11\n16    care medium     2    4.5  12.55      13.4       14.4          6\n60 no_care medium     2    4.5  13.68      14.8      125.5          9\n55 no_care medium     1    4.9   6.89       8.2       52.9          3\n29    care   high     2    9.2  13.26      11.3      108.0          9\n78 no_care   high     2    9.3  18.75      18.4      181.1         16\n18    care   high     1   10.0  18.07      16.9       90.5          3\n19    care   high     1   10.0  13.29      15.8      142.7         12\n22    care   high     1   10.1  15.49      12.6       77.2         12\n70 no_care   high     1   10.9  17.22      49.2      189.6         17\n25    care   high     2   11.5  23.89      14.3      101.5         12\n17    care   high     1   12.6  18.66      18.6       54.0          9\n21    care   high     1   14.1  19.12      13.1      113.2         13\n32    care   high     2   17.2  19.20      10.9       89.9         14\n\n\nIl est Ã  noter que la variable food a Ã©tÃ© classÃ©e dans lâ€™ordre alphabÃ©tique inverse et que la variable height a Ã©tÃ© ordonnÃ©e par valeurs croissantes, Ã  lâ€™intÃ©rieur de chaque niveau de food.\nSi nous voulions ordonner le jeu de donnÃ©es selon les niveau de la variable food, c.-Ã -d.Â low â€“&gt; medium â€“&gt; high au lieu de lâ€™ordre alphabÃ©tique par dÃ©faut (high, low, medium), nous devons dâ€™abord modifier lâ€™ordre des niveaux de food dans le jeu de donnÃ©es Ã  lâ€™aide de la fonction factor(). Une fois que nous avons fait cela, nous pouvons utiliser la fonction order() comme dâ€™habitude. Remarque : si vous lisez la version pdf de ce livre, la sortie a Ã©tÃ© tronquÃ©e pour Ã©conomiser de lâ€™espace.\n\nlicornes$food &lt;- factor(licornes$food,\n  levels = c(\"low\", \"medium\", \"high\")\n)\nnourriture_ord &lt;- licornes[order(licornes$food), ]\nrbind(head(nourriture_ord, n = 10), tail(nourriture_ord, n = 10))\n\n    p_care food block height weight mane_size fluffyness horn_rings\n33    care  low     1    8.0   6.88       9.3       16.1          4\n34    care  low     1    8.0  10.23      11.9       88.1          4\n35    care  low     1    6.4   5.97       8.7        7.3          2\n36    care  low     1    7.6  13.05       7.2       47.2          8\n37    care  low     1    9.7   6.49       8.1       18.0          3\n38    care  low     1   12.3  11.27      13.7       28.7          5\n39    care  low     1    9.1   8.96       9.7       23.8          3\n40    care  low     1    8.9  11.48      11.1       39.4          7\n41    care  low     2    7.4  10.89      13.3        9.5          5\n42    care  low     2    3.1   8.74      16.1       39.1          3\n71 no_care high     1    7.2  15.21      15.9      135.0         14\n72 no_care high     1    2.1  19.15      15.6      176.7          6\n73 no_care high     2    4.7  13.42      19.8      124.7          5\n74 no_care high     2    5.0  16.82      17.3      182.5         15\n75 no_care high     2    6.5  14.00      10.1      126.5          7\n76 no_care high     2    2.6  18.88      16.4      181.5         14\n77 no_care high     2    6.0  13.68      16.2      133.7          2\n78 no_care high     2    9.3  18.75      18.4      181.1         16\n79 no_care high     2    4.6  14.65      16.7       91.7         11\n80 no_care high     2    5.2  17.70      19.1      181.1          8\n\n\n\n3.4.4 Ajout de colonnes et de lignes\nIl est parfois utile de pouvoir ajouter des lignes et des colonnes de donnÃ©es supplÃ©mentaires Ã  nos jeux de donnÃ©es. Il existe plusieurs faÃ§ons dâ€™y parvenir (comme toujours en R !) en fonction des circonstances. Pour ajouter simplement des lignes supplÃ©mentaires Ã  un jeu de donnÃ©es existant, nous pouvons utiliser la fonction rbind() (row/â€˜ligneâ€™ - bind/â€˜liaisonâ€™)  et pour ajouter des colonnes, la fonction cbind() (columns/â€˜colonnesâ€™ - bind/â€˜liaisonâ€™) . CrÃ©ons quelques jeux de donnÃ©es test pour voir cela en action en utilisant notre vieille amie, la fonction data.frame() :\n\n# rbind pour les lignes ('rows')\ndf1 &lt;- data.frame(\n  id = 1:4, taille = c(120, 150, 132, 122),\n  poids = c(44, 56, 49, 45)\n)\ndf1\n\n  id taille poids\n1  1    120    44\n2  2    150    56\n3  3    132    49\n4  4    122    45\n\ndf2 &lt;- data.frame(\n  id = 5:6, taille = c(119, 110),\n  poids = c(39, 35)\n)\ndf2\n\n  id taille poids\n1  5    119    39\n2  6    110    35\n\ndf3 &lt;- data.frame(\n  id = 1:4, taille = c(120, 150, 132, 122),\n  poids = c(44, 56, 49, 45)\n)\ndf3\n\n  id taille poids\n1  1    120    44\n2  2    150    56\n3  3    132    49\n4  4    122    45\n\ndf4 &lt;- data.frame(localisation = c(\"UK\", \"CZ\", \"CZ\", \"UK\"))\ndf4\n\n  localisation\n1           UK\n2           CZ\n3           CZ\n4           UK\n\n\nNous pouvons utiliser la fonction rbind() pour ajouter les lignes du jeu de donnÃ©es df2 aux lignes de df1 et crÃ©er le nouveau jeu de donnÃ©es Ã  df_lcomb :\n\ndf_lcomb &lt;- rbind(df1, df2)\ndf_lcomb\n\n  id taille poids\n1  1    120    44\n2  2    150    56\n3  3    132    49\n4  4    122    45\n5  5    119    39\n6  6    110    35\n\n\nEt cbind pour ajouter la colonne de df4 Ã  la colonne df3 et lâ€™assigner Ã  df_ccomb :\n\ndf_ccomb &lt;- cbind(df3, df4)\ndf_ccomb\n\n  id height weight location\n1  1    120     44       UK\n2  2    150     56       CZ\n3  3    132     49       CZ\n4  4    122     45       UK\n\n\nUne autre situation dans laquelle lâ€™ajout dâ€™une nouvelle colonne Ã  un jeu de donnÃ©es est utile est lorsque vous souhaitez effectuer une sorte de transformation sur une variable existante. Par exemple, supposons que nous voulions appliquer une transformation logarithmique, log10 Ã  une variable existante, la variable taille dans le jeu de donnÃ©es df_rcomb que nous avons crÃ©Ã©e ci-dessus. Nous pourrions simplement crÃ©er une variable distincte contenant ces valeurs, mais il est prÃ©fÃ©rable de crÃ©er cette variable directement en tant que nouvelle colonne dans notre jeu de donnÃ©es existant afin de conserver toutes nos donnÃ©es ensemble. Appelons cette nouvelle variable taille_log10.\n\n# transformation log10\ndf_lcomb$taille_log10 &lt;- log10(df_lcomb$taille)\ndf_lcomb\n\n  id taille poids taille_log10\n1  1    120    44     2.079181\n2  2    150    56     2.176091\n3  3    132    49     2.120574\n4  4    122    45     2.086360\n5  5    119    39     2.075547\n6  6    110    35     2.041393\n\n\nCette situation survient Ã©galement lorsque nous voulons changer le type dâ€™une variable existante dans un jeu de donnÃ©es. Par exemple, la variable id dans la base de donnÃ©es df_lcomb est une donnÃ©e de type numÃ©rique (utilisez la fonction str() ou class() pour le vÃ©rifier). Si nous voulions convertir id en un facteur Ã  utiliser plus tard dans notre analyse, nous pouvons crÃ©er une nouvelle variable appelÃ©e id_f dans notre jeu de donnÃ©es et utiliser la fonction factor() pour convertir la variable id.\n\n# conversion en un facteur\ndf_lcomb$id_f &lt;- factor(df_lcomb$id)\ndf_lcomb\n\n  id taille poids taille_log10 id_f\n1  1    120    44     2.079181    1\n2  2    150    56     2.176091    2\n3  3    132    49     2.120574    3\n4  4    122    45     2.086360    4\n5  5    119    39     2.075547    5\n6  6    110    35     2.041393    6\n\nstr(df_lcomb)\n\n'data.frame':   6 obs. of  5 variables:\n $ id          : int  1 2 3 4 5 6\n $ taille      : num  120 150 132 122 119 110\n $ poids       : num  44 56 49 45 39 35\n $ taille_log10: num  2.08 2.18 2.12 2.09 2.08 ...\n $ id_f        : Factor w/ 6 levels \"1\",\"2\",\"3\",\"4\",..: 1 2 3 4 5 6\n\n\n\n3.4.5 Fusionner des jeux de donnÃ©es\nAu lieu dâ€™ajouter simplement des lignes ou des colonnes Ã  un jeu de donnÃ©es, nous pouvons Ã©galement fusionner deux jeux de donnÃ©es. Supposons que nous ayons un jeu de donnÃ©es contenant des informations taxonomiques sur certains invertÃ©brÃ©s communs des cÃ´tes rocheuses du Royaume-Uni (appelÃ© taxa) et un autre jeu de donnÃ©es qui contient des informations sur lâ€™endroit oÃ¹ ils se trouvent habituellement sur le littoral rocheux (appelÃ© zone). Nous pouvons fusionner ces jeux cadres de donnÃ©es pour produire un seul jeu de donnÃ©es contenant Ã  la fois des informations taxonomiques et des informations sur lâ€™emplacement. CommenÃ§ons par crÃ©er ces deux jeux de donnÃ©es (en rÃ©alitÃ©, il vous suffira probablement dâ€™importer vos diffÃ©rents ensembles de donnÃ©es).\n\ntaxa &lt;- data.frame(\n  GENUS = c(\"Patella\", \"Littorina\", \"Halichondria\", \"Semibalanus\"),\n  espece = c(\"vulgata\", \"littoria\", \"panacea\", \"balanoides\"),\n  famille = c(\"patellidae\", \"Littorinidae\", \"Halichondriidae\", \"Archaeobalanidae\")\n)\ntaxa\n\n         GENUS     espece          famille\n1      Patella    vulgata       patellidae\n2    Littorina   littoria     Littorinidae\n3 Halichondria    panacea  Halichondriidae\n4  Semibalanus balanoides Archaeobalanidae\n\nzone &lt;- data.frame(\n  genus = c(\n    \"Laminaria\", \"Halichondria\", \"Xanthoria\", \"Littorina\",\n    \"Semibalanus\", \"Fucus\"\n  ),\n  espece = c(\n    \"digitata\", \"panacea\", \"parietina\", \"littoria\",\n    \"balanoides\", \"serratus\"\n  ),\n  zone = c(\"v_bas\", \"bas\", \"v_haut\", \"bas_moy\", \"haut\", \"bas_moy\")\n)\nzone\n\n         genus     espece    zone\n1    Laminaria   digitata   v_bas\n2 Halichondria    panacea     bas\n3    Xanthoria  parietina  v_haut\n4    Littorina   littoria bas_moy\n5  Semibalanus balanoides    haut\n6        Fucus   serratus bas_moy\n\n\nPuisque nos deux jeux de donnÃ©es contiennent au moins une variable en commun (espece dans notre cas), nous pouvons simplement utiliser la fonction merge() (â€˜fusionnerâ€™) pour crÃ©er un nouveau jeu de donnÃ©es appelÃ© taxa_zone.\n\ntaxa_zone &lt;- merge(x = taxa, y = zone)\ntaxa_zone\n\n     species        GENUS           family        genus    zone\n1 balanoides  Semibalanus Archaeobalanidae  Semibalanus    high\n2   littoria    Littorina     Littorinidae    Littorina low_mid\n3    panacea Halichondria  Halichondriidae Halichondria     low\n\n\nRemarquez que le jeu de donnÃ©es fusionnÃ© ne contient que les lignes ayant des espÃ¨ces dans les 2 jeux de donnÃ©es. Il existe Ã©galement deux colonnes appelÃ©es GENUS et genus car la fonction merge() les traite comme deux variables diffÃ©rentes provenant des deux jeux de donnÃ©es.\nSi nous voulons inclure toutes les donnÃ©es des deux jeux de donnÃ©es, nous devrons utiliser lâ€™argument all = TRUE dans la fonction merge(). Les valeurs manquantes seront incluses en tant que NA :\n\ntaxa_zone &lt;- merge(x = taxa, y = zone, all = TRUE)\ntaxa_zone\n\n     species        GENUS           family        genus    zone\n1 balanoides  Semibalanus Archaeobalanidae  Semibalanus    high\n2   digitata         &lt;NA&gt;             &lt;NA&gt;    Laminaria   v_low\n3   littoria    Littorina     Littorinidae    Littorina low_mid\n4    panacea Halichondria  Halichondriidae Halichondria     low\n5  parietina         &lt;NA&gt;             &lt;NA&gt;    Xanthoria  v_high\n6   serratus         &lt;NA&gt;             &lt;NA&gt;        Fucus low_mid\n7    vulgata      Patella       patellidae         &lt;NA&gt;    &lt;NA&gt;\n\n\nSi les noms des variables sur lesquelles vous souhaitez baser la fusion sont diffÃ©rents dans chaque jeux de donnÃ©es (par exemple GENUS et genus), vous pouvez spÃ©cifier les noms dans le premier jeu de donnÃ©es (appelÃ© x) et dans le second jeu de donnÃ©es (appelÃ© y) Ã  lâ€™aide des arguments by.x = et by.y =.\n\ntaxa_zone &lt;- merge(x = taxa, y = zone, by.x = \"GENUS\", by.y = \"genus\", all = TRUE)\ntaxa_zone\n\n         GENUS  species.x           family  species.y    zone\n1        Fucus       &lt;NA&gt;             &lt;NA&gt;   serratus low_mid\n2 Halichondria    panacea  Halichondriidae    panacea     low\n3    Laminaria       &lt;NA&gt;             &lt;NA&gt;   digitata   v_low\n4    Littorina   littoria     Littorinidae   littoria low_mid\n5      Patella    vulgata       patellidae       &lt;NA&gt;    &lt;NA&gt;\n6  Semibalanus balanoides Archaeobalanidae balanoides    high\n7    Xanthoria       &lt;NA&gt;             &lt;NA&gt;  parietina  v_high\n\n\nOu utiliser plusieurs noms de variables :\n\ntaxa_zone &lt;- merge(\n  x = taxa, y = zone, by.x = c(\"espece\", \"GENUS\"),\n  by.y = c(\"espece\", \"genus\"), all = TRUE\n)\ntaxa_zone\n\n      espece        GENUS          famille    zone\n1 balanoides  Semibalanus Archaeobalanidae    haut\n2   digitata    Laminaria             &lt;NA&gt;   v_bas\n3   littoria    Littorina     Littorinidae bas_moy\n4    panacea Halichondria  Halichondriidae     bas\n5  parietina    Xanthoria             &lt;NA&gt;  v_haut\n6   serratus        Fucus             &lt;NA&gt; bas_moy\n7    vulgata      Patella       patellidae    &lt;NA&gt;\n\n\n\n3.4.6 Remodeler des jeux de donnÃ©es\nLe remodelage des donnÃ©es dans diffÃ©rents formats est une tÃ¢che courante. Avec des donnÃ©es de type rectangulaire (les jeux de donnÃ©es ont le mÃªme nombre de lignes dans chaque colonne), vous rencontrerez deux formes principales de jeu de donnÃ©es : le format â€œlongâ€ (parfois appelÃ© â€œempilÃ©â€) et le format â€œlargeâ€. Un exemple de jeu de donnÃ©es au format â€œlongâ€ est donnÃ© ci-dessous. Nous pouvons voir que chaque ligne reprÃ©sente une observation unique dâ€™un sujet individuel et que chaque sujet peut avoir plusieurs lignes. Il en rÃ©sulte une seule colonne de notre mesures.\n\ndonnees_longue &lt;- data.frame(\n  sujet = rep(c(\"A\", \"B\", \"C\", \"D\"), each = 3),\n  sexe = rep(c(\"M\", \"F\", \"F\", \"M\"), each = 3),\n  condition = rep(c(\"controle\", \"cond1\", \"cond2\"), times = 4),\n  mesures = c(\n    12.9, 14.2, 8.7, 5.2, 12.6, 10.1, 8.9,\n    12.1, 14.2, 10.5, 12.9, 11.9\n  )\n)\ndonnees_longue\n\n   sujet sexe condition mesures\n1      A    M  controle    12.9\n2      A    M     cond1    14.2\n3      A    M     cond2     8.7\n4      B    F  controle     5.2\n5      B    F     cond1    12.6\n6      B    F     cond2    10.1\n7      C    F  controle     8.9\n8      C    F     cond1    12.1\n9      C    F     cond2    14.2\n10     D    M  controle    10.5\n11     D    M     cond1    12.9\n12     D    M     cond2    11.9\n\n\nNous pouvons Ã©galement formater les mÃªmes donnÃ©es au format â€œlargeâ€, comme indiquÃ© ci-dessous. Dans ce format, nous avons plusieurs observations de chaque sujet dans une seule ligne avec des mesures dans diffÃ©rentes colonnes (controle, cond1 et cond2). Il sâ€™agit dâ€™un format courant lorsquâ€™il sâ€™agit de mesures rÃ©pÃ©tÃ©es Ã  partir dâ€™unitÃ©s dâ€™Ã©chantillonnage.\n\ndonnees_large &lt;- data.frame(\n  sujet = c(\"A\", \"B\", \"C\", \"D\"),\n  sexe = c(\"M\", \"F\", \"F\", \"M\"),\n  controle = c(12.9, 5.2, 8.9, 10.5),\n  cond1 = c(14.2, 12.6, 12.1, 12.9),\n  cond2 = c(8.7, 10.1, 14.2, 11.9)\n)\ndonnees_large\n\n  sujet sexe controle cond1 cond2\n1     A    M     12.9  14.2   8.7\n2     B    F      5.2  12.6  10.1\n3     C    F      8.9  12.1  14.2\n4     D    M     10.5  12.9  11.9\n\n\nBien quâ€™il nâ€™y ait pas de problÃ¨me inhÃ©rent Ã  lâ€™un ou lâ€™autre de ces formats, il est parfois nÃ©cessaire dâ€™effectuer une conversion entre les deux, car certaines fonctions requiÃ¨rent un format spÃ©cifique pour fonctionner. Le format le plus courant est le format â€œlongâ€.\nIl existe de nombreuses faÃ§ons de convertir ces deux formats, mais nous utiliserons les fonctions melt() et dcast() du paquet reshape2 ğŸ“¦ (vous devez dâ€™abord lâ€™installer). Les fonctions melt() est utilisÃ©e pour convertir les formats larges en formats longs. Le premier argument de la fonction melt() est la base de donnÃ©es que nous voulons faire fondre (dans notre cas wide_data). La fonction id.vars = c(\"subject\", \"sex\") est un vecteur des variables que vous souhaitez empiler, lâ€™argument measured.vars = c(\"control\", \"cond1\", \"cond2\") identifie les colonnes des mesures dans les diffÃ©rentes conditions, lâ€™argument variable.name = \"condition\" spÃ©cifie ce que vous voulez appeler la colonne empilÃ©e de vos diffÃ©rentes conditions dans votre cadre de donnÃ©es de sortie et lâ€™argument value.name = \"measurement\" est le nom de la colonne de vos mesures empilÃ©es dans votre cadre de donnÃ©es de sortie.\n\nlibrary(reshape2)\ndonnees_large # rappelons-nous Ã  quoi ressemble le format \"large\"\n\n  sujet sexe controle cond1 cond2\n1     A    M     12.9  14.2   8.7\n2     B    F      5.2  12.6  10.1\n3     C    F      8.9  12.1  14.2\n4     D    M     10.5  12.9  11.9\n\n# conversion du \"large\" en \"long\"\nmon_df_long &lt;- melt(\n  data = donnees_large, id.vars = c(\"sujet\", \"sexe\"),\n  vars.mesures = c(\"controle\", \"cond1\", \"cond2\"),\n  nom.variable = \"condition\", value.name = \"mesures\"\n)\nmon_df_long\n\n   sujet sexe variable mesures\n1      A    M controle    12.9\n2      B    F controle     5.2\n3      C    F controle     8.9\n4      D    M controle    10.5\n5      A    M    cond1    14.2\n6      B    F    cond1    12.6\n7      C    F    cond1    12.1\n8      D    M    cond1    12.9\n9      A    M    cond2     8.7\n10     B    F    cond2    10.1\n11     C    F    cond2    14.2\n12     D    M    cond2    11.9\n\n\nLa fonction dcast() est utilisÃ©e pour convertir un jeu de donnÃ©es au format â€œlongâ€ en un jeu de donnÃ©es au format â€œlargeâ€. Le premier argument est Ã  nouveau le jeu de donnÃ©es que nous voulons convertir (donnees_longue pour cet exemple). Le deuxiÃ¨me argument est la syntaxe de la formule. Lâ€™argument sujet + sexe de la formule signifie que nous voulons garder ces colonnes sÃ©parÃ©es, et lâ€™Ã©lÃ©ment ~ condition est la colonne qui contient les Ã©tiquettes que nous voulons diviser en nouvelles colonnes dans notre nouveau jeu de donnÃ©es. La colonne var.valeur = \"mesures\" est la colonne qui contient les donnÃ©es mesurÃ©es.\n\ndonnees_longue # rappelons-nous Ã  quoi ressemble le format \"long\"\n\n   sujet sexe condition mesures\n1      A    M  controle    12.9\n2      A    M     cond1    14.2\n3      A    M     cond2     8.7\n4      B    F  controle     5.2\n5      B    F     cond1    12.6\n6      B    F     cond2    10.1\n7      C    F  controle     8.9\n8      C    F     cond1    12.1\n9      C    F     cond2    14.2\n10     D    M  controle    10.5\n11     D    M     cond1    12.9\n12     D    M     cond2    11.9\n\n# conversion du \"long\" en \"large\"\nmon_df_large &lt;- dcast(\n  data = donnees_longue, sujet + sexe ~ condition,\n  var.valeur = \"mesures\"\n)\nmon_df_large\n\n  sujet sexe cond1 cond2 controle\n1     A    M  14.2   8.7     12.9\n2     B    F  12.6  10.1      5.2\n3     C    F  12.1  14.2      8.9\n4     D    M  12.9  11.9     10.5",
    "crumbs": [
      "DonnÃ©es",
      "Utiliser R",
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>DonnÃ©es</span>"
    ]
  },
  {
    "objectID": "03-donnees.html#introduction-au-tidyverse-lunivers-ordonnÃ©",
    "href": "03-donnees.html#introduction-au-tidyverse-lunivers-ordonnÃ©",
    "title": "3Â  DonnÃ©es",
    "section": "\n3.5 Introduction au tidyverse (Lâ€™univers ordonnÃ©)",
    "text": "3.5 Introduction au tidyverse (Lâ€™univers ordonnÃ©)\nil semble que ce ne soit pas trÃ¨s ordonnÃ© ici et que nous devons amÃ©liorer Ã§a.",
    "crumbs": [
      "DonnÃ©es",
      "Utiliser R",
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>DonnÃ©es</span>"
    ]
  },
  {
    "objectID": "03-donnees.html#rÃ©sumer-des-jeux-de-donnÃ©es",
    "href": "03-donnees.html#rÃ©sumer-des-jeux-de-donnÃ©es",
    "title": "3Â  DonnÃ©es",
    "section": "\n3.6 RÃ©sumer des jeux de donnÃ©es",
    "text": "3.6 RÃ©sumer des jeux de donnÃ©es\nMaintenant que nous sommes en mesure de manipuler et extraire des donnÃ©es de nos jeux de donnÃ©es, notre prochaine tÃ¢che est de commencer Ã  explorer et connaÃ®tre nos donnÃ©es. Dans cette section, nous commencerons Ã  produire des tableaux de statistiques rÃ©capitulatives utiles sur les variables de notre jeu de donnÃ©es et, dans les deux chapitres suivants, nous aborderons la visualisation de nos donnÃ©es Ã  lâ€™aide de graphiques R de base et lâ€™utilisation du paquet ggplot2 ğŸ“¦.\nUn point de dÃ©part trÃ¨s utile consiste Ã  produire des statistiques rÃ©capitulatives simples pour toutes les variables de notre jeu de donnÃ©es licornes Ã  lâ€™aide de la fonction summary() :\n\nsummary(licornes)\n\n    p_care              food        block         height           weight      \n Length:96          low   :32   Min.   :1.0   Min.   : 1.200   Min.   : 5.790  \n Class :character   medium:32   1st Qu.:1.0   1st Qu.: 4.475   1st Qu.: 9.027  \n Mode  :character   high  :32   Median :1.5   Median : 6.450   Median :11.395  \n                                Mean   :1.5   Mean   : 6.840   Mean   :12.155  \n                                3rd Qu.:2.0   3rd Qu.: 9.025   3rd Qu.:14.537  \n                                Max.   :2.0   Max.   :17.200   Max.   :23.890  \n   mane_size       fluffyness       horn_rings    \n Min.   : 5.80   Min.   :  5.80   Min.   : 1.000  \n 1st Qu.:11.07   1st Qu.: 39.05   1st Qu.: 4.000  \n Median :13.45   Median : 70.05   Median : 6.000  \n Mean   :14.05   Mean   : 79.78   Mean   : 7.062  \n 3rd Qu.:16.45   3rd Qu.:113.28   3rd Qu.: 9.000  \n Max.   :49.20   Max.   :189.60   Max.   :17.000  \n\n\nPour les variables numÃ©riques (câ€™est-Ã -dire height, weight etc.), la moyenne, le minimum, le maximum, la mÃ©diane, le premier quartile (infÃ©rieur) et le troisiÃ¨me quartile (supÃ©rieur) sont prÃ©sentÃ©s. Pour les variables factorielles (i.e. care et food), le nombre dâ€™observations dans chacun des niveaux est indiquÃ©. Si une variable contient des donnÃ©es manquantes, le nombre de NA est Ã©galement indiquÃ©.\nSi nous voulons rÃ©sumer un sous-ensemble plus petit de variables dans notre jeu de donnÃ©es, nous pouvons utiliser nos compÃ©tences en matiÃ¨re dâ€™indexation en combinaison avec la fonction summary(). Par exemple, pour rÃ©sumer uniquement les variables height, weight, mane_size et fluffyness nous pouvons inclure les index de colonne appropriÃ©s avec les crochets [ ]. Remarquez que nous incluons toutes les lignes en ne spÃ©cifiant pas dâ€™index de ligne :\n\nsummary(licornes[, 4:7])\n\n     height           weight         mane_size       fluffyness    \n Min.   : 1.200   Min.   : 5.790   Min.   : 5.80   Min.   :  5.80  \n 1st Qu.: 4.475   1st Qu.: 9.027   1st Qu.:11.07   1st Qu.: 39.05  \n Median : 6.450   Median :11.395   Median :13.45   Median : 70.05  \n Mean   : 6.840   Mean   :12.155   Mean   :14.05   Mean   : 79.78  \n 3rd Qu.: 9.025   3rd Qu.:14.537   3rd Qu.:16.45   3rd Qu.:113.28  \n Max.   :17.200   Max.   :23.890   Max.   :49.20   Max.   :189.60  \n\n# ou de maniÃ¨re Ã©quivalente\n# summary(licornes[, c(\"height\", \"weight\", \"mane_size\", \"fluffyness\")])\n\nEt pour rÃ©sumer une seule variable :\n\nsummary(licornes$mane_size)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   5.80   11.07   13.45   14.05   16.45   49.20 \n\n# ou de maniÃ¨re Ã©quivalente\n# summary(licornes[, 6])\n\nComme vous lâ€™avez vu plus haut, le summary() indique le nombre dâ€™observations dans chaque niveau de nos variables factorielles. Une autre fonction utile pour gÃ©nÃ©rer des tableaux de comptage est la fonction table(). La fonction table() peut Ãªtre utilisÃ©e pour construire des tables de contingence de diffÃ©rentes combinaisons de niveaux de facteurs. Par exemple, pour compter le nombre dâ€™observations pour chaque niveau de food :\n\ntable(licornes$food)\n\n\n   low medium   high \n    32     32     32 \n\n\nNous pouvons aller plus loin en produisant un tableau des effectifs pour chaque combinaison des niveau de food et care :\n\ntable(licornes$food, licornes$p_care)\n\n        \n         care no_care\n  low      16      16\n  medium   16      16\n  high     16      16\n\n\nUne version plus souple de la fonction table() est la fonction xtabs(). La fonction xtabs() utilise une notation de formule (~) pour construire des tables de contingence avec les variables de classification croisÃ©e sÃ©parÃ©es par un + Ã  droite de la formule. xtabs() contient Ã©galement un argument utile, data =, pour ne pas avoir Ã  inclure le nom du jeu de donnÃ©es lors de la spÃ©cification de chaque variable :\n\nxtabs(~ food + p_care, data = licornes)\n\n        p_care\nfood     care no_care\n  low      16      16\n  medium   16      16\n  high     16      16\n\n\nNous pouvons mÃªme construire des tables de contingence plus compliquÃ©es en utilisant davantage de variables. Notez que dans lâ€™exemple ci-dessous, la variable xtabs() a discrÃ¨tement contraint notre block Ã  Ãªtre un facteur.\n\nxtabs(~ food + p_care + block, data = licornes)\n\n, , block = 1\n\n        p_care\nfood     care no_care\n  low       8       8\n  medium    8       8\n  high      8       8\n\n, , block = 2\n\n        p_care\nfood     care no_care\n  low       8       8\n  medium    8       8\n  high      8       8\n\n\nEt pour un tableau mieux formatÃ©, nous pouvons imbriquer la fonction xtabs() Ã  lâ€™intÃ©rieur de la fonction ftable() pour â€œaplatirâ€ le tableau.\n\nftable(xtabs(~ food + p_care + block, data = licornes))\n\n               block 1 2\nfood   p_care           \nlow    care          8 8\n       no_care       8 8\nmedium care          8 8\n       no_care       8 8\nhigh   care          8 8\n       no_care       8 8\n\n\nNous pouvons Ã©galement rÃ©sumer nos donnÃ©es pour chaque niveau dâ€™une variable factorielle. Supposons que nous voulions calculer la valeur moyenne de height pour chacun de nos niveaux low, meadium et high de la variable food. Pour ce faire, nous utilisons la fonction mean() que nous appliquons Ã  la variable height pour chaque niveau de food en utilisant la fonction tapply().\n\ntapply(licornes$height, licornes$food, mean)\n\n     low   medium     high \n5.853125 7.012500 7.653125 \n\n\nLa fonction tapply() nâ€™est pas limitÃ©e au calcul des valeurs moyennes, vous pouvez lâ€™utiliser pour appliquer de nombreuses fonctions fournies avec R ou mÃªme des fonctions que vous avez Ã©crites vous-mÃªme (voir le Chapitre 5 pour plus de dÃ©tails). Par exemple, nous pouvons appliquer la fonction sd() pour calculer lâ€™Ã©cart-type pour chaque niveau de food ou mÃªme la fonction summary().\n\ntapply(licornes$height, licornes$food, sd)\n\n     low   medium     high \n2.828425 3.005345 3.483323 \n\ntapply(licornes$height, licornes$food, summary)\n\n$low\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  1.800   3.600   5.550   5.853   8.000  12.300 \n\n$medium\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  1.800   4.500   7.000   7.013   9.950  12.300 \n\n$high\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  1.200   5.800   7.450   7.653   9.475  17.200 \n\n\nRemarque : si la variable que vous souhaitez rÃ©sumer contient des valeurs manquantes (NA), vous devrez Ã©galement inclure un argument spÃ©cifiant comment vous souhaitez que la fonction traite les valeurs manquantes (NA). Nous en avons vu un exemple dans la Section 2.5.5 oÃ¹ la fonction mean() a renvoyÃ© une valeur NA en cas de donnÃ©es manquantes. Pour inclure les NA, il suffit dâ€™ajouter lâ€™argument na.rm = TRUE lors de lâ€™utilisation de tapply().\n\ntapply(licornes$height, licornes$food, mean, na.rm = TRUE)\n\n     low   medium     high \n5.853125 7.012500 7.653125 \n\n\nNous pouvons Ã©galement utiliser tapply() pour appliquer des fonctions Ã  plus dâ€™un seul facteur. La seule chose Ã  retenir est que les facteurs doivent Ãªtre fournis Ã  la fonction tapply() sous la forme dâ€™une liste Ã  lâ€™aide de la fonction list(). Pour calculer la moyenne de height pour chaque combinaison de food et care nous pouvons utiliser la notation list(licornes$food, licornes$p_care).\n\ntapply(licornes$height, list(licornes$food, licornes$p_care), mean)\n\n         care no_care\nlow    8.0375 3.66875\nmedium 9.1875 4.83750\nhigh   9.6000 5.70625\n\n\nEt si vous en avez un peu marre dâ€™avoir Ã  Ã©crire licornes$ pour chaque variable, vous pouvez imbriquer la notation tapply() Ã  lâ€™intÃ©rieur de la fonction with(). La fonction with() permet Ã  R dâ€™Ã©valuer une expression par rapport Ã  un objet de donnÃ©es nommÃ© (dans ce cas, le jeu de donnÃ©es licornes).\n\nwith(licornes, tapply(height, list(food, p_care), mean))\n\n         care no_care\nlow    8.0375 3.66875\nmedium 9.1875 4.83750\nhigh   9.6000 5.70625\n\n\nLa fonction with() fonctionne Ã©galement avec de nombreuses autres fonctions et peut vous faire Ã©conomiser beaucoup de temps de frappe !\nUne autre fonction trÃ¨s utile pour rÃ©sumer des donnÃ©es est la fonction aggregate(). La fonction aggregate() fonctionne de maniÃ¨re trÃ¨s similaire Ã  la fonction tapply() mais est un peu plus flexible.\nPar exemple, pour calculer la moyenne des variables height, weight, mane_size et fluffyness pour chaque niveau de food :\n\naggregate(licornes[, 4:7], by = list(food = licornes$food), FUN = mean)\n\n    food   height    weight mane_size fluffyness\n1    low 5.853125  8.652812  11.14375    45.1000\n2 medium 7.012500 11.164062  13.83125    67.5625\n3   high 7.653125 16.646875  17.18125   126.6875\n\n\nDans le code ci-dessus, nous avons indexÃ© les colonnes que nous voulons rÃ©sumer dans le jeu de donnÃ©es licornes Ã  lâ€™aide de la notation licornes[, 4:7]. Les by = (â€œpar =â€) spÃ©cifie une liste de facteurs (list(food = licornes$food)) et lâ€™argument FUN = dÃ©signe la fonction Ã  appliquer (mean dans cet exemple).\nComme dans le cas de la fonction tapply() nous pouvons inclure plus dâ€™un facteur sur lequel appliquer une fonction. Ici, nous calculons les valeurs moyennes pour chaque combinaison de food et care :\n\naggregate(licornes[, 4:7], by = list(\n  food = licornes$food,\n  p_care = licornes$p_care\n), FUN = mean)\n\n    food  p_care  height    weight mane_size fluffyness\n1    low    care 8.03750  9.016250   9.96250   30.30625\n2 medium    care 9.18750 11.011250  13.48750   40.59375\n3   high    care 9.60000 16.689375  15.54375   98.05625\n4    low no_care 3.66875  8.289375  12.32500   59.89375\n5 medium no_care 4.83750 11.316875  14.17500   94.53125\n6   high no_care 5.70625 16.604375  18.81875  155.31875\n\n\nNous pouvons Ã©galement utiliser la fonction aggregate() dâ€™une maniÃ¨re diffÃ©rente en utilisant la mÃ©thode de la formule (comme nous lâ€™avons fait avec la fonction xtabs()). Dans la partie gauche de la formule (~), nous spÃ©cifions la variable Ã  laquelle nous voulons appliquer la fonction mean() et, dans la partie droite, nos facteurs sÃ©parÃ©s par un symbole +. La mÃ©thode de la formule permet Ã©galement dâ€™utiliser lâ€™argument data = pour des raisons de commoditÃ©.\n\naggregate(height ~ food + p_care, FUN = mean, data = licornes)\n\n    food  p_care  height\n1    low    care 8.03750\n2 medium    care 9.18750\n3   high    care 9.60000\n4    low no_care 3.66875\n5 medium no_care 4.83750\n6   high no_care 5.70625\n\n\nLâ€™un des avantages de la mÃ©thode de la formule est quâ€™elle permet Ã©galement dâ€™utiliser lâ€™argument subset = pour appliquer la fonction Ã  des sous-ensembles des donnÃ©es originales. Par exemple, pour calculer la moyenne de height pour chaque combinaison de food et care mais seulement pour les licornes qui ont moins de 7 anneaux sur leur corne (horn_rings).\n\naggregate(height ~ food + p_care, FUN = mean, subset = horn_rings &lt; 7, data = licornes)\n\n    food  p_care   height\n1    low    care 8.176923\n2 medium    care 8.570000\n3   high    care 7.900000\n4    low no_care 3.533333\n5 medium no_care 5.316667\n6   high no_care 3.850000\n\n\nOu seulement pour les licornes du block 1.\n\naggregate(height ~ food + p_care, FUN = mean, subset = block == \"1\", data = licornes)\n\n    food  p_care  height\n1    low    care  8.7500\n2 medium    care  9.5375\n3   high    care 10.0375\n4    low no_care  3.3250\n5 medium no_care  5.2375\n6   high no_care  5.9250",
    "crumbs": [
      "DonnÃ©es",
      "Utiliser R",
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>DonnÃ©es</span>"
    ]
  },
  {
    "objectID": "03-donnees.html#exporter-des-donnÃ©es",
    "href": "03-donnees.html#exporter-des-donnÃ©es",
    "title": "3Â  DonnÃ©es",
    "section": "\n3.7 Exporter des donnÃ©es",
    "text": "3.7 Exporter des donnÃ©es\nNous espÃ©rons que vous avez maintenant une idÃ©e de la puissance et de lâ€™utilitÃ© de R pour manipuler et rÃ©sumer des donnÃ©es (et nous nâ€™avons fait quâ€™effleurer la surface). Lâ€™un des grands avantages de lâ€™utilisation de R pour manipuler vos donnÃ©es est que vous disposez dâ€™un enregistrement permanent de tout ce que vous avez fait avec vos donnÃ©es. Fini le temps des modifications non documentÃ©es dans Excel ou Calc ! En traitant vos donnÃ©es en â€œlecture seuleâ€ et en documentant toutes vos dÃ©cisions dans R, vous aurez fait un grand pas en avant pour rendre votre analyse plus reproductible et plus transparente pour les autres. Il est toutefois important de savoir que les modifications apportÃ©es Ã  votre base de donnÃ©es dans R ne changeront pas le fichier de donnÃ©es original que vous avez importÃ© dans R (et câ€™est une bonne chose). Heureusement, il est facile dâ€™exporter des cadres de donnÃ©es vers des fichiers externes dans une grande variÃ©tÃ© de formats.\n\n3.7.1 Fonctions dâ€™exportation\nLa principale fonction dâ€™exportation de jeux de donnÃ©es est write.table(). Comme pour la fonction read.table() la fonction write.table() est trÃ¨s flexible et dispose de nombreux arguments permettant de personnaliser son comportement. Prenons lâ€™exemple de notre jeu de donnÃ©es dâ€™origine licornes et exportons ces modifications vers un fichier externe.\nDe la mÃªme maniÃ¨re que pour read.table(), write.table() possÃ¨de une sÃ©rie de fonctions avec des valeurs par dÃ©faut spÃ©cifiques au format, telles que write.csv() et write.delim() qui utilisent respectivement â€œ,â€ et les tabulations comme dÃ©limiteurs, et incluent les noms de colonnes par dÃ©faut.\nOrdonnons les lignes du jeu de donnÃ©es par ordre croissant de la variable height Ã  lâ€™intÃ©rieur de chaque niveau de food. Nous appliquerons Ã©galement une transformation racine carrÃ©e Ã  la variable du nombre dâ€™anneaux de la corne (horn_rings) et une transformation logarithmique, log10 sur la variable height et enregistrons Ã§a en tant que colonnes supplÃ©mentaires dans notre jeu de donnÃ©es (nous espÃ©rons que cela vous est familier maintenant !).\n\nlicornes_df2 &lt;- licornes[order(licornes$food, licornes$height), ]\nlicornes_df2$horn_rings_sqrt &lt;- sqrt(licornes_df2$horn_rings)\nlicornes_df2$log10_height &lt;- log10(licornes_df2$height)\nstr(licornes_df2)\n\n'data.frame':   96 obs. of  10 variables:\n $ p_care         : chr  \"no_care\" \"no_care\" \"no_care\" \"no_care\" ...\n $ food           : Factor w/ 3 levels \"low\",\"medium\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ block          : int  1 1 1 2 1 2 2 2 1 2 ...\n $ height         : num  1.8 2.2 2.3 2.4 3 3.1 3.2 3.3 3.7 3.7 ...\n $ weight         : num  6.01 9.97 7.28 9.1 9.93 8.74 7.45 8.92 7.03 8.1 ...\n $ mane_size      : num  17.6 9.6 13.8 14.5 12 16.1 14.1 11.6 7.9 10.5 ...\n $ fluffyness     : num  46.2 63.1 32.8 78.7 56.6 39.1 38.1 55.2 36.7 60.5 ...\n $ horn_rings     : int  4 2 6 8 6 3 4 6 5 6 ...\n $ horn_rings_sqrt: num  2 1.41 2.45 2.83 2.45 ...\n $ log10_height   : num  0.255 0.342 0.362 0.38 0.477 ...\n\n\nNous pouvons maintenant exporter notre nouveau jeu de donnÃ©es licornes_df2 Ã  lâ€™aide de la fonction write.table(). Le premier argument est le jeu de donnÃ©es que vous voulez exporter (licornes_df2 dans notre exemple). Nous donnons ensuite le nom du fichier que nous voulons crÃ©er (avec son extension) et le chemin dâ€™accÃ¨s au fichier entre guillemets simples ou doubles en utilisant lâ€™argument file =. Dans cet exemple, nous exportons le jeu de donnÃ©es vers un fichier appelÃ© licornes_transformee.csv dans le rÃ©pertoire donnees. Lâ€™argument row.names = FALSE empÃªche R dâ€™inclure les noms des lignes dans la premiÃ¨re colonne du fichier.\n\nwrite.csv(licornes_transformee,\n  file = \"donnees/licornes_transformee.csv\", \n  row.names = FALSE\n)\n\nComme nous avons enregistrÃ© le fichier en tant que fichier texte dÃ©limitÃ© par des virgules (CSV), nous pouvons ouvrir ce fichier dans nâ€™importe quel Ã©diteur de texte.\nNous pouvons bien sÃ»r exporter nos fichiers dans une variÃ©tÃ© dâ€™autres formats.\n\n3.7.2 Autres fonctions dâ€™exportation\nComme pour lâ€™importation de fichiers de donnÃ©es dans R, il existe Ã©galement de nombreuses fonctions alternatives pour exporter des donnÃ©es vers des fichiers externes, en plus de la fonction write.table(). Si vous avez suivi la rubrique â€œAutres fonctions dâ€™importationâ€ Section 3.3.4 de ce chapitre, vous aurez dÃ©jÃ  installÃ© les paquets nÃ©cessaires.\nLa fonction fwrite() du paquet data.table ğŸ“¦ est trÃ¨s efficace pour exporter des objets de donnÃ©es volumineux et est beaucoup plus rapide que la fonction write.table(). Il est Ã©galement assez simple Ã  utiliser car il possÃ¨de la plupart des arguments de la fonction write.table(). Pour exporter un fichier texte dÃ©limitÃ© par des tabulations, il suffit de spÃ©cifier le nom du jeu de donnÃ©es, le nom et le chemin du fichier de sortie et le sÃ©parateur entre les colonnes :\n\nlibrary(data.table)\nfwrite(licornes_df2, file = \"donnees/licornes_04_12.txt\", sep = \"\\t\")\n\nPour exporter un fichier csv dÃ©limitÃ©, câ€™est encore plus facile car nous nâ€™avons mÃªme pas besoin dâ€™inclure lâ€™option sep = :\n\nlibrary(data.table)\nfwrite(licornes_df2, file = \"donnees/licornes_04_12.csv\")\n\nLe paquet readr ğŸ“¦ est Ã©galement fourni avec deux fonctions utiles pour exporter rapidement des donnÃ©es dans des fichiers externes : la fonction write_tsv() pour Ã©crire des fichiers dÃ©limitÃ©s par des tabulations et la fonction write_csv() pour enregistrer des fichiers de valeurs sÃ©parÃ©es par des virgules (csv).\n\nlibrary(readr)\nwrite_tsv(licornes_df2, path = \"donnees/licornes_04_12.txt\")\n\nwrite_csv(licornes_df2, path = \"donnees/licornes_04_12.csv\")",
    "crumbs": [
      "DonnÃ©es",
      "Utiliser R",
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>DonnÃ©es</span>"
    ]
  },
  {
    "objectID": "03-donnees.html#footnotes",
    "href": "03-donnees.html#footnotes",
    "title": "3Â  DonnÃ©es",
    "section": "",
    "text": "Pour des raisons de place et de simplicitÃ©, nous ne montrons que les cinq premiÃ¨res et cinq derniÃ¨res lignes.â†©ï¸",
    "crumbs": [
      "DonnÃ©es",
      "Utiliser R",
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>DonnÃ©es</span>"
    ]
  },
  {
    "objectID": "04-graphique.html",
    "href": "04-graphique.html",
    "title": "4Â  Figures",
    "section": "",
    "text": "4.1 TracÃ©s de base simples en R\nIl existe de nombreuses fonctions dans R pour produire des graphiques, des plus simples aux plus complexes. Il est impossible de couvrir tous les aspects de la production de graphiques en R dans ce livre. Nous vous prÃ©senterons donc la plupart des mÃ©thodes courantes de reprÃ©sentation graphique des donnÃ©es et nous dÃ©crirons comment personnaliser vos graphiques plus tard dans Section 4.5.\nLa fonction de haut niveau la plus couramment utilisÃ©e pour produire des graphiques en R est (sans surprise) la fonction plot() fonction. Par exemple, traÃ§ons le graphique weight de licornes de notre unicorns que nous avons importÃ© dans Section 3.3.2.\nunicorns &lt;- read.csv(file = \"data/unicorns.csv\")\n\nplot(unicorns$weight)\nR a tracÃ© les valeurs de weight (sur lâ€™axe des y) en fonction dâ€™un indice puisque nous ne traÃ§ons quâ€™une seule variable. Lâ€™indice est simplement lâ€™ordre des weight dans le cadre de donnÃ©es (1 en premier dans le cadre de donnÃ©es et 97 en dernier). Lâ€™indice weight a Ã©tÃ© automatiquement inclus comme Ã©tiquette de lâ€™axe des y et les Ã©chelles des axes ont Ã©tÃ© automatiquement dÃ©finies.\nSi nous nâ€™avions inclus que la variable weight plutÃ´t que unicorns$weight, lâ€™indicateur plot() affichera une erreur car la variable weight nâ€™existe que dans le unicorns lâ€™objet â€œdata frameâ€.\nplot(weight)\n## Error in plot(weight) : object 'weight' not found\nComme de nombreuses fonctions de traÃ§age de base de R nâ€™ont pas dâ€™objet data = pour spÃ©cifier directement le nom de la base de donnÃ©es, nous pouvons utiliser la fonction with() en combinaison avec la fonction plot() comme raccourci.\nwith(unicorns, plot(weight))\nPour tracer un nuage de points dâ€™une variable numÃ©rique par rapport Ã  une autre variable numÃ©rique, il suffit dâ€™inclure les deux variables en tant quâ€™arguments lors de lâ€™utilisation de la fonction plot() comme arguments. Par exemple, pour tracer fluffyness sur lâ€™axe des y et weight de lâ€™axe des x.\nplot(x = unicorns$weight, y = unicorns$fluffyness)\nIl existe une approche Ã©quivalente pour ces types de parcelles, ce qui est souvent source de confusion au dÃ©but. Vous pouvez Ã©galement utiliser la notation de formule lors de lâ€™utilisation de la fonction plot() lorsque vous utilisez la fonction Cependant, contrairement Ã  la mÃ©thode prÃ©cÃ©dente, la mÃ©thode de la formule exige que vous spÃ©cifiiez dâ€™abord la variable de lâ€™axe des y, puis un ~ puis la variable de lâ€™axe des x.\nplot(fluffyness ~ weight, data = unicorns)\n\n\n\n\n\n\nFigureÂ 4.2\nCes deux approches Ã©tant Ã©quivalentes, nous vous suggÃ©rons de choisir celle que vous prÃ©fÃ©rez et de lâ€™appliquer.\nVous pouvez Ã©galement spÃ©cifier le type de graphique que vous souhaitez tracer en utilisant lâ€™argument type =. Vous pouvez tracer uniquement les points (type = \"p\" câ€™est lâ€™option par dÃ©faut), seulement les lignes (type = \"l\"), les points et les lignes connectÃ©s (type = \"b\"), les points et les lignes avec les lignes passant par les points (type = \"o\") et les points vides reliÃ©s par des lignes (type = \"c\"). Par exemple, utilisons nos connaissances acquises lors de Section 2.4 pour gÃ©nÃ©rer deux vecteurs de nombres (my_x et my_y), puis tracer lâ€™un par rapport Ã  lâ€™autre en utilisant diffÃ©rents type = pour voir quels types de tracÃ©s sont produits. Ne vous prÃ©occupez pas des par(mfrow = c(2, 2)) ligne de code pour lâ€™instant. Nous lâ€™utilisons simplement pour diviser le dispositif de traÃ§age afin de pouvoir placer les quatre tracÃ©s sur le mÃªme dispositif pour gagner de la place. Voir Section 4.4 dans le chapitre pour plus de dÃ©tails Ã  ce sujet. Le graphique en haut Ã  gauche est type = \"l\", le graphe en haut Ã  droite type = \"b\" en bas Ã  gauche type = \"o\" et en bas Ã  droite est type = \"c\".\nmy_x &lt;- 1:10\nmy_y &lt;- seq(from = 1, to = 20, by = 2)\n\npar(mfrow = c(2, 2))\nplot(my_x, my_y, type = \"l\")\nplot(my_x, my_y, type = \"b\")\nplot(my_x, my_y, type = \"o\")\nplot(my_x, my_y, type = \"c\")\nIl est vrai que les parcelles que nous avons produites jusquâ€™Ã  prÃ©sent nâ€™ont rien dâ€™extraordinaire. Cependant, les plot() est incroyablement polyvalente et peut gÃ©nÃ©rer un large Ã©ventail de tracÃ©s que vous pouvez personnaliser Ã  votre guise. Nous verrons comment personnaliser les ggplots dans Section 4.5. Pour lâ€™anecdote, la fonction plot() est Ã©galement ce que lâ€™on appelle une fonction gÃ©nÃ©rique, ce qui signifie quâ€™elle peut modifier son comportement par dÃ©faut en fonction du type dâ€™objet utilisÃ© comme argument. Vous en verrez un exemple dans Section 9.6 oÃ¹ nous utilisons la fonction plot() pour gÃ©nÃ©rer des graphiques de diagnostic des rÃ©sidus dâ€™un objet de modÃ¨le linÃ©aire (je parie que vous ne pouvez pas attendre !).",
    "crumbs": [
      "DonnÃ©es",
      "Utiliser R",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Figures</span>"
    ]
  },
  {
    "objectID": "04-graphique.html#ggplot2",
    "href": "04-graphique.html#ggplot2",
    "title": "4Â  Figures",
    "section": "\n4.2 ggplot2",
    "text": "4.2 ggplot2\nComme nous lâ€™avons dÃ©jÃ  mentionnÃ© ggplot la grammaire nÃ©cessite plusieurs Ã©lÃ©ments pour produire un graphique (FigureÂ 4.1) et un minimum de 3 Ã©lÃ©ments est nÃ©cessaire :\n\nun cadre de donnÃ©es\nun systÃ¨me de cartographie dÃ©finissant x et y\nune couche gÃ©omÃ©trique\n\nLes donnÃ©es et la cartographie sont fournies dans le cadre de lâ€™appel Ã  lâ€™application ggplot() Ã  lâ€™aide de la fonction data et mapping arguments. La couche gÃ©omÃ©trique est ajoutÃ©e Ã  lâ€™aide de fonctions spÃ©cifiques.\nEn fait, toutes les couches sont nÃ©cessaires, mais les valeurs simples par dÃ©faut des autres couches sont automatiquement fournies.\nPour refaire la FigureÂ 4.2, qui ne contient quâ€™un nuage de points, nous pouvons utiliser la commande geom_point() fonction.\n\nggplot(\n  data = unicorns,\n  mapping = aes(x = weight, y = fluffyness)\n) +\n  geom_point()\n\n\n\n\n\n\nFigureÂ 4.3\n\n\n\n\nMaintenant que nous avons une comprÃ©hension de base de ggplotnous pouvons explorer quelques graphiques en utilisant Ã  la fois le code de base de R et le code ggplot",
    "crumbs": [
      "DonnÃ©es",
      "Utiliser R",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Figures</span>"
    ]
  },
  {
    "objectID": "04-graphique.html#tracÃ©s-simples",
    "href": "04-graphique.html#tracÃ©s-simples",
    "title": "4Â  Figures",
    "section": "\n4.3 TracÃ©s simples",
    "text": "4.3 TracÃ©s simples\n\n4.3.1 Diagrammes de dispersion\nType de diagramme simple trÃ¨s utile pour Ã©tudier la relation entre deux variables, par exemple. Voici le code pour le faire en utilisant la base R (FigureÂ 4.2)\n\nplot(fluffyness ~ weight, data = unicorns)\n\nou ggplot (FigureÂ 4.3)\n\nggplot(\n  data = unicorns,\n  mapping = aes(x = weight, y = fluffyness)\n) +\n  geom_point()\n\nUn grand avantage de ggplot pour les nuages de points simples est la facilitÃ© avec laquelle nous pouvons ajouter une rÃ©gression, une ligne plus lisse (loes ou gam) au tracÃ© en utilisant stat_smooth()pour ajouter une couche statistique au graphique.\n\nggplot(\n  data = unicorns,\n  mapping = aes(x = weight, y = fluffyness)\n) +\n  geom_point() +\n  stat_smooth()\n\n\n\n\n\n\n\n\n4.3.2 Histogrammes\nLes histogrammes de frÃ©quence sont utiles pour se faire une idÃ©e de la distribution des valeurs dâ€™une variable numÃ©rique. En utilisant la base R, la fonction hist() prend un tableau numÃ©rique comme argument principal. Dans ggplot, nous devons utiliser geom_histogram(). GÃ©nÃ©rons un histogramme de la height valeurs.\nAvec la base R\n\nhist(unicorns$height)\n\n\n\n\n\n\n\navec ggplot2\n\nggplot(unicorns, aes(x = height)) +\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nLes hist() et geom_histogram() crÃ©e automatiquement les points de rupture (ou bins) dans lâ€™histogramme, Ã  moins que vous nâ€™indiquiez le contraire Ã  lâ€™aide de la fonction breaks = pour spÃ©cifier le contraire. Par exemple, disons que nous voulons tracer notre histogramme avec des points de rupture tous les 1 cm de hauteur des licornes. Nous gÃ©nÃ©rons dâ€™abord une sÃ©quence allant de zÃ©ro Ã  la valeur maximale de height (18 arrondi vers le haut) par pas de 1 Ã  lâ€™aide de la fonction seq() Ã  lâ€™aide de la fonction Nous pouvons ensuite utiliser cette sÃ©quence avec la fonction breaks = argument. Pendant que nous y sommes, remplaÃ§ons Ã©galement le titre moche par quelque chose dâ€™un peu mieux en utilisant lâ€™option main = argument\n\nbrk &lt;- seq(from = 0, to = 18, by = 1)\nhist(unicorns$height, breaks = brk, main = \"Unicorn height\")\n\n\n\n\n\n\n\n\nbrk &lt;- seq(from = 0, to = 18, by = 1)\nggplot(unicorns, aes(x = height)) +\n  geom_histogram(breaks = brk) +\n  ggtitle(\"Unicorn height\")\n\n\n\n\n\n\n\nVous pouvez Ã©galement afficher lâ€™histogramme sous forme de proportion plutÃ´t que de frÃ©quence en utilisant lâ€™argument freq = FALSE Ã  lâ€™argument hist() ou en indiquant aes(y = after_stat(density)) dans geom_histogram().\n\nbrk &lt;- seq(from = 0, to = 18, by = 1)\nhist(unicorns$height,\n  breaks = brk, main = \"Unicorn height\",\n  freq = FALSE\n)\nggplot(unicorns, aes(x = height)) +\n  geom_histogram(aes(y = after_stat(density)), breaks = brk) +\n  ggtitle(\"Unicorn height\")\n\nUne alternative au tracÃ© dâ€™un simple histogramme est dâ€™ajouter une densitÃ© du noyau au tracÃ©. Dans la version de base de R, vous devez dâ€™abord calculer les estimations de la densitÃ© du noyau Ã  lâ€™aide de la fonction density() puis ajouter les estimations Ã  un tracÃ© sous forme de ligne Ã  lâ€™aide de la fonction lines() pour tracer une ligne.\n\ndens &lt;- density(unicorns$height)\nhist(unicorns$height,\n  breaks = brk, main = \"Unicorn height\",\n  freq = FALSE\n)\nlines(dens)\n\n\n\n\n\n\n\nAvec ggplot, vous pouvez simplement ajouter la fonction geom_density() au tracÃ©\n\nggplot(unicorns, aes(x = height)) +\n  geom_histogram(aes(y = after_stat(density)), breaks = brk) +\n  geom_density() +\n  ggtitle(\"Unicorn height\")\n\n\n\n\n\n\n\n\n4.3.3 Diagrammes en boÃ®te\nDâ€™accord, nous allons le dire franchement, nous adorons les diagrammes en boÃ®te et leur relation Ã©troite avec le diagramme en violon. Les boxplots (ou box-and-whisker plots pour leur nom complet) sont trÃ¨s utiles pour rÃ©sumer graphiquement la distribution dâ€™une variable, identifier dâ€™Ã©ventuelles valeurs inhabituelles et comparer les distributions entre diffÃ©rents groupes. La raison pour laquelle nous les aimons est leur facilitÃ© dâ€™interprÃ©tation, leur transparence et leur rapport donnÃ©es/encre relativement Ã©levÃ© (câ€™est-Ã -dire quâ€™ils sont plus faciles Ã  interprÃ©ter quâ€™Ã  utiliser). ils transmettent efficacement une grande quantitÃ© dâ€™informations). Nous vous suggÃ©rons dâ€™utiliser les diagrammes en boÃ®te autant que possible lorsque vous explorez vos donnÃ©es et dâ€™Ã©viter la tentation dâ€™utiliser le diagramme en barres plus omniprÃ©sent (mÃªme avec des barres dâ€™erreur standard ou dâ€™intervalles de confiance Ã  95 %). Le problÃ¨me des diagrammes en bÃ¢tons (ou diagrammes en dynamite) est quâ€™ils cachent au lecteur des informations importantes telles que la distribution des donnÃ©es et quâ€™ils supposent que les barres dâ€™erreur (ou les intervalles de confiance) sont symÃ©triques par rapport Ã  la moyenne. Bien sÃ»r, câ€™est Ã  vous de dÃ©cider ce que vous faites, mais si vous Ãªtes tentÃ© dâ€™utiliser des diagrammes Ã  barres, cherchez â€œdynamite plots are evilâ€ (les diagrammes de dynamite sont diaboliques) ou voyez ici ou ici pour une discussion plus complÃ¨te.\nPour crÃ©er un diagramme en boÃ®te dans R, nous utilisons la fonction boxplot() fonction. Par exemple, crÃ©ons un diagramme en boÃ®te de la variable weight Ã  partir de notre unicorns cadre de donnÃ©es. Nous pouvons Ã©galement inclure une Ã©tiquette pour lâ€™axe des y en utilisant la fonction ylab = Ã  lâ€™aide de lâ€™argument\n\nboxplot(unicorns$weight, ylab = \"weight (g)\")\n\n\n\n\n\n\n\n\nggplot(unicorns, aes(y = weight)) +\n  geom_boxplot() +\n  labs(y = \"weight (g)\")\n\n\n\n\n\n\n\nLa ligne horizontale Ã©paisse au milieu de la boÃ®te est la valeur mÃ©diane de weight (environ 11 g). La ligne supÃ©rieure de la boÃ®te est le quartile supÃ©rieur (75e percentile) et la ligne infÃ©rieure est le quartile infÃ©rieur (25e percentile). La distance entre les quartiles supÃ©rieur et infÃ©rieur est appelÃ©e lâ€™intervalle interquartile et reprÃ©sente les valeurs de weight pour 50 % des donnÃ©es. Les lignes verticales en pointillÃ©s sont appelÃ©es moustaches et leur longueur est Ã©gale Ã  1,5 x lâ€™intervalle interquartile. Les points de donnÃ©es qui sont tracÃ©s en dehors des moustaches reprÃ©sentent des observations inhabituelles potentielles. Cela ne signifie pas quâ€™ils sont inhabituels, mais simplement quâ€™ils mÃ©ritent un examen plus approfondi. Nous recommandons dâ€™utiliser les boxplots en combinaison avec les dotplots de Cleveland pour identifier les observations potentiellement inhabituelles (voir les Section 4.3.5 pour plus de dÃ©tails). Ce qui est intÃ©ressant avec les boxplots, câ€™est quâ€™ils ne fournissent pas seulement une mesure de la tendance centrale (la valeur mÃ©diane), mais quâ€™ils vous donnent Ã©galement une idÃ©e de la distribution des donnÃ©es. Si la ligne mÃ©diane se trouve plus ou moins au milieu de la boÃ®te (entre les quartiles supÃ©rieur et infÃ©rieur) et que les moustaches sont plus ou moins de la mÃªme longueur, vous pouvez Ãªtre raisonnablement sÃ»r que la distribution de vos donnÃ©es est symÃ©trique.\nSi nous voulons examiner comment la distribution dâ€™une variable change entre diffÃ©rents niveaux dâ€™un facteur, nous devons utiliser la notation de la formule avec lâ€™attribut boxplot() avec la fonction Par exemple, traÃ§ons notre weight mais cette fois-ci, voyons comment elle Ã©volue avec chaque niveau de food. Lorsque nous utilisons la notation de la formule avec boxplot() nous pouvons utiliser la notation data = afin dâ€™Ã©conomiser de la frappe. Nous introduirons Ã©galement une Ã©tiquette pour lâ€™axe des x Ã  lâ€™aide de la fonction xlab = Ã  lâ€™aide de lâ€™argument\n\nboxplot(weight ~ food,\n  data = unicorns,\n  ylab = \"Weight (g)\", xlab = \"food level\"\n)\n\n\n\n\n\n\n\n\nggplot(unicorns, aes(y = weight, x = food)) +\n  geom_boxplot() +\n  labs(y = \"Weight (g)\", x = \"food Concentration\")\n\n\n\n\n\n\n\nLes niveaux des facteurs sont reprÃ©sentÃ©s dans lâ€™ordre dÃ©fini par notre variable factorielle food (souvent par ordre alphabÃ©tique). Pour modifier lâ€™ordre, nous devons changer lâ€™ordre de nos niveaux du facteur food dans notre cadre de donnÃ©es Ã  lâ€™aide de la fonction factor() puis redessiner le graphique. TraÃ§ons notre diagramme en boÃ®te avec nos niveaux de facteurs allant de low Ã  high.\n\nunicorns$food &lt;- factor(unicorns$food,\n  levels = c(\"low\", \"medium\", \"high\")\n)\nggplot(unicorns, aes(y = weight, x = food)) +\n  geom_boxplot() +\n  labs(y = \"Weight (g)\", x = \"food Concentration\")\n\n\n\n\n\n\n\nNous pouvons Ã©galement regrouper nos variables par deux facteurs dans le mÃªme graphique. TraÃ§ons notre weight mais, cette fois, traÃ§ons une boÃ®te sÃ©parÃ©e pour chaque food et le traitement des soins parentaux (p_care).\n\nboxplot(weight ~ food * p_care,\n  data = unicorns,\n  ylab = \"weight (g)\", xlab = \"food level\"\n)\n\n\n\n\n\n\n\n\nggplot(unicorns, aes(y = weight, x = food)) +\n  geom_boxplot() +\n  labs(y = \"Weight (g)\", x = \"food Concentration\") +\n  facet_grid(.\n  ~ p_care)\n\n\n\n\n\n\n\nCe graphique est beaucoup plus intÃ©ressant dans ggplot, lâ€™utilisation de facet_grid permettant de rÃ©aliser des graphiques similaires en fonction dâ€™une troisiÃ¨me (ou mÃªme dâ€™une quatriÃ¨me) variable.\n\n4.3.4 TracÃ©s de violon\nLes diagrammes en forme de violon sont une combinaison dâ€™un diagramme en boÃ®te et dâ€™un diagramme de densitÃ© de noyau (vous avez vu un exemple de diagramme de densitÃ© de noyau dans la section histogramme ci-dessus), le tout en une seule figure. Nous pouvons crÃ©er un diagramme en violon dans R Ã  lâ€™aide de la fonction vioplot() Ã  partir de la fonction vioplot du paquet. Vous devrez dâ€™abord installer ce paquet en utilisant install.packages('vioplot') comme dâ€™habitude. Lâ€™avantage de lâ€™option vioplot() est quâ€™elle sâ€™utilise Ã  peu prÃ¨s de la mÃªme maniÃ¨re que la fonction boxplot() fonction. Nous utiliserons Ã©galement lâ€™argument col = \"lightblue\" pour changer la couleur de remplissage en bleu clair.\n\nlibrary(vioplot)\nvioplot(weight ~ food,\n  data = unicorns,\n  ylab = \"weight (g)\", xlab = \"food Concentration\",\n  col = \"lightblue\"\n)\n\n\n\n\n\n\n\nDans le diagramme de violon ci-dessus, nous avons notre diagramme en boÃ®te familier pour chaque food mais cette fois, la valeur mÃ©diane est reprÃ©sentÃ©e par un cercle blanc. Autour de chaque diagramme en boÃ®te figure le diagramme de densitÃ© de noyau qui reprÃ©sente la distribution des donnÃ©es pour chaque niveau dâ€™alimentation.\n\nggplot(unicorns, aes(y = weight, x = food)) +\n  geom_violin() +\n  geom_boxplot(width = 0.1) +\n  labs(y = \"Weight (g)\", x = \"food Concentration\")\n\n\n\n\n\n\n\n\n4.3.5 Graphiques en pointillÃ©s\nIl est extrÃªmement important dâ€™identifier les observations inhabituelles (appelÃ©es â€œvaleurs aberrantesâ€) dans les variables numÃ©riques, car elles peuvent influencer les estimations des paramÃ¨tres de votre modÃ¨le statistique ou indiquer une erreur dans vos donnÃ©es. Un graphique trÃ¨s utile (bien que sous-estimÃ©) pour aider Ã  identifier les valeurs aberrantes est le graphique en pointillÃ©s de Cleveland. Vous pouvez produire un graphique en pointillÃ©s en R trÃ¨s simplement en utilisant la commande dotchart() pour produire un graphique en pointillÃ©s.\n\ndotchart(unicorns$height)\n\n\n\n\n\n\n\nDans le diagramme en pointillÃ©s ci-dessus, les donnÃ©es de la base de donnÃ©es height sont reprÃ©sentÃ©es le long de lâ€™axe des x et les donnÃ©es sont reprÃ©sentÃ©es dans lâ€™ordre dans lequel elles apparaissent dans la fonction unicorns sur lâ€™axe des y (les valeurs situÃ©es en haut de lâ€™axe des y apparaissent plus tard dans la base de donnÃ©es et celles situÃ©es plus bas apparaissent au dÃ©but de la base de donnÃ©es). Sur ce graphique, une seule valeur sâ€™Ã©tend vers la droite Ã  environ 17 cm, mais elle ne semble pas particuliÃ¨rement importante par rapport aux autres. Un exemple de diagramme Ã  points avec une observation inhabituelle est donnÃ© ci-dessous.\n\n\n\n\n\n\n\n\nNous pouvons Ã©galement regrouper les valeurs dans notre height par une variable factorielle telle que food en utilisant le groups = argument. Ceci est utile pour identifier des observations inhabituelles au sein dâ€™un niveau de facteur qui pourraient Ãªtre masquÃ©es lorsque lâ€™on examine toutes les donnÃ©es ensemble.\n\ndotchart(unicorns$height, groups = unicorns$food)\n\n\n\n\n\n\n\n\n\nggdotchart(data = unicorns, x = \"height\", y = \"food\")\n\n\n\n\n\n\n\n\n4.3.6 Diagrammes de paires\nDans ce chapitre, nous avons dÃ©jÃ  utilisÃ© la fonction plot() pour crÃ©er un nuage de points afin dâ€™explorer la relation entre deux variables numÃ©riques. Dans le cas dâ€™ensembles de donnÃ©es contenant de nombreuses variables numÃ©riques, il est souvent utile de crÃ©er plusieurs diagrammes de dispersion pour visualiser les relations entre toutes ces variables. Nous pouvons utiliser la fonction plot() pour crÃ©er chacun de ces diagrammes individuellement, mais il est beaucoup plus facile dâ€™utiliser la fonction pairs() fonction. La fonction pairs() crÃ©e un nuage de points Ã  plusieurs panneaux (parfois appelÃ© matrice de nuage de points) qui reprÃ©sente toutes les combinaisons de variables. CrÃ©ons un nuage de points multi-panneaux de toutes les variables numÃ©riques de notre unicorns cadre de donnÃ©es. Notez que vous devrez peut-Ãªtre cliquer sur le bouton â€œZoomâ€ dans RStudio pour afficher clairement le graphique.\n\npairs(unicorns[, c(\n  \"height\", \"weight\", \"mane_size\",\n  \"fluffyness\", \"horn_rings\"\n)])\n\n\n\n\n\n\n# or we could use the equivalent\n# pairs(unicorns[, 4:8])\n\nIl faut un peu de temps pour sâ€™habituer Ã  lâ€™interprÃ©tation du diagramme des paires. Les panneaux sur la diagonale indiquent les noms des variables. La premiÃ¨re rangÃ©e de diagrammes affiche les height sur lâ€™axe des y et les variables weight, mane_size, fluffyness et unicorns sur lâ€™axe des x pour chacun des quatre graphiques respectivement. La rangÃ©e suivante de placettes comporte weight sur lâ€™axe des y et height, mane_size, fluffyness et unicorns sur lâ€™axe des x. Nous interprÃ©tons les autres lignes de la mÃªme maniÃ¨re, la derniÃ¨re ligne affichant la valeur unicorns sur lâ€™axe des y et les autres variables sur lâ€™axe des x. Nous espÃ©rons que vous remarquerez que les graphiques situÃ©s sous la diagonale sont les mÃªmes que ceux situÃ©s au-dessus de la diagonale, mais avec lâ€™axe inversÃ©.\nPour rÃ©aliser des tracÃ©s par paires avec ggplot, vous avez besoin de lâ€™option ggpairs()de GGallypaquet. La sortie est assez similaire mais vous nâ€™avez que la partie infÃ©rieure de la matrice des tracÃ©s, vous obtenez un tracÃ© de densitÃ© sur la diagonale et les corrÃ©lations sur la partie supÃ©rieure du tracÃ©.\n\nggpairs(unicorns[, c(\n  \"height\", \"weight\", \"mane_size\",\n  \"fluffyness\", \"horn_rings\"\n)])\n\n\n\n\n\n\n\nLes pairs() peut Ãªtre modifiÃ©e pour faire des choses similaires et plus, mais elle est plus complexe. Jetez un coup dâ€™Å“il Ã  lâ€™excellent fichier dâ€™aide de la fonction pairs() (?pairs), qui fournit tous les dÃ©tails permettant de faire quelque chose comme le tracÃ© ci-dessous.\n\n\n\n\n\n\n\n\n\n4.3.7 TracÃ©s\nLorsque lâ€™on examine la relation entre deux variables numÃ©riques, il est souvent utile de pouvoir dÃ©terminer si une troisiÃ¨me variable obscurcit ou modifie la relation. Un graphique trÃ¨s pratique Ã  utiliser dans ces situations est un graphique de conditionnement (Ã©galement connu sous le nom de graphique de dispersion conditionnel) que nous pouvons crÃ©er dans R Ã  lâ€™aide de la fonction coplot() fonction. La fonction coplot() trace deux variables, mais chaque tracÃ© est conditionnÃ© (|) par une troisiÃ¨me variable. Cette troisiÃ¨me variable peut Ãªtre soit numÃ©rique, soit un facteur. Ã€ titre dâ€™exemple, voyons comment la relation entre le nombre de licornes (unicorns ) et le weight de licornes change en fonction de mane_size. Notez que les coplot() a une fonction data = il nâ€™est donc pas nÃ©cessaire dâ€™utiliser lâ€™argument $ la notation.\n\ncoplot(horn_rings ~ weight | mane_size, data = unicorns)\n\n\n\n\n\n\n\n\ngg_coplot(unicorns,\n  x = weight, y = horn_rings,\n  faceting = mane_size\n)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nIl faut un peu de pratique pour interprÃ©ter les coplots. Le nombre de licornes est reprÃ©sentÃ© sur lâ€™axe des y et le poids des licornes sur lâ€™axe des x. Les six diagrammes montrent la relation entre ces deux variables pour diffÃ©rents intervalles de surface foliaire. Le diagramme Ã  barres en haut indique la plage de valeurs de la surface foliaire pour chacun des diagrammes. Les panneaux sont lus de bas en gauche Ã  haut en droite le long de chaque ligne. Par exemple, le panneau infÃ©rieur gauche montre la relation entre le nombre de licornes et le poids des licornes dont la surface foliaire est la plus faible (environ 5 - 11 cm2). Le graphique en haut Ã  droite montre la relation entre le nombre de licornes et le poids des licornes dont la surface foliaire est comprise entre 16 et 50 cm2. Remarquez que la plage de valeurs de la surface foliaire diffÃ¨re dâ€™un panneau Ã  lâ€™autre et que les plages se chevauchent dâ€™un panneau Ã  lâ€™autre. Les coplot() fait de son mieux pour diviser les donnÃ©es afin de sâ€™assurer quâ€™il y a un nombre adÃ©quat de points de donnÃ©es dans chaque panneau. Si vous ne souhaitez pas produire des graphiques avec des donnÃ©es qui se chevauchent dans le panneau, vous pouvez dÃ©finir lâ€™option overlap = Ã  overlap = 0\nVous pouvez Ã©galement utiliser lâ€™option coplot() avec des variables de conditionnement factorielles. Avec gg_coplot() vous devez dâ€™abord dÃ©finir le facteur comme numÃ©rique avant de tracer le graphique et spÃ©cifier overlap=0. Par exemple, nous pouvons examiner la relation entre unicorns et weight conditionnÃ©es par le facteur food. Le graphique en bas Ã  gauche reprÃ©sente la relation entre unicorns et weight pour les licornes de la low traitement alimentaire. Le graphique en haut Ã  gauche montre la mÃªme relation mais pour les licornes dans le traitement alimentaire. high traitement alimentaire.\n\ncoplot(horn_rings ~ weight | food, data = unicorns)\n\n\n\n\n\n\n\n\nunicorns &lt;- mutate(unicorns, food_num = as.numeric(food))\ngg_coplot(unicorns,\n  x = weight, y = horn_rings,\n  faceting = food_num, overlap = 0\n)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n4.3.8 RÃ©sumÃ© de la fonction du graphique\n\n\n\n\n\n\n\nType de graphique\nggplot2\nFonction de base de R\n\n\n\nnuage de points\ngeom_point()\nplot()\n\n\nhistogramme de frÃ©quence\ngeom_histogram()\nhist()\n\n\ndiagramme en boÃ®te\ngeom_boxplot()\nboxplot()\n\n\nCleveland dotplot\nggdotchart()\ndotchart()\n\n\nmatrice de nuage de points\nggpairs()\npairs()\n\n\ngraphique de conditionnement\ngg_coplot()\ncoplot()\n\n\n\nNous espÃ©rons que vous avez compris quâ€™il est possible de crÃ©er facilement des graphiques exploratoires trÃ¨s instructifs Ã  lâ€™aide des graphiques de base de R ou de ggplot. Le choix de lâ€™un ou lâ€™autre est entiÃ¨rement libre (câ€™est ce qui fait lâ€™intÃ©rÃªt de R, vous pouvez choisir) et nous mÃ©langeons volontiers les deux pour rÃ©pondre Ã  nos besoins. Dans la section suivante, nous verrons comment personnaliser vos graphiques R de base pour leur donner lâ€™aspect que vous souhaitez.",
    "crumbs": [
      "DonnÃ©es",
      "Utiliser R",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Figures</span>"
    ]
  },
  {
    "objectID": "04-graphique.html#sec-mult-graphs",
    "href": "04-graphique.html#sec-mult-graphs",
    "title": "4Â  Figures",
    "section": "\n4.4 Graphiques multiples",
    "text": "4.4 Graphiques multiples\n\n4.4.1 Base R\nDans la base R, lâ€™une des mÃ©thodes les plus courantes pour tracer plusieurs graphiques consiste Ã  utiliser la fonction graphique principale par() pour diviser le dispositif de traÃ§age en un certain nombre de sections dÃ©finies Ã  lâ€™aide de la fonction mfrow = pour diviser le dispositif de traÃ§age en plusieurs sections dÃ©finies. Avec cette mÃ©thode, vous devez dâ€™abord spÃ©cifier le nombre de lignes et de colonnes de tracÃ©s que vous souhaitez, puis exÃ©cuter le code pour chaque tracÃ©. Par exemple, pour tracer deux graphiques cÃ´te Ã  cÃ´te, nous utiliserions par(mfrow = c(1, 2)) pour diviser le dispositif en une ligne et deux colonnes.\n\npar(mfrow = c(1, 2))\nplot(unicorns$weight, unicorns$fluffyness,\n  xlab = \"weight\",\n  ylab = \"Fluffyness\"\n)\nboxplot(fluffyness ~ food, data = unicorns, cex.axis = 0.6)\n\n\n\n\n\n\n\nUne fois que vous avez terminÃ© vos tracÃ©s, nâ€™oubliez pas de rÃ©initialiser votre dispositif de traÃ§age Ã  la normale avec par(mfrow = c(1,1)).\n\n4.4.2 ggplot\nEn plus des fonctions facet_grid() et facet_wrap qui permettent de rÃ©pÃ©ter et dâ€™organiser facilement plusieurs tracÃ©s en fonction de variables spÃ©cifiques, ggplot permet dâ€™organiser plusieurs ggplots ensemble. Lâ€™approche que nous recommandons est dâ€™utiliser le paquet patchwork.\nVous devrez dâ€™abord lâ€™installer (si vous ne lâ€™avez pas encore) et crÃ©er le fichier patchwork ğŸ“¦ disponible.\n\ninstall.packages(\"patchwork\")\nlibrary(patchwork)\n\nUne note importante : pour ceux qui ont utilisÃ© la base R pour produire leurs chiffres et qui sont familiers avec lâ€™utilisation de par(mfrow = c(2,2)) (qui permet de tracer quatre figures sur deux lignes et deux colonnes), sachez que cela ne fonctionne pas avec ggplot2 les objets. Vous devrez utiliser soit la fonction patchwork ou dâ€™autres paquets tels que gridArrange ou cowplot ou dissimuler le ggplot2 objets en grobs.\nPour tracer les deux tracÃ©s ensemble, nous devons assigner chaque figure Ã  un objet distinct, puis utiliser ces objets lorsque nous utilisons la fonction patchwork.\nNous pouvons donc gÃ©nÃ©rer 2 figures et les assigner Ã  des objets. Comme vous pouvez le constater, les figures nâ€™apparaissent pas dans la fenÃªtre de tracÃ©. Elles nâ€™apparaÃ®tront que lorsque vous appellerez lâ€™objet.\n\nfirst_figure &lt;- ggplot(\n  aes(x = height, y = fluffyness, color = food),\n  data = unicorns\n) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  facet_grid(block ~ p_care)\nsecond_figure &lt;- ggplot(\n  aes(x = weight, y = fluffyness, color = food),\n  data = unicorns\n) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  facet_grid(block ~ p_care)\n\nDeux options simples et immÃ©diates sâ€™offrent Ã  nous avec le patchwork : disposer les figures les unes sur les autres (spÃ©cifiÃ©es avec un /) ou arranger les figures cÃ´te Ã  cÃ´te (spÃ©cifiÃ© avec soit un + ou a |). Essayons de tracer les deux figures, lâ€™une au-dessus de lâ€™autre.\n\nfirst_figure / second_figure\n\n\n\n\n\n\n\nSâ€™amuser Essayez de crÃ©er une version juxtaposÃ©e de la figure ci-dessus (indice : essayez les autres opÃ©rateurs).\nNous pouvons aller plus loin et assigner des opÃ©rateurs imbriquÃ©s patchwork Ã  un objet et lâ€™utiliser Ã  son tour pour crÃ©er des Ã©tiquettes pour les figures individuelles.\n\nnested_compare &lt;- first_figure / second_figure\n\nnested_compare +\n  plot_annotation(tag_levels = \"A\", tag_suffix = \")\")",
    "crumbs": [
      "DonnÃ©es",
      "Utiliser R",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Figures</span>"
    ]
  },
  {
    "objectID": "04-graphique.html#sec-custom-plot",
    "href": "04-graphique.html#sec-custom-plot",
    "title": "4Â  Figures",
    "section": "\n4.5 Personnalisation de ggplots",
    "text": "4.5 Personnalisation de ggplots\nPromenade pour Ãªtre Ã©ditÃ© :licorne :",
    "crumbs": [
      "DonnÃ©es",
      "Utiliser R",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Figures</span>"
    ]
  },
  {
    "objectID": "04-graphique.html#sec-export-plots",
    "href": "04-graphique.html#sec-export-plots",
    "title": "4Â  Figures",
    "section": "\n4.6 Exportation des parcelles",
    "text": "4.6 Exportation des parcelles\nCrÃ©er des graphiques dans R, câ€™est bien, mais que faire si vous souhaitez utiliser ces graphiques dans votre thÃ¨se, votre rapport ou votre publication ? Une option consiste Ã  cliquer sur le bouton â€œExporterâ€ dans lâ€™onglet â€œTracÃ©sâ€ de RStudio. Vous pouvez Ã©galement exporter vos tracÃ©s de R vers un fichier externe en Ã©crivant du code dans votre script R. Lâ€™avantage de cette approche est que vous avez un peu plus de contrÃ´le sur le format de sortie et quâ€™elle vous permet Ã©galement de gÃ©nÃ©rer (ou de mettre Ã  jour) des graphiques automatiquement chaque fois que vous exÃ©cutez votre script. Vous pouvez exporter vos tracÃ©s dans de nombreux formats diffÃ©rents, mais les plus courants sont pdf, png, jpeg et tiff.\nPar dÃ©faut, R (et donc RStudio) dirige tous les tracÃ©s que vous crÃ©ez vers la fenÃªtre de tracÃ©. Pour enregistrer votre tracÃ© dans un fichier externe, vous devez dâ€™abord rediriger votre tracÃ© vers un pÃ©riphÃ©rique graphique diffÃ©rent. Pour ce faire, vous pouvez utiliser lâ€™une des nombreuses fonctions de pÃ©riphÃ©rique graphique pour dÃ©marrer un nouveau pÃ©riphÃ©rique graphique. Par exemple, pour enregistrer un tracÃ© au format pdf, nous utiliserons la fonction pdf() pour sauvegarder un tracÃ© au format pdf. Le premier argument de la fonction pdf() est le chemin dâ€™accÃ¨s et le nom du fichier que nous voulons enregistrer (nâ€™oubliez pas dâ€™inclure lâ€™extension .pdf). Une fois que nous avons utilisÃ© la fonction pdf() nous pouvons alors Ã©crire tout le code que nous avons utilisÃ© pour crÃ©er notre graphique, y compris les paramÃ¨tres graphiques tels que le rÃ©glage des marges et la division du dispositif de traÃ§age. Une fois le code exÃ©cutÃ©, nous devons fermer le dispositif de traÃ§age pdf Ã  lâ€™aide de la fonction dev.off() Ã  lâ€™aide de la fonction\n\npdf(file = \"output/my_plot.pdf\")\npar(mar = c(4.1, 4.4, 4.1, 1.9), xaxs = \"i\", yaxs = \"i\")\nplot(unicorns$weight, unicorns$fluffyness,\n  xlab = \"weight (g)\",\n  ylab = expression(paste(\"shoot area (cm\"^\"2\", \")\")),\n  xlim = c(0, 30), ylim = c(0, 200), bty = \"l\",\n  las = 1, cex.axis = 0.8, tcl = -0.2,\n  pch = 16, col = \"dodgerblue1\", cex = 0.9\n)\ntext(x = 28, y = 190, label = \"A\", cex = 2)\ndev.off()\n\nSi nous voulons sauvegarder ce tracÃ© au format png, il nous suffit dâ€™utiliser la fonction png() plus ou moins de la mÃªme maniÃ¨re que nous avons utilisÃ© la fonction pdf() de la mÃªme maniÃ¨re que nous avons utilisÃ© la fonction\n\npng(\"output/my_plot.png\")\npar(mar = c(4.1, 4.4, 4.1, 1.9), xaxs = \"i\", yaxs = \"i\")\nplot(unicorns$weight, unicorns$fluffyness,\n  xlab = \"weight (g)\",\n  ylab = expression(paste(\"shoot area (cm\"^\"2\", \")\")),\n  xlim = c(0, 30), ylim = c(0, 200), bty = \"l\",\n  las = 1, cex.axis = 0.8, tcl = -0.2,\n  pch = 16, col = \"dodgerblue1\", cex = 0.9\n)\ntext(x = 28, y = 190, label = \"A\", cex = 2)\ndev.off()\n\nDâ€™autres fonctions utiles sont ; jpeg(), tiff() et bmp(). Des arguments supplÃ©mentaires Ã  ces fonctions vous permettent de modifier la taille, la rÃ©solution et la couleur dâ€™arriÃ¨re-plan de vos images enregistrÃ©es. Voir aussi ?png pour plus de dÃ©tails.\nggplot2 ğŸ“¦ fournir une fonction trÃ¨s utile ggsave() qui simplifie grandement la sauvegarde des tracÃ©s, mais ne fonctionne que pour les ggplots.\nAprÃ¨s avoir produit un tracÃ© et lâ€™avoir vu dans votre IDE, vous pouvez simplement exÃ©cuter ggsave() avec lâ€™argument adÃ©quat pour sauvegarder le dernier ggplot produit. Vous pouvez aussi, bien sÃ»r, spÃ©cifier quel tracÃ© doit Ãªtre sauvegardÃ©.\n\nggsave(\"file.png\")\n\n\n\n\n\nWilkinson, L. 2005. The Grammar of Graphics. Springer Science & Business Media.",
    "crumbs": [
      "DonnÃ©es",
      "Utiliser R",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Figures</span>"
    ]
  },
  {
    "objectID": "05-programmation.html",
    "href": "05-programmation.html",
    "title": "5Â  Programmation",
    "section": "",
    "text": "5.1 Regarder derriÃ¨re le rideau\nUne bonne faÃ§on de commencer Ã  apprendre Ã  programmer en R est de voir ce que dâ€™autres ont fait. Nous pouvons commencer par jeter un bref coup dâ€™Å“il derriÃ¨re le rideau. Avec de nombreuses fonctions en R, si vous voulez jeter un coup dâ€™Å“il rapide Ã  la machinerie en coulisses, nous pouvons simplement Ã©crire le nom de la fonction, mais sans lâ€™attribut ().\nNotez que lâ€™affichage du code source des paquets R de base (ceux qui sont livrÃ©s avec R) nÃ©cessite quelques Ã©tapes supplÃ©mentaires que nous ne couvrirons pas ici (voir ce lien si cela vous intÃ©resse), mais pour la plupart des autres paquets que vous installez vous-mÃªme, il suffit gÃ©nÃ©ralement dâ€™entrer le nom de la fonction sans la mention() affichera le code source de la fonction.\nVous pouvez jeter un coup dâ€™oeil Ã  la fonction dâ€™ajustement dâ€™un modÃ¨le linÃ©aire lm()\nlm\n\nfunction (formula, data, subset, weights, na.action, method = \"qr\", \n    model = TRUE, x = FALSE, y = FALSE, qr = TRUE, singular.ok = TRUE, \n    contrasts = NULL, offset, ...) \n{\n    ret.x &lt;- x\n    ret.y &lt;- y\n    cl &lt;- match.call()\n    mf &lt;- match.call(expand.dots = FALSE)\n    m &lt;- match(c(\"formula\", \"data\", \"subset\", \"weights\", \"na.action\", \n        \"offset\"), names(mf), 0L)\n    mf &lt;- mf[c(1L, m)]\n    mf$drop.unused.levels &lt;- TRUE\n    mf[[1L]] &lt;- quote(stats::model.frame)\n    mf &lt;- eval(mf, parent.frame())\n    if (method == \"model.frame\") \n        return(mf)\n    else if (method != \"qr\") \n        warning(gettextf(\"method = '%s' is not supported. Using 'qr'\", \n            method), domain = NA)\n    mt &lt;- attr(mf, \"terms\")\n    y &lt;- model.response(mf, \"numeric\")\n    w &lt;- as.vector(model.weights(mf))\n    if (!is.null(w) && !is.numeric(w)) \n        stop(\"'weights' must be a numeric vector\")\n    offset &lt;- model.offset(mf)\n    mlm &lt;- is.matrix(y)\n    ny &lt;- if (mlm) \n        nrow(y)\n    else length(y)\n    if (!is.null(offset)) {\n        if (!mlm) \n            offset &lt;- as.vector(offset)\n        if (NROW(offset) != ny) \n            stop(gettextf(\"number of offsets is %d, should equal %d (number of observations)\", \n                NROW(offset), ny), domain = NA)\n    }\n    if (is.empty.model(mt)) {\n        x &lt;- NULL\n        z &lt;- list(coefficients = if (mlm) matrix(NA_real_, 0, \n            ncol(y)) else numeric(), residuals = y, fitted.values = 0 * \n            y, weights = w, rank = 0L, df.residual = if (!is.null(w)) sum(w != \n            0) else ny)\n        if (!is.null(offset)) {\n            z$fitted.values &lt;- offset\n            z$residuals &lt;- y - offset\n        }\n    }\n    else {\n        x &lt;- model.matrix(mt, mf, contrasts)\n        z &lt;- if (is.null(w)) \n            lm.fit(x, y, offset = offset, singular.ok = singular.ok, \n                ...)\n        else lm.wfit(x, y, w, offset = offset, singular.ok = singular.ok, \n            ...)\n    }\n    class(z) &lt;- c(if (mlm) \"mlm\", \"lm\")\n    z$na.action &lt;- attr(mf, \"na.action\")\n    z$offset &lt;- offset\n    z$contrasts &lt;- attr(x, \"contrasts\")\n    z$xlevels &lt;- .getXlevels(mt, mf)\n    z$call &lt;- cl\n    z$terms &lt;- mt\n    if (model) \n        z$model &lt;- mf\n    if (ret.x) \n        z$x &lt;- x\n    if (ret.y) \n        z$y &lt;- y\n    if (!qr) \n        z$qr &lt;- NULL\n    z\n}\n&lt;bytecode: 0x5ce5e486c128&gt;\n&lt;environment: namespace:stats&gt;\nCe que nous voyons ci-dessus est le code sous-jacent de cette fonction particuliÃ¨re. Nous pourrions le copier et le coller dans notre propre script et y apporter toutes les modifications que nous jugerions nÃ©cessaires, mais en faisant preuve de prudence et en testant les changements que vous avez apportÃ©s.\nNe vous inquiÃ©tez pas outre mesure si la majeure partie du code contenu dans les fonctions nâ€™a pas de sens immÃ©diat. Câ€™est particuliÃ¨rement vrai si vous Ãªtes novice en matiÃ¨re de R, auquel cas cela semble incroyablement intimidant. HonnÃªtement, cela peut Ãªtre intimidant mÃªme aprÃ¨s des annÃ©es dâ€™expÃ©rience avec R. Pour y remÃ©dier, nous commencerons par crÃ©er nos propres fonctions en R dans la section suivante.",
    "crumbs": [
      "DonnÃ©es",
      "Utiliser R",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Programmation</span>"
    ]
  },
  {
    "objectID": "05-programmation.html#fonctions-en-r",
    "href": "05-programmation.html#fonctions-en-r",
    "title": "5Â  Programmation",
    "section": "\n5.2 Fonctions en R",
    "text": "5.2 Fonctions en R\nLes fonctions sont le pain et le beurre de R, les Ã©lÃ©ments essentiels qui vous permettent de travailler avec R. Elles sont crÃ©Ã©es (la plupart du temps) avec le plus grand soin et la plus grande attention, mais peuvent finir par ressembler Ã  un monstre de Frankenstein - avec des membres bizarrement attachÃ©s. Mais aussi alambiquÃ©s quâ€™ils puissent Ãªtre, ils feront toujours fidÃ¨lement la mÃªme chose.\nCela signifie que les fonctions peuvent Ã©galement Ãªtre trÃ¨s stupides.\nSi nous vous demandons dâ€™aller au supermarchÃ© pour nous procurer des ingrÃ©dients pour faire des du poulet Balmoral mÃªme si vous ne savez pas ce que câ€™est, vous serez capable de deviner et dâ€™apporter au moins quelque chose quelque chose. Vous pouvez aussi dÃ©cider de faire autre chose. Ou vous pouvez demander de lâ€™aide Ã  un chef cuisinier. Ou vous pouvez sortir votre tÃ©lÃ©phone et chercher en ligne ce que vous voulez faire. Poulet Balmoral est. Le fait est que, mÃªme si nous ne vous avons pas donnÃ© suffisamment dâ€™informations pour accomplir la tÃ¢che, vous Ãªtes suffisamment intelligent pour, au moins, essayer de trouver une solution de contournement.\nSi, au contraire, nous demandions Ã  une fonction de faire la mÃªme chose, elle Ã©couterait attentivement notre demande, puis renverrait simplement une erreur. Elle rÃ©pÃ©terait cela Ã  chaque fois que nous lui demanderions de faire le travail lorsque la tÃ¢che nâ€™est pas claire. Ce quâ€™il faut retenir ici, câ€™est que le code et les fonctions ne peuvent pas trouver de solutions de contournement Ã  des informations mal fournies, ce qui est une excellente chose. Il dÃ©pend entiÃ¨rement de vous pour lui dire trÃ¨s explicitement ce quâ€™il doit faire, Ã©tape par Ã©tape.\nNâ€™oubliez pas deux choses : lâ€™intelligence du code vient du codeur, pas de lâ€™ordinateur, et les fonctions ont besoin dâ€™instructions exactes pour fonctionner.\nPour Ã©viter que les fonctions ne soient trop stupides, vous devez fournir les informations dont la fonction a besoin pour fonctionner. Comme pour la fonction poulet du Balmoral si nous avions fourni une liste de recettes Ã  la fonction, tout se serait bien passÃ©. Câ€™est ce que nous appelons â€œremplir un argumentâ€. La grande majoritÃ© des fonctions exigent de lâ€™utilisateur quâ€™il remplisse au moins un argument.\nCeci peut Ãªtre illustrÃ© dans le pseudocode ci-dessous. Lorsque nous crÃ©ons une fonction, nous pouvons :\n\nspÃ©cifier les arguments que lâ€™utilisateur doit remplir (par exemple arg1 et arg2)\nfournissent des valeurs par dÃ©faut aux arguments (par exemple arg2 = TRUE)\ndÃ©finir ce quâ€™il faut faire avec les arguments (expression) :\n\n\nmy_function &lt;- function(arg1, arg2, ...) {\n  expression\n}\n\nLa premiÃ¨re chose Ã  noter est que nous avons utilisÃ© la fonction function() pour crÃ©er une nouvelle fonction appelÃ©e my_function. Pour parcourir le code ci-dessus, nous crÃ©ons une fonction appelÃ©e my_function. Entre les crochets ronds, nous spÃ©cifions les informations (câ€™est-Ã -dire arguments) dont la fonction a besoin pour fonctionner (autant ou aussi peu que nÃ©cessaire). Ces arguments sont ensuite transmis Ã  la partie expression de la fonction. Lâ€™expression peut Ãªtre nâ€™importe quelle commande R valide ou nâ€™importe quel ensemble de commandes R et est gÃ©nÃ©ralement entre une paire dâ€™accolades { }. Une fois que vous avez exÃ©cutÃ© le code ci-dessus, vous pouvez utiliser votre nouvelle fonction en tapant :\n\nmy_function(arg1, arg2)\n\nPrenons un exemple pour clarifier les choses.\nTout dâ€™abord, nous allons crÃ©er un cadre de donnÃ©es appelÃ© dishes oÃ¹ les colonnes lasagna, stovies, poutine et tartiflette sont remplis avec 10 valeurs alÃ©atoires tirÃ©es dâ€™un sac (Ã  lâ€™aide de la fonction rnorm() pour tirer des valeurs alÃ©atoires dâ€™une distribution normale avec une moyenne de 0 et un Ã©cart type de 1). Nous incluons Ã©galement un â€œproblÃ¨meâ€, que nous devrons rÃ©soudre plus tard, en incluant 3 NA dans la fonction poutine (en utilisant rep(NA, 3)).\n\ndishes &lt;- data.frame(\n  lasagna = rnorm(10),\n  stovies = rnorm(10),\n  poutine = c(rep(NA, 3), rnorm(7)),\n  tartiflette = rnorm(10)\n)\n\nSupposons que vous souhaitiez multiplier les valeurs des variables stovies et lasagna et crÃ©er un nouvel objet appelÃ© stovies_lasagna. Nous pouvons le faire â€œÃ  la mainâ€ en utilisant :\n\nstovies_lasagna &lt;- dishes$stovies * dishes$lasagna\n\nSi câ€™Ã©tait tout ce que nous avions Ã  faire, nous pourrions nous arrÃªter ici. R fonctionne avec des vecteurs, de sorte quâ€™effectuer ce type dâ€™opÃ©rations dans R est en fait beaucoup plus simple que dans dâ€™autres langages de programmation, oÃ¹ ce type de code peut nÃ©cessiter des boucles (nous disons que R est un langage vectorisÃ©). Une chose Ã  garder Ã  lâ€™esprit pour plus tard est que faire ce genre dâ€™opÃ©rations avec des boucles peut Ãªtre beaucoup plus lent que la vectorisation.\nMais que se passe-t-il si nous voulons rÃ©pÃ©ter cette multiplication plusieurs fois ? Supposons que nous voulions multiplier les colonnes lasagna et stovies, stovies et tartiflette et poutine et tartiflette. Dans ce cas, nous pouvons copier et coller le code en remplaÃ§ant les informations pertinentes.\n\nlasagna_stovies &lt;- dishes$lasagna * dishes$stovies\nstovies_tartiflette &lt;- dishes$stovies * dishes$stovies\npoutine_tartiflette &lt;- dishes$poutine * dishes$tartiflette\n\nBien que cette approche fonctionne, il est facile de faire des erreurs. En fait, ici, nous avons â€œoubliÃ©â€ de modifier stovies en tartiflette dans la deuxiÃ¨me ligne de code lors du copier-coller. Câ€™est lÃ  que lâ€™Ã©criture dâ€™une fonction sâ€™avÃ¨re utile. Si nous Ã©crivions cela sous forme de fonction, il nâ€™y aurait quâ€™une seule source dâ€™erreur potentielle (dans la fonction elle-mÃªme) au lieu de nombreuses lignes de code copiÃ©es-collÃ©es (que nous rÃ©duisons Ã©galement en utilisant une fonction).\n\n\n\n\n\n\nAstuce\n\n\n\nEn rÃ¨gle gÃ©nÃ©rale, si nous devons faire la mÃªme chose (par copier/coller et modifier) 3 fois ou plus, nous crÃ©ons une fonction pour cela.\n\n\nDans ce cas, nous utilisons un code assez trivial oÃ¹ il est peut-Ãªtre difficile de faire une vÃ©ritable erreur. Mais que se passerait-il si nous augmentions la complexitÃ© ?\n\ndishes$lasagna * dishes$stovies / dishes$lasagna + (dishes$lasagna * 10^(dishes$stovies))\n-dishes$stovies - (dishes$lasagna * sqrt(dishes$stovies + 10))\n\nImaginez maintenant que vous deviez copier et coller ce code trois fois, et que vous deviez Ã  chaque fois modifier lâ€™Ã©lÃ©ment lasagna et stovies (surtout si nous devions le faire plus de trois fois).\nCe que nous pourrions faire Ã  la place, câ€™est gÃ©nÃ©raliser notre code pour x et y au lieu de nommer des plats spÃ©cifiques. En procÃ©dant de la sorte, nous pourrions recycler la x * y code. Chaque fois que nous voulions regrouper plusieurs colonnes, nous assignions une parabole Ã  lâ€™un ou lâ€™autre des Ã©lÃ©ments suivants x ou y. Nous attribuerons la multiplication aux objets lasagna_stovies et stovies_poutine afin de pouvoir y revenir plus tard.\n\n# Assign x and y values\nx &lt;- dishes$lasagna\ny &lt;- dishes$stovies\n\n# Use multiplication code\nlasagna_stovies &lt;- x * y\n\n# Assign new x and y values\nx &lt;- dishes$stovies\ny &lt;- dishes$poutine\n\n# Reuse multiplication code\nstovies_poutine &lt;- x * y\n\nCâ€™est essentiellement ce que fait une fonction. Appelons notre nouvelle fonction multiply_cols() et dÃ©finissons-la avec deux arguments, x et y. Une fonction dans R renvoie simplement sa derniÃ¨re valeur. Toutefois, il est possible de forcer la fonction Ã  renvoyer une valeur antÃ©rieure si cela sâ€™avÃ¨re nÃ©cessaire. Pour ce faire, il suffit dâ€™utiliser la fonction return() nâ€™est pas strictement nÃ©cessaire dans cet exemple car R retournera automatiquement la valeur de la derniÃ¨re ligne de code de notre fonction. Nous lâ€™incluons ici pour lâ€™expliciter.\n\nmultiply_cols &lt;- function(x, y) {\n  return(x * y)\n}\n\nMaintenant que nous avons dÃ©fini notre fonction, nous pouvons lâ€™utiliser. Utilisons la fonction pour multiplier les colonnes lasagna et stovies et assigner le rÃ©sultat Ã  un nouvel objet appelÃ© lasagna_stovies_func\n\nlasagna_stovies_func &lt;- multiply_cols(x = dishes$lasagna, y = dishes$stovies)\nlasagna_stovies_func\n\n [1]  0.39870077 -0.75520781  0.05353023  0.23102663  0.45329894 -2.78623418\n [7] -0.35813571  0.10336648 -0.10248847  0.14124923\n\n\nSi nous ne nous intÃ©ressons quâ€™Ã  la multiplication dishes$lasagna et dishes$stovies il serait exagÃ©rÃ© de crÃ©er une fonction pour faire quelque chose une seule fois. Cependant, lâ€™avantage de crÃ©er une fonction est que nous avons maintenant cette fonction ajoutÃ©e Ã  notre environnement que nous pouvons utiliser aussi souvent que nous le souhaitons. Nous disposons Ã©galement du code pour crÃ©er la fonction, ce qui signifie que nous pouvons lâ€™utiliser dans des projets entiÃ¨rement nouveaux, rÃ©duisant ainsi la quantitÃ© de code qui doit Ãªtre Ã©crite (et testÃ©e Ã  nouveau) Ã  partir de zÃ©ro Ã  chaque fois.\nPour sâ€™assurer que la fonction a fonctionnÃ© correctement, nous pouvons comparer le code lasagna_stovies avec notre nouvelle variable lasagna_stovies_func Ã  lâ€™aide de la fonction identical() fonction. La fonction identical() teste si deux objets sont exactement identiques et renvoie soit un TRUE ou FALSE valeur. Utiliser ?identical pour en savoir plus sur cette fonction.\n\nidentical(lasagna_stovies, lasagna_stovies_func)\n\n[1] TRUE\n\n\nEt nous confirmons que la fonction a produit le mÃªme rÃ©sultat que lorsque nous effectuons le calcul manuellement. Nous vous recommandons de prendre lâ€™habitude de vÃ©rifier que la fonction que vous avez crÃ©Ã©e fonctionne comme vous le pensez.\nUtilisons maintenant notre multiply_cols() pour multiplier les colonnes stovies et poutine. Remarquez maintenant que lâ€™argument x reÃ§oit la valeur dishes$stovieset y la valeur dishes$poutine.\n\nstovies_poutine_func &lt;- multiply_cols(x = dishes$stovies, y = dishes$poutine)\nstovies_poutine_func\n\n [1]            NA            NA            NA  0.0879287405  0.4392946420\n [6]  0.0605509100  0.9761694387  1.2215362724 -0.2825366740 -0.0005892957\n\n\nJusquâ€™Ã  prÃ©sent, tout va bien. Tout ce que nous avons fait, câ€™est envelopper le code x * y dans une fonction, oÃ¹ nous demandons Ã  lâ€™utilisateur de spÃ©cifier ce que son x et y sont.\nLâ€™utilisation de la fonction est un peu longue car nous devons retaper le nom de la base de donnÃ©es pour chaque variable. Pour nous amuser un peu, nous pouvons modifier la fonction afin de spÃ©cifier le cadre de donnÃ©es en tant quâ€™argument et les noms des colonnes sans les mettre entre guillemets (comme dans le style tidyverse).\n\nmultiply_cols &lt;- function(data, x, y) {\n  temp_var &lt;- data %&gt;%\n    select({{ x }}, {{ y }}) %&gt;%\n    mutate(xy = prod(.)) %&gt;%\n    pull(xy)\n}\n\nPour cette nouvelle version de la fonction, nous avons ajoutÃ© un paramÃ¨tre data Ã  la ligne 1. A la ligne 3, nous sÃ©lectionnons les variables x et y fournies comme arguments. A la ligne 4, nous crÃ©ons le produit des 2 colonnes sÃ©lectionnÃ©es et Ã  la ligne 5, nous extrayons la colonne que nous venons de crÃ©er. Nous supprimons Ã©galement la return() puisquâ€™elle nâ€™Ã©tait pas nÃ©cessaire\nNotre fonction est maintenant compatible avec le pipe (soit en natif |&gt; ou magrittr %&gt;%). Toutefois, Ã©tant donnÃ© que la fonction utilise dÃ©sormais le tuyau de magrittr ğŸ“¦ et dplyr ğŸ“¦, nous devons charger le paquet ğŸ“¦ de tidyverse pour quâ€™elle fonctionne.\n\nlibrary(tidyverse)\n\nâ”€â”€ Attaching core tidyverse packages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse 2.0.0 â”€â”€\nâœ” dplyr     1.1.4     âœ” readr     2.1.5\nâœ” forcats   1.0.0     âœ” stringr   1.5.1\nâœ” ggplot2   3.5.1     âœ” tibble    3.2.1\nâœ” lubridate 1.9.3     âœ” tidyr     1.3.1\nâœ” purrr     1.0.2     \nâ”€â”€ Conflicts â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse_conflicts() â”€â”€\nâœ– dplyr::filter() masks stats::filter()\nâœ– dplyr::lag()    masks stats::lag()\nâ„¹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlasagna_stovies_func &lt;- multiply_cols(dishes, lasagna, stovies)\nlasagna_stovies_func &lt;- dishes |&gt; multiply_cols(lasagna, stovies)\n\nAjoutons maintenant un peu plus de complexitÃ©. Si vous regardez la sortie de poutine_tartiflette certains des calculs ont produit NA valeurs. Cela sâ€™explique par le fait que les NA que nous avons incluses dans poutine lorsque nous avons crÃ©Ã© lâ€™Ã©lÃ©ment dishes cadre de donnÃ©es. MalgrÃ© ces NA valeurs, la fonction semble avoir fonctionnÃ©, mais elle ne nous a donnÃ© aucune indication quant Ã  lâ€™existence dâ€™un problÃ¨me. Dans ce cas, nous prÃ©fÃ©rerions quâ€™elle nous avertisse que quelque chose ne va pas. Comment pouvons-nous faire en sorte que la fonction nous informe lorsque NA sont produites ? Voici une solution.\n\nmultiply_cols &lt;- function(data, x, y) {\n  temp_var &lt;- data %&gt;%\n    select({{ x }}, {{ y }}) %&gt;%\n    mutate(xy = {\n      .[1] * .[2]\n    }) %&gt;%\n    pull(xy)\n  if (any(is.na(temp_var))) {\n    warning(\"The function has produced NAs\")\n    return(temp_var)\n  } else {\n    return(temp_var)\n  }\n}\n\n\nstovies_poutine_func &lt;- multiply_cols(dishes, stovies, poutine)\n\nWarning in multiply_cols(dishes, stovies, poutine): The function has produced\nNAs\n\nlasagna_stovies_func &lt;- multiply_cols(dishes, lasagna, stovies)\n\nLe cÅ“ur de notre fonction reste le mÃªme, mais nous avons maintenant six lignes de code supplÃ©mentaires (lignes 6 Ã  11). Nous avons inclus des instructions conditionnelles, if (lignes 6-8) et else (lignes 9-11), afin de tester si un NAont Ã©tÃ© produites et, si câ€™est le cas, nous affichons un message dâ€™avertissement Ã  lâ€™intention de lâ€™utilisateur. La section suivante de ce chapitre explique le fonctionnement et lâ€™utilisation de ces fonctions.",
    "crumbs": [
      "DonnÃ©es",
      "Utiliser R",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Programmation</span>"
    ]
  },
  {
    "objectID": "05-programmation.html#dÃ©clarations-conditionnelles",
    "href": "05-programmation.html#dÃ©clarations-conditionnelles",
    "title": "5Â  Programmation",
    "section": "\n5.3 DÃ©clarations conditionnelles",
    "text": "5.3 DÃ©clarations conditionnelles\nx * y nâ€™applique aucune logique. Il prend simplement la valeur de x et la multiplie par la valeur de y. Les instructions conditionnelles permettent dâ€™injecter de la logique dans votre code. Lâ€™instruction conditionnelle la plus couramment utilisÃ©e est if. Chaque fois que vous voyez un if lisez-le comme * Si X est VRAI, faites une choseâ€.. Incluant un else permet simplement dâ€™Ã©tendre la logique Ã   Si X est VRAI, faites une chose, ou bien faites quelque chose de diffÃ©rent.*.\nLes deux if et else vous permettent dâ€™exÃ©cuter des sections de code, en fonction dâ€™une condition qui est soit TRUE ou FALSE. Le pseudo-code ci-dessous vous montre la forme gÃ©nÃ©rale.\n  if (condition) {\n  Code executed when condition is TRUE\n  } else {\n  Code executed when condition is FALSE\n  }\nPour approfondir la question, nous pouvons utiliser une vieille blague de programmeur pour poser un problÃ¨me.\n\nLe partenaire dâ€™un programmeur dit : * Allez au magasin acheter une brique de lait et, sâ€™il y a des Å“ufs, prenez-en six.*\nLe programmeur est revenu avec 6 briques de lait.\nLorsque le partenaire sâ€™en aperÃ§oit, il sâ€™exclame * Pourquoi diable as-tu achetÃ© six briques de lait ?*\nLe programmeur a rÃ©pondu â€œIls avaient des Å“ufs\n\nAu risque dâ€™expliquer une blague, lâ€™Ã©noncÃ© conditionnel ici est de savoir si le magasin avait ou non des Å“ufs. Si le codage est conforme Ã  la demande initiale, le programmeur doit apporter 6 briques de lait si le magasin a des Å“ufs (condition = VRAI), ou apporter 1 brique de lait sâ€™il nâ€™y a pas dâ€™Å“ufs (condition = FAUX). Dans R, cela est codÃ© comme suit :\n\neggs &lt;- TRUE # Whether there were eggs in the store\n\nif (eggs == TRUE) { # If there are eggs\n  n.milk &lt;- 6 # Get 6 cartons of milk\n} else { # If there are not eggs\n  n.milk &lt;- 1 # Get 1 carton of milk\n}\n\nNous pouvons alors vÃ©rifier n.milk le nombre de briques de lait quâ€™ils ont ramenÃ©es.\n\nn.milk\n\n[1] 6\n\n\nEt comme dans la blague, notre code R nâ€™a pas compris que la condition Ã©tait de dÃ©terminer sâ€™il fallait ou non acheter des Å“ufs, et non plus du lait (il sâ€™agit en fait dâ€™un exemple libre du schÃ©ma de Winograd conÃ§u pour tester la conditionlâ€™intelligence dâ€™une intelligence artificielle en fonction de sa capacitÃ© Ã  raisonner sur le sens dâ€™une phrase).\nNous pourrions coder exactement la mÃªme instruction conditionnelle de blague Å“uf-lait Ã  lâ€™aide dâ€™un ifelse() fonction.\n\neggs &lt;- TRUE\nn.milk &lt;- ifelse(eggs == TRUE, yes = 6, no = 1)\n\nCette ifelse() fait exactement la mÃªme chose que la version plus Ã©toffÃ©e de tout Ã  lâ€™heure, mais elle est maintenant condensÃ©e en une seule ligne de code. Elle prÃ©sente lâ€™avantage supplÃ©mentaire de travailler sur des vecteurs plutÃ´t que sur des valeurs individuelles (nous y reviendrons plus tard lorsque nous introduirons les boucles). La logique est lue de la mÃªme maniÃ¨re : â€œSâ€™il y a des oeufs, assignez une valeur de 6 Ã  n.milk sâ€™il nâ€™y a pas dâ€™oeufs, assigner la valeur 1 Ã  n.milkâ€.\nNous pouvons vÃ©rifier Ã  nouveau que la logique renvoie toujours 6 briques de lait :\n\nn.milk\n\n[1] 6\n\n\nActuellement, nous devrions copier et coller du code si nous voulions changer la prÃ©sence ou lâ€™absence dâ€™Å“ufs dans le magasin. Nous avons appris plus haut comment Ã©viter de nombreux copier-coller en crÃ©ant une fonction. Comme avec la simple fonction x * y de notre prÃ©cÃ©dente expression multiply_cols() les dÃ©clarations logiques ci-dessus sont simples Ã  coder et se prÃªtent bien Ã  la transformation en fonction. Et si nous faisions justement cela et enveloppions cette dÃ©claration logique dans une fonction ?\n\nmilk &lt;- function(eggs) {\n  if (eggs == TRUE) {\n    6\n  } else {\n    1\n  }\n}\n\nNous avons crÃ©Ã© une fonction appelÃ©e milk() dont le seul argument est eggs. Lâ€™utilisateur de la fonction spÃ©cifie si les Å“ufs sont soit TRUE ou FALSE et la fonction utilisera alors une instruction conditionnelle pour dÃ©terminer le nombre de cartons de lait renvoyÃ©s.\nEssayons rapidement :\n\nmilk(eggs = TRUE)\n\n[1] 6\n\n\nEt la plaisanterie est maintenue. Remarquez que, dans ce cas, nous avons spÃ©cifiÃ© que nous remplissons la fonction eggs (eggs = TRUE). Dans certaines fonctions, comme la nÃ´tre ici, lorsquâ€™une fonction nâ€™a quâ€™un seul argument, nous pouvons Ãªtre paresseux et ne pas nommer lâ€™argument que nous remplissons. En rÃ©alitÃ©, on considÃ¨re gÃ©nÃ©ralement quâ€™il est prÃ©fÃ©rable dâ€™indiquer explicitement les arguments que lâ€™on remplit afin dâ€™Ã©viter les erreurs potentielles.\nOK, revenons Ã  la fonction multiply_cols() que nous avons crÃ©Ã©e ci-dessus et expliquons comment nous avons utilisÃ© des instructions conditionnelles pour avertir lâ€™utilisateur si NA sont produites lorsque nous multiplions deux colonnes.\n\nmultiply_cols &lt;- function(data, x, y) {\n  temp_var &lt;- data %&gt;%\n    select({{ x }}, {{ y }}) %&gt;%\n    mutate(xy = {\n      .[1] * .[2]\n    }) %&gt;%\n    pull(xy)\n  if (any(is.na(temp_var))) {\n    warning(\"The function has produced NAs\")\n    return(temp_var)\n  } else {\n    return(temp_var)\n  }\n}\n\nDans cette nouvelle version de la fonction, nous utilisons toujours x * y comme auparavant, mais cette fois nous avons assignÃ© les valeurs de ce calcul Ã  un vecteur temporaire appelÃ© temp_var afin de pouvoir lâ€™utiliser dans nos instructions conditionnelles. Notez que ce temp_var est locale Ã  notre fonction et nâ€™existera pas en dehors de la fonction en raison de ce que lâ€™on appelle les rÃ¨gles de cadrage de R . [rÃ¨gles de cadrage de R][cadrage] . Nous utilisons ensuite un if pour dÃ©terminer si notre temp_var contient des NA valeurs. Pour ce faire, nous utilisons dâ€™abord la fonction is.na() pour vÃ©rifier si chaque valeur de notre temp_var est un NA. Les is.na() renvoie TRUE si la valeur est un NA et FALSE si la valeur nâ€™est pas un NA. Nous imbriquons ensuite le is.na(temp_var) Ã  lâ€™intÃ©rieur de la fonction any() pour vÃ©rifier si une des valeurs retournÃ©es par is.na(temp_var) sont TRUE. Si au moins une valeur est TRUE lâ€™une any() renverra une valeur TRUE. Ainsi, sâ€™il existe des NA valeurs dans notre temp_var la condition pour le if() sera TRUE alors que sâ€™il nâ€™y a pas de NA valeurs prÃ©sentes, la condition sera FALSE. Si la condition est TRUE la warning() gÃ©nÃ¨re un message dâ€™avertissement Ã  lâ€™intention de lâ€™utilisateur et renvoie la valeur de la fonction temp_var variable. Si la condition est FALSE le code sous le else est exÃ©cutÃ©, ce qui renvoie simplement la valeur temp_var .\nAinsi, si nous exÃ©cutons notre multiple_columns() sur les colonnes dishes$stovies et dishes$poutine (qui contient NAs), nous recevrons un message dâ€™avertissement.\n\nstovies_poutine_func &lt;- multiply_cols(dishes, stovies, poutine)\n\nWarning in multiply_cols(dishes, stovies, poutine): The function has produced\nNAs\n\n\nEn revanche, si nous multiplions deux colonnes qui ne contiennent pas de NA nous ne recevons pas de message dâ€™avertissement\n\nlasagna_stovies_func &lt;- multiply_cols(dishes, lasagna, stovies)",
    "crumbs": [
      "DonnÃ©es",
      "Utiliser R",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Programmation</span>"
    ]
  },
  {
    "objectID": "05-programmation.html#combinaison-dopÃ©rateurs-logiques",
    "href": "05-programmation.html#combinaison-dopÃ©rateurs-logiques",
    "title": "5Â  Programmation",
    "section": "\n5.4 Combinaison dâ€™opÃ©rateurs logiques",
    "text": "5.4 Combinaison dâ€™opÃ©rateurs logiques\nLes fonctions que nous avons crÃ©Ã©es jusquâ€™Ã  prÃ©sent Ã©taient parfaitement adaptÃ©es Ã  nos besoins, mÃªme si elles Ã©taient assez simplistes. Essayons de crÃ©er une fonction un peu plus complexe. Nous allons crÃ©er une fonction permettant de dÃ©terminer si la journÃ©e dâ€™aujourdâ€™hui sera bonne ou non en fonction de deux critÃ¨res. Le premier critÃ¨re dÃ©pendra du jour de la semaine (vendredi ou non) et le second sera de savoir si votre code fonctionne ou non (VRAI ou FAUX). Pour ce faire, nous utiliserons if et else et des dÃ©clarations. La complexitÃ© viendra de if des dÃ©clarations qui suivent immÃ©diatement les else pertinente. Nous utiliserons ces instructions conditionnelles quatre fois pour obtenir toutes les combinaisons possibles, quâ€™il sâ€™agisse dâ€™un vendredi ou non, et pour savoir si votre code fonctionne ou non.\nNous avons Ã©galement utilisÃ© lâ€™instruction cat() pour produire un texte formatÃ© correctement.\n\ngood.day &lt;- function(code.working, day) {\n  if (code.working == TRUE && day == \"Friday\") {\n    cat(\n  \"BEST.\n  DAY.\n    EVER.\n      Stop while you are ahead and go to the pub!\"\n    )\n  } else if (code.working == FALSE && day == \"Friday\") {\n    cat(\"Oh well, but at least it's Friday! Pub time!\")\n  } else if (code.working == TRUE && day != \"Friday\") {\n    cat(\"\n  So close to a good day...\n  shame it's not a Friday\"\n    )\n  } else if (code.working == FALSE && day != \"Friday\") {\n    cat(\"Hello darkness.\")\n  }\n}\n\n\ngood.day(code.working = TRUE, day = \"Friday\")\n\nBEST.\n  DAY.\n    EVER.\n      Stop while you are ahead and go to the pub!\n\ngood.day(FALSE, \"Tuesday\")\n\nHello darkness.\n\n\nVous avez remarquÃ© que nous nâ€™avons jamais spÃ©cifiÃ© ce quâ€™il fallait faire si le jour nâ€™Ã©tait pas un vendredi ? Câ€™est parce que, pour cette fonction, la seule chose qui compte est de savoir si câ€™est un vendredi ou non.\nNous avons Ã©galement utilisÃ© des opÃ©rateurs logiques chaque fois que nous avons utilisÃ© la fonction if Ã  chaque fois que nous avons utilisÃ© des instructions. Les opÃ©rateurs logiques sont la derniÃ¨re piÃ¨ce du puzzle des conditions logiques. Le tableau ci-dessous rÃ©sume les opÃ©rateurs. Les deux premiers sont des opÃ©rateurs logiques et les six derniers sont des opÃ©rateurs relationnels. Vous pouvez utiliser nâ€™importe lequel de ces opÃ©rateurs lorsque vous crÃ©ez vos propres fonctions (ou boucles).\n\n\n\n\n\n\n\n\nOpÃ©rateur\nDescription technique\nCe que cela signifie\nExemple dâ€™application\n\n\n\n&&\nET logique\nLes deux conditions doivent Ãªtre remplies\nif(cond1 == test && cond2 == test)\n\n\n`\n\n`\nOU logique\n\n\n&lt;\nInfÃ©rieur Ã \nX est infÃ©rieur Ã  Y\nif(X &lt; Y)\n\n\n&gt;\nSupÃ©rieur Ã \nX est supÃ©rieur Ã  Y\nif(X &gt; Y)\n\n\n&lt;=\nInfÃ©rieur ou Ã©gal Ã \nX est infÃ©rieur/Ã©gal Ã  Y\nif(X &lt;= Y)\n\n\n&gt;=\nSupÃ©rieur ou Ã©gal Ã \nX est supÃ©rieur/Ã©gal Ã  Y\nif(X &gt;= Y)\n\n\n==\nEgal Ã \nX est Ã©gal Ã  Y\nif(X == Y)\n\n\n!=\nNâ€™est pas Ã©gal Ã \nX nâ€™est pas Ã©gal Ã  Y\nif(X != Y)",
    "crumbs": [
      "DonnÃ©es",
      "Utiliser R",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Programmation</span>"
    ]
  },
  {
    "objectID": "05-programmation.html#boucles",
    "href": "05-programmation.html#boucles",
    "title": "5Â  Programmation",
    "section": "\n5.5 Boucles",
    "text": "5.5 Boucles\nR est trÃ¨s performant dans lâ€™exÃ©cution de tÃ¢ches rÃ©pÃ©titives. Si nous voulons quâ€™un ensemble dâ€™opÃ©rations soit rÃ©pÃ©tÃ© plusieurs fois, nous utilisons ce que lâ€™on appelle une boucle. Lorsque vous crÃ©ez une boucle, R exÃ©cute les instructions quâ€™elle contient un certain nombre de fois ou jusquâ€™Ã  ce quâ€™une condition donnÃ©e soit remplie. Il existe trois principaux types de boucles dans R : la boucle for la boucle while et la boucle rÃ©pÃ©ter boucle.\nLes boucles sont lâ€™un des Ã©lÃ©ments de base de tous les langages de programmation, et pas seulement de R, et peuvent Ãªtre un outil puissant (bien quâ€™Ã  notre avis, elles soient utilisÃ©es beaucoup trop souvent lors de lâ€™Ã©criture de code R).\n\n5.5.1 Boucle For\nLa structure de boucle la plus couramment utilisÃ©e lorsque vous souhaitez rÃ©pÃ©ter une tÃ¢che un nombre dÃ©fini de fois est la boucle for boucle. Lâ€™exemple le plus simple de boucle for est le suivant :\n\nfor (i in 1:5) {\n  print(i)\n}\n\n[1] 1\n[1] 2\n[1] 3\n[1] 4\n[1] 5\n\n\nMais que fait rÃ©ellement le code ? Il sâ€™agit dâ€™un morceau de code dynamique oÃ¹ un index i est remplacÃ© itÃ©rativement par chaque valeur du vecteur 1:5. DÃ©composons. Parce que la premiÃ¨re valeur de notre sÃ©quence (1:5) est 1 la boucle commence par remplacer i par 1 et exÃ©cute tout ce qui se trouve entre le { }. Les boucles utilisent conventionnellement i comme compteur, abrÃ©viation dâ€™itÃ©ration, mais vous Ãªtes libre dâ€™utiliser ce que vous voulez, mÃªme le nom de votre animal de compagnie, cela nâ€™a pas vraiment dâ€™importance (sauf lorsque vous utilisez des boucles imbriquÃ©es, auquel cas les compteurs doivent Ãªtre appelÃ©s diffÃ©remment, comme SenorWhiskers et HerrFlufferkins).\nAinsi, si nous devions effectuer manuellement la premiÃ¨re itÃ©ration de la boucle\n\ni &lt;- 1\nprint(i)\n\n[1] 1\n\n\nUne fois cette premiÃ¨re itÃ©ration terminÃ©e, la boucle for boucle revient au dÃ©but et remplace i par la valeur suivante dans notre 1:5 sÃ©quence (2 dans ce cas) :\n\ni &lt;- 2\nprint(i)\n\n[1] 2\n\n\nCe processus est ensuite rÃ©pÃ©tÃ© jusquâ€™Ã  ce que la boucle atteigne la derniÃ¨re valeur de la sÃ©quence (5 dans cet exemple), aprÃ¨s quoi elle sâ€™arrÃªte.\nPour renforcer la faÃ§on dont les for et vous prÃ©senter une caractÃ©ristique importante des boucles, nous allons modifier notre compteur Ã  lâ€™intÃ©rieur de la boucle. Cela peut Ãªtre utilisÃ©, par exemple, si nous utilisons une boucle pour parcourir un vecteur mais que nous voulons sÃ©lectionner la ligne suivante (ou toute autre valeur). Pour ce faire, nous ajouterons simplement 1 Ã  la valeur de notre index Ã  chaque fois que nous itÃ©rons notre boucle.\n\nfor (i in 1:5) {\n  print(i + 1)\n}\n\n[1] 2\n[1] 3\n[1] 4\n[1] 5\n[1] 6\n\n\nComme dans la boucle prÃ©cÃ©dente, la premiÃ¨re valeur de notre sÃ©quence est 1. La boucle commence par remplacer i par 1 mais cette fois, nous avons spÃ©cifiÃ© quâ€™une valeur de 1 doit Ãªtre ajoutÃ©e Ã  i dans lâ€™expression rÃ©sultant en une valeur de 1 + 1.\n\ni &lt;- 1\ni + 1\n\n[1] 2\n\n\nComme prÃ©cÃ©demment, une fois lâ€™itÃ©ration terminÃ©e, la boucle passe Ã  la valeur suivante de la sÃ©quence et remplace i par la valeur suivante (2 dans ce cas), de sorte que i + 1 devient 2 + 1.\n\ni &lt;- 2\ni + 1\n\n[1] 3\n\n\nEt ainsi de suite. Nous pensons que vous comprenez lâ€™idÃ©e ! En fait, il sâ€™agit dâ€™une for et rien dâ€™autre.\nBien que nous ayons utilisÃ© une simple addition dans le corps de la boucle, vous pouvez Ã©galement combiner des boucles avec des fonctions.\nRevenons Ã  notre cadre de donnÃ©es dishes. PrÃ©cÃ©demment dans le chapitre, nous avons crÃ©Ã© une fonction pour multiplier deux colonnes et lâ€™avons utilisÃ©e pour crÃ©er notre lasagna_stovies, stovies_poutine, et poutine_tartiflette objets. Nous aurions pu utiliser une boucle pour cela. Rappelons-nous Ã  quoi ressemblent nos donnÃ©es et le code de la fonction multiple_columns() fonction.\n\ndishes &lt;- data.frame(\n  lasagna = rnorm(10),\n  stovies = rnorm(10),\n  poutine = c(rep(NA, 3), rnorm(7)),\n  tartiflette = rnorm(10)\n)\n\n\nmultiply_cols &lt;- function(data, x, y) {\n  temp_var &lt;- data %&gt;%\n    select({{ x }}, {{ y }}) %&gt;%\n    mutate(xy = {\n      .[1] * .[2]\n    }) %&gt;%\n    pull(xy)\n  if (any(is.na(temp_var))) {\n    warning(\"The function has produced NAs\")\n    return(temp_var)\n  } else {\n    return(temp_var)\n  }\n}\n\nPour utiliser une liste afin dâ€™itÃ©rer sur ces colonnes, nous devons dâ€™abord crÃ©er une liste vide (vous vous souvenez de Section 3.2.3 ?) que nous appelons temp (abrÃ©viation de temporary) qui sera utilisÃ©e pour stocker les rÃ©sultats de la fonction for boucle.\n\ntemp &lt;- list()\nfor (i in 1:(ncol(dishes) - 1)) {\n  temp[[i]] &lt;- multiply_cols(dishes, x = colnames(dishes)[i], y = colnames(dishes)[i + 1])\n}\n\nWarning in multiply_cols(dishes, x = colnames(dishes)[i], y =\ncolnames(dishes)[i + : The function has produced NAs\nWarning in multiply_cols(dishes, x = colnames(dishes)[i], y =\ncolnames(dishes)[i + : The function has produced NAs\n\n\nLorsque nous spÃ©cifions notre for remarquez que nous avons soustrait 1 de ncol(dishes). La boucle ncol() renvoie le nombre de colonnes dans notre dishes cadre de donnÃ©es qui est 4 et donc notre boucle sâ€™exÃ©cute de i = 1 Ã  i = 4 - 1 qui est i = 3.\nAinsi, lors de la premiÃ¨re itÃ©ration de la boucle i prend la valeur 1. Les multiply_cols() multiplie le dishes[, 1] (lasagna) et dishes[, 1 + 1] (stovies) et le stocke dans la colonne temp[[1]] qui est le premier Ã©lÃ©ment de la colonne temp liste.\nLa deuxiÃ¨me itÃ©ration de la boucle i prend la valeur 2. Les multiply_cols() multiplie le dishes[, 2] (stovies) et dishes[, 2 + 1] (poutine) et le stocke dans la colonne temp[[2]] qui est le deuxiÃ¨me Ã©lÃ©ment de la colonne temp liste.\nLa troisiÃ¨me et derniÃ¨re itÃ©ration de la boucle i prend la valeur 3. Les multiply_cols() multiplie le dishes[, 3] (poutine) et dishes[, 3 + 1] (tartiflette) et le stocke dans la colonne temp[[3]] qui est le troisiÃ¨me Ã©lÃ©ment de la colonne temp liste.\nEncore une fois, il est bon de vÃ©rifier que nous obtenons quelque chose de sensÃ© de notre boucle (rappelez-vous, vÃ©rifiez, vÃ©rifiez et vÃ©rifiez encore !). Pour ce faire, nous pouvons utiliser la fonction identical() pour comparer les variables que nous avons crÃ©Ã©es by hand Ã  chaque itÃ©ration de la boucle manuellement.\n\nlasagna_stovies_func &lt;- multiply_cols(dishes, lasagna, stovies)\ni &lt;- 1\nidentical(\n  multiply_cols(dishes, colnames(dishes)[i], colnames(dishes)[i + 1]),\n  lasagna_stovies_func\n)\n\n[1] TRUE\n\nstovies_poutine_func &lt;- multiply_cols(dishes, stovies, poutine)\n\nWarning in multiply_cols(dishes, stovies, poutine): The function has produced\nNAs\n\ni &lt;- 2\nidentical(\n  multiply_cols(dishes, colnames(dishes)[i], colnames(dishes)[i + 1]),\n  stovies_poutine_func\n)\n\nWarning in multiply_cols(dishes, colnames(dishes)[i], colnames(dishes)[i + :\nThe function has produced NAs\n\n\n[1] TRUE\n\n\nSi vous pouvez suivre les exemples ci-dessus, vous serez en bonne position pour commencer Ã  Ã©crire vos propres boucles for. Cela dit, il existe dâ€™autres types de boucles.\n\n5.5.2 Boucle While\nUn autre type de boucle que vous pouvez utiliser (bien que moins frÃ©quemment) est la boucle while boucle. La boucle while est utilisÃ©e lorsque vous voulez continuer Ã  tourner en boucle jusquâ€™Ã  ce quâ€™une condition logique spÃ©cifique soit remplie (Ã  comparer avec la boucle for qui parcourt toujours une sÃ©quence entiÃ¨re).\nLa structure de base de la boucle while est la suivante\n\nwhile (logical_condition) {\n  expression\n}\n\nUn exemple simple de boucle while est le suivant :\n\ni &lt;- 0\nwhile (i &lt;= 4) {\n  i &lt;- i + 1\n  print(i)\n}\n\n[1] 1\n[1] 2\n[1] 3\n[1] 4\n[1] 5\n\n\nIci, la boucle continuera uniquement Ã  transmettre des valeurs au corps principal de la boucle (lâ€™Ã©lÃ©ment expression corps) que lorsque i est infÃ©rieur ou Ã©gal Ã  4 (spÃ©cifiÃ© Ã  lâ€™aide de lâ€™attribut &lt;= dans cet exemple). Une fois que i est supÃ©rieur Ã  4, la boucle sâ€™arrÃªte.\nIl existe un autre type de boucle, trÃ¨s rarement utilisÃ© : la boucle repeat boucle. La boucle repeat nâ€™a pas de contrÃ´le conditionnel et peut donc continuer Ã  itÃ©rer indÃ©finiment (ce qui signifie quâ€™une pause, ou â€œstop hereâ€, doit Ãªtre codÃ©e dans la boucle). Cela vaut la peine dâ€™Ãªtre conscient de son existence, mais pour lâ€™instant nous ne pensons pas quâ€™il faille sâ€™en prÃ©occuper ; la fonction for et while vous permettront de rÃ©pondre Ã  la plupart de vos besoins en matiÃ¨re de boucles.\n\n5.5.3 Quand utiliser une boucle ?\nLes boucles sont assez couramment utilisÃ©es, bien que parfois un peu trop Ã  notre avis. Des tÃ¢ches Ã©quivalentes peuvent Ãªtre effectuÃ©es avec des fonctions, qui sont souvent plus efficaces que les boucles. La question se pose donc de savoir quand il faut utiliser une boucle.\nEn gÃ©nÃ©ral, les boucles sont implÃ©mentÃ©es de maniÃ¨re inefficace dans R et doivent Ãªtre Ã©vitÃ©es lorsque de meilleures alternatives existent, en particulier lorsque vous travaillez avec de grands ensembles de donnÃ©es. Cependant, les boucles sont parfois le seul moyen dâ€™obtenir le rÃ©sultat souhaitÃ©.\nVoici quelques exemples de cas oÃ¹ lâ€™utilisation de boucles peut sâ€™avÃ©rer appropriÃ©e :\n\nCertaines simulations (par exemple le modÃ¨le de Ricker peut, en partie, Ãªtre construit Ã  lâ€™aide de boucles)\nRelations rÃ©cursives (une relation qui dÃ©pend de la valeur de la relation prÃ©cÃ©dente) [â€œpour comprendre la rÃ©cursivitÃ©, il faut comprendre la rÃ©cursivitÃ©â€.] )\nProblÃ¨mes plus complexes (par exemple, depuis combien de temps le dernier blaireau a-t-il Ã©tÃ© vu sur le site ? \\(j\\) Ã©tant donnÃ© quâ€™une martre des pins a Ã©tÃ© vue Ã  lâ€™heure \\(t\\) au mÃªme endroit \\(j\\) que le blaireau, lorsque la martre a Ã©tÃ© dÃ©tectÃ©e au cours dâ€™une pÃ©riode spÃ©cifique de 6 heures, mais excluant les blaireaux vus 30 minutes avant lâ€™arrivÃ©e de la martre, rÃ©pÃ©tÃ©e pour toutes les dÃ©tections de martres)\nBoucles While (continuez Ã  sauter jusquâ€™Ã  ce que vous ayez atteint la lune)\n\n5.5.4 Si ce ne sont pas des boucles, alors quoi ?\nEn bref, utilisez la famille de fonctions apply ; apply(), lapply(), tapply(), sapply(), vapply() et mapply(). Les fonctions apply peuvent souvent accomplir les tÃ¢ches de la plupart des boucles â€œmaisonâ€, parfois plus rapidement (bien que cela ne soit pas vraiment un problÃ¨me pour la plupart des gens), mais surtout avec un risque dâ€™erreur beaucoup plus faible. Une stratÃ©gie Ã  garder Ã  lâ€™esprit et qui peut sâ€™avÃ©rer utile est la suivante : pour chaque boucle que vous faites, essayez de la refaire en utilisant une fonction apply (souvent lapply ou sapply fonctionneront). Si vous le pouvez, utilisez la version applicable. Il nâ€™y a rien de pire que de se rendre compte quâ€™il y avait une petite, minuscule, erreur apparemment insignifiante dans une boucle qui, des semaines, des mois ou des annÃ©es plus tard, sâ€™est propagÃ©e dans un Ã©norme gÃ¢chis. Nous recommandons vivement dâ€™essayer dâ€™utiliser les fonctions apply chaque fois que cela est possible.\nlapply\nVotre fonction dâ€™application sera souvent lapply() du moins au dÃ©but. La faÃ§on dont les lapply() et la raison pour laquelle il constitue souvent une bonne alternative aux boucles for, est quâ€™il passe en revue chaque Ã©lÃ©ment dâ€™une liste et effectue une tÃ¢che (câ€™est-Ã -dire exÃ©cuter une fonction). Il prÃ©sente lâ€™avantage supplÃ©mentaire de produire les rÃ©sultats sous forme de liste, ce que vous devriez autrement coder vous-mÃªme dans une boucle.\nUne fonction lapply() a la structure suivante :\nlapply(X, FUN)\nIci X est le vecteur que nous voulons faire quelque chose quelque chose. FUN Les stands de lâ€™association sont trÃ¨s amusants (je plaisante !). Câ€™est aussi lâ€™abrÃ©viation de â€œfonctionâ€.\nCommenÃ§ons par une dÃ©monstration simple. Utilisons la fonction lapply() pour crÃ©er une sÃ©quence de 1 Ã  5 et ajouter 1 Ã  chaque observation (comme nous lâ€™avons fait lorsque nous avons utilisÃ© une boucle for) :\n\nlapply(0:4, function(a) {\n  a + 1\n})\n\n[[1]]\n[1] 1\n\n[[2]]\n[1] 2\n\n[[3]]\n[1] 3\n\n[[4]]\n[1] 4\n\n[[5]]\n[1] 5\n\n\nRemarquez que nous devons spÃ©cifier notre sÃ©quence en tant que 0:4 pour obtenir la sortie 1 ,2 ,3 ,4 , 5 puisque nous ajoutons 1 Ã  chaque Ã©lÃ©ment de la sÃ©quence. Voyez ce qui se passe si vous utilisez 1:5 Ã  la place.\nDe maniÃ¨re Ã©quivalente, nous aurions pu dÃ©finir la fonction dâ€™abord, puis lâ€™utiliser dans lapply()\n\nadd_fun &lt;- function(a) {\n  a + 1\n}\nlapply(0:4, add_fun)\n\n[[1]]\n[1] 1\n\n[[2]]\n[1] 2\n\n[[3]]\n[1] 3\n\n[[4]]\n[1] 4\n\n[[5]]\n[1] 5\n\n\nLes sapply() fait la mÃªme chose que lapply() mais au lieu de stocker les rÃ©sultats sous forme de liste, elle les stocke sous forme de vecteur.\n\nsapply(0:4, function(a) {\n  a + 1\n})\n\n[1] 1 2 3 4 5\n\n\nComme vous pouvez le voir, dans les deux cas, nous obtenons exactement les mÃªmes rÃ©sultats que lorsque nous avons utilisÃ© la boucle for.",
    "crumbs": [
      "DonnÃ©es",
      "Utiliser R",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Programmation</span>"
    ]
  },
  {
    "objectID": "06-quarto.html",
    "href": "06-quarto.html",
    "title": "6Â  Rapports reproductibles avec Quarto",
    "section": "",
    "text": "6.1 Quâ€™est-ce que R markdown / Quarto ?",
    "crumbs": [
      "DonnÃ©es",
      "Utiliser R",
      "<span class='chapter-number'>6</span>Â  <span class='chapter-title'>Rapports reproductibles avec Quarto</span>"
    ]
  },
  {
    "objectID": "06-quarto.html#quest-ce-que-r-markdown-quarto",
    "href": "06-quarto.html#quest-ce-que-r-markdown-quarto",
    "title": "6Â  Rapports reproductibles avec Quarto",
    "section": "",
    "text": "6.1.1 R Markdown\nR markdown est un langage de texte simple et facile Ã  utiliser pour combiner votre code R, les rÃ©sultats de votre analyse de donnÃ©es (y compris les graphiques et les tableaux) et vos commentaires Ã©crits dans un document unique, bien formatÃ© et reproductible (comme un rapport, une publication, un chapitre de thÃ¨se ou une page web comme celle-ci).\nTechniquement, R markdown est une combinaison de trois langages, R, Markdown et YAML (un autre langage de balisage). Markdown et YAML sont tous deux un type de langage de balisage. Un langage de balisage permet simplement de crÃ©er un fichier de texte brut facile Ã  lire, qui peut contenir du texte formatÃ©, des images, des en-tÃªtes et des liens vers dâ€™autres documents. Si vous Ãªtes intÃ©ressÃ©, vous pouvez trouver plus dâ€™informations sur les langages de balisage [ici][balisage] . En fait, vous Ãªtes exposÃ© Ã  un langage de balisage tous les jours, car la plupart des contenus Internet que vous digÃ©rez quotidiennement sont Ã©tayÃ©s par un langage de balisage appelÃ© HTML (Hypertext Markup Language). Quoi quâ€™il en soit, le point principal est que R markdown est trÃ¨s facile Ã  apprendre (beaucoup, beaucoup plus facile que HTML) et lorsquâ€™il est utilisÃ© avec un bon IDE (RStudio ou VS Code), il est ridiculement facile Ã  intÃ©grer dans votre flux de travail pour produire un contenu riche en fonctionnalitÃ©s (alors pourquoi ne le feriez-vous pas ?!).\n\n6.1.2 Quarto ?\nQuarto est une version multilingue de la nouvelle gÃ©nÃ©ration de R Markdown de Posit, avec de nombreuses nouvelles fonctionnalitÃ©s et capacitÃ©s, compatible non seulement avec R mais aussi avec dâ€™autres langages comme Python et Julia. Comme R Markdown, Quarto utilise knitr ğŸ“¦ package pour exÃ©cuter le code R, et est donc capable de rendre la plupart des codes R existants. .Rmd existants sans modification. Cependant, il sâ€™accompagne Ã©galement dâ€™une plÃ©thore de nouvelles fonctionnalitÃ©s. Plus important encore, il facilite grandement la crÃ©ation de diffÃ©rents types de sorties puisque le codage est homogÃ©nÃ©isÃ© pour un format spÃ©cifique sans avoir Ã  se fier Ã  diffÃ©rents paquets r ayant chacun leurs propres spÃ©cificitÃ©s (Par exemple bookdown, hugodown, blogdown, thesisdown, rticles, xaringan, â€¦).\nDans la suite de ce chapitre, nous parlerons de Quarto mais beaucoup de choses peuvent Ãªtre faites avec R markdown. Quarto utilise .qmd alors que R markdown fonctionne avec des fichiers .Rmd mais Quarto peut rendre .Rmd Ã©galement.",
    "crumbs": [
      "DonnÃ©es",
      "Utiliser R",
      "<span class='chapter-number'>6</span>Â  <span class='chapter-title'>Rapports reproductibles avec Quarto</span>"
    ]
  },
  {
    "objectID": "06-quarto.html#pourquoi-utiliser-quarto",
    "href": "06-quarto.html#pourquoi-utiliser-quarto",
    "title": "6Â  Rapports reproductibles avec Quarto",
    "section": "\n6.2 Pourquoi utiliser Quarto ?",
    "text": "6.2 Pourquoi utiliser Quarto ?\nAu cours des chapitres prÃ©cÃ©dents, nous avons beaucoup parlÃ© de la nÃ©cessitÃ© de mener vos recherches de maniÃ¨re robuste et reproductible afin de faciliter la science ouverte. En rÃ©sumÃ©, la science ouverte consiste Ã  faire tout ce qui est en notre pouvoir pour rendre nos donnÃ©es, nos mÃ©thodes, nos rÃ©sultats et nos conclusions transparents et accessibles Ã  tous. Certains des principaux principes de la science ouverte sont dÃ©crits ici et comprennent\n\nTransparence de la mÃ©thodologie expÃ©rimentale, de lâ€™observation, de la collecte des donnÃ©es et des mÃ©thodes dâ€™analyse.\nDisponibilitÃ© publique et rÃ©utilisation des donnÃ©es scientifiques\nAccessibilitÃ© au public et transparence de la communication scientifique\nUtilisation dâ€™outils en ligne pour faciliter la collaboration scientifique\n\nÃ€ lâ€™heure actuelle, vous utilisez tous (avec un peu de chance) R pour explorer et analyser vos donnÃ©es intÃ©ressantes. En tant que tel, vous Ãªtes dÃ©jÃ  bien avancÃ© dans votre dÃ©marche visant Ã  rendre votre analyse plus reproductible, plus transparente et plus facile Ã  partager. Cependant, il se peut que votre flux de travail actuel ressemble Ã  ceci :\n\n\n\n\n\n\n\nFigureÂ 6.1: Non-reproducible workflow\n\n\n\n\nVos donnÃ©es sont importÃ©es dans R Ã  partir de votre tableur prÃ©fÃ©rÃ©, vous Ã©crivez votre code R pour explorer et analyser vos donnÃ©es, vous enregistrez les tracÃ©s sous forme de fichiers externes, vous copiez les tableaux des rÃ©sultats dâ€™analyse, puis vous combinez manuellement tous ces Ã©lÃ©ments et votre prose Ã©crite dans un seul document MS Word (peut-Ãªtre pour un article ou un chapitre de thÃ¨se). Bien quâ€™il nâ€™y ait rien de particuliÃ¨rement mauvais dans cette approche (et quâ€™elle soit certainement meilleure que lâ€™utilisation dâ€™un logiciel â€œpointer-cliquerâ€ pour analyser vos donnÃ©es), elle prÃ©sente certaines limites :\n\nElle nâ€™est pas particuliÃ¨rement reproductible. Parce que ce flux de travail sÃ©pare votre code R du document final, il y a de multiples occasions de prendre des dÃ©cisions non documentÃ©es (quels graphiques avez-vous utilisÃ©s ? quelles analyses avez-vous incluses ou non ? etc.)\nIl est inefficace. Si vous devez revenir en arriÃ¨re et modifier quelque chose (crÃ©er un nouveau graphique ou mettre Ã  jour votre analyse, etc.), vous devrez crÃ©er ou modifier plusieurs documents, ce qui augmente le risque que des erreurs se glissent dans votre flux de travail.\nIl est difficile Ã  maintenir. Si votre analyse change, vous devrez Ã  nouveau mettre Ã  jour plusieurs fichiers et documents.\nIl peut Ãªtre difficile de dÃ©cider ce qui doit Ãªtre partagÃ© avec dâ€™autres. Partagez-vous lâ€™ensemble de votre code (exploration initiale des donnÃ©es, validation du modÃ¨le, etc.) ou seulement le code spÃ©cifique Ã  votre document final ? Il est assez courant (et mauvais !) pour les chercheurs de maintenir deux scripts R, lâ€™un utilisÃ© pour lâ€™analyse proprement dite et lâ€™autre Ã  partager avec le document final ou le chapitre de la thÃ¨se. Cela peut prendre du temps et prÃªter Ã  confusion et devrait Ãªtre Ã©vitÃ©.\n\nUn flux de travail plus efficace et plus robuste pourrait ressembler Ã  ceci :\n\n\n\n\n\n\n\nFigureÂ 6.2: A-reproducible (and more fficient) workflow\n\n\n\n\nVos donnÃ©es sont importÃ©es dans R comme prÃ©cÃ©demment, mais cette fois-ci, tout le code R que vous avez utilisÃ© pour analyser vos donnÃ©es, produire vos graphiques et votre texte Ã©crit (Introduction, MatÃ©riel et MÃ©thodes, Discussion, etc.) est contenu dans un seul document Quarto qui est ensuite utilisÃ© (avec vos donnÃ©es) pour crÃ©er automatiquement votre document final. Câ€™est exactement ce que Quarto vous permet de faire.\nVoici quelques-uns des avantages de lâ€™utilisation de Quarto :\n\nIl relie explicitement vos donnÃ©es Ã  votre code R et Ã  vos rÃ©sultats, crÃ©ant ainsi un flux de travail entiÃ¨rement reproductible. TOUT du code R utilisÃ© pour explorer, rÃ©sumer et analyser vos donnÃ©es peut Ãªtre inclus dans un seul document facile Ã  lire. Vous pouvez dÃ©cider de ce que vous voulez inclure dans votre document final (comme vous lâ€™apprendrez ci-dessous), mais tout votre code R peut Ãªtre inclus dans le document Quarto.\nVous pouvez crÃ©er une grande variÃ©tÃ© de formats de sortie (pdf, pages web html, MS Word et bien dâ€™autres) Ã  partir dâ€™un seul document Quarto, ce qui amÃ©liore Ã  la fois la collaboration et la communication.\nAmÃ©liore la transparence de votre recherche. Vos donnÃ©es et votre fichier Quarto peuvent Ãªtre joints Ã  votre publication ou au chapitre de votre thÃ¨se en tant que matÃ©riel supplÃ©mentaire ou Ãªtre hÃ©bergÃ©s sur un dÃ©pÃ´t GitHub (voir Chapitre 7).\nAugmente lâ€™efficacitÃ© de votre flux de travail. Si vous avez besoin de modifier ou dâ€™Ã©tendre votre analyse actuelle, il vous suffit de mettre Ã  jour votre document Quarto et ces changements seront automatiquement inclus dans votre document final.",
    "crumbs": [
      "DonnÃ©es",
      "Utiliser R",
      "<span class='chapter-number'>6</span>Â  <span class='chapter-title'>Rapports reproductibles avec Quarto</span>"
    ]
  },
  {
    "objectID": "06-quarto.html#commencer-avec-quarto",
    "href": "06-quarto.html#commencer-avec-quarto",
    "title": "6Â  Rapports reproductibles avec Quarto",
    "section": "\n6.3 Commencer avec Quarto",
    "text": "6.3 Commencer avec Quarto\nQuarto sâ€™intÃ¨gre trÃ¨s bien avec R Studio et VS Code et fournissent Ã  la fois un Ã©diteur de source et un Ã©diteur visuel offrant une expÃ©rience proche de votre logiciel dâ€™Ã©criture classique WYSIWYG (ce que vous voyez est ce que vous Ã©crivez) (par exemple Microsoft Word ou LibreOffice writer).\n\n6.3.1 Installation de la solution\nPour utiliser Quarto, vous devez dâ€™abord installer le logiciel Quarto et le logiciel quarto ğŸ“¦ (avec ses dÃ©pendances). Vous trouverez des instructions sur la faÃ§on de procÃ©der dans Section 1.1.1 et sur le site web de Quarto. Si vous souhaitez crÃ©er des documents PDF (ou des documents MS Word) Ã  partir de votre fichier Quarto, vous devrez Ã©galement installer une version de {{&lt; latex &gt;}} sur votre ordinateur. Si vous nâ€™avez pas installÃ© {{&lt; latex &gt;} }, nous vous recommandons dâ€™installer TinyTeX . LÃ  encore, des instructions sur la maniÃ¨re de procÃ©der sont disponibles Ã  lâ€™adresse suivante : Section 1.1.1.\n\n6.3.2 CrÃ©ez un document Quarto, .qmd\n\nIl est temps de crÃ©er votre premier document Quarto. Dans RStudio, cliquez sur le menu File -&gt; New File -&gt; Quarto.... Dans la fenÃªtre qui sâ€™ouvre, donnez un â€œtitreâ€ au document, saisissez les informations relatives Ã  lâ€™â€œauteurâ€ (votre nom) et sÃ©lectionnez HTML comme format de sortie par dÃ©faut. Nous pourrons modifier tout cela ultÃ©rieurement, ne vous en prÃ©occupez donc pas pour lâ€™instant.\n\n\n\n\n\n\n\nFigureÂ 6.3: Creating a Quarto document\n\n\n\n\nVous remarquerez que lorsque votre nouveau document Quarto est crÃ©Ã©, il comprend un exemple de code Quarto. Normalement, vous devriez surligner et supprimer tout ce qui se trouve dans le document, Ã  lâ€™exception de lâ€™information situÃ©e en haut, entre les boutons --- (câ€™est ce quâ€™on appelle lâ€™en-tÃªte YAML dont nous parlerons dans un instant) et commencer Ã  Ã©crire votre propre code. Cependant, pour lâ€™instant, nous allons utiliser ce document pour nous entraÃ®ner Ã  convertir Quarto aux formats html et pdf et vÃ©rifier que tout fonctionne.\n\n\n\n\n\n\n\nFigureÂ 6.4: A new Quarto document\n\n\n\n\nUne fois que vous avez crÃ©Ã© votre document Quarto, câ€™est une bonne pratique de sauvegarder ce fichier dans un endroit pratique (Section 1.4 et FigureÂ 1.11). Vous pouvez le faire en sÃ©lectionnant File -&gt; Save dans le menu de RStudio (ou utilisez le raccourci clavier ctrl + s sous Windows ou cmd + s sur Mac) et entrez un nom de fichier appropriÃ© (appelez-le par exemple my_first_quarto). Notez que lâ€™extension de votre nouveau fichier Quarto est .qmd.\nMaintenant, pour convertir votre fichier .qmd en document HTML, cliquez sur le petit triangle noir Ã  cÃ´tÃ© de lâ€™icÃ´ne Knit en haut de la fenÃªtre source et sÃ©lectionnez knit to HTML\n\n\n\n\n\n\n\nFigureÂ 6.5: Knitting a Qmd file\n\n\n\n\nRStudio va maintenant â€œtricoterâ€ (ou rendre) votre fichier .qmd en un fichier HTML. Remarquez quâ€™il y a un nouveau Quarto dans votre fenÃªtre de console, qui vous fournit des informations sur le processus de rendu et affiche Ã©galement les erreurs si quelque chose ne va pas.\nSi tout sâ€™est dÃ©roulÃ© sans problÃ¨me, un nouveau fichier HTML a Ã©tÃ© crÃ©Ã© et enregistrÃ© dans le mÃªme rÃ©pertoire que votre fichier .qmd (le nÃ´tre sâ€™appellera my_first_quarto.html). Pour visualiser ce document, il suffit de double-cliquer sur le fichier pour lâ€™ouvrir dans un navigateur (comme Chrome ou Firefox) et afficher le contenu rendu. RStudio affichera Ã©galement un aperÃ§u du fichier rendu dans une nouvelle fenÃªtre pour que vous puissiez le vÃ©rifier (votre fenÃªtre peut Ãªtre lÃ©gÃ¨rement diffÃ©rente si vous utilisez un ordinateur Windows).\n\n\n\n\n\n\n\nFigureÂ 6.6: A my first rendered html\n\n\n\n\nVous venez de rendre votre premier document Quarto. Si vous souhaitez tricoter votre .qmd en un document pdf, il vous suffit de choisir knit to PDF au lieu de knit to HTML lorsque vous cliquez sur le bouton knit lâ€™icÃ´ne Cela crÃ©era un fichier appelÃ© my_first_quarto.pdf que vous pouvez ouvrir en double-cliquant dessus. Essayez-le !\nVous pouvez Ã©galement tricoter un .qmd en utilisant la ligne de commande dans la console plutÃ´t quâ€™en cliquant sur lâ€™icÃ´ne de tricotage. Pour ce faire, il suffit dâ€™utiliser la commande quarto_render() de la fonction quarto ğŸ“¦ package, comme indiquÃ© ci-dessous. LÃ  encore, vous pouvez modifier le format de sortie Ã  lâ€™aide de la fonction output_format = ainsi que de nombreuses autres options.\nlibrary(quarto)\n\nquarto_render('my_first_quarto.qmd', output_format = 'html_document')\n\n# alternatively if you don't want to load the quarto package\n\nquarto::quarto_render('my_first_quarto.Rmd', output_format = 'html_document')",
    "crumbs": [
      "DonnÃ©es",
      "Utiliser R",
      "<span class='chapter-number'>6</span>Â  <span class='chapter-title'>Rapports reproductibles avec Quarto</span>"
    ]
  },
  {
    "objectID": "06-quarto.html#anatomie-du-document-quarto-.qmd",
    "href": "06-quarto.html#anatomie-du-document-quarto-.qmd",
    "title": "6Â  Rapports reproductibles avec Quarto",
    "section": "\n6.4 Anatomie du document Quarto (.qmd)",
    "text": "6.4 Anatomie du document Quarto (.qmd)\nMaintenant que vous pouvez rendre un fichier Quarto dans RStudio aux formats HTML et PDF, examinons de plus prÃ¨s les diffÃ©rents composants dâ€™un document Quarto typique. Normalement, chaque document Quarto est composÃ© de 3 Ã©lÃ©ments principaux :\n\nun en-tÃªte YAML\ntexte formatÃ©\ndes morceaux de code.\n\n\n\n\n\n\n\n\nFigureÂ 6.7: Structure of a qmd file\n\n\n\n\n\n6.4.1 En-tÃªte YAML\nYAML signifie â€™YAML Ainâ€™t Markup L anguageâ€ (câ€™est une blague â€œinâ€) [plaisanterie][blague] !) et ce composant optionnel contient les mÃ©tadonnÃ©es et les options pour lâ€™ensemble du document comme le nom de lâ€™auteur, la date, le format de sortie, etc. Lâ€™en-tÃªte YAML est entourÃ© avant et aprÃ¨s dâ€™une balise --- sur sa propre ligne. Dans RStudio, un en-tÃªte YAML minimal est automatiquement crÃ©Ã© pour vous lorsque vous crÃ©ez un nouveau document Quarto comme nous lâ€™avons fait ci-dessus (Section 6.3.2), mais vous pouvez le modifier Ã  tout moment. Un en-tÃªte YAML simple peut ressembler Ã  ceci :\n---\ntitle: My first Quarto document\nauthor: Jane Doe\ndate: March 01, 2020\nformat: html\n---\nDans lâ€™en-tÃªte YAML ci-dessus, le format de sortie est dÃ©fini sur HTML. Si vous souhaitez changer le format de sortie au format pdf, vous pouvez le changer de format: html Ã  format: pdf (vous pouvez Ã©galement dÃ©finir plusieurs formats de sortie si vous le souhaitez). Vous pouvez Ã©galement modifier la police et la taille de police par dÃ©faut pour lâ€™ensemble du document et mÃªme inclure des options fantaisistes telles quâ€™une table des matiÃ¨res, des rÃ©fÃ©rences en ligne et une bibliographie. Si vous souhaitez explorer la plÃ©thore dâ€™autres options, voir ici . Attention, la plupart des options que vous pouvez spÃ©cifier dans lâ€™en-tÃªte YAML fonctionneront avec les documents au format HTML et PDF, mais pas toutes. Si vous avez besoin de plusieurs formats de sortie pour votre document Quarto, vÃ©rifiez si vos options YAML sont compatibles avec ces formats. De plus, lâ€™indentation dans lâ€™en-tÃªte YAML a une signification, soyez donc prudent lorsque vous alignez du texte. Par exemple, si vous souhaitez inclure une table des matiÃ¨res, vous devez modifier lâ€™option output: dans lâ€™en-tÃªte YAML comme suit\n---\ntitle: My first Quarto document\nauthor: Bob Hette\ndate: March 01, 2020\nformat:\n  html:\n    toc: true\n---\n\n6.4.2 Texte formatÃ©\nComme mentionnÃ© ci-dessus, lâ€™un des avantages de Quarto est que vous nâ€™avez pas besoin de votre traitement de texte pour rassembler votre code R, votre analyse et votre Ã©criture. Quarto est capable de restituer (presque) tout le formatage de texte dont vous pourriez avoir besoin, comme lâ€™italique, le gras, le barrÃ©, lâ€™indice supÃ©rieur et lâ€™indice infÃ©rieur, ainsi que les listes Ã  puces et numÃ©rotÃ©es, les en-tÃªtes et les pieds de page, les images, les liens vers dâ€™autres documents ou pages web, et aussi les Ã©quations. Cependant, contrairement Ã  ce que vous connaissez, le Ce que vous voyez, câ€™est ce que vous obtenez ( WYSIWYG ), vous ne voyez pas le texte formatÃ© final dans votre document Quarto (comme vous le feriez avec MS Word), mais vous devez â€œbaliserâ€ le formatage de votre texte pour quâ€™il soit rendu dans votre document de sortie. Ã€ premiÃ¨re vue, cela peut sembler une vÃ©ritable plaie, mais câ€™est en fait trÃ¨s facile Ã  faire et cela prÃ©sente de nombreux avantages. avantages (passez-vous plus de temps Ã  embellir votre texte dans MS Word quâ€™Ã  rÃ©diger un contenu de qualitÃ© ?)\nVoici un exemple de marquage du formatage du texte dans un document Quarto\n#### Tadpole sediment experiment\n\nThese data were obtained from a mesocosm experiment which aimed to examine the\neffect of bullfrog tadpoles (*Lithobates catesbeianus*) biomass on sediment\nnutrient (NH~4~, NO~3~ and PO~3~) release.\nAt the start of the experiment 15 replicate mesocosms were filled with\n20 cm^2^ of **homogenised** marine sediment and assigned to one of five \ntadpole biomass treatments.\nqui ressemblerait Ã  ceci dans le document rendu final (pouvez-vous repÃ©rer les marques ?)\n\nExpÃ©rience de sÃ©dimentation sur les tÃªtards\n\n\nCes donnÃ©es proviennent dâ€™une expÃ©rience en mÃ©socosme qui visait Ã  examiner les effets de la sÃ©dimentation sur les tÃªtards. lâ€™effet des tÃªtards de grenouille-taureau (Lithobates catesbeianus) sur les sÃ©diments nutriments (NH4 NO3 et PO3). Au dÃ©but de lâ€™expÃ©rience, 15 mÃ©socosmes rÃ©pÃ©tÃ©s ont Ã©tÃ© remplis de 20 cm2 de homogÃ©nÃ©isÃ© sÃ©diments marins homogÃ©nÃ©isÃ©s et classÃ©s dans lâ€™une des cinq catÃ©gories suivantes biomasse de tÃªtards.\n\nLâ€™accent est mis\nLa syntaxe markdown la plus courante pour mettre en valeur et formater du texte est prÃ©sentÃ©e ci-dessous.\n\n\n\n\n\n\n\nObjectif\nQuarto\nproduction\n\n\n\ntexte en gras\n**mytext**\nmon texte\n\n\ntexte en italique\n*mytext*\nmon texte\n\n\nbarrÃ©\n~~mytext~~\nmon texte\n\n\nexposant\nmytext^2^\nmon texte2\n\n\n\nindice\nmytext~2~\nmon texte2\n\n\n\n\nIl est intÃ©ressant de noter quâ€™il nâ€™y a pas de soulignement par dÃ©faut dans la syntaxe de R markdown, pour des raisons plus ou moins Ã©sotÃ©riques (par exemple. un soulignement est considÃ©rÃ© comme un Ã©lÃ©ment stylistique (il peut y avoir dâ€™autres raisons). [raisons][souligner] )). Quarto a corrigÃ© ce problÃ¨me, vous pouvez simplement faire [text to underline]{.underline} pour souligner votre texte.\nEspaces blancs et sauts de ligne\nLâ€™une des choses qui peut Ãªtre dÃ©routante pour les nouveaux utilisateurs de markdown est lâ€™utilisation des espaces et des retours Ã  la ligne (la touche EntrÃ©e de votre clavier). En markdown, les espaces multiples dans le texte sont gÃ©nÃ©ralement ignorÃ©s, tout comme les retours Ã  la ligne. Par exemple, ce texte en markdown\nThese      data were      obtained from a\nmesocosm experiment which    aimed to examine the\neffect\nof          bullfrog tadpoles (*Lithobates catesbeianus*) biomass.\nsera rendu sous la forme\n\nCes donnÃ©es ont Ã©tÃ© obtenues Ã  partir dâ€™un expÃ©rience en mÃ©socosme qui visait Ã  examiner lâ€™impact de lâ€™utilisation de lâ€™eau sur la santÃ©. lâ€™effet des tÃªtards de grenouille-taureau (Lithobates catesbeianus) biomasse.\n\nCâ€™est gÃ©nÃ©ralement une bonne chose (plus dâ€™espaces multiples alÃ©atoires dans votre texte). Si vous voulez que votre texte commence sur une nouvelle ligne, vous pouvez simplement ajouter deux espaces vides Ã  la fin de la ligne prÃ©cÃ©dente.\n\nCes donnÃ©es ont Ã©tÃ© obtenues Ã  partir dâ€™un\nexpÃ©rience en mÃ©socosme qui visait Ã  examiner lâ€™impact de lâ€™utilisation de lâ€™eau sur la qualitÃ© de lâ€™air.\neffet des tÃªtards de grenouille-taureau (Lithobates catesbeianus).\n\nSi vous voulez vraiment des espaces multiples dans votre texte, vous pouvez utiliser la fonction Nsur breaking space tag &nbsp;\nThese &nbsp; &nbsp; &nbsp; data were &nbsp; &nbsp; &nbsp; &nbsp; obtained from a  \nmesocosm experiment which &nbsp; &nbsp; aimed to examine the    \neffect &nbsp; &nbsp; &nbsp; &nbsp; bullfrog tadpoles (*Lithobates catesbeianus*) biomass.\n\nCes donnÃ©es ont Ã©tÃ© obtenues Ã  partir dâ€™un\ndâ€™une expÃ©rience en mÃ©socosme qui visait Ã  examiner lâ€™impact de lâ€™utilisation de lâ€™eau sur la santÃ©.\neffet des tÃªtards de grenouille-taureau (Lithobates catesbeianus).\n\nRubriques\nVous pouvez ajouter des titres et des sous-titres Ã  votre document Quarto en utilisant la fonction # en dÃ©but de ligne. Vous pouvez rÃ©duire la taille des titres en ajoutant simplement plus de # symboles. Par exemple, il est possible de rÃ©duire la taille des titres en ajoutant simplement des symboles supplÃ©mentaires.\n# Header 1\n## Header 2\n### Header 3\n#### Header 4\n##### Header 5\n###### Header 6\npermet dâ€™obtenir des titres par ordre de taille dÃ©croissante\n\nEn-tÃªte 1\nEn-tÃªte 2\nEn-tÃªte 3\nEn-tÃªte 4\nEn-tÃªte 5\nEn-tÃªte 6\n\nCommentaires\nComme vous pouvez le voir ci-dessus, la signification de la # est diffÃ©rente lorsquâ€™il sâ€™agit de formater du texte dans un document Quarto par rapport Ã  un script R standard (qui est utilisÃ© pour inclure un commentaire - vous vous souvenez ?!). Vous pouvez cependant utiliser un # pour commenter du code Ã  lâ€™intÃ©rieur dâ€™un morceau de code (Section 6.4.3) comme dâ€™habitude (plus dâ€™informations Ã  ce sujet dans un instant). Si vous souhaitez inclure un commentaire dans votre document Quarto en dehors dâ€™un morceau de code qui ne sera pas inclus dans le document rendu final, placez votre commentaire entre les symboles &lt;!-- et --&gt;.\n&lt;!--\nthis is an example of how to format a comment using Quarto.\n--&gt;\nListes\nSi vous souhaitez crÃ©er une liste de texte Ã  puces, vous pouvez mettre en forme une liste non ordonnÃ©e avec des sous-Ã©lÃ©ments. Notez que les sous-Ã©lÃ©ments doivent Ãªtre indentÃ©s.\n- item 1\n- item 2\n   + sub-item 2\n   + sub-item 3\n- item 3\n- item 4\n\n\nÃ©lÃ©ment 1\npoint 2\n\nsous-poste 2\nsous-poste 3\n\n\npoint 3\npoint 4\n\n\nSi vous avez besoin dâ€™une liste ordonnÃ©e\n1. item 1\n1. item 2\n    + sub-item 2\n    + sub-item 3\n1. item 3\n1. item 4\n\n\narticle 1\npoint 2\n\n\nsous-poste 2\nsous-poste 3\n\n\npoint 3\npoint 4\n\n\nLiens\nOutre les images, vous pouvez Ã©galement inclure des liens vers des pages web ou dâ€™autres liens dans votre document. Utilisez la syntaxe suivante pour crÃ©er un lien cliquable vers une page web existante. Le texte du lien est placÃ© entre les crochets et lâ€™URL de la page web entre les crochets ronds immÃ©diatement aprÃ¨s.\nYou can include a text for your clickable [link](https://www.worldwildlife.org)\nqui vous donne :\n\nVous pouvez inclure un texte pour votre lien cliquable cliquable\n\n\n6.4.3 Morceaux de code\nVenons-en maintenant au cÅ“ur du problÃ¨me. Pour inclure du code R dans votre document Quarto, il vous suffit de placer votre code dans un â€œmorceau de codeâ€. Tous les morceaux de code commencent et se terminent par trois antisÃ¨ches ```````````. Remarque : ces signes sont Ã©galement appelÃ©s â€œaccents gravesâ€ ou â€œguillemets arriÃ¨reâ€ et nâ€™ont rien Ã  voir avec une apostrophe ! Sur la plupart des claviers, vous pouvez [trouver la coche arriÃ¨re][bÃ¢ton arriÃ¨re] sur la mÃªme touche que le tilde (~).\n```{r}\nAny valid R code goes here\n```\nVous pouvez insÃ©rer un morceau de code soit en tapant les dÃ©limiteurs du morceau ```{r} et ``````````soit en utilisant l'option de votre IDE (barre d'outils de RStudio (bouton InsÃ©rer) ou en cliquant sur le menuCode-&gt;Insert Chunk`. Dans VS Code, vous pouvez utiliser des extraits de code). Le mieux est peut-Ãªtre de se familiariser avec les raccourcis clavier de votre IDE ou de vos extraits de code.\nIl y a beaucoup de choses que vous pouvez faire avec des morceaux de code : vous pouvez produire du texte Ã  partir de votre analyse, crÃ©er des tableaux et des figures et insÃ©rer des images, entre autres choses. Ã€ lâ€™intÃ©rieur du morceau de code, vous pouvez placer des rÃ¨gles et des arguments entre les accolades. {} qui vous permettent de contrÃ´ler lâ€™interprÃ©tation de votre code et le rendu des rÃ©sultats. Câ€™est ce quâ€™on appelle les options du bloc de code. La seule option obligatoire est le premier argument qui spÃ©cifie le langage utilisÃ© (r dans notre cas, mais [dâ€™autres][moteurs] langues sont prises en charge). Remarque : les options de blocs peuvent Ãªtre Ã©crites de deux maniÃ¨res :\n\nsoit toutes les options de blocs doivent Ãªtre Ã©crites entre les crochets, sur une seule ligne, sans retour Ã  la ligne. 1. soit elles peuvent Ãªtre Ã©crites en utilisant une notation YAML Ã  lâ€™intÃ©rieur du morceau de code en utilisant #| au dÃ©but de la ligne.\n\nNous utilisons la notation YAML pour les options du bloc de code car nous la trouvons beaucoup plus facile Ã  lire lorsque vous avez plusieurs options de longues lÃ©gendes.\nVous pouvez Ã©galement spÃ©cifier un nom (ou Ã©tiquette) facultatif pour le morceau de code, ce qui peut sâ€™avÃ©rer utile en cas de problÃ¨mes de dÃ©bogage et de rendu avancÃ© de documents. Dans le bloc suivant, nous nommons le morceau de code summary-stats, nous chargeons le paquet ggplot2 ğŸ“¦ crÃ©er un cadre de donnÃ©es (dataf) avec deux variables x et y, utiliser la mÃ©thode summary() pour afficher des statistiques sommaires et tracer un nuage de points des donnÃ©es Ã  lâ€™aide de la fonction ggplot(). Lorsque nous exÃ©cutons le bloc de code, le code R et la sortie rÃ©sultante sont affichÃ©s dans le document final.\n```{r, summary-stats, echo = TRUE, fig.cap = \"Caption for a simple figure but making the chunk options long and hard to read\"}\nlibrary(ggplot)\nx &lt;- 1:10    # create an x variable\ny &lt;- 10:1    # create a y variable\ndataf &lt;- data.frame(x = x, y = y)\n\nsummary(dataf)\nggplot(dataf, aes(x = x, y = y)) + geom_point()\n```\n```{r}\n#| label: summary-stats\n#| echo: true\n#| fig-cap = \"Caption for a simple figure but making the chunk options long and hard to read\"\n\nx &lt;- 1:10    # create an x variable\ny &lt;- 10:1    # create a y variable\ndataf &lt;- data.frame(x = x, y = y)\n\nsummary(dataf)\nggplot(dataf, aes(x = x, y = y)) + geom_point()\n```\nTous deux produiront\n\nx &lt;- 1:10    # create an x variable\ny &lt;- 10:1    # create a y variable\ndataf &lt;- data.frame(x = x, y = y)\n\nsummary(dataf)\n\n       x               y        \n Min.   : 1.00   Min.   : 1.00  \n 1st Qu.: 3.25   1st Qu.: 3.25  \n Median : 5.50   Median : 5.50  \n Mean   : 5.50   Mean   : 5.50  \n 3rd Qu.: 7.75   3rd Qu.: 7.75  \n Max.   :10.00   Max.   :10.00  \n\nggplot(dataf, aes(x = x, y = y)) + geom_point()\n\n\n\n\n\n\nFigureÂ 6.8: Caption for a simple figure but making the chunk options long and hard to read\n\n\n\n\nLorsque vous utilisez des noms de morceaux, assurez-vous que vous nâ€™avez pas de noms de morceaux en double dans votre document Quarto et Ã©vitez les espaces et les points, car cela posera des problÃ¨mes lorsque vous devrez tricoter votre document. - pour sÃ©parer les mots dans nos noms de blocs).\nSi nous voulons afficher uniquement la sortie de notre code R (juste les statistiques sommaires par exemple) et non le code lui-mÃªme dans notre document final, nous pouvons utiliser lâ€™option chunk. echo=FALSE\n```{r}\n#| label: summary-stats2\n#| echo: false\nx &lt;- 1:10    # create an x variable\ny &lt;- 10:1    # create a y variable\ndataf &lt;- data.frame(x = x, y = y)\nsummary(dataf)\n```\n\n\n       x               y        \n Min.   : 1.00   Min.   : 1.00  \n 1st Qu.: 3.25   1st Qu.: 3.25  \n Median : 5.50   Median : 5.50  \n Mean   : 5.50   Mean   : 5.50  \n 3rd Qu.: 7.75   3rd Qu.: 7.75  \n Max.   :10.00   Max.   :10.00  \n\n\nPour afficher le code R mais pas la sortie, utilisez lâ€™option results='hide' lâ€™option chunk.\n```{r}\n#| label: summary-stats\n#| results: 'hide'\nx &lt;- 1:10    # create an x variable\ny &lt;- 10:1    # create a y variable\ndataf &lt;- data.frame(x = x, y = y)\nsummary(dataf)\n```\n\nx &lt;- 1:10    # create an x variable\ny &lt;- 10:1    # create a y variable\ndataf &lt;- data.frame(x = x, y = y)\nsummary(dataf)\n\nIl peut arriver que vous souhaitiez exÃ©cuter un morceau de code sans afficher aucune sortie. Vous pouvez supprimer la totalitÃ© de la sortie en utilisant lâ€™option chunk include: false.\n```{r}\n#| label: summary-stats4\n#| include: false\nx &lt;- 1:10    # create an x variable\ny &lt;- 10:1    # create a y variable\ndataf &lt;- data.frame(x = x, y = y)\nsummary(dataf)\n```\nIl existe un grand nombre dâ€™options de morceaux documentÃ©es ici avec une version plus condensÃ©e ici . Les plus couramment utilisÃ©es sont rÃ©sumÃ©es ci-dessous, les valeurs par dÃ©faut Ã©tant indiquÃ©es.\n\n\n\n\n\n\n\nOption dâ€™assemblage\nvaleur par dÃ©faut\nFonction\n\n\n\nÃ©cho\necho: true\nSi false nâ€™affichera pas le code dans le document final\n\n\nrÃ©sultats\nresults: 'markup'\nSi â€œcacherâ€, les rÃ©sultats du code ne seront pas affichÃ©s dans le document final.\n\n\nSi â€œholdâ€, lâ€™affichage de tous les Ã©lÃ©ments de sortie sera retardÃ© jusquâ€™Ã  la fin du morceau.\n\n\n\n\nSi â€˜asisâ€™, les rÃ©sultats seront affichÃ©s sans Ãªtre reformatÃ©s.\n\n\n\n\n\n\n\ninclude | include: true | Si false exÃ©cute le bloc mais ne lâ€™inclut pas dans le document final.\neval | eval: true | Si false nâ€™exÃ©cutera pas le code contenu dans le morceau de code.\nmessage | message: true | Si false nâ€™affichera pas les messages gÃ©nÃ©rÃ©s par le code.\navertissement | warning: true | Si false nâ€™affichera pas les messages dâ€™avertissement gÃ©nÃ©rÃ©s par le code.\n\n\n6.4.4 Code R en ligne\nJusquâ€™Ã  prÃ©sent, nous avons Ã©crit et exÃ©cutÃ© notre code R par morceaux. Une autre bonne raison dâ€™utiliser Quarto est que nous pouvons Ã©galement inclure notre code R directement dans notre texte. Câ€™est ce quâ€™on appelle le â€œcode en ligneâ€. Pour inclure votre code dans votre texte Quarto, il vous suffit dâ€™Ã©crire r write your code here. Cela peut sâ€™avÃ©rer trÃ¨s utile lorsque vous souhaitez inclure des statistiques sommaires dans votre texte. Par exemple, nous pourrions dÃ©crire le iris comme suit :\nMorphological characteristics (variable names: \n`r names(iris)[1:4]`) were measured from \n`r nrow(iris)` *Iris sp.* plants from \n`r length(levels(iris$Species))` different species.\nThe mean Sepal length was\n`r round(mean(iris$Sepal.Length), digits = 2)` mm.\n  \nqui sera rendu par\n\nCaractÃ©ristiques morphologiques (noms de variables : Sepal.Length, Sepal.Width, Petal.Length, Petal.Width) Ã©taient mesurÃ©s Ã  partir de 150 lâ€™iris plantes de 3 diffÃ©rentes espÃ¨ces. La longueur moyenne des sÃ©pales Ã©tait de 5.84 mm.\n\nLâ€™avantage dâ€™inclure du code R en ligne dans votre texte est que ces valeurs seront automatiquement mises Ã  jour si vos donnÃ©es changent.\n\n6.4.5 Images et photos\nLa possibilitÃ© dâ€™intÃ©grer des images et des liens vers des pages web (ou dâ€™autres documents) dans votre document Quarto est une fonctionnalitÃ© utile. Vous pouvez inclure des images dans votre document Quarto de diffÃ©rentes maniÃ¨res. La mÃ©thode la plus simple est sans doute dâ€™utiliser le format markdown de Quarto :\n![Image caption](path/to/you/image){options}\nVoici un exemple avec une image occupant 75 % de la largeur et centrÃ©e.\n![Waiting for the eclipse](images/markdown/eclipse_ready.jpg){fig-align=\"center\" width=\"75%\"}\nrÃ©sultant en :\n\n\n\n\n\nFigureÂ 6.9: En attendant lâ€™Ã©clipse\n\n\nUne autre faÃ§on dâ€™inclure des images dans votre document est dâ€™utiliser la fonction include_graphics() de la fonction knitr du paquet. Le code suivant produira un rÃ©sultat similaire.\n```{r}\n#| label: fig-knitr\n#| fig-align: center\n#| out-width: 75%\n#| fig-cap: Waiting for the eclipse\nknitr::include_graphics(\"images/markdown/eclipse_ready.jpg\")\n```\nLe code ci-dessus ne fonctionnera que si le fichier image (eclipse_ready.jpg) se trouve au bon endroit par rapport Ã  lâ€™endroit oÃ¹ vous avez enregistrÃ© votre fichier .qmd fichier. Dans lâ€™exemple, le fichier image se trouve dans un sous-rÃ©pertoire (dossier) appelÃ© images/markdown dans le rÃ©pertoire oÃ¹ nous avons enregistrÃ© notre my_first_quarto.qmd fichier. Vous pouvez intÃ©grer des images enregistrÃ©es dans de nombreux types de fichiers diffÃ©rents, mais les plus courants sont les suivants .jpg et .png.\n\n6.4.6 Les chiffres\nPar dÃ©faut, les figures produites par le code R sont placÃ©es immÃ©diatement aprÃ¨s le morceau de code Ã  partir duquel elles ont Ã©tÃ© gÃ©nÃ©rÃ©es. Par exemple :\n\n```{r}\n#| label: fig-simple-plot\n#| fig-cap: A simple plot\nx &lt;- 1:10    # create an x variable\ny &lt;- 10:1    # create a y variable\ndataf &lt;- data.frame(x = x, y = y)\nplot(dataf$x, dataf$y, xlab = \"x axis\", ylab = \"y axis\")\n```\n\n\n\n\n\n\nFigureÂ 6.10: A simple plot\n\n\n\n\nLe fichier fig-cap: permet de fournir une lÃ©gende de figure reconnue par Quarto et utilisÃ©e dans la numÃ©rotation des figures et les rÃ©fÃ©rences croisÃ©es (Section 6.4.8).\nSi vous souhaitez modifier les dimensions de lâ€™intrigue dans le document final, vous pouvez utiliser lâ€™option fig-width: et fig-height: (en pouces !). Vous pouvez Ã©galement modifier lâ€™alignement de la figure Ã  lâ€™aide de la fonction fig-align: option chunk.\n\n```{r}\n#| label: fig-simple-plot2\n#| fig-cap: A shrinked figure\n#| fig-width: 4\n#| fig-height: 3\n#| fig-align: center\nx &lt;- 1:10    # create an x variable\ny &lt;- 10:1    # create a y variable\ndataf &lt;- data.frame(x = x, y = y)\nplot(dataf$x, dataf$y, xlab = \"x axis\", ylab = \"y axis\")\n```\n\n\n\n\n\n\nFigureÂ 6.11: A shrinked figure\n\n\n\n\nVous pouvez ajouter une lÃ©gende Ã  la figure Ã  lâ€™aide de la fonction fig-cap: option.\n\n```{r}\n#| label: fig-simple-plot-cap\n#| class-source: fold-show\n#| fig-cap: A simple plot\n#| fig-align: center\nx &lt;- 1:10    # create an x variable\ny &lt;- 10:1    # create a y variable\ndataf &lt;- data.frame(x = x, y = y)\nplot(dataf$x, dataf$y, xlab = \"x axis\", ylab = \"y axis\")\n```\n\n\n\n\n\n\nFigureÂ 6.12: A simple plot\n\n\n\n\nSi vous souhaitez supprimer la figure dans le document final, utilisez lâ€™option fig-show: 'hide' pour supprimer la figure dans le document final.\n\n```{r}\n#| label: fig-simple-plot5\n#| fig-show: hide\nx &lt;- 1:10    # create an x variable\ny &lt;- 10:1    # create a y variable\ndataf &lt;- data.frame(x = x, y = y)\nplot(dataf$x, dataf$y, xlab = \"x axis\", ylab = \"y axis\")\n```\n\nSi vous utilisez un logiciel comme ggplot2 ğŸ“¦ pour crÃ©er vos parcelles, nâ€™oubliez pas que vous devrez rendre le paquet disponible avec lâ€™option library() dans le morceau de code (ou dans un morceau de code prÃ©cÃ©dent).\n\n```{r}\n#| label: fig-simple-ggplot\n#| fig-cap: A simple ggplot\nx &lt;- 1:10    # create an x variable\ny &lt;- 10:1    # create a y variable\ndataf &lt;- data.frame(x = x, y = y)\n\nlibrary(ggplot2)\nggplot(dataf, aes(x = x, y = y)) +\n  geom_point()\n```\n\n\n\n\n\n\nFigureÂ 6.13: A simple ggplot\n\n\n\n\nLÃ  encore, il existe un grand nombre dâ€™options spÃ©cifiques Ã  la production de graphiques et de figures. Voir ici pour plus de dÃ©tails.\n\n6.4.7 Tableaux\nDans Quarto, vous pouvez crÃ©er des tableaux en utilisant la syntaxe markdown native (il nâ€™est pas nÃ©cessaire que ce soit dans un morceau de code).\n|  x  |  y  |\n|:---:|:---:|\n|  1  |  5  | \n|  2  |  4  |\n|  3  |  3  |\n|  4  |  2  |\n|  5  |  1  |\n\n: Caption for a simple markdown table\n\n\n\n\n\n\nx\ny\n\n\n\n1\n5\n\n\n2\n4\n\n\n3\n3\n\n\n4\n2\n\n\n5\n1\n\n\n\nCaption pour un simple tableau markdown {#tbl-simp-md}\nLe :-------: indique Ã  markdown que la ligne du dessus doit Ãªtre traitÃ©e comme un en-tÃªte et les lignes du dessous comme le corps du tableau. Lâ€™alignement Ã  lâ€™intÃ©rieur du tableau est dÃ©terminÃ© par la position de la balise :. Pour centrer lâ€™alignement, utilisez :------: pour aligner Ã  gauche :------ et aligner Ã  droite ------:. Bien quâ€™il puisse Ãªtre amusant ( !) de crÃ©er des tableaux avec des balises brutes, cela nâ€™est pratique que pour les tableaux trÃ¨s petits et trÃ¨s simples.\nLa faÃ§on la plus simple dâ€™inclure des tableaux dans un document Quarto est dâ€™utiliser la fonction kable() de la fonction knitr ğŸ“¦ package. La fonction kable() permet de crÃ©er des tableaux pour les formats HTML, PDF et Word.\nPour crÃ©er un tableau des 2 premiÃ¨res lignes par espÃ¨ce de lâ€™Ã©chantillon iris Ã  lâ€™aide de la fonction kable() il suffit dâ€™Ã©crire\nlibrary(knitr)\niris %&gt;%\n  group_by(Species) %&gt;%\n  slice_head(n = 2) %&gt;%\nkable()\nou sans charger knitr ğŸ“¦ mais en indiquant oÃ¹ trouver le kable() fonction.\niris %&gt;%\n  group_by(Species) %&gt;%\n  slice_head(n = 2) %&gt;%\n  knitr::kable()\n\n\n\nTableÂ 6.1: A simple kable table\n\n\n\n\nSepal.Length\nSepal.Width\nPetal.Length\nPetal.Width\nSpecies\n\n\n\n5.1\n3.5\n1.4\n0.2\nsetosa\n\n\n4.9\n3.0\n1.4\n0.2\nsetosa\n\n\n7.0\n3.2\n4.7\n1.4\nversicolor\n\n\n6.4\n3.2\n4.5\n1.5\nversicolor\n\n\n6.3\n3.3\n6.0\n2.5\nvirginica\n\n\n5.8\n2.7\n5.1\n1.9\nvirginica\n\n\n\n\n\n\n\n\nLa fonction kable() offre de nombreuses options pour modifier la mise en forme du tableau. Par exemple, si nous voulons arrondir les valeurs numÃ©riques Ã  une dÃ©cimale, utilisez la fonction digits = argument. Pour centrer le contenu du tableau, utilisez align = 'c' et pour fournir des en-tÃªtes de colonne personnalisÃ©s, utilisez lâ€™argument col.names = argument. Voir ?knitr::kable pour plus dâ€™informations.\niris %&gt;%\n  group_by(Species) %&gt;%\n  slice_head(n = 2) %&gt;%\n  knitr::kable(\n    digits=0,\n    align = 'c',\n    col.names = c(\n      'Sepal length', 'Sepal width',\n      'Petal length', 'Petal width', 'Species'\n    )\n)\n\n\n\nTableÂ 6.2: A nicer kable table\n\n\n\n\nSepal length\nSepal width\nPetal length\nPetal width\nSpecies\n\n\n\n5\n4\n1\n0\nsetosa\n\n\n5\n3\n1\n0\nsetosa\n\n\n7\n3\n5\n1\nversicolor\n\n\n6\n3\n4\n2\nversicolor\n\n\n6\n3\n6\n2\nvirginica\n\n\n6\n3\n5\n2\nvirginica\n\n\n\n\n\n\n\n\nVous pouvez encore amÃ©liorer lâ€™aspect de votre kable tables en utilisant la fonction kableExtra ğŸ“¦ package (nâ€™oubliez pas dâ€™installer le package au prÃ©alable !). Voir ici pour plus de dÃ©tails et un tutoriel utile.\nSi vous voulez encore plus de contrÃ´le et dâ€™options de personnalisation pour vos tables, jetez un coup dâ€™Å“il Ã  lâ€™option gt ğŸ“¦ [paquet][gt] . gt est un acronyme pour grammar de tet est basÃ© sur un principe similaire pour les tableaux qui sont utilisÃ©s pour les tracÃ©s dans ggplot.\n\niris %&gt;%\n  group_by(Species) %&gt;%\n  slice_head(n = 2) %&gt;%\n  rename_with(~ gsub(\"([._])\", \" \", .x)) %&gt;%\n  gt()\n\n\nTableÂ 6.3: A nice gt table\n\n\n\n\n\n\nSepal Length\nSepal Width\nPetal Length\nPetal Width\n\n\n\nsetosa\n\n\n5.1\n3.5\n1.4\n0.2\n\n\n4.9\n3.0\n1.4\n0.2\n\n\nversicolor\n\n\n7.0\n3.2\n4.7\n1.4\n\n\n6.4\n3.2\n4.5\n1.5\n\n\nvirginica\n\n\n6.3\n3.3\n6.0\n2.5\n\n\n5.8\n2.7\n5.1\n1.9\n\n\n\n\n\n\n\n\n\nDans la plupart des paquets R dÃ©veloppÃ©s pour produire des tableaux, il existe des options permettant dâ€™inclure des lÃ©gendes de tableaux. Cependant, si vous souhaitez ajouter une lÃ©gende de tableau, nous vous recommandons dâ€™utiliser lâ€™option code chunk dans Quarto tbl-cap: car cela permet des rÃ©fÃ©rences croisÃ©es (Section 6.4.8) et une meilleure intÃ©gration dans le document.\n```{r}\n#| label: tbl-gt-table\n#| tbl-cap: A nice gt table\n#| echo: true\niris %&gt;%\n  group_by(Species) %&gt;%\n  slice_head(n=2) %&gt;%\n  rename_with(~gsub(\"([._])\", \" \", .x)) %&gt;%\n  gt()\n```\n\n6.4.8 RÃ©fÃ©rences croisÃ©es\nLes rÃ©fÃ©rences croisÃ©es permettent aux lecteurs de naviguer plus facilement dans votre document en fournissant des rÃ©fÃ©rences numÃ©rotÃ©es et des liens hypertextes vers diverses entitÃ©s telles que les figures et les tableaux. Une fois configurÃ©e, la numÃ©rotation des tableaux et des figures se fait automatiquement, de sorte quâ€™il nâ€™est pas nÃ©cessaire de renumÃ©roter toutes les figures lorsque vous en ajoutez ou en supprimez une.\nChaque entitÃ© pouvant faire lâ€™objet dâ€™une rÃ©fÃ©rence croisÃ©e nÃ©cessite une Ã©tiquette (un identifiant unique) prÃ©cÃ©dÃ©e dâ€™un type de rÃ©fÃ©rence croisÃ©e, par exemple #fig-element.\nPour plus de dÃ©tails, voir le site section sur les rÃ©fÃ©rences croisÃ©es sur le site web de Quarto.\n\n6.4.8.1 Sections du document\nVous pouvez faire des rÃ©fÃ©rences croisÃ©es avec dâ€™autres sections du document. Pour ce faire, vous devez\n\ndÃ©finir un identifiant pour la section vers laquelle vous souhaitez Ã©tablir un lien. Lâ€™identifiant doit :\n\n\ncommencer par #sec-\n\nen minuscules (figure 6.3)\nnâ€™a pas dâ€™espace, en utilisant - Ã  la place\n\n\nutiliser le @ et lâ€™identifiant pour faire rÃ©fÃ©rence Ã  la section\n\n## Cross-referencing sections {#sec-cross-ref-sections}\n\n[...]\n\nAs seen before(@sec-cross-ref-sections)\n\n6.4.8.2 Images, figures et tableaux\nPour les tableaux, les images et les figures, outre lâ€™identifiant, lâ€™Ã©lÃ©ment doit Ã©galement Ãªtre accompagnÃ© dâ€™une lÃ©gende pour que les rÃ©fÃ©rences croisÃ©es fonctionnent.\nLe prÃ©fixe pour les tableaux est #tbl- et #fig- pour les images et les figures.\nVoici un exemple dâ€™image incluse dans un texte en markdown :\n![Rocking the eclipse](images/markdown/eclipse_ready.jpg){#fig-cute-dog}\n\nSee @fig-cute-dog for an illustration.\n\n\n\n\n\nFigureÂ 6.14: Le rock de lâ€™Ã©clipse\n\n\nVoir FigureÂ 6.14 pour une illustration.\nPour les figures et les tableaux produits avec des morceaux de code R, il suffit de fournir lâ€™identifiant dans le champ label et la lÃ©gende Ã©galement en tant quâ€™option de bloc.\nVoici le code pour une figure et un tableau.\n\n```{r}\n#| label: fig-cr-plot\n#| fig-cap: A nice figure\nx &lt;- 1:10    # create an x variable\ny &lt;- 10:1    # create a y variable\ndataf &lt;- data.frame(x = x, y = y)\n\nlibrary(ggplot2)\nggplot(dataf, aes(x = x, y = y)) +\n  geom_point()\n```\n\n\n\n\n\n\nFigureÂ 6.15: A nice figure\n\n\n\n\n\n```{r}\n#| label: tbl-cr-table\n#| tbl-cap: A nice table\n#| warning: false\nlibrary(knitr)\nkable(iris[1:5,], digits=0, align = 'c', col.names = c('sepal length', 'sepal width', 'petal length', 'petal width', 'species'))\n```\n\n\nTableÂ 6.4: A nice table\n\n\n\n\nsepal length\nsepal width\npetal length\npetal width\nspecies\n\n\n\n5\n4\n1\n0\nsetosa\n\n\n5\n3\n1\n0\nsetosa\n\n\n5\n3\n1\n0\nsetosa\n\n\n5\n3\n2\n0\nsetosa\n\n\n5\n4\n1\n0\nsetosa\n\n\n\n\n\n\n\n\nEn utilisant les rÃ©fÃ©rences croisÃ©es, on peut Ã©crire :\nTel que vu sur @fig-cr-plot et @tbl-cr-table â€¦\nPour obtenir :\nComme vu sur FigureÂ 6.15 et TableÂ 6.4 â€¦\n\n6.4.9 Citations et bibliographie\nPour gÃ©nÃ©rer des citations et une bibliographie, Quarto a besoin de :\n\nun document correctement formatÃ© .qmd formatÃ©\nun fichier source bibliographique comprenant toutes les informations pour les citations. Il fonctionne avec une grande variÃ©tÃ© de formats mais nous suggÃ©rons lâ€™utilisation de {{&lt; bibtex &gt;} le format }.\n(optionnel) un fichier CSL qui spÃ©cifie le formatage Ã  utiliser lors de la gÃ©nÃ©ration des citations et de la bibliographie.\n\nLa source bibliographique et le fichier csl (facultatif) sont spÃ©cifiÃ©s dans lâ€™en-tÃªte yaml sous la forme :\n---\ntitle: \"My Document\"\nbibliography: references.bib\ncsl: ecology.csl\n---\n\n6.4.9.1 Citations\nQuarto utilise la reprÃ©sentation markdown standard de Pandoc pour les citations (par ex. [@citation]) - les citations sont placÃ©es entre crochets et sÃ©parÃ©es par des points-virgules. Chaque citation doit avoir une clÃ©, composÃ©e de â€˜@â€™ + lâ€™identifiant de la base de donnÃ©es, et peut optionnellement avoir un prÃ©fixe, un localisateur, et un suffixe. La clÃ© de la citation doit commencer par une lettre, un chiffre ou , et peut contenir des caractÃ¨res alphanumÃ©riques,  et des caractÃ¨res de ponctuation internes.\n\n\n\n\n\n\nFormat Markdown\nSortie (default)\n\n\n\nLes licornes sont les meilleures [voir @martin1219, pp.Â 33-35 ; aussi @martin2200, chap.Â 1]\nLes licornes sont les meilleures (voir Martin 1219, pp.Â 33-35, aussi Martin 2200 chap. 1)\n\n\n\nLes licornes sont les meilleures [@martin2200 ; @martin1219]\nLes licornes sont les meilleures (Martin 1219, 2200)\n\n\n\nMartin dit que les licornes sont les meilleures [-@martin2200]\nMartin dit que les licornes sont les meilleures (2200)\n\n\n\n\n@martin1219 dit que les licornes sont les meilleures.\n\nMartin (1219) dit que les licornes sont les meilleures.\n\n\n\n@martin1219 [p.Â 33] dit que les licornes sont ce quâ€™il y a de mieux.\nLa plupart des gens disent que les licornes sont ce quâ€™il y a de mieux.\n\n\n\n6.4.9.2 CrÃ©er la bibliographie\nPar dÃ©faut, la liste des ouvrages citÃ©s sera automatiquement gÃ©nÃ©rÃ©e et placÃ©e en fin de document si le style lâ€™exige. Elle sera placÃ©e dans une div avec lâ€™id refs sâ€™il y en a une comme\n### Bibliography\n\n::: {#refs}\n:::\nPour plus de dÃ©tails, voir le site page Citation sur le site de Quarto.\n\n6.4.9.3 IntÃ©gration avec Zotero\nQuarto sâ€™intÃ¨gre trÃ¨s bien avec Zotero si vous utilisez lâ€™Ã©diteur visuel de RStudio ou VS Code.",
    "crumbs": [
      "DonnÃ©es",
      "Utiliser R",
      "<span class='chapter-number'>6</span>Â  <span class='chapter-title'>Rapports reproductibles avec Quarto</span>"
    ]
  },
  {
    "objectID": "06-quarto.html#sec-tips-tricks",
    "href": "06-quarto.html#sec-tips-tricks",
    "title": "6Â  Rapports reproductibles avec Quarto",
    "section": "\n6.5 Quelques conseils et astuces",
    "text": "6.5 Quelques conseils et astuces\nProblÃ¨me :\nLors du rendu de mon document Quarto au format pdf, mon code sort du bord de la page.\nSolution :\nAjoutez un argument global_options au dÃ©but de votre fichier .qmd dans un morceau de code :\n```{r}\n#| label: global_options\n#| include: false \nknitr::opts_chunk$set(message=FALSE, tidy.opts=list(width.cutoff=60), tidy=TRUE) \n```\nCe morceau de code ne sera pas affichÃ© dans le document final en raison de lâ€™argument global_options. include: false et vous devez placer le morceau de code immÃ©diatement aprÃ¨s lâ€™en-tÃªte YAML pour affecter tout ce qui se trouve en dessous.\ntidy.opts = list(width.cutoff = 60), tidy=TRUE dÃ©finit le point de coupure de la marge et fait passer le texte Ã  la ligne suivante. Jouez avec cette valeur pour lâ€™obtenir correctement (60-80 devrait convenir Ã  la plupart des documents).\nAvec quarto, vous pouvez Ã©galement utiliser la fonction globale knitr dans un fichier knitrdans lâ€™en-tÃªte YAML (voir Site web de Quarto pour plus de dÃ©tails).\n---\ntitle: \"My Document\"\nformat: html\nknitr:\n  opts_chunk: \n    message: false\n    tidy.opts: !expr 'list(width.cutoff=60)'\n    tidy: true \n---\nProblÃ¨me :\nLorsque je charge un paquet dans mon document Quarto, le rendu contient tous les messages de dÃ©marrage et/ou les avertissements.\nSolution :\nVous pouvez charger tous vos paquets au dÃ©but de votre document Quarto dans un morceau de code en mÃªme temps que vous dÃ©finissez vos options globales.\n```{r}\n#| label: global_options\n#| include: false\nknitr::opts_chunk$set(\n  message = FALSE,\n  warning=FALSE,\n  tidy.opts=list(width.cutoff=60)\n) \nsuppressPackageStartupMessages(library(ggplot2))\n```\nLâ€™option message = FALSE et warning = FALSE suppriment les messages et les avertissements. Les suppressPackageStartupMessages(library(ggplot2)) chargera le fichier ggplot2 ğŸ“¦ mais supprimera les messages de dÃ©marrage.\nLe problÃ¨me est le suivant :\nLors de la conversion de mon document Quarto en PDF, mes tableaux et/ou figures sont rÃ©partis sur deux pages.\nSolution :\nAjoutez un saut de page Ã  lâ€™aide de la fonction {{&lt; latex &gt;}} \\pagebreak avant le tableau ou la figure incriminÃ©(e)\nproblÃ¨me :\nLe code dans mon document rendu est laid !\nSolution :\nAjouter lâ€™argument tidy: true Ã  vos arguments globaux. Cependant, cela peut parfois poser des problÃ¨mes, notamment en ce qui concerne lâ€™indentation du code. La meilleure solution est dâ€™Ã©crire un code qui a de lâ€™allure (insÃ©rer des espaces et utiliser plusieurs lignes)",
    "crumbs": [
      "DonnÃ©es",
      "Utiliser R",
      "<span class='chapter-number'>6</span>Â  <span class='chapter-title'>Rapports reproductibles avec Quarto</span>"
    ]
  },
  {
    "objectID": "06-quarto.html#informations-complÃ©mentaires",
    "href": "06-quarto.html#informations-complÃ©mentaires",
    "title": "6Â  Rapports reproductibles avec Quarto",
    "section": "\n6.6 Informations complÃ©mentaires",
    "text": "6.6 Informations complÃ©mentaires\nBien que nous ayons couvert plus quâ€™il nâ€™en faut pour vous permettre dâ€™aller loin avec Quarto, nous nâ€™avons eu le temps que dâ€™effleurer la surface, comme câ€™est le cas pour la plupart des choses liÃ©es aux technologies de lâ€™information et de la communication. Heureusement, il existe une mine dâ€™informations Ã  votre disposition si vous souhaitez approfondir vos connaissances et votre expÃ©rience. Un bon point de dÃ©part est lâ€™excellent site web de Quarto ici.\nUn autre guide de rÃ©fÃ©rence Quarto utile et concis peut Ãªtre trouvÃ© ici\nUne feuille de calcul rapide et facile pour R Markdown de R Markdown",
    "crumbs": [
      "DonnÃ©es",
      "Utiliser R",
      "<span class='chapter-number'>6</span>Â  <span class='chapter-title'>Rapports reproductibles avec Quarto</span>"
    ]
  },
  {
    "objectID": "06-quarto.html#pratique",
    "href": "06-quarto.html#pratique",
    "title": "6Â  Rapports reproductibles avec Quarto",
    "section": "\n6.7 Pratique",
    "text": "6.7 Pratique\nNous allons crÃ©er un nouveau document Rmarkdown et lâ€™Ã©diter en utilisant les fonctions de base de Rmarkdown. R et Rmarkdown et les fonctions\n\n6.7.1 Le contexte\nNous utiliserons lâ€™awesome palmerpenguins jeu de donnÃ©es ğŸ§ pour explorer et visualiser les donnÃ©es.\nCes donnÃ©es ont Ã©tÃ© collectÃ©es et partagÃ©es par Dr.Â Kristen Gorman et Station Palmer, Antarctique LTER.\nLâ€™ensemble a Ã©tÃ© conÃ§u par les Drs Allison Horst et Alison Hill. site officiel.\nLe paquet palmerpenguins comporte deux ensembles de donnÃ©es :\n\n\npenguins_raw a les donnÃ©es brutes des observations des manchots (voir ?penguins_raw pour plus dâ€™informations)\n\npenguins est une version simplifiÃ©e des donnÃ©es brutes (voir ?penguins pour plus dâ€™informations)\n\nPour cet exercice, nous allons utiliser la fonction penguins jeu de donnÃ©es.\n\nlibrary(palmerpenguins)\nhead(penguins)\n\n# A tibble: 6 Ã— 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Adelie  Torgersen           39.1          18.7               181        3750\n2 Adelie  Torgersen           39.5          17.4               186        3800\n3 Adelie  Torgersen           40.3          18                 195        3250\n4 Adelie  Torgersen           NA            NA                  NA          NA\n5 Adelie  Torgersen           36.7          19.3               193        3450\n6 Adelie  Torgersen           39.3          20.6               190        3650\n# â„¹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\n\n6.7.2 Questions\n1) Installer le paquet palmerpenguins.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ninstall.packages(\"palmerpenguins\")\n\n\n\n\n2)\n\nCrÃ©ez un nouveau document Quarto, nommez-le et enregistrez-le.\nSupprimez tout ce qui se trouve aprÃ¨s la ligne 12.\nAjouter un nouveau titre de section, un texte simple et un texte en caractÃ¨res gras.\nCompiler (â€œTricoterâ€).\n\n3)\n\nAjoutez un morceau dans lequel vous chargez le palmerpenguins. La ligne de code correspondante devrait Ãªtre cachÃ©e dans la sortie.\nChargez Ã©galement le fichier tidyverse de paquets. Modifier les valeurs par dÃ©faut pour supprimer tous les messages.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n```{r}\n#| echo: false\n#| message:false\nlibrary(palmerpenguins)\nlibrary(tidyverse)\n```\n\n\n\n4) Ajoutez un autre morceau dans lequel vous construisez un tableau avec les 10 premiÃ¨res lignes de lâ€™ensemble de donnÃ©es.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n```{r}\npenguins %&gt;%\n  slice(1:10) %&gt;%\n  knitr::kable()\n```\n\n\n\n5) Dans une nouvelle section, affichez le nombre dâ€™individus, dâ€™espÃ¨ces de manchots et dâ€™Ã®les que nous avons dans lâ€™ensemble de donnÃ©es. Cette information doit apparaÃ®tre directement dans le texte, vous devez utiliser du code en ligne. ğŸ˜„. Calculer la moyenne des traits (numÃ©riques) mesurÃ©s sur les manchots.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n## Numerical exploration\n\nThere are `r nrow(penguins)` penguins in the dataset,\nand `r length(unique(penguins$species))` different species.\nThe data were collected in `r length(unique(penguins$island))`\nislands of the Palmer archipelago in Antarctica.\n\nThe mean of all traits that were measured on the penguins are:\n```{r}\n#| echo: false\npenguins %&gt;%\n  group_by(species) %&gt;%\n  summarize(across(where(is.numeric), mean, na.rm = TRUE))\n```\n\n\n\n6) Dans une autre section, intitulÃ©e â€œExploration graphiqueâ€, construisez une figure avec 3 histogrammes superposÃ©s, chacun correspondant Ã  la masse corporelle dâ€™une espÃ¨ce.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n## Graphical exploration\n\nA histogram of body mass per species:\n```{r}\n#| fig-cap: Distribution of body mass by species of penguins\n  ggplot(data = penguins) +\n  aes(x = body_mass_g) +\n  geom_histogram(aes(fill = species),\n                 alpha = 0.5,\n                 position = \"identity\") +\n  scale_fill_manual(values = c(\"darkorange\",\"purple\",\"cyan4\")) +\n  theme_minimal() +\n  labs(x = \"Body mass (g)\",\n       y = \"Frequency\",\n       title = \"Penguin body mass\")\n```\n\n\n\n7) Dans une autre section, intitulÃ©e RÃ©gression linÃ©aire Ajustez un modÃ¨le de la longueur du bec en fonction de la taille du corps (longueur des nageoires), de la masse corporelle et du sexe. Obtenez le rÃ©sultat et Ã©valuez graphiquement les hypothÃ¨ses du modÃ¨le. Pour rappel, voici comment effectuer une rÃ©gression linÃ©aire.\n```{r}\nmodel &lt;- lm(Y ~  X1 + X2, data = data)\nsummary(model)\nplot(model)\n```\n\n\n\n\n\n\nSolution\n\n\n\n\n\n## Linear regression\n\nAnd here is a nice model with graphical output\n```{r}\n#| fig-cap: \"Checking assumptions of the model\"\nm1 &lt;- lm(bill_length_mm ~  flipper_length_mm + body_mass_g + sex, data = penguins)\nsummary(m1)\npar(mfrow= c(2,2))\nplot(m1)\n```\n\n\n\n8) Ajouter des rÃ©fÃ©rences manuellement ou Ã  lâ€™aide de citr dans RStudio.\n\nChoisissez une publication rÃ©cente du chercheur qui a partagÃ© les donnÃ©es, le Dr Kristen Gorman. Importez cette publication dans votre gestionnaire de rÃ©fÃ©rences favori (nous utilisons Zotero, sans complexe), et crÃ©ez une rÃ©fÃ©rence bibtex que vous ajouterez au fichier mabiblio.bib.\nAjouter bibliography: mabiblio.bib au dÃ©but de votre document R Markdown (YAML).\nCitez la rÃ©fÃ©rence dans le texte en la tapant manuellement ou en utilisant la commande citr. Pour utiliser citr installez-le dâ€™abord ; si tout se passe bien, vous devriez le voir apparaÃ®tre dans le menu dÃ©roulant Addins ğŸ’ª. Il suffit ensuite dâ€™utiliser Insert citations dans le menu dÃ©roulant Addins.\nCompiler.\n\n9) Changez le format de citation par dÃ©faut (style Chicago) en format The American Naturalist. Il se trouve ici https://www.zotero.org/styles. Pour ce faire, ajoutez csl: the-american-naturalist.csl dans le YAML.\n10) CrÃ©ez votre rapport au format html, pdf et docx. ğŸ‰\nExemple de rÃ©sultats\nVous pouvez voir un exemple de la sortie fichier source Rmarkdown et sortie pdf\n\n\n\n\nHappy coding\n\n\n\n\n\n\n\nA. C. Davison, and D. V. Hinkley. 1997. Bootstrap methods and their\napplications. Cambridge University Press, Cambridge.\n\n\nAdler, D., S. T. Kelly, T. Elliott, and J. Adamson. 2024. vioplot: Violin plot.\n\n\nAllaire, J., Y. Xie, C. Dervieux, J. McPherson, J. Luraschi, K. Ushey,\nA. Atkins, H. Wickham, J. Cheng, W. Chang, and R. Iannone. 2024. rmarkdown: Dynamic documents for r.\n\n\nAngelo Canty, and B. D. Ripley. 2024. boot:\nBootstrap r (s-plus) functions.\n\n\nBartoÅ„, K. 2024. MuMIn:\nMulti-model inference.\n\n\nBates, D., M. MÃ¤chler, B. Bolker, and S. Walker. 2015. Fitting linear\nmixed-effects models using lme4. Journal\nof Statistical Software 67:1â€“48.\n\n\nChampely, S. 2020. pwr: Basic functions for power analysis.\n\n\nDouglas, A. 2023. An introduction to\nr.\n\n\nFox, J. 2003. Effect\ndisplays in R for generalised linear models. Journal of\nStatistical Software 8:1â€“27.\n\n\nFox, J., and J. Hong. 2009. Effect displays in\nR for multinomial and proportional-odds logit models:\nExtensions to the effects package.\nJournal of Statistical Software 32:1â€“24.\n\n\nFox, J., and S. Weisberg. 2018. Visualizing fit and lack of\nfit in complex regression models with predictor effect plots and partial\nresiduals. Journal of Statistical Software 87:1â€“27.\n\n\nFox, J., and S. Weisberg. 2019a. An R companion to\napplied regression. Third. Sage, Thousand Oaks CA.\n\n\nFox, J., and S. Weisberg. 2019b. An\nr companion to applied regression. 3rd edition. Sage, Thousand Oaks\nCA.\n\n\nFriendly, M. 2023. vcdExtra: â€œvcdâ€ extensions and additions.\n\n\nHorst, A. M., A. P. Hill, and K. B. Gorman. 2020. palmerpenguins: Palmer archipelago (antarctica)\npenguin data.\n\n\nHothorn, T., F. Bretz, and P. Westfall. 2008. Simultaneous inference in\ngeneral parametric models. Biometrical Journal 50:346â€“363.\n\n\nHvitfeldt, E. 2022. emoji: Data and function to work with emojis.\n\n\nIannone, R., J. Cheng, B. Schloerke, E. Hughes, A. Lauer, J. Seo, K.\nBrevoort, and O. Roy. 2024. gt: Easily create presentation-ready display\ntables.\n\n\nKassambara, A. 2023. ggpubr: â€œggplot2â€ based publication ready plots.\n\n\nLÃ¼decke, D., M. S. Ben-Shachar, I. Patil, P. Waggoner, and D. Makowski.\n2021. performance: An R package for\nassessment, comparison and testing of statistical models. Journal of\nOpen Source Software 6:3139.\n\n\nMartin, J. 1219. Another lasagna recipe from medieval times. Journal of\nLasagna 4:1686.\n\n\nMartin, J. 2200. A silly example. Chapman; Hall/CRC, Boca Raton,\nFlorida.\n\n\nMeyer, D., A. Zeileis, and K. Hornik. 2006. The strucplot framework:\nVisualizing multi-way contingency tables with vcd. Journal of\nStatistical Software 17:1â€“48.\n\n\nPedersen, T. L. 2024. patchwork: The composer of plots.\n\n\nPeng, R. D. 2024. simpleboot: Simple bootstrap routines.\n\n\nPrunello, M., and G. Mari. 2021. ggcleveland: Implementation of plots from\nclevelandâ€™s visualizing data book.\n\n\nR Core Team. 2024. R:\nA language and environment for statistical computing. R Foundation\nfor Statistical Computing, Vienna, Austria.\n\n\nRodriguez-Sanchez, F., and C. P. Jackson. 2023. grateful: Facilitate citation of r packages.\n\n\nSchloerke, B., D. Cook, J. Larmarange, F. Briatte, M. Marbach, E. Thoen,\nA. Elberg, and J. Crowley. 2024. GGally:\nExtension to â€œggplot2â€.\n\n\nWheeler, B., and M. Torchiano. 2016. lmPerm: Permutation tests for linear models.\n\n\nWickham, H. 2007. Reshaping\ndata with the reshape package. Journal\nof Statistical Software 21:1â€“20.\n\n\nWickham, H., M. Averick, J. Bryan, W. Chang, L. D. McGowan, R. FranÃ§ois,\nG. Grolemund, A. Hayes, L. Henry, J. Hester, M. Kuhn, T. L. Pedersen, E.\nMiller, S. M. Bache, K. MÃ¼ller, J. Ooms, D. Robinson, D. P. Seidel, V.\nSpinu, K. Takahashi, D. Vaughan, C. Wilke, K. Woo, and H. Yutani. 2019.\nWelcome to the tidyverse. Journal of Open Source Software\n4:1686.\n\n\nWilkinson, L. 2005. The Grammar of Graphics.\nSpringer Science & Business Media.\n\n\nXie, Y. 2014. knitr: A comprehensive tool\nfor reproducible research in R. in V. Stodden, F.\nLeisch, and R. D. Peng, editors. Implementing reproducible computational\nresearch. Chapman; Hall/CRC.\n\n\nXie, Y. 2015. Dynamic documents with\nR and knitr. 2nd edition. Chapman; Hall/CRC, Boca\nRaton, Florida.\n\n\nXie, Y. 2024. knitr: A general-purpose package for dynamic\nreport generation in r.\n\n\nXie, Y., J. J. Allaire, and G. Grolemund. 2018. R markdown: The definitive\nguide. Chapman; Hall/CRC, Boca Raton, Florida.\n\n\nXie, Y., C. Dervieux, and E. Riederer. 2020. R markdown\ncookbook. Chapman; Hall/CRC, Boca Raton, Florida.\n\n\nZeileis, A., and T. Hothorn. 2002. Diagnostic checking in\nregression relationships. R News 2:7â€“10.\n\n\nZeileis, A., D. Meyer, and K. Hornik. 2007. Residual-based shadings\nfor visualizing (conditional) independence. Journal of Computational\nand Graphical Statistics 16:507â€“525.\n\n\nZhu, H. 2024. kableExtra: Construct complex table with\nâ€œkableâ€ and pipe syntax.",
    "crumbs": [
      "DonnÃ©es",
      "Utiliser R",
      "<span class='chapter-number'>6</span>Â  <span class='chapter-title'>Rapports reproductibles avec Quarto</span>"
    ]
  },
  {
    "objectID": "07-github.html",
    "href": "07-github.html",
    "title": "7Â  ContrÃ´le de version avec Git et GitHub",
    "section": "",
    "text": "7.1 Quâ€™est-ce que le contrÃ´le de version ?\nA SystÃ¨me de contrÃ´le des versions (VCS) conserve un enregistrement de toutes les modifications que vous apportez aux fichiers qui composent un projet particulier et vous permet de revenir Ã  des versions antÃ©rieures des fichiers si nÃ©cessaire. En dâ€™autres termes, si vous vous trompez ou si vous perdez accidentellement des fichiers importants, vous pouvez facilement revenir Ã  une Ã©tape antÃ©rieure de votre projet pour rÃ©gler le problÃ¨me. Le contrÃ´le de version a Ã©tÃ© conÃ§u Ã  lâ€™origine pour le dÃ©veloppement collaboratif de logiciels, mais il est tout aussi utile pour la recherche scientifique et les collaborations (mÃªme sâ€™il est vrai que la plupart des termes, du jargon et des fonctionnalitÃ©s sont axÃ©s sur le dÃ©veloppement de logiciels). Il existe actuellement de nombreux systÃ¨mes de contrÃ´le de version diffÃ©rents, mais nous nous concentrerons sur lâ€™utilisation de Git parce quâ€™il est gratuit et open source et quâ€™il sâ€™intÃ¨gre bien Ã  RStudio. Cela signifie quâ€™il peut facilement faire partie de votre flux de travail habituel avec un minimum de frais supplÃ©mentaires.",
    "crumbs": [
      "DonnÃ©es",
      "Utiliser R",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>ContrÃ´le de version avec Git et GitHub</span>"
    ]
  },
  {
    "objectID": "07-github.html#pourquoi-utiliser-le-contrÃ´le-de-version",
    "href": "07-github.html#pourquoi-utiliser-le-contrÃ´le-de-version",
    "title": "7Â  ContrÃ´le de version avec Git et GitHub",
    "section": "\n7.2 Pourquoi utiliser le contrÃ´le de version ?",
    "text": "7.2 Pourquoi utiliser le contrÃ´le de version ?\nPourquoi devriez-vous vous prÃ©occuper du contrÃ´le des versions ? Tout dâ€™abord, il permet dâ€™Ã©viter cette situation (familiÃ¨re ?) lorsque vous travaillez sur un projet qui dÃ©coule gÃ©nÃ©ralement de ce scÃ©nario (familier ?).\n\n\n\n\n\n\n\nFigureÂ 7.1: Why you need version control (source: PhDComics)\n\n\n\n\nLe contrÃ´le de version se charge automatiquement de conserver une trace de toutes les versions dâ€™un fichier particulier et vous permet de revenir aux versions prÃ©cÃ©dentes si nÃ©cessaire. Le contrÃ´le de version vous aide Ã©galement (en particulier le futur vous) Ã  garder une trace de tous vos fichiers en un seul endroit et il aide les autres (en particulier les collaborateurs) Ã  revoir, contribuer et rÃ©utiliser votre travail via le site web GitHub. Enfin, vos fichiers sont toujours disponibles de nâ€™importe oÃ¹ et sur nâ€™importe quel ordinateur, tout ce dont vous avez besoin, câ€™est dâ€™une connexion internet.",
    "crumbs": [
      "DonnÃ©es",
      "Utiliser R",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>ContrÃ´le de version avec Git et GitHub</span>"
    ]
  },
  {
    "objectID": "07-github.html#quest-ce-que-git-et-github",
    "href": "07-github.html#quest-ce-que-git-et-github",
    "title": "7Â  ContrÃ´le de version avec Git et GitHub",
    "section": "\n7.3 Quâ€™est-ce que Git et GitHub ?",
    "text": "7.3 Quâ€™est-ce que Git et GitHub ?\nGit est un systÃ¨me de contrÃ´le de version dÃ©veloppÃ© Ã  lâ€™origine par Linus Torvalds qui permet de suivre les modifications apportÃ©es Ã  un ensemble de fichiers. Ces fichiers peuvent Ãªtre de nâ€™importe quel type, y compris la mÃ©nagerie de fichiers qui composent gÃ©nÃ©ralement un projet axÃ© sur les donnÃ©es (.pdf, .Rmd, .docx, .txt, .jpg, etc.), bien que les fichiers texte simples soient ceux qui fonctionnent le mieux. Lâ€™ensemble des fichiers qui composent un projet sâ€™appelle un rÃ©fÃ©rentiel (ou simplement repo).\nGitHub est un service dâ€™hÃ©bergement de dÃ©pÃ´ts Git basÃ© sur le web qui vous permet de crÃ©er une copie distante de votre projet local contrÃ´lÃ© par version. Cette copie peut servir de sauvegarde ou dâ€™archive de votre projet ou vous permettre, ainsi quâ€™Ã  vos collÃ¨gues, dâ€™y accÃ©der pour travailler en collaboration.\nAu dÃ©but dâ€™un projet, nous crÃ©ons gÃ©nÃ©ralement (mais pas toujours) un dÃ©pÃ´t Git. distant sur GitHub, puis cloner (il sâ€™agit dâ€™une copie) de ce dÃ©pÃ´t dans notre base de donnÃ©es local local (celui qui se trouve devant vous). Ce clonage est gÃ©nÃ©ralement un Ã©vÃ©nement unique et vous ne devriez pas avoir besoin de cloner ce dÃ©pÃ´t Ã  nouveau, Ã  moins que vous ne fassiez vraiment nâ€™importe quoi. Une fois que vous avez clonÃ© votre dÃ©pÃ´t, vous pouvez travailler localement sur votre projet comme dâ€™habitude, en crÃ©ant et en sauvegardant des fichiers pour votre analyse de donnÃ©es (scripts, documents R markdown, figures, etc.). En cours de route, vous pouvez prendre des instantanÃ©s (appelÃ©s commits) de ces fichiers aprÃ¨s y avoir apportÃ© des modifications importantes. Nous pouvons alors pousser ces modifications vers le dÃ©pÃ´t GitHub distant pour en faire une sauvegarde ou les mettre Ã  la disposition de nos collaborateurs. Si dâ€™autres personnes travaillent sur le mÃªme projet (dÃ©pÃ´t), ou si vous travaillez sur un autre ordinateur, vous pouvez tirer les modifications vers votre dÃ©pÃ´t local afin que tout soit synchronisÃ©.\n\n\n\n\n\n\n\nFigureÂ 7.2: How git works",
    "crumbs": [
      "DonnÃ©es",
      "Utiliser R",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>ContrÃ´le de version avec Git et GitHub</span>"
    ]
  },
  {
    "objectID": "07-github.html#sec-setup-git",
    "href": "07-github.html#sec-setup-git",
    "title": "7Â  ContrÃ´le de version avec Git et GitHub",
    "section": "\n7.4 Pour commencer",
    "text": "7.4 Pour commencer\nCe chapitre suppose que vous avez dÃ©jÃ  installÃ© les derniÃ¨res versions de R et un IDE (RStudio ou VSCode). Si vous ne lâ€™avez pas encore fait, vous trouverez des instructions dans Section 1.1.1.\n\n7.4.1 Installer Git\nPour commencer, vous devez dâ€™abord installer Git. Si vous avez de la chance, vous avez peut-Ãªtre dÃ©jÃ  installÃ© Git (surtout si vous avez un ordinateur Mac ou Linux). Vous pouvez vÃ©rifier si vous avez dÃ©jÃ  installÃ© Git en cliquant sur le bouton Terminal tab dans RStudio et en tapant git --version. Si vous voyez quelque chose qui ressemble Ã  git version 2.25.0 (le numÃ©ro de version peut Ãªtre diffÃ©rent sur votre ordinateur), alors vous avez dÃ©jÃ  installÃ© Git (jours heureux). Si vous obtenez une erreur (quelque chose comme git: command not found), cela signifie que Git nâ€™est pas (encore) installÃ©.\nVous pouvez Ã©galement faire cette vÃ©rification en dehors de RStudio en ouvrant un terminal sÃ©parÃ© si vous le souhaitez. Sous Windows, allez dans le menu â€œDÃ©marrerâ€ et dans la barre de recherche (ou la boÃ®te dâ€™exÃ©cution) tapez cmd et appuyez sur la touche EntrÃ©e. Sur Mac, allez dans â€œApplicationsâ€ dans le Finder, cliquez sur le dossier â€œUtilitairesâ€, puis sur le programme â€œTerminalâ€. Sur une machine Linux, ouvrez simplement le Terminal (Ctrl+Alt+T fait souvent lâ€™affaire).\nPour installer Git sur un Windows nous vous recommandons de tÃ©lÃ©charger et dâ€™installer Git pour Windows (Ã©galement connu sous le nom de â€œGit Bashâ€). Vous trouverez le fichier de tÃ©lÃ©chargement et les instructions dâ€™installation ici .\nPour ceux qui utilisent un Mac nous vous recommandons de tÃ©lÃ©charger Git Ã  partir de ici et de lâ€™installer de la maniÃ¨re habituelle (double-cliquez sur le paquet dâ€™installation une fois tÃ©lÃ©chargÃ©). Si vous avez dÃ©jÃ  installÃ© Xcode sur votre Mac et que vous souhaitez utiliser une version plus rÃ©cente de Git, vous devrez suivre quelques Ã©tapes supplÃ©mentaires documentÃ©es ici . Si vous nâ€™avez jamais entendu parler de Xcode, ne vous inquiÃ©tez pas !\nPour ceux dâ€™entre vous qui ont la chance de travailler sur un Linux vous pouvez simplement utiliser le gestionnaire de paquets de votre systÃ¨me dâ€™exploitation pour installer Git Ã  partir du dÃ©pÃ´t officiel. Pour Ubuntu Linux (ou ses variantes), ouvrez votre Terminal et tapez\nsudo apt update\nsudo apt install git\nVous aurez besoin de privilÃ¨ges administratifs pour effectuer cette opÃ©ration. Pour les autres versions de Linux, voir ici pour de plus amples instructions dâ€™installation.\nQuelle que soit la version de Git que vous installez, une fois lâ€™installation terminÃ©e, vÃ©rifiez que le processus dâ€™installation sâ€™est bien dÃ©roulÃ© en exÃ©cutant la commande git --version dans lâ€™onglet Terminal de RStudio (comme dÃ©crit ci-dessus). Sur certaines installations de Git (oui, nous vous regardons MS Windows), cela peut encore produire une erreur car vous devrez Ã©galement configurer RStudio pour quâ€™il puisse trouver lâ€™exÃ©cutable Git (dÃ©crit dans Section 7.4.3).\n\n7.4.2 Configurer Git\nAprÃ¨s avoir installÃ© Git, vous devez le configurer pour pouvoir lâ€™utiliser. Cliquez Ã  nouveau sur lâ€™onglet Terminal dans la fenÃªtre Console et tapez ce qui suit :\ngit config --global user.email 'you@youremail.com'\n\ngit config --global user.name 'Your Name'\nen remplaÃ§ant 'Your Name' votre nom rÃ©el et 'you@youremail.com' par votre adresse Ã©lectronique. Nous vous recommandons dâ€™utiliser lâ€™adresse Ã©lectronique de votre universitÃ© (si vous en avez une), car vous lâ€™utiliserez Ã©galement lors de lâ€™ouverture de votre compte GitHub (voir plus loin).\nSi vous avez rÃ©ussi, vous ne devriez pas voir de message dâ€™erreur dans ces commandes. Pour vÃ©rifier que vous avez configurÃ© Git avec succÃ¨s, tapez ce qui suit dans le Terminal\ngit config --global --list\nVous devriez voir vos deux user.name et user.email configurÃ©s.\n\n7.4.3 Configurer RStudio\nComme vous pouvez le voir ci-dessus, Git peut Ãªtre utilisÃ© Ã  partir de la ligne de commande, mais il sâ€™intÃ¨gre Ã©galement bien Ã  RStudio, en fournissant une interface utilisateur graphique conviviale. Si vous souhaitez utiliser lâ€™intÃ©gration Git de RStudio (nous vous le recommandons, au moins au dÃ©but), vous devez vÃ©rifier que le chemin dâ€™accÃ¨s Ã  lâ€™exÃ©cutable Git est correctement spÃ©cifiÃ©. Dans RStudio, allez dans le menu Tools -&gt; Global Options -&gt; Git/SVN et assurez-vous que â€˜Enable version control interface for RStudio projectsâ€™ est cochÃ© et que le chemin â€˜Git executable:â€™ est correct pour votre installation. Si ce nâ€™est pas le cas, cliquez sur le bouton Browse... et naviguez jusquâ€™Ã  lâ€™endroit oÃ¹ vous avez installÃ© git et cliquez sur le fichier exÃ©cutable. Vous devrez redÃ©marrer RStudio aprÃ¨s cette opÃ©ration.\n\n\n\n\n\n\n\nFigureÂ 7.3: Providing path to git software in RStudio\n\n\n\n\n\n7.4.4 Configurer VSCode\n\npour dÃ©velopper\n\n\n7.4.5 CrÃ©er un compte GitHub\nSi tout ce que vous voulez, câ€™est garder une trace des fichiers et de leurs versions sur votre ordinateur local, alors Git est suffisant. En revanche, si vous souhaitez faire une copie hors site de votre projet ou le mettre Ã  la disposition de vos collaborateurs, vous aurez besoin dâ€™un service dâ€™hÃ©bergement en ligne pour vos dÃ©pÃ´ts Git. Câ€™est lÃ  que GitHub entre en jeu (il existe Ã©galement dâ€™autres services tels que GitLab , Bitbucket et Savannah ). Vous pouvez vous inscrire pour un compte gratuit sur GitHub ici . Vous devrez spÃ©cifier un nom dâ€™utilisateur, une adresse email et un mot de passe fort. Nous vous suggÃ©rons dâ€™utiliser lâ€™adresse Ã©lectronique de votre universitÃ© (si vous en avez une), car elle vous permettra Ã©galement de demander un compte gratuit dâ€™Ã©ducateur ou de chercheur . gratuit pour les Ã©ducateurs ou les chercheurs ce qui vous permettra de bÃ©nÃ©ficier dâ€™un certain nombre dâ€™avantages avantages (ne vous en prÃ©occupez pas pour lâ€™instant). Quand il sâ€™agit de choisir un nom dâ€™utilisateur, nous vous suggÃ©rons dâ€™y rÃ©flÃ©chir. Choisissez un nom dâ€™utilisateur court plutÃ´t que long, utilisez des minuscules et des traits dâ€™union si vous voulez inclure plusieurs mots, trouvez un moyen dâ€™incorporer votre nom rÃ©el et, enfin, choisissez un nom dâ€™utilisateur que vous vous sentirez Ã  lâ€™aise de rÃ©vÃ©ler Ã  votre futur employeur !\nCliquez ensuite sur â€œSÃ©lectionnez un planâ€ (il se peut que vous deviez dâ€™abord rÃ©soudre une Ã©nigme simple pour vÃ©rifier que vous Ãªtes un Ãªtre humain) et choisissez lâ€™option â€œPlan gratuitâ€. Github vous enverra un courriel Ã  lâ€™adresse que vous avez fournie pour que vous puissiez vÃ©rifier.\nUne fois que vous avez terminÃ© toutes ces Ã©tapes, vous devriez avoir installÃ© Git et GitHub, prÃªts Ã  lâ€™emploi (enfin !).",
    "crumbs": [
      "DonnÃ©es",
      "Utiliser R",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>ContrÃ´le de version avec Git et GitHub</span>"
    ]
  },
  {
    "objectID": "07-github.html#mise-en-place-dun-projet",
    "href": "07-github.html#mise-en-place-dun-projet",
    "title": "7Â  ContrÃ´le de version avec Git et GitHub",
    "section": "\n7.5 Mise en place dâ€™un projet",
    "text": "7.5 Mise en place dâ€™un projet\n\n7.5.1 dans RStudio\nMaintenant que tout est prÃªt, crÃ©ons notre premier projet RStudio Ã  version contrÃ´lÃ©e. Pour ce faire, il existe plusieurs approches diffÃ©rentes. Vous pouvez dâ€™abord crÃ©er un dÃ©pÃ´t GitHub distant, puis connecter un projet RStudio Ã  ce dÃ©pÃ´t (câ€™est ce que nous appellerons lâ€™option 1). Une autre option consiste Ã  crÃ©er dâ€™abord un dÃ©pÃ´t local, puis Ã  lier un dÃ©pÃ´t GitHub distant Ã  ce dÃ©pÃ´t (Option 2). Vous pouvez Ã©galement connecter un projet existant Ã  un dÃ©pÃ´t GitHub, mais nous nâ€™aborderons pas cette option ici. Si vous Ãªtes totalement novice en matiÃ¨re de Git et de GitHub, nous vous suggÃ©rons dâ€™utiliser lâ€™option 1, car cette approche met en place votre dÃ©pÃ´t Git local de maniÃ¨re satisfaisante et vous pouvez pousser et tirer immÃ©diatement. Lâ€™option 2 nÃ©cessite un peu plus de travail et offre donc plus de possibilitÃ©s de se tromper. Nous aborderons ces deux options ci-dessous.\n\n7.5.2 Option 1 - GitHub dâ€™abord\nPour utiliser lâ€™approche GitHub first, vous devez dâ€™abord crÃ©er un fichier dÃ©pÃ´t (repo) sur GitHub. AccÃ©dez Ã  votre page GitHub et connectez-vous si nÃ©cessaire. Cliquez sur lâ€™onglet â€œDÃ©pÃ´tsâ€ en haut et ensuite sur le bouton vert â€œNouveauâ€ Ã  droite.\n\n\n\n\n\n\n\nFigureÂ 7.4: Creating a new repository on Github\n\n\n\n\nDonnez un nom Ã  votre nouveau dÃ©pÃ´t (appelons-le first_repo pour ce chapitre), sÃ©lectionnez â€˜Publicâ€™, cochez la case â€˜Initialize this repository with a READMEâ€™ (câ€™est important) et cliquez sur â€˜Create repositoryâ€™ (ignorez les autres options pour lâ€™instant).\n\n\n\n\n\n\n\nFigureÂ 7.5: Configuring a new repository on Github\n\n\n\n\nVotre nouveau dÃ©pÃ´t GitHub est maintenant crÃ©Ã©. Notez que le README a Ã©tÃ© rendu dans GitHub et quâ€™il est au format markdown (.md) (voir Chapitre 6 sur R markdown si cela ne vous dit rien). Cliquez ensuite sur le bouton vert â€œCloner ou tÃ©lÃ©chargerâ€ et copiez le fichier https//... URL qui sâ€™affiche pour plus tard (mettez tout en surbrillance et copiez ou cliquez sur lâ€™icÃ´ne de copie dans le presse-papiers Ã  droite).\n\n\n\n\n\n\n\nFigureÂ 7.6: Getting the cloning path for a directory on github\n\n\n\n\nOk, nous allons maintenant nous intÃ©resser Ã  RStudio. Dans RStudio, cliquez sur le bouton File -&gt; New Project le menu Dans la fenÃªtre qui sâ€™ouvre, sÃ©lectionnez Version Control.\n\n\n\n\n\n\n\nFigureÂ 7.7: Setting a new Github project in RStudio\n\n\n\n\nCollez maintenant lâ€™URL que vous avez prÃ©cÃ©demment copiÃ©e de GitHub dans le champ Repository URL: dans la boÃ®te de dialogue. Cela devrait remplir automatiquement le champ Project Directory Name: avec le nom correct du dÃ©pÃ´t (il est important que le nom de ce rÃ©pertoire soit le mÃªme que celui du dÃ©pÃ´t que vous avez crÃ©Ã© sur GitHub). Vous pouvez ensuite sÃ©lectionner lâ€™endroit oÃ¹ vous souhaitez crÃ©er ce rÃ©pertoire en cliquant sur le bouton Browse en face du bouton Create project as a subdirectory of: en face de lâ€™option Naviguez jusquâ€™Ã  lâ€™endroit oÃ¹ vous souhaitez crÃ©er le rÃ©pertoire et cliquez sur OK. Nous cochons Ã©galement lâ€™option Open in new session option.\n\n\n\n\n\n\n\n\nFigureÂ 7.8\n\n\n\n\nRStudio va maintenant crÃ©er un nouveau rÃ©pertoire portant le mÃªme nom que votre rÃ©fÃ©rentiel sur votre ordinateur local et va ensuite cloner votre rÃ©fÃ©rentiel distant dans ce rÃ©pertoire. Le rÃ©pertoire contiendra trois nouveaux fichiers ; first_repo.Rproj (ou quel que soit le nom que vous avez donnÃ© Ã  votre rÃ©fÃ©rentiel), README.md et .gitignore. Vous pouvez vÃ©rifier cela dans le Files qui se trouve gÃ©nÃ©ralement dans le volet infÃ©rieur droit de RStudio. Vous disposerez Ã©galement dâ€™un Git dans le volet supÃ©rieur droit avec deux fichiers listÃ©s (nous y reviendrons plus tard dans le chapitre). Câ€™est tout pour lâ€™option 1, vous avez maintenant un dÃ©pÃ´t GitHub distant qui est liÃ© Ã  votre dÃ©pÃ´t local gÃ©rÃ© par RStudio. Toutes les modifications que vous apportez aux fichiers de ce rÃ©pertoire seront contrÃ´lÃ©es par Git.\n\n\n\n\n\n\n\nFigureÂ 7.9\n\n\n\n\n\n7.5.3 Option 2 - RStudio dâ€™abord\nUne autre approche consiste Ã  crÃ©er dâ€™abord un projet RStudio local, puis Ã  Ã©tablir un lien avec un dÃ©pÃ´t Github distant. Comme nous lâ€™avons mentionnÃ© prÃ©cÃ©demment, cette option est plus complexe que lâ€™option 1. Nâ€™hÃ©sitez donc pas Ã  sauter cette Ã©tape et Ã  y revenir plus tard si vous Ãªtes intÃ©ressÃ©. Cette option est Ã©galement utile si vous souhaitez simplement crÃ©er un projet RStudio local liÃ© Ã  un dÃ©pÃ´t Git local (i.e. GitHub nâ€™est pas impliquÃ©). Dans ce cas, suivez les instructions ci-dessous en omettant la partie GitHub.\nDans RStudio, cliquez sur le bouton File -&gt; New Project et sÃ©lectionnez lâ€™option New Directory option.\n\n\n\n\n\n\n\nFigureÂ 7.10\n\n\n\n\nDans la fenÃªtre qui sâ€™ouvre, sÃ©lectionnez lâ€™option New Project lâ€™option\n\n\n\n\n\n\n\nFigureÂ 7.11\n\n\n\n\nDans la fenÃªtre Nouveau projet, spÃ©cifiez un Directory name (choisissez second_repo pour ce chapitre) et sÃ©lectionnez lâ€™endroit oÃ¹ vous souhaitez crÃ©er ce rÃ©pertoire sur votre ordinateur (cliquez sur le bouton Browse (cliquez sur le bouton ). Assurez-vous que le rÃ©pertoire Create a git repository est cochÃ©e\n\n\n\n\n\n\n\nFigureÂ 7.12\n\n\n\n\nCela crÃ©era un rÃ©pertoire Ã  version contrÃ´lÃ©e appelÃ© second_repo sur votre ordinateur qui contient deux fichiers, second_repo.Rproj et .gitignore (il peut Ã©galement y avoir un fichier .Rhistory mais nâ€™en tenez pas compte). Vous pouvez le vÃ©rifier en consultant le fichier Files dans RStudio (gÃ©nÃ©ralement dans le volet infÃ©rieur droit).\n\n\n\n\n\n\n\nFigureÂ 7.13\n\n\n\n\nOK, avant de crÃ©er un dÃ©pÃ´t sur GitHub, nous devons faire une derniÃ¨re chose - nous devons placer notre fichier second_repo.Rproj et .gitignoresous contrÃ´le de version. Malheureusement, nous nâ€™avons pas encore abordÃ© ce sujet en dÃ©tail, alors suivez les quelques instructions suivantes (Ã  lâ€™aveugle !) et nous y reviendrons dans Section 7.6 de ce chapitre.\nPour placer nos deux fichiers sous contrÃ´le de version, cliquez sur lâ€™onglet â€œGitâ€ qui se trouve gÃ©nÃ©ralement dans le panneau supÃ©rieur de RStudio.\n\n\n\n\n\n\n\nFigureÂ 7.14\n\n\n\n\nVous pouvez voir que les deux fichiers sont listÃ©s. Ensuite, cochez les cases de la colonne â€œStagedâ€ pour les deux fichiers et cliquez sur le bouton â€œCommitâ€.\n\n\n\n\n\n\n\nFigureÂ 7.15\n\n\n\n\nVous accÃ©dez alors Ã  la fenÃªtre â€œExaminer les modificationsâ€. Saisissez le message de validation â€œPremiÃ¨re validationâ€ dans la fenÃªtre â€œMessage de validationâ€ et cliquez sur le bouton â€œValiderâ€. Une nouvelle fenÃªtre apparaÃ®t avec des messages que vous pouvez ignorer pour lâ€™instant. Cliquez sur â€œFermerâ€ pour fermer cette fenÃªtre ainsi que la fenÃªtre â€œExaminer les modificationsâ€. Les deux fichiers devraient maintenant avoir disparu du panneau Git dans RStudio, ce qui indique que la validation a Ã©tÃ© effectuÃ©e avec succÃ¨s.\n\n\n\n\n\n\n\nFigureÂ 7.16\n\n\n\n\nOK, ces deux fichiers sont maintenant sous contrÃ´le de version. Nous devons maintenant crÃ©er un nouveau dÃ©pÃ´t sur GitHub. Dans votre navigateur, allez sur votre page GitHub et connectez-vous si nÃ©cessaire. Cliquez sur lâ€™onglet â€œDÃ©pÃ´tsâ€ et cliquez sur le bouton vert â€œNouveauâ€ Ã  droite. Donnez Ã  votre nouveau dÃ©pÃ´t le nom second_repo (identique au nom de votre rÃ©pertoire de contrÃ´le de version) et sÃ©lectionnez â€œPublicâ€. Cette fois-ci ne pas cocher la case â€˜Initialize this repository with a READMEâ€™ (câ€™est important) et cliquer sur â€˜Create repositoryâ€™.\n\n\n\n\n\n\n\nFigureÂ 7.17\n\n\n\n\nCela vous amÃ¨nera Ã  une page de configuration rapide qui vous fournira du code pour diffÃ©rentes situations. Le code qui nous intÃ©resse est celui qui se trouve sous ...or push an existing repository from the command line lâ€™en-tÃªte.\n\n\n\n\n\n\n\nFigureÂ 7.18\n\n\n\n\nSurlignez et copiez la premiÃ¨re ligne de code (note : la vÃ´tre sera lÃ©gÃ¨rement diffÃ©rente car elle inclura votre nom dâ€™utilisateur GitHub et non le mien).\ngit remote add origin https://github.com/alexd106/second_repo.git\nPassez Ã  RStudio, cliquez sur lâ€™onglet â€œTerminalâ€ et collez la commande dans le terminal. Retournez ensuite sur GitHub et copiez la deuxiÃ¨me ligne de code\ngit push -u origin master\net collez-la dans le terminal de RStudio. Vous devriez voir quelque chose comme ceci\n\n\n\n\n\n\n\nFigureÂ 7.19\n\n\n\n\nSi vous jetez un coup dâ€™Å“il Ã  votre repo sur GitHub (cliquez sur lâ€™icÃ´ne /second_repo en haut de la page), vous verrez le second_repo.Rproj et .gitignore ont Ã©tÃ© remplacÃ©s par les fichiers poussÃ©s sur GitHub depuis votre dÃ©pÃ´t local.\n\n\n\n\n\n\n\nFigureÂ 7.20\n\n\n\n\nLa derniÃ¨re chose Ã  faire est de crÃ©er et dâ€™ajouter un fichier README Ã  votre dÃ©pÃ´t. Un fichier README dÃ©crit votre projet et est Ã©crit en utilisant le mÃªme langage Markdown que vous avez appris dans Chapitre 6. Un bon fichier README permet aux autres (ou au futur vous !) dâ€™utiliser votre code et de reproduire votre projet. Vous pouvez crÃ©er un fichier README dans RStudio ou dans GitHub. Utilisons la seconde option.\nDans votre dÃ©pÃ´t sur GitHub, cliquez sur le bouton vert Add a README vert.\n\n\n\n\n\n\n\nFigureÂ 7.21\n\n\n\n\nRÃ©digez maintenant une brÃ¨ve description de votre projet dans la rubrique &lt;&gt; Edit new file puis cliquez sur le bouton vert Commit new file vert.\n\n\n\n\n\n\n\nFigureÂ 7.22\n\n\n\n\nVous devriez maintenant voir lâ€™Ã©cran README.md dans votre rÃ©fÃ©rentiel. Il nâ€™existera pas encore sur votre ordinateur car vous devrez tirer ces changements dans votre dÃ©pÃ´t local, mais nous y reviendrons dans la section suivante.\nQue vous ayez suivi lâ€™option 1 ou lâ€™option 2 (ou les deux), vous avez maintenant configurÃ© avec succÃ¨s un projet RStudio Ã  version contrÃ´lÃ©e (et un rÃ©pertoire associÃ©) et lâ€™avez liÃ© Ã  un dÃ©pÃ´t GitHub. Git va maintenant surveiller ce rÃ©pertoire pour toutes les modifications que vous apportez aux fichiers et aussi si vous ajoutez ou supprimez des fichiers. Si les Ã©tapes ci-dessus vous semblent un peu difficiles, rappelez-vous que vous nâ€™avez Ã  le faire quâ€™une seule fois pour chaque projet et que cela devient de plus en plus facile avec le temps.\n\n7.5.4 dans VSCode\n\npour dÃ©velopper",
    "crumbs": [
      "DonnÃ©es",
      "Utiliser R",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>ContrÃ´le de version avec Git et GitHub</span>"
    ]
  },
  {
    "objectID": "07-github.html#sec-use-git",
    "href": "07-github.html#sec-use-git",
    "title": "7Â  ContrÃ´le de version avec Git et GitHub",
    "section": "\n7.6 Utiliser Git avec RStudio",
    "text": "7.6 Utiliser Git avec RStudio\nMaintenant que nous avons mis en place notre projet et nos dÃ©pÃ´ts (locaux et distants), il est enfin temps dâ€™apprendre Ã  utiliser Git dans votre IDE !\nTypiquement, lorsque vous utilisez Git, votre flux de travail se dÃ©roule comme suit :\n\nVous crÃ©ez/supprimez et modifiez les fichiers dans le rÃ©pertoire de votre projet sur votre ordinateur comme dâ€™habitude (en sauvegardant les modifications au fur et Ã  mesure).\nUne fois que vous avez atteint un â€œpoint dâ€™arrÃªtâ€ naturel dans votre progression (c.-Ã -d. vous seriez triste si vous perdiez ce progrÃ¨s), vous Ã©tape ces fichiers\nEnsuite, vous engager les modifications que vous avez apportÃ©es Ã  ces fichiers mis en scÃ¨ne (avec un message de validation utile), ce qui crÃ©e un instantanÃ© permanent de ces modifications.\nVous continuez ce cycle jusquâ€™Ã  ce que vous arriviez Ã  un point oÃ¹ vous souhaitez pousser ces changements sur GitHub\nSi vous travaillez avec dâ€™autres personnes sur le mÃªme projet, vous pouvez Ã©galement avoir besoin de tirer leurs modifications sur votre ordinateur local\n\n\n\n\n\n\n\n\nFigureÂ 7.23\n\n\n\n\nPrenons un exemple pour clarifier ce flux de travail.\nOuvrez le first_repo.Rproj que vous avez crÃ©Ã© prÃ©cÃ©demment dans lâ€™option 1. Utilisez soit lâ€™outil File -&gt; Open Project ou cliquer sur lâ€™icÃ´ne de projet en haut Ã  droite et sÃ©lectionner le projet appropriÃ©.\n\n\n\n\n\n\n\nFigureÂ 7.24\n\n\n\n\nCrÃ©ez un document R markdown Ã  lâ€™intÃ©rieur de ce projet en cliquant sur lâ€™icÃ´ne File -&gt; New File -&gt; R markdown menu (vous vous souvenez de Chapitre 6 ?).\nUne fois crÃ©Ã©, nous pouvons supprimer tout le code R markdown de lâ€™exemple (Ã  lâ€™exception de lâ€™en-tÃªte YAML) comme dâ€™habitude et Ã©crire du texte R markdown intÃ©ressant et inclure un tracÃ©. Nous utiliserons la fonction cars pour ce faire. Enregistrez ce fichier (cmd + s pour Mac ou ctrl + s sous Windows). Votre document R markdown devrait ressembler Ã  ce qui suit (ce nâ€™est pas grave si ce nâ€™est pas exactement la mÃªme chose).\n\n\n\n\n\n\n\nFigureÂ 7.25\n\n\n\n\nJetez un coup dâ€™Å“il Ã  lâ€™onglet â€˜Gitâ€™ qui devrait contenir votre nouveau document R markdown (first_doc.Rmd dans cet exemple) ainsi que first_repo.Rproj et .gitignore (vous avez crÃ©Ã© ces fichiers prÃ©cÃ©demment en suivant lâ€™option 1).\n\n\n\n\n\n\n\nFigureÂ 7.26\n\n\n\n\nEn suivant notre flux de travail, nous devons maintenant mettre en scÃ¨ne ces fichiers. Pour ce faire, cochez les cases de la colonne â€œEtagÃ©â€ pour tous les fichiers. Notez quâ€™une icÃ´ne dâ€™Ã©tat se trouve Ã  cÃ´tÃ© de la case, ce qui vous donne une indication sur la faÃ§on dont les fichiers ont Ã©tÃ© modifiÃ©s. Dans notre cas, tous les fichiers doivent Ãªtre ajoutÃ©s (A majuscule) car nous venons de les crÃ©er.\n\n\n\n\n\n\n\nFigureÂ 7.27\n\n\n\n\nAprÃ¨s avoir mis en scÃ¨ne les fichiers, lâ€™Ã©tape suivante consiste Ã  engager les fichiers. Pour ce faire, cliquez sur le bouton â€œCommitâ€.\n\n\n\n\n\n\n\nFigureÂ 7.28\n\n\n\n\nAprÃ¨s avoir cliquÃ© sur le bouton â€œValiderâ€, vous accÃ©derez Ã  la fenÃªtre â€œRevoir les modificationsâ€. Vous devriez voir les trois fichiers que vous avez mis en scÃ¨ne Ã  lâ€™Ã©tape prÃ©cÃ©dente dans le panneau de gauche. Si vous cliquez sur le nom du fichier first_doc.Rmd vous verrez les modifications que vous avez apportÃ©es Ã  ce fichier en surbrillance dans le volet infÃ©rieur. Le contenu que vous avez ajoutÃ© est surlignÃ© en vert et le contenu supprimÃ© est surlignÃ© en rouge. Comme vous venez de crÃ©er ce fichier, tout le contenu est surlignÃ© en vert. Pour valider ces fichiers (prendre un instantanÃ©), saisissez dâ€™abord un message de validation obligatoire dans le champ â€œMessage de validationâ€. Ce message doit Ãªtre relativement court et informatif (pour vous et vos collaborateurs) et indiquer pourquoi vous avez effectuÃ© les modifications, et non ce que vous avez modifiÃ©. Ceci est logique car Git garde une trace de ce que a changÃ© et quâ€™il est donc prÃ©fÃ©rable de ne pas utiliser les messages de livraison Ã  cette fin. Il est traditionnel de saisir le message â€œFirst commitâ€ (ou â€œInitial commitâ€) lorsque vous livrez des fichiers pour la premiÃ¨re fois. Cliquez maintenant sur le bouton â€œCommitâ€ pour valider ces modifications.\n\n\n\n\n\n\n\nFigureÂ 7.29\n\n\n\n\nUn rÃ©sumÃ© de la validation que vous venez dâ€™effectuer sâ€™affiche. Cliquez ensuite sur le bouton â€œFermerâ€ pour revenir Ã  la fenÃªtre â€œRevoir les modificationsâ€. Notez que les fichiers mis Ã  disposition ont Ã©tÃ© supprimÃ©s.\n\n\n\n\n\n\n\nFigureÂ 7.30\n\n\n\n\nMaintenant que vous avez validÃ© vos modifications, lâ€™Ã©tape suivante consiste Ã  pousser ces changements sur GitHub. Avant de pousser vos modifications, il est conseillÃ© de commencer par tirer les modifications depuis GitHub. Ceci est particuliÃ¨rement important si vous et vos collaborateurs travaillez sur les mÃªmes fichiers, car cela permet de garder votre copie locale Ã  jour et dâ€™Ã©viter tout conflit potentiel. Dans ce cas, votre dÃ©pÃ´t sera dÃ©jÃ  Ã  jour, mais câ€™est une bonne habitude Ã  prendre. Pour ce faire, cliquez sur le bouton â€œTirerâ€ en haut Ã  droite de la fenÃªtre â€œExaminer les modificationsâ€. Une fois que vous avez retirÃ© les modifications, cliquez sur le bouton vert â€œPousserâ€ pour transfÃ©rer vos modifications. Vous verrez un rÃ©sumÃ© de lâ€™opÃ©ration que vous venez dâ€™effectuer. Cliquez sur le bouton â€œFermerâ€ et fermez la fenÃªtre â€œRevoir les modificationsâ€.\n\n\n\n\n\n\n\nFigureÂ 7.31\n\n\n\n\nPour confirmer que les modifications que vous avez apportÃ©es au projet ont Ã©tÃ© transfÃ©rÃ©es sur GitHub, ouvrez votre page GitHub, cliquez sur le lien DÃ©pÃ´ts, puis sur lâ€™icÃ´ne first_repo dÃ©pÃ´t. Vous devriez voir quatre fichiers listÃ©s, dont le fichier first_doc.Rmd que vous venez de pousser. Ã€ cÃ´tÃ© du nom du fichier, vous verrez votre dernier message de validation (â€œPremiÃ¨re validationâ€ dans ce cas) et la date de la derniÃ¨re validation.\n\n\n\n\n\n\n\nFigureÂ 7.32\n\n\n\n\nPour voir le contenu du fichier, cliquez sur le bouton first_doc.Rmd nom du fichier.\n\n\n\n\n\n\n\nFigureÂ 7.33\n\n\n\n\n\n7.6.1 Suivi des modifications\nAprÃ¨s avoir suivi les Ã©tapes dÃ©crites ci-dessus, vous aurez rÃ©ussi Ã  modifier un projet RStudio en crÃ©ant un nouveau document R markdown, Ã  mettre en scÃ¨ne puis Ã  valider ces changements et enfin Ã  pousser les changements vers votre dÃ©pÃ´t GitHub. Maintenant, apportons dâ€™autres modifications Ã  votre fichier R markdown et suivons Ã  nouveau le flux de travail, mais cette fois, nous verrons comment identifier les modifications apportÃ©es aux fichiers, examiner lâ€™historique des livraisons et comment restaurer une version prÃ©cÃ©dente du document.\nDans RStudio, ouvrez le fichier first_repo.Rproj que vous avez crÃ©Ã© prÃ©cÃ©demment (sâ€™il nâ€™est pas dÃ©jÃ  ouvert), puis ouvrez le fichier first_doc.Rmd (cliquez sur le nom du fichier dans la fenÃªtre Files dans RStudio).\nApportez quelques modifications Ã  ce document. Supprimez la ligne commenÃ§ant par â€œMa premiÃ¨re version contrÃ´lÃ©eâ€¦â€ et remplacez-la par quelque chose de plus informatif (voir figure ci-dessous). Nous allons Ã©galement changer les symboles de tracÃ© en rouge et donner des Ã©tiquettes aux axes de tracÃ©. Enfin, ajoutons un tableau rÃ©capitulatif du cadre de donnÃ©es Ã  lâ€™aide de la commande kable() et summary() (il se peut que vous ayez besoin dâ€™installer le programme knitr si vous ne lâ€™avez pas fait auparavant pour utiliser le paquet kable() ) et enfin rendre ce document au format pdf en changeant lâ€™option YAML en output: pdf_document.\n\n\n\n\n\n\n\nFigureÂ 7.34\n\n\n\n\nSauvegardez ces modifications, puis cliquez sur le bouton knit pour effectuer le rendu au format pdf. Un nouveau fichier pdf nommÃ© first_doc.pdf sera crÃ©Ã© et vous pourrez lâ€™afficher en cliquant sur le nom du fichier dans la fenÃªtre Files dans RStudio.\nNotez que ces deux fichiers ont Ã©tÃ© ajoutÃ©s Ã  la base de donnÃ©es Git dans RStudio. Les icÃ´nes dâ€™Ã©tat indiquent que le fichier first_doc.Rmd a Ã©tÃ© modifiÃ© (M majuscule) et que le fichier first_doc.pdf nâ€™est pas suivi (point dâ€™interrogation).\n\n\n\n\n\n\n\nFigureÂ 7.35\n\n\n\n\nPour mettre en scÃ¨ne ces fichiers, cochez la case â€œMis en scÃ¨neâ€ pour chaque fichier et cliquez sur le bouton â€œValiderâ€ pour accÃ©der Ã  la fenÃªtre â€œExaminer les modificationsâ€.\n\n\n\n\n\n\n\nFigureÂ 7.36\n\n\n\n\nAvant de valider vos modifications, notez lâ€™Ã©tat des fichiers first_doc.pdf est passÃ© de non suivi Ã  ajoutÃ© (A). Vous pouvez consulter les modifications que vous avez apportÃ©es Ã  lâ€™Ã©lÃ©ment first_doc.Rmd en cliquant sur le nom du fichier dans le volet supÃ©rieur gauche, ce qui vous donnera un rÃ©sumÃ© utile des modifications dans le volet infÃ©rieur (techniquement appelÃ© diffs). Les lignes qui ont Ã©tÃ© supprimÃ©es sont surlignÃ©es en rouge et les lignes qui ont Ã©tÃ© ajoutÃ©es sont surlignÃ©es en vert (notez que du point de vue de Git, une modification de ligne est en fait deux opÃ©rations : la suppression de la ligne dâ€™origine suivie de la crÃ©ation dâ€™une nouvelle ligne). Une fois que vous Ãªtes satisfait, validez ces modifications en rÃ©digeant un message de validation appropriÃ© et cliquez sur le bouton â€œValiderâ€.\n\n\n\n\n\n\n\nFigureÂ 7.37\n\n\n\n\nPour transfÃ©rer les modifications sur GitHub, cliquez dâ€™abord sur le bouton â€œPullâ€ (rappelez-vous quâ€™il sâ€™agit dâ€™une bonne pratique, mÃªme si vous ne collaborez quâ€™avec vous-mÃªme pour lâ€™instant), puis cliquez sur le bouton â€œPushâ€. AccÃ©dez Ã  votre dÃ©pÃ´t GitHub en ligne et vous verrez vos nouveaux commits, y compris le bouton first_doc.pdf que vous avez crÃ©Ã© lorsque vous avez rendu votre document R markdown.\n\n\n\n\n\n\n\nFigureÂ 7.38\n\n\n\n\nPour voir les changements dans first_doc.Rmd cliquez sur le nom de ce fichier.\n\n\n\n\n\n\n\nFigureÂ 7.39\n\n\n\n\n\n7.6.2 Historique des engagements\nLâ€™un des avantages de Git et de GitHub est que vous pouvez consulter lâ€™historique de tous les commits que vous avez effectuÃ©s, ainsi que les messages de commits associÃ©s. Vous pouvez le faire localement en utilisant RStudio (ou la ligne de commande Git) ou si vous avez poussÃ© vos commits sur GitHub, vous pouvez les consulter sur le site web de GitHub.\nPour consulter lâ€™historique des livraisons dans RStudio, cliquez sur le bouton â€ History â€ (celui qui ressemble Ã  une horloge) dans le volet Git pour afficher lâ€™historique dans la fenÃªtre â€ Review Changes â€œ. Vous pouvez Ã©galement cliquer sur les boutonsâ€Commitâ€ ou â€œDiffâ€ pour accÃ©der Ã  la mÃªme fenÃªtre (il vous suffit de cliquer en plus sur le bouton â€œHistoryâ€ dans la fenÃªtre â€œReview Changesâ€).\n\n\n\n\n\n\n\nFigureÂ 7.40\n\n\n\n\nLa fenÃªtre dâ€™historique est divisÃ©e en deux parties. Le volet supÃ©rieur rÃ©pertorie toutes les livraisons que vous avez effectuÃ©es dans ce dÃ©pÃ´t (avec les messages de livraison associÃ©s), en commenÃ§ant par la plus rÃ©cente en haut et la plus ancienne en bas. Vous pouvez cliquer sur chacune de ces livraisons et le volet infÃ©rieur vous montre les modifications que vous avez apportÃ©es ainsi quâ€™un rÃ©sumÃ© de lâ€™historique. Date Ã  laquelle la validation a Ã©tÃ© effectuÃ©e, lâ€™auteur du commit et le message du commit (Sujet). Il existe Ã©galement un identifiant unique pour lâ€™engagement (SHA - Secure Hash Algorithm) et un identifiant Parent qui identifie la livraison prÃ©cÃ©dente. Ces identifiants SHA sont trÃ¨s importants car vous pouvez les utiliser pour visualiser et revenir Ã  des versions antÃ©rieures de fichiers (dÃ©tails ci-dessous Section 7.6.3). Vous pouvez Ã©galement consulter le contenu de chaque fichier en cliquant sur le lien â€œVoir le fichier @ clÃ© SHAâ€ (dans notre cas, â€œVoir le fichier @ 2b4693d1â€).\n\n\n\n\n\n\n\nFigureÂ 7.41\n\n\n\n\nVous pouvez Ã©galement consulter lâ€™historique de vos commits sur le site GitHub, mais cette consultation sera limitÃ©e aux commits que vous avez dÃ©jÃ  transfÃ©rÃ©s sur GitHub. Pour consulter lâ€™historique des livraisons, accÃ©dez au dÃ©pÃ´t et cliquez sur le lien â€œlivraisonsâ€ (dans notre cas, le lien sera intitulÃ© â€œ3 livraisonsâ€ car nous avons effectuÃ© 3 livraisons).\n\n\n\n\n\n\n\nFigureÂ 7.42\n\n\n\n\nVous verrez une liste de tous les commits que vous avez faits, avec les messages de commit, la date du commit et lâ€™identifiant SHA (ce sont les mÃªmes identifiants SHA que vous avez vus dans lâ€™historique de RStudio). Vous pouvez mÃªme parcourir le dÃ©pÃ´t Ã  un moment donnÃ© en cliquant sur le bouton &lt;&gt; lien. Pour visualiser les modifications apportÃ©es aux fichiers associÃ©s au commit, il suffit de cliquer sur le lien du commit concernÃ© dans la liste.\n\n\n\n\n\n\n\nFigureÂ 7.43\n\n\n\n\nLes modifications seront affichÃ©es selon le format habituel : vert pour les ajouts et rouge pour les suppressions.\n\n\n\n\n\n\n\nFigureÂ 7.44\n\n\n\n\n\n7.6.3 Annulation des modifications\nLâ€™un des avantages de lâ€™utilisation de Git est la possibilitÃ© de revenir Ã  des versions antÃ©rieures des fichiers si vous avez fait une erreur, si vous avez cassÃ© quelque chose ou si vous prÃ©fÃ©rez simplement une approche plus ancienne. La faÃ§on de procÃ©der dÃ©pend du fait que les modifications que vous souhaitez supprimer ont Ã©tÃ© mises Ã  disposition, validÃ©es ou poussÃ©es sur GitHub. Nous allons passer en revue quelques scÃ©narios courants ci-dessous, en utilisant principalement RStudio, mais nous aurons parfois besoin dâ€™utiliser le Terminal (toujours dans RStudio cependant).\nModifications sauvegardÃ©es mais non mises Ã  jour, validÃ©es ou poussÃ©es\nSi vous avez enregistrÃ© des modifications dans votre ou vos fichiers mais que vous ne les avez pas mis en page, livrÃ©s ou poussÃ©s sur GitHub, vous pouvez cliquer avec le bouton droit de la souris sur le fichier incriminÃ© dans le panneau Git et sÃ©lectionner â€œRevert â€¦â€ (revenir en arriÃ¨re). Cela ramÃ¨nera toutes les modifications que vous avez faites au mÃªme Ã©tat que votre dernier commit. Sachez quâ€™il nâ€™est pas possible dâ€™annuler cette opÃ©ration, alors utilisez-la avec prÃ©caution.\n\n\n\n\n\n\n\nFigureÂ 7.45\n\n\n\n\nVous pouvez Ã©galement annuler les modifications apportÃ©es Ã  une partie seulement dâ€™un fichier en ouvrant la fenÃªtre â€œDiffâ€ (cliquez sur le bouton â€œDiffâ€ dans le panneau Git). SÃ©lectionnez la ligne que vous souhaitez annuler en double-cliquant dessus, puis cliquez sur le bouton â€œAnnuler la ligneâ€. De la mÃªme maniÃ¨re, vous pouvez supprimer des morceaux de code en cliquant sur le bouton â€œSupprimer le morceauâ€.\n\n\n\n\n\n\n\nFigureÂ 7.46\n\n\n\n\nStagÃ© mais non validÃ© et non poussÃ©\nSi vous avez mis en scÃ¨ne vos fichiers, mais que vous ne les avez pas validÃ©s, dÃ©cochez-les simplement en cliquant sur la case â€œMis en scÃ¨neâ€ dans le panneau Git (ou dans la fenÃªtre â€œExaminer les modificationsâ€) pour supprimer la coche. Vous pouvez alors revenir sur tout ou partie du fichier comme dÃ©crit dans la section ci-dessus.\nStagÃ© et validÃ© mais non poussÃ©\nSi vous avez fait une erreur ou avez oubliÃ© dâ€™inclure un fichier dans votre dernier commit que vous nâ€™avez pas encore poussÃ© sur GitHub, vous pouvez simplement corriger votre erreur, enregistrer vos modifications, puis modifier votre prÃ©cÃ©dent commit. Vous pouvez le faire en mettant en scÃ¨ne votre fichier, puis en cochant la case â€œModifier la livraison prÃ©cÃ©denteâ€ dans la fenÃªtre â€œExaminer les modificationsâ€ avant de livrer.\n\n\n\n\n\n\n\nFigureÂ 7.47\n\n\n\n\nSi nous consultons lâ€™historique des livraisons, nous pouvons voir que notre derniÃ¨re livraison contient les deux modifications apportÃ©es au fichier plutÃ´t que deux livraisons distinctes. Nous utilisons souvent lâ€™approche â€œamend commitâ€, mais il est important de comprendre que vous devez ne pas faire si vous avez dÃ©jÃ  poussÃ© votre dernier commit sur GitHub car vous rÃ©Ã©crivez lâ€™histoire et toutes sortes de mauvaises choses peuvent arriver !\n\n\n\n\n\n\n\nFigureÂ 7.48\n\n\n\n\nSi vous repÃ©rez une erreur qui sâ€™est produite plusieurs fois ou si vous souhaitez simplement revenir Ã  une version prÃ©cÃ©dente dâ€™un document, plusieurs options sâ€™offrent Ã  vous.\nOption 1 - (probablement la plus simple mais trÃ¨s peu Git - mais bon, peu importe !) est de regarder dans votre historique de commit dans RStudio, de trouver le commit sur lequel vous souhaitez revenir et de cliquer sur le bouton â€˜View file @â€™ pour afficher le contenu du fichier.\n\n\n\n\n\n\n\nFigureÂ 7.49\n\n\n\n\nVous pouvez alors copier le contenu du fichier dans le presse-papiers et le coller dans votre fichier actuel pour remplacer le code ou le texte dÃ©fectueux. Vous pouvez Ã©galement cliquer sur le bouton â€œEnregistrer sousâ€ et enregistrer le fichier sous un autre nom. Une fois que vous avez enregistrÃ© votre nouveau fichier, vous pouvez supprimer votre fichier indÃ©sirable actuel et continuer Ã  travailler sur votre nouveau fichier. Nâ€™oubliez pas de mettre en scÃ¨ne et de valider ce nouveau fichier.\n\n\n\n\n\n\n\nFigureÂ 7.50\n\n\n\n\nOption 2 - (Git like) Allez dans votre historique Git, trouvez le commit sur lequel vous souhaitez revenir et notez (ou copiez) son identifiant SHA.\n\n\n\n\n\n\n\nFigureÂ 7.51\n\n\n\n\nAllez maintenant au Terminal dans RStudio et tapez git checkout &lt;SHA&gt; &lt;filename&gt;. Dans notre cas, la clÃ© SHA est 2b4693d1 et le nom du fichier est first_doc.Rmd notre commande ressemblerait donc Ã  ceci :\ngit checkout 2b4693d1 first_doc.Rmd\nLa commande ci-dessus copiera la version du fichier sÃ©lectionnÃ© dans le passÃ© et la placera dans le prÃ©sent. RStudio peut vous demander si vous souhaitez recharger le fichier tel quâ€™il a Ã©tÃ© modifiÃ© - sÃ©lectionnez oui. Vous devrez Ã©galement mettre en scÃ¨ne et valider le fichier comme dâ€™habitude.\nSi vous souhaitez ramener tous vos fichiers au mÃªme Ã©tat quâ€™une livraison prÃ©cÃ©dente plutÃ´t quâ€™un seul fichier, vous pouvez utiliser (le seul â€œpoint . est important, sinon votre HEAD se dÃ©tachera) :\ngit rm -r .\ngit checkout 2b4693d1 .\n\nNotez que cela supprimera tous les fichiers que vous avez crÃ©Ã©s depuis que vous avez effectuÃ© ce commit, alors soyez prudent !\nMise en scÃ¨ne, livrÃ©e et poussÃ©e\nSi vous avez dÃ©jÃ  transfÃ©rÃ© vos modifications sur GitHub, vous pouvez utiliser la commande git checkout dÃ©crite ci-dessus, puis commiter et pousser pour mettre Ã  jour GitHub (bien que cela ne soit pas vraiment considÃ©rÃ© comme une â€œmeilleureâ€ pratique). Une autre approche serait dâ€™utiliser git revert (Note : pour autant que nous puissions en juger git revert nâ€™est pas la mÃªme chose que lâ€™option â€˜Revertâ€™ dans RStudio). Lâ€™option revert dans Git crÃ©e essentiellement un nouveau commit basÃ© sur un commit prÃ©cÃ©dent et prÃ©serve donc tout lâ€™historique des commits. Pour revenir Ã  un Ã©tat antÃ©rieur (commit), vous devez dâ€™abord identifier la ZSD du commit auquel vous souhaitez revenir (comme nous lâ€™avons fait ci-dessus), puis utiliser la commande revert dans le terminal. Supposons que nous voulions revenir Ã  notre â€œPremier commitâ€ qui a un identifiant SHA d27e79f1.\n\n\n\n\n\n\n\nFigureÂ 7.52\n\n\n\n\nNous pouvons utiliser le revert comme indiquÃ© ci-dessous dans le terminal. La commande --no-commit est utilisÃ©e pour Ã©viter dâ€™avoir Ã  gÃ©rer chaque livraison intermÃ©diaire.\ngit revert --no-commit d27e79f1..HEAD\nVotre first_doc.Rmd va maintenant revenir au mÃªme Ã©tat que celui dans lequel il se trouvait lorsque vous avez effectuÃ© votre â€œpremier commitâ€. Notez Ã©galement que lâ€™Ã©lÃ©ment first_doc.pdf a Ã©tÃ© supprimÃ©, car il nâ€™Ã©tait pas prÃ©sent lorsque nous avons effectuÃ© notre premiÃ¨re livraison. Vous pouvez maintenant mettre en scÃ¨ne et livrer ces fichiers avec un nouveau message de livraison et enfin les pousser sur GitHub. Remarquez que si nous regardons notre historique des livraisons, toutes les livraisons que nous avons faites sont toujours prÃ©sentes.\n\n\n\n\n\n\n\nFigureÂ 7.53\n\n\n\n\net notre repo sur GitHub reflÃ¨te Ã©galement ces changements\n\n\n\n\n\n\n\nFigureÂ 7.54",
    "crumbs": [
      "DonnÃ©es",
      "Utiliser R",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>ContrÃ´le de version avec Git et GitHub</span>"
    ]
  },
  {
    "objectID": "07-github.html#sec-use-git_vsc",
    "href": "07-github.html#sec-use-git_vsc",
    "title": "7Â  ContrÃ´le de version avec Git et GitHub",
    "section": "\n7.7 Utiliser Git avec VSCode",
    "text": "7.7 Utiliser Git avec VSCode\nMaintenant que nous avons mis en place notre projet et nos dÃ©pÃ´ts (locaux et distants), il est enfin temps dâ€™apprendre Ã  utiliser Git dans VSCode !\nTypiquement, lorsque vous utilisez Git, votre flux de travail se dÃ©roule comme suit :\n\nVous crÃ©ez/supprimez et modifiez les fichiers dans le rÃ©pertoire de votre projet sur votre ordinateur comme dâ€™habitude (en sauvegardant les modifications au fur et Ã  mesure).\nUne fois que vous avez atteint un â€œpoint dâ€™arrÃªtâ€ naturel dans votre progression (c.-Ã -d. vous seriez triste si vous perdiez ce progrÃ¨s), vous Ã©tape ces fichiers\nEnsuite, vous engager les modifications que vous avez apportÃ©es Ã  ces fichiers mis en scÃ¨ne (avec un message de validation utile), ce qui crÃ©e un instantanÃ© permanent de ces modifications.\nVous continuez ce cycle jusquâ€™Ã  ce que vous arriviez Ã  un point oÃ¹ vous souhaitez pousser ces changements sur GitHub\nSi vous travaillez avec dâ€™autres personnes sur le mÃªme projet, vous pouvez Ã©galement avoir besoin de tirer leurs modifications sur votre ordinateur local\n\n\n\n\n\n\n\n\nFigureÂ 7.55\n\n\n\n\nPrenons un exemple pour clarifier ce flux de travail.\nSuivi des modifications\nHistorique des modifications\nAnnulation des modifications",
    "crumbs": [
      "DonnÃ©es",
      "Utiliser R",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>ContrÃ´le de version avec Git et GitHub</span>"
    ]
  },
  {
    "objectID": "07-github.html#sec-collab",
    "href": "07-github.html#sec-collab",
    "title": "7Â  ContrÃ´le de version avec Git et GitHub",
    "section": "\n7.8 Collaborer avec Git",
    "text": "7.8 Collaborer avec Git\nGitHub est un excellent outil de collaboration. Il peut sembler effrayant et compliquÃ© au dÃ©but, mais cela vaut la peine dâ€™investir un peu de temps pour apprendre comment il fonctionne. Ce qui rend GitHub si bon pour la collaboration, câ€™est quâ€™il sâ€™agit dâ€™un systÃ¨me de systÃ¨me distribuÃ© Cela signifie que chaque collaborateur travaille sur sa propre copie du projet et que les modifications sont ensuite fusionnÃ©es dans le dÃ©pÃ´t distant. Il existe deux faÃ§ons principales de mettre en place un projet collaboratif sur GitHub. Lâ€™une est le flux de travail que nous avons dÃ©crit ci-dessus, oÃ¹ chacun connecte son dÃ©pÃ´t local au mÃªme dÃ©pÃ´t distant ; ce systÃ¨me fonctionne bien avec les petits projets oÃ¹ diffÃ©rentes personnes travaillent principalement sur diffÃ©rents aspects du projet, mais il peut rapidement devenir lourd si de nombreuses personnes collaborent et travaillent sur les mÃªmes fichiers (misÃ¨re de la fusion !). La seconde approche consiste Ã  ce que chaque collaborateur crÃ©e une copie (ou fork) du dÃ©pÃ´t principal, qui devient leur dÃ©pÃ´t distant. Chaque collaborateur doit alors envoyer une demande (une demande dâ€™extraction) au propriÃ©taire du rÃ©fÃ©rentiel principal afin dâ€™incorporer les modifications dans le rÃ©fÃ©rentiel principal, ce qui inclut un processus de rÃ©vision avant lâ€™intÃ©gration des modifications. Plus de dÃ©tails sur ces sujets peuvent Ãªtre trouvÃ©s dans Section 7.10.",
    "crumbs": [
      "DonnÃ©es",
      "Utiliser R",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>ContrÃ´le de version avec Git et GitHub</span>"
    ]
  },
  {
    "objectID": "07-github.html#conseils-git",
    "href": "07-github.html#conseils-git",
    "title": "7Â  ContrÃ´le de version avec Git et GitHub",
    "section": "\n7.9 Conseils Git",
    "text": "7.9 Conseils Git\nDâ€™une maniÃ¨re gÃ©nÃ©rale, vous devriez commiter souvent (y compris les commits modifiÃ©s) mais pousser beaucoup moins souvent. Cela facilite la collaboration et rend le processus de retour aux versions prÃ©cÃ©dentes des documents beaucoup plus simple. En gÃ©nÃ©ral, nous nâ€™envoyons des modifications sur GitHub que lorsque nous sommes satisfaits que nos collaborateurs (ou le reste du monde) puissent voir notre travail. Cependant, cela dÃ©pend entiÃ¨rement de vous, du projet (et des personnes avec lesquelles vous travaillez) et de vos prioritÃ©s dans lâ€™utilisation de Git.\nSi vous ne voulez pas suivre un fichier dans votre dÃ©pÃ´t (peut-Ãªtre sâ€™agit-il de fichiers trop volumineux ou transitoires), vous pouvez faire en sorte que Git ignore le fichier en lâ€™ajoutant Ã  la balise .gitignore pour quâ€™il soit ignorÃ© par Git. Sur RStudio, dans le panneau git, vous pouvez faire un clic droit sur le nom du fichier Ã  exclure et sÃ©lectionner â€˜Ignoreâ€¦â€™\n\n\n\n\n\n\n\nFigureÂ 7.56\n\n\n\n\nCela ajoutera le nom du fichier Ã  la base de donnÃ©es .gitignore fichier. Si vous souhaitez ignorer plusieurs fichiers ou un type de fichier particulier, vous pouvez Ã©galement inclure des caractÃ¨res gÃ©nÃ©riques dans la commande .gitignore dans le fichier. Par exemple, pour ignorer tous les fichiers png vous pouvez inclure lâ€™expression *.png dans votre .gitignore et enregistrer.\nSi tout va de travers et que vous finissez par dÃ©truire complÃ¨tement votre dÃ©pÃ´t Git, ne dÃ©sespÃ©rez pas (nous sommes tous passÃ©s par lÃ  !). Tant que votre dÃ©pÃ´t GitHub est bon, tout ce que vous avez Ã  faire est de supprimer le rÃ©pertoire du projet en question sur votre ordinateur, de crÃ©er un nouveau projet RStudio et de le lier Ã  votre dÃ©pÃ´t GitHub distant en utilisant lâ€™option 2 (-Section 7.5.3). Une fois que vous avez clonÃ© le dÃ©pÃ´t distant, vous devriez Ãªtre prÃªt Ã  partir.",
    "crumbs": [
      "DonnÃ©es",
      "Utiliser R",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>ContrÃ´le de version avec Git et GitHub</span>"
    ]
  },
  {
    "objectID": "07-github.html#sec-resources",
    "href": "07-github.html#sec-resources",
    "title": "7Â  ContrÃ´le de version avec Git et GitHub",
    "section": "\n7.10 Autres ressources",
    "text": "7.10 Autres ressources\nIl existe de nombreux guides en ligne pour en savoir plus sur git et GitHub et, comme pour tout logiciel open source, il existe une vaste communautÃ© qui peut Ãªtre dâ€™une grande aide :\n\nLe guide de la British Ecological Society sur Code reproductible\nLes guides guides GitHub\nLe laboratoire scientifique de Mozilla Guide GitHub pour la collaboration sur les projets ouverts\nJenny Bryanâ€™s Joyeux Git et GitHub . Nous avons empruntÃ© lâ€™idÃ©e (mais avec un contenu diffÃ©rent) de RStudio dâ€™abord, RStudio ensuite dans la section â€œMise en place dâ€™un projet Ã  version contrÃ´lÃ©e dans RStudioâ€.\nLâ€™article de Melanie Frazier GitHub : Un guide du dÃ©butant pour remonter le temps (et rÃ©parer les erreurs) . Nous avons suivi cette structure (avec des modifications et un contenu diffÃ©rent) dans la section â€œRevenir sur les modificationsâ€.\nSi vous avez fait quelque chose de terriblement mauvais et que vous ne savez pas comment le rÃ©parer, essayez Oh Shit, Git ou si vous Ãªtes facilement offensÃ© Dangit, Git\n\nCe ne sont que quelques exemples, il vous suffit de faire une recherche sur â€œcontrÃ´le de version avec git et GitHubâ€ pour voir Ã  quel point la communautÃ© autour de ces projets open source est importante et combien de ressources gratuites sont disponibles pour que vous deveniez un expert en contrÃ´le de version.",
    "crumbs": [
      "DonnÃ©es",
      "Utiliser R",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>ContrÃ´le de version avec Git et GitHub</span>"
    ]
  },
  {
    "objectID": "07-github.html#git_practical",
    "href": "07-github.html#git_practical",
    "title": "7Â  ContrÃ´le de version avec Git et GitHub",
    "section": "\n7.11 Pratique",
    "text": "7.11 Pratique\n\n7.11.1 Contexte\nNous allons configurer Rstudio pour quâ€™il fonctionne avec notre compte github, puis nous crÃ©erons un nouveau projet et commencerons Ã  utiliser github. Pour avoir des donnÃ©es, je suggÃ¨re dâ€™utiliser lâ€™outil gÃ©nial palmerpenguins dataset ğŸ§.\n\n7.11.2 Informations sur les donnÃ©es\nCes donnÃ©es ont Ã©tÃ© collectÃ©es et partagÃ©es par Dr.Â Kristen Gorman et Station Palmer, Antarctique LTER.\nLâ€™ensemble a Ã©tÃ© conÃ§u par les Drs Allison Horst et Alison Hill. site officiel.\nLe paquet palmerpenguins comporte deux ensembles de donnÃ©es.\n\nlibrary(palmerpenguins)\n\nLâ€™ensemble de donnÃ©es penguins est une version simplifiÃ©e des donnÃ©es brutes ; voir ?penguins pour plus dâ€™informations :\n\nhead(penguins)\n\n# A tibble: 6 Ã— 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Adelie  Torgersen           39.1          18.7               181        3750\n2 Adelie  Torgersen           39.5          17.4               186        3800\n3 Adelie  Torgersen           40.3          18                 195        3250\n4 Adelie  Torgersen           NA            NA                  NA          NA\n5 Adelie  Torgersen           36.7          19.3               193        3450\n6 Adelie  Torgersen           39.3          20.6               190        3650\n# â„¹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\nLâ€™autre jeu de donnÃ©es penguins_raw contient les donnÃ©es brutes ; voir ?penguins_raw pour plus dâ€™informations :\n\nhead(penguins_raw)\n\n# A tibble: 6 Ã— 17\n  studyName `Sample Number` Species          Region Island Stage `Individual ID`\n  &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;          \n1 PAL0708                 1 Adelie Penguin â€¦ Anvers Torgeâ€¦ Adulâ€¦ N1A1           \n2 PAL0708                 2 Adelie Penguin â€¦ Anvers Torgeâ€¦ Adulâ€¦ N1A2           \n3 PAL0708                 3 Adelie Penguin â€¦ Anvers Torgeâ€¦ Adulâ€¦ N2A1           \n4 PAL0708                 4 Adelie Penguin â€¦ Anvers Torgeâ€¦ Adulâ€¦ N2A2           \n5 PAL0708                 5 Adelie Penguin â€¦ Anvers Torgeâ€¦ Adulâ€¦ N3A1           \n6 PAL0708                 6 Adelie Penguin â€¦ Anvers Torgeâ€¦ Adulâ€¦ N3A2           \n# â„¹ 10 more variables: `Clutch Completion` &lt;chr&gt;, `Date Egg` &lt;date&gt;,\n#   `Culmen Length (mm)` &lt;dbl&gt;, `Culmen Depth (mm)` &lt;dbl&gt;,\n#   `Flipper Length (mm)` &lt;dbl&gt;, `Body Mass (g)` &lt;dbl&gt;, Sex &lt;chr&gt;,\n#   `Delta 15 N (o/oo)` &lt;dbl&gt;, `Delta 13 C (o/oo)` &lt;dbl&gt;, Comments &lt;chr&gt;\n\n\nPour cet exercice, nous allons utiliser lâ€™outil penguins jeu de donnÃ©es.\n\n7.11.3 Questions\n1) CrÃ©er un compte github si ce nâ€™est pas encore fait.\n2) Configurez Rstudio avec votre compte github en utilisant lâ€™option usethis paquet.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nusethis::git_sitrep()\nusethis::use_git_config(\n  user.name = \"your_username\",\n  user.email = \"your_email@address.com\"\n)\n\n\n\n\n3) CrÃ©ez et stockez votre jeton dâ€™autorisation personnel GITHUB\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nusethis::create_github_token()\ngitcreds::gitcreds_set()\n\n\n\n\n4) CrÃ©er un nouveau projet R Markdown, lâ€™initialiser pour git, et crÃ©er un nouveau dÃ©pÃ´t git\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n#create R project\nusethis::use_git()\n\n#restart R\nusethis::use_github()\nusethis::git_vaccinate()\n\n\n\n\n5) CrÃ©ez un nouveau document Rmarkdown dans votre projet. Sauvegardez ensuite le fichier et mettez-le en scÃ¨ne.\n6) CrÃ©er un nouveau commit incluant le nouveau fichier et le pousser sur github (VÃ©rifier sur github que cela fonctionne).\n7) Modifiez le fichier. Supprimez tout ce qui se trouve aprÃ¨s la ligne 12. Ajoutez un nouveau titre de section, un texte simple et un texte en caractÃ¨res gras. Puis tricotez et compilez.\n8) Faire un nouveau commit (avec un message significatif), et pousser sur github.\n9) CrÃ©ez une nouvelle branche, et ajoutez une nouvelle section au fichier rmarkdown dans cette branche. Ce que vous voulez. Je suggÃ©rerais un graphique des donnÃ©es.\n10) CrÃ©er un commit et le pousser sur la branche.\n11) Sur github, crÃ©er une pull request pour fusionner les 2 branches diffÃ©rentes.\n12) VÃ©rifier et accepter la pull request pour fusionner les 2 branches.\nVous avez utilisÃ© avec succÃ¨s tous les outils essentiels de git ğŸ‰ . Vous Ãªtes prÃªt Ã  explorer ğŸ•µï¸ et dÃ©couvrir sa puissance ğŸ’ª\n\n\n\n\nHappy git(hub)-ing\n\n\n\n\n7.11.4 Solution\n2)\n\nusethis::git_sitrep()\nusethis::use_git_config(\n  user.name = \"your_username\",\n  user.email = \"your_email@address.com\"\n)\n\n3)\n\nusethis::create_github_token()\ngitcreds::gitcreds_set()\n\n4)\n\n#create R project\nusethis::use_git()\n\n#restart R\nusethis::use_github()\nusethis::git_vaccinate()",
    "crumbs": [
      "DonnÃ©es",
      "Utiliser R",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>ContrÃ´le de version avec Git et GitHub</span>"
    ]
  },
  {
    "objectID": "25-puissance.html",
    "href": "25-puissance.html",
    "title": "\n8Â  Analyse de puissance avec R et G*Power\n",
    "section": "",
    "text": "8.1 La thÃ©orie",
    "crumbs": [
      "DonnÃ©es",
      "Principes de statistique",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>Analyse de puissance avec R et G\\*Power</span>"
    ]
  },
  {
    "objectID": "25-puissance.html#la-thÃ©orie",
    "href": "25-puissance.html#la-thÃ©orie",
    "title": "\n8Â  Analyse de puissance avec R et G*Power\n",
    "section": "",
    "text": "8.1.1 Quâ€™est-ce que la puissance?\nLa puissance est la probabilitÃ© de rejeter lâ€™hypothÃ¨se nulle quand elle est fausse.\n\n8.1.2 Pourquoi faire une analyse de puissance?\nÃ‰valuer lâ€™Ã©vidence\nLâ€™analyse de puissance effectuÃ©e aprÃ¨s avoir acceptÃ© une hypothÃ¨se nulle permet de calculer la probabilitÃ© que lâ€™hypothÃ¨se nulle soit rejetÃ©e si elle Ã©tait fausse et que la taille dâ€™effet Ã©tait dâ€™une valeur donnÃ©e. Ce type dâ€™analyse a posteriori est trÃ¨s commun.\nPlanifier de meilleures expÃ©riences\nLâ€™analyse de puissance effectuÃ©e avant de rÃ©aliser une expÃ©rience (le plus souvent aprÃ¨s une expÃ©rience prÃ©liminaire cependant), permet de dÃ©terminer le nombre dâ€™observations nÃ©cessaires pour dÃ©tecter un effet dâ€™une taille donnÃ©e Ã  un niveau fixe de probabilitÃ© (la puissance). Ce type dâ€™analyse a priori devrait Ãªtre rÃ©alisÃ© plus souvent.\nEstimer la â€œlimite de dÃ©tectionâ€ statistique\nLâ€™effort dâ€™Ã©chantillonnage est souvent dÃ©terminÃ© Ã  lâ€™avance (par exemple lorsque vous hÃ©ritez de donnÃ©es rÃ©coltÃ©es par quelquâ€™un dâ€™autre), ou trÃ¨s sÃ©vÃ¨rement limitÃ© (lorsque les contraintes logistiques prÃ©valent). Que ce soit a priori ou a posteriori lâ€™analyse de puissance vous permet dâ€™estimer, pour un effort dâ€™Ã©chantillonnage donnÃ© et un niveau de puissance fixe, quelle est la taille minimale de lâ€™effet qui peut Ãªtre dÃ©tectÃ© (comme Ã©tant statistiquement significatif).\n\n8.1.3 Facteurs qui affectent la puissance\nIl y a 3 facteurs qui affectent la puissance dâ€™un test statistique.\nLe critÃ¨re de dÃ©cision\nLa puissance dÃ©pend de \\(\\alpha\\), le seuil de probabilitÃ© auquel on rejette lâ€™hypothÃ¨se nulle. Si ce seuil est trÃ¨s strict (i.e. si \\(\\alpha\\) est fixÃ© Ã  une valeur trÃ¨s basse, comme 0.1% ou p = 0.001), alors la puissance sera plus faible que si le seuil Ã©tait moins strict.\nLa taille de lâ€™Ã©chantillon\nPlus lâ€™Ã©chantillon est grand, plus la puissance est Ã©levÃ©e. La capacitÃ© dâ€™un test Ã  dÃ©tecter de petites diffÃ©rences comme Ã©tant statistiquement significatives augmente avec une augmentation du nombre dâ€™observations.\nLa taille dâ€™effet\nPlus la taille dâ€™effet est grande, plus un test a de puissance. Pour un Ã©chantillon de taille fixe, la capacitÃ© dâ€™un test Ã  dÃ©tecter un effet comme Ã©tant statistiquement significatif est plus Ã©levÃ©e si lâ€™effet est grand que sâ€™il est petit. La taille dâ€™effet est en fait une mesure du degrÃ© de faussetÃ© de lâ€™hypothÃ¨se nulle.",
    "crumbs": [
      "DonnÃ©es",
      "Principes de statistique",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>Analyse de puissance avec R et G\\*Power</span>"
    ]
  },
  {
    "objectID": "25-puissance.html#quest-ce-que-gpower",
    "href": "25-puissance.html#quest-ce-que-gpower",
    "title": "\n8Â  Analyse de puissance avec R et G*Power\n",
    "section": "\n8.2 Quâ€™est ce que G*Power?",
    "text": "8.2 Quâ€™est ce que G*Power?\nG*Power est un programme gratuit, dÃ©veloppÃ© par des psychologues de lâ€™UniversitÃ© de Dusseldorf en Allemagne. Le programme existe en version Mac et Windows. Il peut cependant Ãªtre utilisÃ© sous linux via Wine ou une machine virtuelle.\nG*Power vous permettra dâ€™effectuer une analyse de puissance pour la majoritÃ© des tests que nous verrons au cours de la session sans avoir Ã  effectuer des calculs complexes ou farfouiller dans des tableaux ou des figures dÃ©crivant des distributions ou des courbes de puissance. G*power est vraiment un outil trÃ¨s utile que vous devrez maÃ®triser.\nIl est possible de faire toutes les analyses de G*power avec R, mais cela est un peu plus complexes et nÃ©cessite un peu plus de code et donc une meilleure comprÃ©hension du processus. Dans les cas les plus simple le code R est aussi fourni.\n\n\n\n\n\n\nExercice\n\n\n\nTÃ©lÃ©chargez le programme ici et installez-le sur votre ordi et votre station de travail au laboratoire (si ce nâ€™est dÃ©jÃ  fait).",
    "crumbs": [
      "DonnÃ©es",
      "Principes de statistique",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>Analyse de puissance avec R et G\\*Power</span>"
    ]
  },
  {
    "objectID": "25-puissance.html#comment-utiliser-gpower",
    "href": "25-puissance.html#comment-utiliser-gpower",
    "title": "\n8Â  Analyse de puissance avec R et G*Power\n",
    "section": "\n8.3 Comment utiliser G*Power",
    "text": "8.3 Comment utiliser G*Power\n\n8.3.1 Principe gÃ©nÃ©ral\nLâ€™utilisation de G*Power implique gÃ©nÃ©ralement 3 Ã©tapes:\n\nChoisir le test appropriÃ©\nChoisir lâ€™un des 5 types dâ€™analyses de puissance disponibles\nInscrire les valeurs des paramÃ¨tres requis et cliquer sur Calculate\n\n\n8.3.2 Types dâ€™analyses de puissance disponibles\nA priori\nCalcule lâ€™effectif requis pour une valeur de \\(\\alpha\\), \\(\\beta\\) et de taille dâ€™effet donnÃ©e. Ce type dâ€™analyse est utile Ã  lâ€™Ã©tape de planification des expÃ©riences.\nCompromis\nCalcule \\(\\boldsymbol{\\alpha}\\) et \\(\\boldsymbol{\\beta}\\) pour un rapport \\(\\beta / \\alpha\\) donnÃ©, un effectif fixe, et une taille dâ€™effet donnÃ©e. Ce type dâ€™analyse est plus rarement utilisÃ© (je ne lâ€™ai jamais fait), mais peut Ãªtre utile lorsque le rapport \\(\\beta / \\alpha\\) est dâ€™intÃ©rÃªt, par exemple lorsque le coÃ»t dâ€™une erreur de type I et de type II peut Ãªtre quantifiÃ©.\nCritÃ¨re\nCalcule \\(\\boldsymbol{\\alpha}\\) pour \\(\\beta\\), effectif et taille dâ€™effet donnÃ©. En pratique, je vois peu dâ€™utilitÃ© pour ce type de calcul. Contactez-moi si vous en voyez une!\nPost-hoc\nCalcule la puissance (1 - \\(\\boldsymbol{\\beta}\\)) pour \\(\\alpha\\), une taille dâ€™effet et un effectif donnÃ©. TrÃ¨s utilisÃ©e pour interprÃ©ter les rÃ©sultats dâ€™une analyse statistique non-significative, mais seulement si lâ€™on utilise une taille dâ€™effet biologiquement significative (et non la taille dâ€™effet observÃ©e). Peu pertinente lorsque le test est significatif.\nSensitivitÃ©\nCalcule la taille dâ€™effet dÃ©tectable pour une valeur dâ€™\\(\\alpha\\), \\(\\beta\\) et un effectif donnÃ©. TrÃ¨s utile Ã©galement au stade de planification des expÃ©riences.\n\n8.3.3 Comment calculer la taille dâ€™effet ?\nG*Power permet de faire une analyse de puissance pour de nombreux tests statistiques.\nLâ€™indice de la taille dâ€™effet qui est utilisÃ© par G*Power pour les calculs dÃ©pend du test. Notez que dâ€™autres logiciels peuvent utiliser des indices diffÃ©rents et il est important de vÃ©rifier que lâ€™indice que lâ€™on utilise est celui qui convient. G*Power vous facilite la tÃ¢che et permet de calculer la taille dâ€™effet en inscrivant seulement les valeurs pertinentes dans la fenÃªtre de calcul. Le tableau suivant donne les indices utilisÃ©s par G*Power pour les diffÃ©rents tests.\n\n\n\n\n\n\n\nTest\nTaille dâ€™effet\nFormule\n\n\n\ntest de t sur des moyennes\nd\n\\(d = \\frac{|\\mu_1 - \\mu_2|}{\\sqrt{({s_1}^2 + {s_2}^2)/2}}\\)\n\n\ntest de t pour des corrÃ©lations\nr\n\n\n\nautres tests de t\nd\n\\(d = \\frac{\\mu}{\\sigma}\\)\n\n\ntest F (ANOVA)\nf\n\\(f = \\frac{\\frac{\\sqrt{\\sum_{i=1}^k (\\mu_i - \\mu)^2}}{k}}{\\sigma}\\)\n\n\nautres test F\n\\(f^2\\)\n\\(f^2 = \\frac{{R_p}^2}{1-{R_p}^2}\\)\n\n\n\n\n\n\\({R_p}\\) est le coefficient de corrÃ©lation partiel\n\n\ntest Chi-carrÃ©\nw\n\\(w = \\sqrt{ \\sum_{i=1}^m \\frac{(p_{0i} - p_{1i})^2 }{ p_{0i}} }\\)\n\n\n\n\n\n\\(p_{0i}\\) \\(p_{1i}\\) sont les proportions de la catÃ©gorie i prÃ©dites par lâ€™hypothÃ¨se nulle et alternative respectivement",
    "crumbs": [
      "DonnÃ©es",
      "Principes de statistique",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>Analyse de puissance avec R et G\\*Power</span>"
    ]
  },
  {
    "objectID": "25-puissance.html#puissance-pour-un-test-de-t-comparant-deux-moyennes",
    "href": "25-puissance.html#puissance-pour-un-test-de-t-comparant-deux-moyennes",
    "title": "\n8Â  Analyse de puissance avec R et G*Power\n",
    "section": "\n8.4 Puissance pour un test de t comparant deux moyennes",
    "text": "8.4 Puissance pour un test de t comparant deux moyennes\n\n\n\n\n\n\nImportant\n\n\n\nLâ€™ensemble des analyses de puissance dÃ©crites aprÃ¨s peuvent Ãªtre rÃ©alisÃ© avec 2 fonctions dans R.\n\n\npwr.t.test(): lorsque les tailles dâ€™Ã©chantillons sont identiques\n\npwr.t2n.test(): lorsque les Ã©chantillons ont des tailles diffÃ©rentes\n\n\n\nLâ€™objectif de cette sÃ©ance de laboratoire est de vous familiariser avec G*Power et de vous aider Ã  comprendre comment les quatre paramÃ¨tres des analyses de puissance (\\(\\alpha\\), \\(\\beta\\), effectif et taille dâ€™effet) sont reliÃ©s entre eux. On examinera seulement lâ€™un des nombreux tests : le test de t permettant de comparer deux moyennes indÃ©pendantes. Câ€™est le test le plus communÃ©ment utilisÃ© par les biologistes, vous lâ€™avez tous dÃ©jÃ  utilisÃ©, et il conviendra trÃ¨s bien pour les besoins de la cause. Ce que vous apprendrez aujourdâ€™hui sâ€™appliquera Ã  toutes les autres analyses de puissance que vous effectuerez Ã  lâ€™avenir.\nJaynie Stephenson a Ã©tudiÃ© la productivitÃ© des ruisseaux de la rÃ©gion dâ€™Ottawa. Elle a, entre autres, quantifiÃ© la biomasse des poissons dans 18 ruisseaux sur le Bouclier Canadien dâ€™une part, et dans 18 autres ruisseaux de la vallÃ©e de la riviÃ¨re des Outaouais et de la riviÃ¨re Rideau dâ€™autre part. Elle a observÃ© une biomasse plus faible dans les ruisseaux de la vallÃ©e (2.64 \\(g/m^2\\), Ã©cart-type=3.28) que dans ceux du Bouclier (3.31 \\(g/m^2\\), Ã©cart-type=2.79). En faisant un test de t pour Ã©prouver lâ€™hypothÃ¨se nulle que la biomasse des poissons est la mÃªme dans les deux rÃ©gions, elle obtient:\nPooled-Variance Two-Sample t-Test\nt = -0.5746, df = 34, p-value = 0.5693\nElle accepte lâ€™hypothÃ¨se nulle (puisque p est plus Ã©levÃ© que 0.05) conclue donc que la biomasse moyenne des poissons est la mÃªme dans ces deux rÃ©gions.\n\n8.4.1 Analyse post-hoc - Calculer la puissance du test\nCompte tenu des valeurs des moyennes observÃ©es et de leur Ã©cart- type, on peut utiliser G*Power pour calculer la puissance du test de t bilatÃ©ral pour deux moyennes indÃ©pendantes et pour la taille dâ€™effet (i.e.Â la diffÃ©rence entre la biomasse entre les deux rÃ©gions, pondÃ©rÃ©e par les Ã©carts-type) Ã  \\(\\alpha\\) = 0.05.\nDÃ©marrer G*Power.\n\nÃ€ Test family, choisir: t tests\nÃ€ Statistical test, choisir: Means: Difference between two independent means (two groups)\nÃ€ Type of power analysis, choisir: Post hoc: Compute achieved power - given \\(\\alpha\\), sample size, and effect size\nDans Input Parameters,\n\n\nÃ  la boÃ®te Tail(s), choisir: Two,\nvÃ©rifier que \\(\\boldsymbol{\\alpha}\\) err prob est Ã©gal Ã  0.05\ninscrire 18 pour Sample size group 1 et 2\npour calculer la taille dâ€™effet (Effect size d), cliquer sur le bouton Determine =&gt;\n\n\n\nDans la fenÃªtre qui sâ€™ouvre Ã  droite, sÃ©lectionner \\(\\boldsymbol{n1 = n2}\\)\n\n\n\nentrer les moyennes (Mean group 1 et 2)\nentrer les Ã©carts types (SD \\(\\boldsymbol{\\sigma}\\) group 1 et 2)\ncliquer sur le bouton Calculate and transfer to main window\n\n\n\nCliquer sur le bouton Calculate dans la fenÃªtre principale et vous devriez obtenir ceci:\n\n\n\n\n\n\n\n\nFigureÂ 8.1: Analyse post-hoc avec la taille dâ€™effet estimÃ©e\n\n\n\n\nLa mÃªme analyse peut Ãªtre faites en utlisant R. Dâ€™abord, il faut calculer la taille dâ€™effet d pour un test de t comparant deux moyennes, puis utiliser la fonction pwr.t.test du paquet pwr ğŸ“¦. Le plus simple comme nous allons estimer la taille dâ€™effet d plusieurs fois et de crÃ©er une petite fonction qui estime d basÃ© sur les paramÃ¨tres nÃ©cessaires.\n\n# charger le paquet pwr\nlibrary(pwr)\n# dÃ©finir une fonction pour d\nd &lt;- function(u1, u2, sd1, sd2) {\n  abs(u1 - u2) / sqrt((sd1^2 + sd2^2) / 2)\n}\n\n# analyse de puissance\n\nd_cohen &lt;- d(u1 = 2.64, sd1 = 3.28, u2 = 3.31, sd2 = 2.79)\n\npwr.t.test(\n  n = 18, d = d_cohen, sig.level = 0.05,\n  type = \"two.sample\"\n)\n\n\n     Two-sample t test power calculation \n\n              n = 18\n              d = 0.220042\n      sig.level = 0.05\n          power = 0.09833902\n    alternative = two.sided\n\nNOTE: n is number in *each* group\n\n# graphique comme g*Power\nx &lt;- seq(-4, 4, length = 200)\ny0 &lt;- dt(x, 34)\ny1 &lt;- dt(x, 34, ncp = d_cohen * sqrt(36) / 2)\nplot(x, y0, type = \"l\", col = \"red\", lwd = 2)\nqc &lt;- qt(0.025, 34)\nabline(v = qc, col = \"green\")\nabline(v = -qc, col = \"green\")\nlines(x, y1, type = \"l\", col = \"blue\", lwd = 2)\n\n# l'erreur de type 2 correspond Ã  la zone bleue\npolygon(\n  c(x[x &lt;= -qc], -qc), c(y1[x &lt;= -qc], 0),\n  col = rgb(red = 0, green = 0.2, blue = 1, alpha = 0.5)\n)\npolygon(\n  c(-qc, x[x &gt;= -qc]), c(0, y0[x &gt;= -qc]),\n  col = rgb(red = 1, green = 0, blue = 0.2, alpha = 0.5)\n)\npolygon(\n  c(x[x &lt;= qc], qc), c(y0[x &lt;= qc], 0),\n  col = rgb(red = 1, green = 0, blue = 0.2, alpha = 0.5)\n)\n\n\n\n\n\n\nFigureÂ 8.2: Graphique de lâ€™analyse de puissance dans R\n\n\n\n\nVoici le code pour faire la figure avec ggplot.\n\nqc &lt;- qt(0.025, 34)\nncp &lt;- d_cohen * sqrt(36) / 2\ndat &lt;- data.frame(\n  x = seq(-4, 4, length = 200),\n  y0 = dt(x, (n - 1) * 2),\n  y1 = dt(x, (n - 1) * 2, ncp = ncp)\n) %&gt;%\n  mutate(\n    beta = ifelse(x &lt;= -qc, y1, 0),\n    alpha = ifelse(x &lt;= qc | x &gt;= -qc, y0, 0)\n  )\n\nggplot(dat, aes(x = x)) +\n  geom_line(aes(y = y0), color = \"red\") +\n  geom_line(aes(y = y1), color = \"blue\") +\n  geom_vline(xintercept = qcl, color = \"green\") +\n  geom_area(\n    aes(x = x, y = beta),\n    fill = rgb(red = 0, green = 0.2, blue = 1, alpha = 0.5)\n  ) +\n  geom_area(\n    aes(x = x, y = alpha),\n    fill = rgb(red = 1, green = 0, blue = 0.2, alpha = 0.5)\n  ) +\n  theme_classic() +\n  ylab(\"dt(x)\")\n\nÃ‰tudions un peu la figure FigureÂ 8.1.\n\nLa courbe de gauche, en rouge, correspond Ã  la distribution de la statistique t si \\(\\boldsymbol{H_0}\\) est vraie (i.e si les deux moyennes Ã©taient Ã©gales) compte tenu de lâ€™effectif (18 dans chaque rÃ©gion) et des Ã©carts- types observÃ©s.\nLes lignes verticales vertes correspondent aux valeurs critiques de t pour \\(\\boldsymbol{\\alpha = 0.05}\\) et un effectif total de 36 (2x18).\nLes rÃ©gions ombrÃ©es en rose correspondent aux zones de rejet de \\(\\boldsymbol{H_0}\\) (\\({\\alpha/2}\\)) . Si Jaynie avait obtenu une valeur de t en dehors de lâ€™intervalle dÃ©limitÃ© par les valeurs critiques allant de -2.03224 Ã  2.03224, alors elle aurait rejetÃ© \\(H_0\\), lâ€™hypothÃ¨se nulle dâ€™Ã©galitÃ© des deux moyennes. En fait, elle a obtenu une valeur de t Ã©gale Ã  -0.5746 et conclu que la biomasse est la mÃªme dans les deux rÃ©gions.\nLa courbe de droite, en bleu, correspond Ã  la distribution de la statistique t si \\(\\boldsymbol{H_1}\\) est vraie (ici \\(H_1\\) correspond Ã  une diffÃ©rence de biomasse entre les deux rÃ©gions de \\(3.33-2.64=0.69g/m^2\\), compte tenu des Ã©carts-types observÃ©s). Cette distribution correspond Ã  ce quâ€™on devrait sâ€™attendre Ã  observer si \\(H_1\\) Ã©tait vraie et que lâ€™on rÃ©pÃ©tait un grand nombre de fois les mesures dans des Ã©chantillons alÃ©atoires de 18 ruisseaux des deux rÃ©gions en calculant la statistique t Ã  chaque fois. En moyenne, on observerait une valeur de t dâ€™environ 0.6.\nNotez que la distribution de droite chevauche considÃ©rablement celle de gauche, et une bonne partie de la surface sous la courbe de droite se retrouve Ã  lâ€™intÃ©rieur de lâ€™intervalle dâ€™acceptation de \\(H_0\\), dÃ©limitÃ© par les deux lignes vertes et allant de -2.03224 Ã  2.03224. Cette proportion, correspondant Ã  la partie ombrÃ©e en bleu sous la courbe de droite et dÃ©notÃ© par \\(\\beta\\) correspond au risque dâ€™erreur de type II qui est dâ€™accepter \\(H_0\\) quand \\(H_1\\) est vraie.\nLa puissance est simplement \\(\\boldsymbol{1-\\beta}\\), et est ici de 0.098339 (RÃ©sultats du test dâ€™estimation de puissance) . Donc, si la biomasse diffÃ©rait de 0.69\\(g/m^2\\) entre les deux rÃ©gions, Jaynie nâ€™avait que 9.8% des chances dâ€™Ãªtre capable de dÃ©tecter une diffÃ©rence statistiquement significative Ã  \\(\\alpha=5%\\) en Ã©chantillonnant 18 ruisseaux de chaque rÃ©gion.\n\nRÃ©capitulons: La diffÃ©rence de biomasse entre les deux rÃ©gions nâ€™est pas statistiquement significative dâ€™aprÃ¨s le test de t. Câ€™est donc que cette diffÃ©rence est relativement petite compte tenu de la prÃ©cision des mesures. Il nâ€™est donc pas trÃ¨s surprenant que la puissance, i.e.Â la probabilitÃ© de dÃ©tecter une diffÃ©rence significative, soit faible. Toute cette analyse ne nous informe pas beaucoup.\nUne analyse de puissance post hoc avec la taille dâ€™effet observÃ© nâ€™est pas trÃ¨s utile. On la fera plutÃ´t pour une taille dâ€™effet autre que celle observÃ©e quand \\(H_0\\) est acceptÃ©e. Quelle taille dâ€™effet utiliser? Câ€™est la biologie du systÃ¨me Ã©tudiÃ© qui peut nous guider. Par exemple, en ce qui concerne la biomasse des poissons, on pourrait sâ€™attendre Ã  ce quâ€™une diffÃ©rence de biomasse du simple au double (disons de 2.64 Ã  5.28 \\(g/m^2\\)) ait des consÃ©quences Ã©cologiques. On voudrait sâ€™assurer que Jaynie avait de bonnes chances de dÃ©tecter une diffÃ©rence aussi grande que celle-lÃ  avant dâ€™accepter ses conclusions que la biomasse est la mÃªme entre les deux rÃ©gions. Quelles Ã©taient les chances de Jaynie de dÃ©tecter une diffÃ©rence de 2.64 \\(g/m^2\\) entre les deux rÃ©gions? G*Power peut nous le dire.\n\n\n\n\n\n\nExercice\n\n\n\nChanger la moyenne du groupe 2 Ã  5.28, recalculer la taille dâ€™effet, et cliquer sur Calculate pour obtenir FigureÂ 8.3.\n\n\n\n\n\n\n\n\n\nFigureÂ 8.3: Analyse post-hoc avec une taille dâ€™effet diffÃ©rente\n\n\n\n\n\npwr.t.test(\n  n = 18, d = d(u1 = 2.64, sd1 = 3.28, u2 = 5.28, sd2 = 2.79),\n  sig.level = 0.05, type = \"two.sample\"\n)\n\n\n     Two-sample t test power calculation \n\n              n = 18\n              d = 0.8670313\n      sig.level = 0.05\n          power = 0.7146763\n    alternative = two.sided\n\nNOTE: n is number in *each* group\n\n\n\n\n\n\n\n\n\nFigureÂ 8.4\n\n\n\n\nLa puissance est de 0.71, donc Jaynie avait une chance raisonnable (71%) de dÃ©tecter une diffÃ©rence du simple au double avec 18 ruisseaux dans chaque rÃ©gion.\nNotez que cette analyse de puissance post hoc pour une taille dâ€™effet jugÃ©e biologiquement significative est bien plus informative que lâ€™analyse prÃ©cÃ©dente pour la taille dâ€™effet observÃ©e (qui est celle effectuÃ©e par dÃ©faut par bien des nÃ©ophytes et de trop nombreux logiciels qui essaient de penser pour nous). En effet, Jaynie nâ€™a pu dÃ©tecter de diffÃ©rences significatives entre les deux rÃ©gions. Cela pourrait Ãªtre pour deux raisons: soit quâ€™il nâ€™y a pas de diffÃ©rences entre les rÃ©gions, ou alors parce que la prÃ©cision des mesures est si faible et lâ€™effort dâ€™Ã©chantillonnage si limitÃ© quâ€™il Ã©tait trÃ¨s peu probable de dÃ©tecter mÃªme dâ€™Ã©normes diffÃ©rences. La deuxiÃ¨me analyse de puissance permet dâ€™Ã©liminer cette seconde possibilitÃ© puisque Jaynie avait 71% des chances de dÃ©tecter une diffÃ©rence du simple au double.\n\n8.4.2 Analyse Ã  priori - Calculer la taille de lâ€™effectif Ã  Ã©chantillonner\nSupposons quâ€™on puisse dÃ©fendre la position quâ€™une diffÃ©rence de biomasse observÃ©e par Jaynie entre les deux rÃ©gions, \\(3.31- 2.64=0.67g/m^2\\), soit Ã©cologiquement significative. On devrait donc planifier la prochaine saison dâ€™Ã©chantillonnage de maniÃ¨re Ã  avoir de bonnes chances de dÃ©tecter une diffÃ©rence de cette taille. Combien de ruisseaux Jaynie devrait-elle Ã©chantillonner pour avoir 80% des chances de la dÃ©tecter (compte tenu de la variabilitÃ© observÃ©e)?\n\n\n\n\n\n\nExercice\n\n\n\nChanger le type dâ€™analyse de puissance dans G*Power Ã  A priori: Compute sample size - given \\(\\alpha\\), power, and effect size. Assurez-vous que les valeurs pour les moyennes et les Ã©carts-type soient celles quâ€™a obtenu Jaynie, recalculez la taille de lâ€™effet, et inscrivez 0.8 pour la puissance FigureÂ 8.5.\n\n\n\n\n\n\n\n\n\nFigureÂ 8.5: Analyse Ã  priori\n\n\n\n\n\npwr.t.test(\n  power = 0.8, d = d(u1 = 2.64, sd1 = 3.28, u2 = 3.31, sd2 = 2.79),\n  sig.level = 0.05, type = \"two.sample\"\n)\n\n\n     Two-sample t test power calculation \n\n              n = 325.1723\n              d = 0.220042\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided\n\nNOTE: n is number in *each* group\n\n\nOuch! Il faudrait Ã©chantillonner 326 ruisseaux dans chaque rÃ©gion! Cela coÃ»terait une fortune et exigerait de nombreuses Ã©quipes de travail. Sans cela, on ne pourrait Ã©chantillonner que quelques dizaines de ruisseaux, et il serait peu probable que lâ€™on puisse dÃ©tecter une si faible diffÃ©rence de biomasse entre les deux rÃ©gions. Ce serait vraisemblablement en vain et pourrait Ãªtre considÃ©rÃ© comme une perte de temps: pourquoi tant dâ€™efforts et de dÃ©penses si les chances de succÃ¨s sont si faibles.\nSi on refait le mÃªme calcul pour une puissance de 95%, on obtient 538 ruisseaux par rÃ©gion. Augmenter la puissance Ã§a demande plus dâ€™effort.\n\npwr.t.test(\n  power = 0.95, d = d(u1 = 2.64, sd1 = 3.28, u2 = 3.31, sd2 = 2.79),\n  sig.level = 0.05, type = \"two.sample\"\n)\n\n\n     Two-sample t test power calculation \n\n              n = 537.7286\n              d = 0.220042\n      sig.level = 0.05\n          power = 0.95\n    alternative = two.sided\n\nNOTE: n is number in *each* group\n\n\n\n8.4.3 Analyse de sensitivitÃ© - Calculer la taille dâ€™effet dÃ©tectable\nCompte tenu de la variabilitÃ© observÃ©e, dâ€™un effort dâ€™Ã©chantillonnage de 18 ruisseaux par rÃ©gion, et en conservant \\(\\alpha=0.05\\), quelle est la taille dâ€™effet que Jaynie pouvait dÃ©tecter avec 80% de chances (\\(\\beta=0.2\\)) ?\n\n\n\n\n\n\nExercice\n\n\n\nChangez le type dâ€™analyse dans G*Power Ã  Sensitivity: Compute required effect size - given \\(\\alpha\\), power, and sample size et assurez-vous que la taille des Ã©chantillons est de 18 dans chaque rÃ©gion.\n\n\n\n\n\n\n\n\n\nFigureÂ 8.6: Analyse de sensitivitÃ©\n\n\n\n\n\npwr.t.test(power = 0.8, n = 18,\n           sig.level = 0.05, type = \"two.sample\")\n\n\n     Two-sample t test power calculation \n\n              n = 18\n              d = 0.9612854\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided\n\nNOTE: n is number in *each* group\n\n\nLa taille dâ€™effet dÃ©tectable pour cette taille dâ€™Ã©chantillon, \\(\\alpha=0.05\\) et \\(\\beta=0.2\\) (ou une puissance de 80%) est de 0.961296.\n\n\n\n\n\n\nAvertissement\n\n\n\ncette valeur est lâ€™indice d de la taille dâ€™effet et est pondÃ©rÃ©e par la variabilitÃ© des mesures.\n\n\nDans ce cas ci, d est approximativement Ã©gal Ã  \\[ d = \\frac{| \\bar{X_1} \\bar{X_2} |} {\\sqrt{\\frac{{s_1}^2 +{s_2}^2}{2}}}\\] Pour convertir cette valeur de d sans unitÃ©s en une valeur de diffÃ©rence de biomasse dÃ©tectable (i.e \\(| \\bar{X_1} \\bar{X_2} |\\)), il suffit de multiplier d par le dÃ©nominateur de lâ€™Ã©quation. \\[\n| \\bar{X_1} \\bar{X_2} | = d * \\sqrt{\\frac{{s_1}^2 +{s_2}^2}{2}}\n\\] Dans R, on peut estimer cela avec:\n\npwr.t.test(\n  power = 0.8, n = 18, sig.level = 0.05,\n  type = \"two.sample\")$d * sqrt((3.28^2 + 2.79^2) / 2)\n\n[1] 2.926992\n\n\nDonc, avec 18 ruisseaux dans chaque rÃ©gion, pour \\(\\alpha=0.05\\) et \\(\\beta=0.2\\) (une puissance de 80%), Jaynie pouvait dÃ©tecter une diffÃ©rence de biomasse de 2.93\\(g/m^2\\) entre les rÃ©gions, un peu plus que du simple au double.",
    "crumbs": [
      "DonnÃ©es",
      "Principes de statistique",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>Analyse de puissance avec R et G\\*Power</span>"
    ]
  },
  {
    "objectID": "25-puissance.html#points-Ã -retenir",
    "href": "25-puissance.html#points-Ã -retenir",
    "title": "\n8Â  Analyse de puissance avec R et G*Power\n",
    "section": "\n8.5 Points Ã  retenir",
    "text": "8.5 Points Ã  retenir\n\nLâ€™analyse de puissance post hoc nâ€™est pertinente que lorsque lâ€™on a acceptÃ© lâ€™hypothÃ¨se nulle. Il est en effet impossible de faire une erreur de type II quand on rejette \\(H_0\\).\nAvec de trÃ¨s grands Ã©chantillons, on a une puissance quasi infinie et on peut dÃ©tecter statistiquement de trÃ¨s petites diffÃ©rences qui ne sont pas nÃ©cessairement biologiquement significatives.\nEn utilisant un critÃ¨re de signification plus strict (\\(\\alpha &lt; 0.05\\)) on diminue notre puissance.\nEn voulant maximiser la puissance, on augmente lâ€™effort requis, Ã  moins dâ€™utiliser une valeur critique plus libÃ©rale (\\(\\alpha&gt;0.05\\))\nLe choix de \\(\\beta\\) est quelque peu arbitraire. On considÃ¨re que \\(\\beta=0.2\\) (puissance de 80%) est relativement Ã©levÃ©.",
    "crumbs": [
      "DonnÃ©es",
      "Principes de statistique",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>Analyse de puissance avec R et G\\*Power</span>"
    ]
  },
  {
    "objectID": "31-reg_lin.html",
    "href": "31-reg_lin.html",
    "title": "\n9Â  CorrÃ©lation et rÃ©gression linÃ©aire simple\n",
    "section": "",
    "text": "9.1 Paquets R et donnÃ©es requises\nPour ce laboratoire vous aurez besoin de :\nIl ne faut pas oublier de charge les paquets avec library() (et de les installer au besoin avec install.packages()). Pour les donnÃ©es, il faut les charger et les assigner Ã  un objet R avec la fonction read.csv().\nlibrary(car)\nlibrary(lmtest)\nlibrary(boot)\nlibrary(ggplot2)\nlibrary(pwr)\nlibrary(performance)\n\nesturgeon &lt;- read.csv(\"data/sturgeon.csv\")",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>CorrÃ©lation et rÃ©gression linÃ©aire simple</span>"
    ]
  },
  {
    "objectID": "31-reg_lin.html#set-lm",
    "href": "31-reg_lin.html#set-lm",
    "title": "\n9Â  CorrÃ©lation et rÃ©gression linÃ©aire simple\n",
    "section": "",
    "text": "paquets R :\n\n\ncar ğŸ“¦\n\n\nlmtest ğŸ“¦\n\n\nboot ğŸ“¦\n\n\npwr ğŸ“¦\n\n\nggplot ğŸ“¦\n\n\n\nJeu de donnÃ©es :\n\nâ€œsturgeon.csvâ€\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nNotez que la ligne de code pour charger les donnÃ©es considÃ¨re que le fichier de donnÃ©es se trouve dans un dossier data au sein de votre rÃ©pertoire de travail. Si ce nâ€™est pas le cas veuillez ajuster la ligne de commande selon votre rÃ©pertoire de travail.",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>CorrÃ©lation et rÃ©gression linÃ©aire simple</span>"
    ]
  },
  {
    "objectID": "31-reg_lin.html#diagrammes-de-dispersion",
    "href": "31-reg_lin.html#diagrammes-de-dispersion",
    "title": "\n9Â  CorrÃ©lation et rÃ©gression linÃ©aire simple\n",
    "section": "\n9.2 Diagrammes de dispersion",
    "text": "9.2 Diagrammes de dispersion\nLes analyses de corrÃ©lation et de rÃ©gression devraient toujours commencer par un examen des donnÃ©es; câ€™est une Ã©tape critique qui sert Ã  Ã©valuer si ce type dâ€™analyse est appropriÃ© pour un ensemble de donnÃ©es. Supposons que nous voulons Ã©valuer si la longueur dâ€™esturgeons mÃ¢les dans la rÃ©gion de The Pas covarie avec leur poids. Pour rÃ©pondre Ã  cette question, regardons dâ€™abord la corrÃ©lation entre la longueur et le poids. Souvenez-vous quâ€™une des conditions dâ€™application de lâ€™analyse de corrÃ©lation est que la relation entre les deux variables est linÃ©aire. Pour Ã©valuer cela, commenÃ§ons par faire un diagramme de dispersion.\n\nLes donnÃ©es sur les esturgeons son disponibles dans le fichier sturgeon.csv. AprÃ¨s avoir chargÃ© les donnÃ©es en les assignant Ã  un objet esturgeon, faites un diagramme de dispersion avec une droite de rÃ©gression linÃ©aire et une courbe de Lowess de la longueur en fonction du poids.\n\n\nesturgeon &lt;- read.csv(\"data/sturgeon.csv\")\nstr(esturgeon)\n\n'data.frame':   186 obs. of  9 variables:\n $ fklngth : num  37 50.2 28.9 50.2 45.6 ...\n $ totlngth: num  40.7 54.1 31.3 53.1 49.5 ...\n $ drlngth : num  23.6 31.5 17.3 32.3 32.1 ...\n $ rdwght  : num  15.95 NA 6.49 NA 29.92 ...\n $ age     : int  11 24 7 23 20 23 20 7 23 19 ...\n $ girth   : num  40.5 53.5 31 52.5 50 54.2 48 28.5 44 39 ...\n $ sex     : chr  \"MALE\" \"FEMALE\" \"MALE\" \"FEMALE\" ...\n $ location: chr  \"THE_PAS\" \"THE_PAS\" \"THE_PAS\" \"THE_PAS\" ...\n $ year    : int  1978 1978 1978 1978 1978 1978 1978 1978 1978 1978 ...\n\n\n\nmongraph &lt;- ggplot(\n  data = esturgeon[!is.na(esturgeon$rdwght), ], # origine des donnÃ©es\n  aes(x = fklngth, y = rdwght)\n)\n# ReprÃ©sentez les donnÃ©es sous forme de Points, RÃ©gression linÃ©aire, \"Lowess\"\nmongraph &lt;- mongraph +\n  stat_smooth(method = lm, se = FALSE, color = \"green\") + # Ajoutez une rÃ©gression linÃ©aire, mais sans l'erreur-type (en vert)\n  stat_smooth(color = \"red\", se = FALSE) + # Ajoutez la \"lowess\" (en rouge)\n  geom_point() + # Ajoutez les donnÃ©es sous forme de points\n  labs(x = \"Longueur\", y = \"Poids\") # Modifiez les noms des axes pour rendre le graphique plus lisible\n\nmongraph # Affichez le graphique\n\n\n\n\n\n\nFigureÂ 9.1: Graphique du poids en fonction de la longueur des esturgeons.\n\n\n\n\n\n\n\nEst-ce que la dispersion des points suggÃ¨re une bonne corrÃ©lation entre les deux variables? Est-ce que la relation semble linÃ©aire?\n\nCe graphique suggÃ¨re une tendance plus curvilinÃ©aire que linÃ©aire. MalgrÃ© tout, il semble y avoir une forte corrÃ©lation entre les deux variables.\n\nRefaites le diagramme de dispersion avec des transformations logarithmiques sur les deux axes.\n\n\n# Appliquez une transformation log sur le graphique dÃ©jÃ  dÃ©fini\nmongraph + scale_x_log10() + scale_y_log10()\n\n\n\n\n\n\nFigureÂ 9.2: Graphique poids-longueur avec une Ã©chelle log.\n\n\n\n\nComparez les diagrammes de dispersion avant et aprÃ¨s transformation (FigureÂ 9.1 et FigureÂ 9.2). Sachant que lâ€™analyse de corrÃ©lation prÃ©suppose une relation linÃ©aire entre les variables, on devrait donc privilÃ©gier lâ€™analyse sur les donnÃ©es log-transformÃ©es.",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>CorrÃ©lation et rÃ©gression linÃ©aire simple</span>"
    ]
  },
  {
    "objectID": "31-reg_lin.html#transformations-de-donnÃ©es-et-coefficient-de-corrÃ©lation",
    "href": "31-reg_lin.html#transformations-de-donnÃ©es-et-coefficient-de-corrÃ©lation",
    "title": "\n9Â  CorrÃ©lation et rÃ©gression linÃ©aire simple\n",
    "section": "\n9.3 Transformations de donnÃ©es et coefficient de corrÃ©lation",
    "text": "9.3 Transformations de donnÃ©es et coefficient de corrÃ©lation\nUne autre condition prÃ©alable Ã  lâ€™analyse de corrÃ©lation est que les deux variables concernÃ©es suivent une distribution normale bivariÃ©e. On peut aisÃ©ment vÃ©rifier la normalitÃ© de chacune des 2 variables sÃ©parÃ©ment tel que dÃ©crit dans plus bas dans la section Section 9.6.1. Si les deux variables sont normalement distribuÃ©es, on prÃ©sume gÃ©nÃ©ralement que la distribution commune des deux variables est Ã©galement normale (notez que ce nâ€™est pas toujours le cas cependant).\n\nExaminez la distribution des quatre variables (les deux variables originales et les variables transformÃ©es). Que concluez-vous de lâ€™inspection visuelle de ces graphiques ?\n\nLes figures ci-dessous sont les 4 diagrammes Q(uantile)-Q(uantile) (qqplot()). Le code pour produire des graphiques multiples sur une seule page avec 2 lignes et 2 colonnes, comme on voit ci-dessous, est :\n\npar(mfrow = c(2, 2)) # divise le graphique en 4 sections\nqqnorm(esturgeon$fklngth, ylab = \"fklngth\")\nqqline(esturgeon$fklngth)\nqqnorm(log10(esturgeon$fklngth), ylab = \"log10(fklngth)\")\nqqline(log10(esturgeon$fklngth))\nqqnorm(esturgeon$rdwght, ylab = \"rdwght\")\nqqline(esturgeon$rdwght)\nqqnorm(log10(esturgeon$rdwght), ylab = \"log10(rdwgth)\")\nqqline(log10(esturgeon$rdwght))\npar(mfrow = c(1, 1)) # redÃ©finie la zone de graphique par dÃ©faut\n\n\n\n\n\n\nFigureÂ 9.3: Diagrammes Q-Q des quatres variables Ã©tudiÃ©es (Poids, Longueur, Originale et Log-transformÃ©es).\n\n\n\n\n\nIl nâ€™y a pas grand-chose Ã  redire: aucune des distributions nâ€™est parfaitement normale, mais les dÃ©viations semblent mineures.\n\nGÃ©nÃ©rez une matrice de graphiques de dispersion de toutes les paires de variables (avec rÃ©gression linÃ©aires et â€œlowessâ€) en utilisant la fonction scatterplotMatrix du paquet car ğŸ“¦.\n\n\nscatterplotMatrix(\n  ~ fklngth + log10(fklngth) + rdwght + log10(rdwght),\n  data = esturgeon,\n  smooth = TRUE, diagonal = \"density\"\n)\n\n\n\n\n\n\nFigureÂ 9.4: CorrÃ©lations entre chaque paires de variables\n\n\n\n\n\n\nEnsuite, calculez le coefficient de corrÃ©lation de Pearson entre chaque paire (variables originales et log-transformÃ©es) en utilisant la fonction cor(). Avant de commencer, on va cependant ajouter les variables transformÃ©es au jeu de donnÃ©es esturgeon :\n\n\nesturgeon$lfklngth &lt;- with(esturgeon, log10(fklngth))\nesturgeon$lrdwght &lt;- log10(esturgeon$rdwght)\n\nVous pouvez ensuite obtenir la matrice de corrÃ©lation par :\n\ncor(esturgeon[, c(\"fklngth\", \"lfklngth\", \"lrdwght\", \"rdwght\")], use = \"complete.obs\")\n\nFrÃ©quemment, il y a des donnÃ©es manquantes dans un Ã©chantillon. En prÃ©cisant use=\"complete.obs\", toutes les lignes du fichier pour lesquelles les variables ne sont pas toutes mesurÃ©es sont Ã©liminÃ©es. Dans ce cas, toutes les corrÃ©lations seront calculÃ©es avec le mÃªme nombre de cas. Par contre, en utilisant use=\"pairwise.complete.obs\", R Ã©limine une observation seulement lorsque lâ€™un des deux membres de la paire a une valeur manquante. Dans ce cas, si les donnÃ©es manquantes pour diffÃ©rentes variables se retrouvent dans un groupe diffÃ©rent dâ€™observation, les corrÃ©lations ne seront pas nÃ©cessairement calculÃ©es sur le mÃªme nombre de cas ni sur le mÃªme sous-ensemble de cas. En gÃ©nÃ©ral, vous devriez utiliser lâ€™option use=\"complete.obs\" Ã  moins que vous ayez un trÃ¨s grand nombre de donnÃ©es manquantes et que cette faÃ§on de procÃ©der Ã©limine la plus grande partie de vos observations.\nPourquoi la corrÃ©lation entre les variables originales est-elle plus faible quâ€™entre les variables transformÃ©es ?\n\ncor(esturgeon[, c(\"fklngth\", \"lfklngth\", \"lrdwght\", \"rdwght\")], use = \"complete.obs\")\n\n           fklngth  lfklngth   lrdwght    rdwght\nfklngth  1.0000000 0.9921435 0.9645108 0.9175435\nlfklngth 0.9921435 1.0000000 0.9670139 0.8756203\nlrdwght  0.9645108 0.9670139 1.0000000 0.9265513\nrdwght   0.9175435 0.8756203 0.9265513 1.0000000\n\n\nIl y a plusieurs choses Ã  noter ici.\n\nPremiÃ¨rement, la corrÃ©lation entre la longueur (â€œfklngthâ€) et le poids (â€œrdwghtâ€) est Ã©levÃ©e, peu importe la transformation: les poissons lourds ont tendance Ã  Ãªtre longs.\nDeuxiÃ¨mement, la corrÃ©lation est plus forte pour les donnÃ©es transformÃ©es que pour les donnÃ©es brutes.\n\nPourquoi? Parce que le coefficient de corrÃ©lation est inversement proportionnel au bruit autour de la relation linÃ©aire. Si la relation est curvilinÃ©aire (comme dans le cas des donnÃ©es non transformÃ©es), le bruit est plus grand que si la relation est parfaitement linÃ©aire. Par consÃ©quent, la corrÃ©lation est plus faible.",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>CorrÃ©lation et rÃ©gression linÃ©aire simple</span>"
    ]
  },
  {
    "objectID": "31-reg_lin.html#matrices-de-corrÃ©lations-et-correction-de-bonferroni",
    "href": "31-reg_lin.html#matrices-de-corrÃ©lations-et-correction-de-bonferroni",
    "title": "\n9Â  CorrÃ©lation et rÃ©gression linÃ©aire simple\n",
    "section": "\n9.4 Matrices de corrÃ©lations et correction de Bonferroni",
    "text": "9.4 Matrices de corrÃ©lations et correction de Bonferroni\nUne pratique courante est dâ€™examiner la matrice de corrÃ©lation Ã  la recherche dâ€™associations significatives. Comme exemple, essayons de tester si la corrÃ©lation entre lfklngth et rdwght est significative (le plus faible coefficient de corrÃ©lation de cette matrice).\n\nEstimez la corrÃ©lation entre la longueur (fklngth et le poids (rdwght) des esturgeons:\n\n\ncor.test(\n  esturgeon$lfklngth, esturgeon$rdwght,\n  alternative = \"two.sided\",\n  method = \"pearson\"\n)\n\n\n    Pearson's product-moment correlation\n\ndata:  esturgeon$lfklngth and esturgeon$rdwght\nt = 24.322, df = 180, p-value &lt; 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.8367345 0.9057199\nsample estimates:\n      cor \n0.8756203 \n\n\nOn voit ici que la corrÃ©lation est hautement significative (\\(p &lt; 2.2e-16\\)), ce qui nâ€™est pas surprenant Ã©tant donnÃ© la valeur du coefficient de corrÃ©lation (0.8756 = 87.6%). Il est important de rÃ©aliser que si une matrice contient un grand nombre de corrÃ©lations, il nâ€™est pas surprenant dâ€™en trouver au moins une qui soit â€œsignificativeâ€. En effet, on sâ€™attend Ã  en trouver 5% en moyenne lorsquâ€™il nâ€™y a en fait aucune corrÃ©lation entre les paires de moyennes (correspondant au risque dâ€™erreur de type I \\(\\alpha\\)) . Une faÃ§on de corriger pour cette tendance est dâ€™ajuster le niveau \\(\\alpha\\) critique auquel on attribue une signification statistique en divisant \\(\\alpha\\) par le nombre \\(k\\) de corrÃ©lations qui sont examinÃ©es :\n\\(\\alpha' = \\alpha / k\\) (ajustement de Bonferroni).\nSi initialement \\(\\alpha = 0.05\\) et quâ€™il y a 10 corrÃ©lations qui sont examinÃ©es, alors \\(\\alpha'= 0.005\\). Donc, afin de rejeter lâ€™hypothÃ¨se nulle, la valeur de p devra Ãªtre plus petite que \\(\\alpha'\\), en lâ€™occurrence 0.005. Dans lâ€™exemple qui prÃ©cÃ¨de, on devrait donc ajuster \\(\\alpha\\) critique en divisant par le nombre total de corrÃ©lations dans la matrice (6 dans ce cas, donc \\(\\alpha'=0.00833\\)). Cette correction modifie-t-elle votre conclusion quant Ã  la corrÃ©lation entre lkflngth et rdwght?",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>CorrÃ©lation et rÃ©gression linÃ©aire simple</span>"
    ]
  },
  {
    "objectID": "31-reg_lin.html#corrÃ©lations-non-paramÃ©triques-r-de-spearman-et-tau-de-kendall",
    "href": "31-reg_lin.html#corrÃ©lations-non-paramÃ©triques-r-de-spearman-et-tau-de-kendall",
    "title": "\n9Â  CorrÃ©lation et rÃ©gression linÃ©aire simple\n",
    "section": "\n9.5 CorrÃ©lations non paramÃ©triques: r de Spearman et \\(\\tau\\) de Kendall",
    "text": "9.5 CorrÃ©lations non paramÃ©triques: r de Spearman et \\(\\tau\\) de Kendall\nLâ€™analyse faite dans la section prÃ©cÃ©dente avec les esturgeons suggÃ¨re que lâ€™une des conditions prÃ©alables Ã  lâ€™analyse de corrÃ©lation, soit la distribution normale bivariÃ©e de donnÃ©es, pourrait ne pas Ãªtre remplie pour fklngth et rdwght, ni pour les paires de variables transformÃ©es. La recherche dâ€™une transformation appropriÃ©e peut parfois Ãªtre difficile. Pire encore, pour certaines distributions il nâ€™existe pas de transformation qui va normaliser les donnÃ©es. Dans ces cas-lÃ , la meilleure option est de faire une analyse non paramÃ©trique qui ne prÃ©sume ni de la normalitÃ© ni de la linÃ©aritÃ©. Ces analyses sont basÃ©es sur les rangs. Les deux plus communes sont le coefficient de rang de Spearman et le \\(\\tau\\) (tau) de Kendall.\n\nDans R, testez la corrÃ©lation entre fklngth et rdwght en utilisant Spearman et Kendallâ€™s .\n\n\ncor.test(\n  esturgeon$lfklngth, esturgeon$rdwght,\n  alternative = \"two.sided\",\n  method = \"spearman\"\n)\n\nWarning in cor.test.default(esturgeon$lfklngth, esturgeon$rdwght, alternative =\n\"two.sided\", : Cannot compute exact p-value with ties\n\n\n\n    Spearman's rank correlation rho\n\ndata:  esturgeon$lfklngth and esturgeon$rdwght\nS = 47971, p-value &lt; 2.2e-16\nalternative hypothesis: true rho is not equal to 0\nsample estimates:\n      rho \n0.9522546 \n\n\n\ncor.test(\n  esturgeon$lfklngth, esturgeon$rdwght,\n  alternative = \"two.sided\",\n  method = \"kendall\"\n)\n\n\n    Kendall's rank correlation tau\n\ndata:  esturgeon$lfklngth and esturgeon$rdwght\nz = 16.358, p-value &lt; 2.2e-16\nalternative hypothesis: true tau is not equal to 0\nsample estimates:\n      tau \n0.8208065 \n\n\nComparer les rÃ©sultats de cette analyse Ã  lâ€™analyse paramÃ©trique. Pourquoi y-a-tâ€™il une diffÃ©rence ?\nCalculez les corrÃ©lations non paramÃ©triques sur les paires de variables transformÃ©es. Vous devriez voir tout de suite que les corrÃ©lations des donnÃ©es transformÃ©es et non transformÃ©es sont identiques puisque dans les deux cas la corrÃ©lation est calculÃ©e Ã  partir des rangs qui ne sont pas affectÃ©s par la transformation.\nNotez que les corrÃ©lations obtenues avec le \\(\\tau\\) de Kendall (0.820) sont plus faibles que celles du coefficient de Spearman (0.952). Le \\(\\tau\\) de Kendall pondÃ¨re un peu plus les grandes diffÃ©rences entre les rangs alors que le coefficient de Spearman donne le mÃªme poids Ã  chaque paire dâ€™observations. En gÃ©nÃ©ral, on prÃ©fÃ¨re le \\(\\tau\\) de Kendall lorsquâ€™il y a plus dâ€™incertitude quant aux rangs qui sont prÃ¨s les uns des autres.\nLes esturgeons de cet Ã©chantillon ont Ã©tÃ© capturÃ©s Ã  lâ€™aide de filets et dâ€™hameÃ§ons dâ€™une taille fixe. Quel impact cette mÃ©thode de capture peut-elle avoir eu sur la forme de la distribution de fklngth et rdwght? Compte tenu de ces circonstances, lâ€™analyse de corrÃ©lation est-elle appropriÃ©e ?\nRappelez-vous que lâ€™analyse de corrÃ©lation prÃ©sume aussi que chaque variable est Ã©chantillonnÃ©e alÃ©atoirement. Dans le cas de nos esturgeons, ce nâ€™est pas le cas: les hameÃ§ons appÃ¢tÃ©s et les filets ne capturent pas de petits esturgeons (et câ€™est pourquoi il nâ€™y en a pas dans lâ€™Ã©chantillon). Il faut donc rÃ©aliser que les coefficients de corrÃ©lation obtenus dans cette analyse ne reflÃ¨tent pas nÃ©cessairement ceux de la population totale des esturgeons.",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>CorrÃ©lation et rÃ©gression linÃ©aire simple</span>"
    ]
  },
  {
    "objectID": "31-reg_lin.html#sec-simple-lm",
    "href": "31-reg_lin.html#sec-simple-lm",
    "title": "\n9Â  CorrÃ©lation et rÃ©gression linÃ©aire simple\n",
    "section": "\n9.6 RÃ©gression linÃ©aire simple",
    "text": "9.6 RÃ©gression linÃ©aire simple\nLâ€™analyse de corrÃ©lation vise Ã  dÃ©crire comment deux variables covarient. Lâ€™analyse de rÃ©gression vise plutÃ´t Ã  produire un modÃ¨le permettant de prÃ©dire une variable (la variable dÃ©pendante) par lâ€™autre (la variable indÃ©pendante).\nComme pour lâ€™analyse de corrÃ©lation, on devrait commencer en examinant des graphiques. Puisque lâ€™on veut quantifier la relation entre deux variables, un graphique de la variable dÃ©pendante (Y) en fonction de la variable indÃ©pendante (X) est tout Ã  fait appropriÃ©.\n\nLe fichier sturgeon.csv contient les donnÃ©es dâ€™un inventaire dâ€™esturgeons rÃ©coltÃ©s entre 1978 et 1980 Ã  Cumberland House en Saskatchewan et Ã  The Pas au Manitoba. Faites un diagramme de dispersion de fklngth (la variable dÃ©pendante, Y) en fonction de lâ€™age (la variable indÃ©pendante, X) pour les esturgeons mÃ¢les uniquement et ajoutez-y une rÃ©gression linÃ©aire et une â€œlowessâ€. Que concluez-vous de ce diagramme de dispersion ?\n\n\nesturgeon.male &lt;- subset(esturgeon, subset = sex == \"MALE\")\nmongraph &lt;- ggplot(\n  data = esturgeon.male, # origine des donnÃ©es\n  aes(x = age, y = fklngth)\n) # aesthetics: y=fklngth, x=rdwght\n# ReprÃ©sentez les donnÃ©es sous forme de Points, RÃ©gression linÃ©aire, \"Lowess\"\nmongraph &lt;- mongraph +\n  stat_smooth(method = lm, se = FALSE, color = \"green\") + # Ajoutez une rÃ©gression linÃ©aire, mais sans l'erreur-type (en vert)\n  stat_smooth(color = \"red\") + # Ajoutez la \"lowess\" (en rouge)\n  geom_point() +# Ajoutez les donnÃ©es sous forme de points\n  labs(x = \"Age\", y = \"Longueur\") # Modifiez les noms des axes pour rendre le graphique plus lisible\nmongraph # Affichez le graphique\n\n\n\n\n\n\nFigureÂ 9.5: Graphique de la longueur en fonction de lâ€™Ã¢ge des esturgeons males.\n\n\n\n\nCe graphique suggÃ¨re que la relation nâ€™est pas linÃ©aire.\nSupposons que nous dÃ©sirions estimer le taux de croissance des esturgeons mÃ¢les. Un estimÃ© (peut-Ãªtre pas terribleâ€¦) du taux de croissance peut Ãªtre obtenu en calculant la pente de la rÃ©gression de la longueur en fonction de lâ€™Ã¢ge.\nAjustons dâ€™abord une rÃ©gression avec la commande lm() et sauvons ces rÃ©sultats dans un objet appelÃ© RegModel.1.\n\nRegModele.1 &lt;- lm(fklngth ~ age, data = esturgeon.male)\n\nRien nâ€™apparait Ã  lâ€™Ã©cran, câ€™est normal ne vous inquiÃ©tez pas, tout a Ã©tÃ© sauvegardÃ© en mÃ©moire (nouvel objet visible dans lâ€™onglet environnement) . Pour voir les rÃ©sultats, tapez:\n\nsummary(RegModele.1)\n\n\nCall:\nlm(formula = fklngth ~ age, data = esturgeon.male)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-8.4936 -2.2263  0.1849  1.7526 10.8234 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 28.50359    1.16873   24.39   &lt;2e-16 ***\nage          0.70724    0.05888   12.01   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.307 on 73 degrees of freedom\n  (5 observations deleted due to missingness)\nMultiple R-squared:  0.664, Adjusted R-squared:  0.6594 \nF-statistic: 144.3 on 1 and 73 DF,  p-value: &lt; 2.2e-16\n\n\nla sortie R donne:\n\n\nCall: Un petit rappel du modÃ¨le qui a Ã©tÃ© ajustÃ© et des donnÃ©es utilisÃ©es.\n\nResiduals: Un sommaire statistique des rÃ©sidus autour du modÃ¨le estimÃ©.\n\nCoefficients: Valeurs estimÃ©es des paramÃ¨tres du modÃ¨le, erreurs-types, statistiques t et probabilitÃ©s associÃ©es.\n\nResidual standard error: Racine carrÃ©e de la variance rÃ©siduelle.\n\nMultiple R-squared: Coefficient de dÃ©termination. Il correspond Ã  la proportion de la variabilitÃ© de la variable dÃ©pendante qui peut Ãªtre expliquÃ©e par la rÃ©gression.\n\nAdjusted R-squared: Le R-carrÃ© ajustÃ© tient compte du nombre de paramÃ¨tres du modÃ¨le. Si vous voulez comparer diffÃ©rents modÃ¨les qui nâ€™ont pas le mÃªme nombre de paramÃ¨tres, câ€™est ce quâ€™il faut utiliser.\n\nF-statistic: Câ€™est le test de signification omnibus du modÃ¨le. Dans le cas de la rÃ©gression simple, il est Ã©quivalent au test sur la pente de la rÃ©gression.\n\nLa rÃ©gression estimÃ©e est donc:\n\\[ Fklngth = 28.50359 + 0.70724 * age\\]\nÃ‰tant donnÃ© la valeur significative du test de F (ainsi que pour le test de t pour la pente de la droite), on rejette lâ€™hypothÃ¨se nulle quâ€™il nâ€™y a pas de relation entre la taille et lâ€™Ã¢ge.\n\n9.6.1 VÃ©rifier les conditions dâ€™application de la rÃ©gression\nLa rÃ©gression simple de type I a quatre conditions prÃ©alables :\n\nil nâ€™y a pas dâ€™erreur de mesure sur la variable indÃ©pendante (X)\nla relation entre Y et X est linÃ©aire\n\nles rÃ©sidus sont normalement distribuÃ©s\n\nla variance des rÃ©sidus est constante pour toutes les valeurs de la variable indÃ©pendante (homoscedasticitÃ©)\n\nProcÃ©dons maintenant Ã  lâ€™examen post-mortem. La premiÃ¨re condition est rarement remplie avec des donnÃ©es biologiques ; il y presque toujours de lâ€™erreur sur X et sur Y. Cela veut dire quâ€™en gÃ©nÃ©ral les pentes estimÃ©es sont biaisÃ©es, mais que les valeurs prÃ©dites ne le sont pas. Toutefois, si lâ€™erreur de mesure sur X est petite par rapport Ã  lâ€™Ã©tendue des valeurs de X, le rÃ©sultat de lâ€™analyse nâ€™est pas dramatiquement influencÃ©. Par contre, si lâ€™erreur de mesure est relativement grande (toujours par rapport Ã  lâ€™Ã©tendue des valeurs de X), la droite de rÃ©gression obtenue par la rÃ©gression de modÃ¨le I est un piÃ¨tre estimÃ© de la relation fonctionnelle entre X et Y. Dans ce cas, il est prÃ©fÃ©rable de passer Ã  la rÃ©gression de modÃ¨le II, malheureusement au-delÃ  du contenu de ce cours. Les autres conditions prÃ©alables Ã  lâ€™analyse de rÃ©gression de modÃ¨le I peuvent cependant Ãªtre vÃ©rifiÃ©es, ou du moins Ã©valuÃ©es visuellement. La fonction plot() (appliquÃ© directement sur un objet de type model) permet de visualiser des graphiques diagnostiques pour des modÃ¨les linÃ©aires.\n\npar(mfrow = c(2, 2), las = 1)\nplot(RegModele.1)\n\nLa fonction par() est utilisÃ©e pour dire Ã  R de tracer 2 rangÃ©es et 2 colonnes de graphiques par page (il y a quatre graphiques diagnostiques qui sont gÃ©nÃ©rÃ©s automatiquement pour les modÃ¨les linÃ©aires), et lâ€™argument las = indique Ã  R dâ€™effectuer une rotation des lÃ©gendes des axes Y pour quâ€™elles soient perpendiculaires Ã  lâ€™axe (oui. Je sais. Rien de tout Ã§a nâ€™est Ã©vident.)\nVous obtiendrez:\n\n\n\n\n\n\n\nFigureÂ 9.6: Graphiques diagnostiques du modÃ¨le.\n\n\n\n\n\n\nLe graphique en haut Ã  gauche, permet dâ€™Ã©valuer la linÃ©aritÃ©, la normalitÃ©, et lâ€™homoscÃ©dasticitÃ© des rÃ©sidus. Il illustre les dÃ©viations autour de la rÃ©gression en fonction des valeurs prÃ©dites. Rappelez-vous que le graphique de fklngth vs age suggÃ¨re que la relation entre la longueur et lâ€™Ã¢ge nâ€™est pas linÃ©aire. Les trÃ¨s jeunes et trÃ¨s vieux esturgeons sont sous la droite en gÃ©nÃ©ral, alors que les esturgeons dâ€™Ã¢ge moyen sont retrouvÃ©s gÃ©nÃ©ralement au-dessus de la droite de rÃ©gression. Câ€™est exactement ce que le graphique des rÃ©sidus en fonction des valeurs prÃ©dites illustre. La ligne en rouge est une trace â€œlowessâ€ au travers de ce nuage de points. Si la relation Ã©tait linÃ©aire, la trace â€œlowessâ€ serait presque plate et prÃ¨s de 0. La dispersion des rÃ©sidus permet dâ€™Ã©valuer visuellement leur normalitÃ© et hÃ©tÃ©roscÃ©dasticitÃ©; mais ce graphique nâ€™est pas optimal pour Ã©valuer ces propriÃ©tÃ©s. Les deux graphiques suivants sont mieux pour cela.\nLe graphique en haut Ã  droite permet dâ€™Ã©valuer la normalitÃ© des rÃ©sidus. Câ€™est un graphique QQ des rÃ©sidus (QQ plot). Des rÃ©sidus distribuÃ©s normalement tomberaient exactement sur la diagonale. Ici, on voit que câ€™est presque le cas, sauf dans les queues de la distribution.\n\nLe graphique en bas Ã  gauche, intitulÃ© Scale-Location, permet dâ€™Ã©valuer lâ€™homoscÃ©dasticitÃ©. On y retrouve sur lâ€™ordonnÃ©e (lâ€™axe des y) la racine carrÃ©e de la valeur absolue des rÃ©sidus standardisÃ©s (rÃ©sidus divisÃ©s par lâ€™Ã©cart-type des rÃ©sidus) en fonction des valeurs prÃ©dites. Le graphique aide Ã  dÃ©terminer si la variation des rÃ©sidus est constante ou non. Si les rÃ©sidus sont homoscÃ©dastiques, la valeur moyenne sur lâ€™axe des y ne va pas changer en fonction de la valeur prÃ©dite. Ici, il y a une certaine tendance, mais pas une tendance monotone puisquâ€™il y a dâ€™abord une baisse puis une hausse..; bref, rien qui soit une forte Ã©vidence contre la supposition dâ€™homoscÃ©dasticitÃ©.\n\nLe graphique en bas Ã  droite, montre les rÃ©sidus en fonction du â€œleverageâ€ et permet de dÃ©tecter certaines valeurs extrÃªmes qui ont une grande influence sur la rÃ©gression. Le leverage dâ€™un point mesure sa distance des autres points, mais seulement en ce qui concerne les variables indÃ©pendantes. Dans le cas dâ€™une rÃ©gression simple, cela revient Ã  la distance entre le point sur lâ€™axe des x et la moyenne de tous les points sur cet axe. Vous devriez porter une attention particuliÃ¨re aux observations qui ont un leverage plus grand que \\(2(k+1)/n\\), oÃ¹ k est le nombre de variables indÃ©pendantes (ici, 1) et n est le nombre dâ€™observations. Dans cet exemple, il y a 75 observations et une variable indÃ©pendante et donc les points ayant un leverage plus grand que \\(4 / 75 =  0.053\\) devrait Ãªtre considÃ©rÃ©s avec attention. Le graphique indique Ã©galement comment la rÃ©gression changerait si on enlevait un point. Ce changement est mesurÃ© par la distance de Cook, illustrÃ©e par les bandes en rouge sur le graphique. Un point ayant une distance de Cook supÃ©rieure Ã  1 a une grande influence.\n\n\n\n\n\n\n\nAvertissement\n\n\n\nNotez que R identifie automatiquement les cas les plus extrÃªmes sur chacun de ces 4 graphiques. Le fait quâ€™un point soit identifiÃ© ne signifie pas nÃ©cessairement que câ€™est une valeur rÃ©ellement extrÃªme, ou que vous devez vous en prÃ©occuper. Dans tous les ensembles de donnÃ©es il y aura toujours un rÃ©sidu plus grand que les autresâ€¦\n\n\nIl est possible dâ€™obtenir des graphiques dâ€™Ã©valuations des conditions dâ€™applications, qui sont plus simple Ã  interprÃ©ter et plus joli (avec des couleurs). On peut utiliser la fonction check_model() du paquet performance ğŸ“¦.\n\ncheck_model(RegModele.1)\n\n\n\n\n\n\nFigureÂ 9.7: Graphiques diagnostiques du modÃ¨le avec la fonction check_model().\n\n\n\n\nFinalement, quel est le verdict concernant la rÃ©gression linÃ©aire entre fklngth et age ? Elle viole la condition de linÃ©aritÃ©, possiblement celle de normalitÃ©, remplit la condition dâ€™homoscÃ©dasticitÃ©, et ne semble pas Ãªtre influencÃ©e outre mesure par des valeurs bizarres ou extrÃªmes.\n\n9.6.2 Tests formels des conditions dâ€™application pour la rÃ©gression\nPersonnellement, je nâ€™utilise jamais les tests formels des conditions dâ€™application de la rÃ©gression et me contente des graphiques des rÃ©sidus pour guider mes dÃ©cisions. Câ€™est ce que la plupart des praticiens font. Cependant, lors de mes premiÃ¨res analyses, je nâ€™Ã©tais pas toujours certain de bien interprÃ©ter les graphiques et jâ€™aurais aimÃ© un indice plus formel ou un test permettant de dÃ©tecter les violations des conditions dâ€™application de la rÃ©gression.\nLe package lmtest ğŸ“¦ (disponible sur CRAN), permet de faire plusieurs tests de linÃ©aritÃ© et dâ€™homoscÃ©dasticitÃ©. Et on peut tester la normalitÃ© avec le test Shapiro-Wilk vu prÃ©cÃ©demment.\nCharger le package lmtest de CRAN (et installer le si besoin).\n\nlibrary(lmtest)\n\n\n\n\n\n\n\nExercice\n\n\n\nExÃ©cutez les commandes suivantes\n\n\n\nbptest(RegModele.1)\n\n\n    studentized Breusch-Pagan test\n\ndata:  RegModele.1\nBP = 1.1765, df = 1, p-value = 0.2781\n\n\nLe test Breusch-Pagan examine si la variabilitÃ© des rÃ©sidus est constantes lorsque les valeurs prÃ©dites changent. Une faible valeur de p suggÃ¨re de lâ€™hÃ©tÃ©roscÃ©dasticitÃ©. Ici, la valeur p est Ã©levÃ©e et suggÃ¨re que la condition dâ€™application dâ€™homoscÃ©dasticitÃ© est remplie avec ces donnÃ©es.\n\ndwtest(RegModele.1)\n\n\n    Durbin-Watson test\n\ndata:  RegModele.1\nDW = 2.242, p-value = 0.8489\nalternative hypothesis: true autocorrelation is greater than 0\n\n\nLe test Durbin-Watson permet de dÃ©tecter lâ€™autocorrÃ©lation sÃ©rielle des rÃ©sidus. En lâ€™absence dâ€™autocorrÃ©lation (i.e.Â dâ€™indÃ©pendance des rÃ©sidus) la valeur attendue de la statistique D est 2. Ce test permet dâ€™Ã©prouver lâ€™hypothÃ¨se dâ€™indÃ©pendance des rÃ©sidus, mais ne permet de dÃ©tecter quâ€™un type particulier de dÃ©pendance. Ici, le test ne permet pas de rejeter lâ€™hypothÃ¨se dâ€™indÃ©pendance.\n\nresettest(RegModele.1)\n\n\n    RESET test\n\ndata:  RegModele.1\nRESET = 14.544, df1 = 2, df2 = 71, p-value = 5.082e-06\n\n\nLe test RESET permet dâ€™Ã©prouver la linÃ©aritÃ©. Si la relation est linÃ©aire, alors la statistique RESET sera dâ€™environ 1. Ici, la statistique est beaucoup plus Ã©levÃ©e (14.54) et hautement significative. Le test confirme la tendance que nous avons dÃ©tectÃ©e visuellement plus haut: la relation nâ€™est pas linÃ©aire.\n\nshapiro.test(residuals(RegModele.1))\n\n\n    Shapiro-Wilk normality test\n\ndata:  residuals(RegModele.1)\nW = 0.98037, p-value = 0.2961\n\n\nLe test de normalitÃ© Shapiro-Wilk sur les rÃ©sidus confirme que la dÃ©viation par rapport Ã  une distribution normale des rÃ©sidus nâ€™est pas grande.",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>CorrÃ©lation et rÃ©gression linÃ©aire simple</span>"
    ]
  },
  {
    "objectID": "31-reg_lin.html#transformation-des-donnÃ©es-en-rÃ©gression",
    "href": "31-reg_lin.html#transformation-des-donnÃ©es-en-rÃ©gression",
    "title": "\n9Â  CorrÃ©lation et rÃ©gression linÃ©aire simple\n",
    "section": "\n9.7 Transformation des donnÃ©es en rÃ©gression",
    "text": "9.7 Transformation des donnÃ©es en rÃ©gression\nLa relation entre fklngth et age nâ€™Ã©tant pas linÃ©aire, on devrait donc essayer de transformer les donnÃ©es pour tenter de les linÃ©ariser :\n\nVoyons ce quâ€™une transformation log donne:\n\n\npar(mfrow = c(1, 1), las = 1)\nggplot(\n  data = esturgeon.male,\n  aes(x = log10(age), y = log10(fklngth))\n) +\n  geom_smooth(color = \"red\") +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"green\") +\n  geom_point()\n\n\n\n\n\n\nFigureÂ 9.8: Graphique du log de la longueur en fonction du log de lâ€™Ã¢ge des esturgeons males\n\n\n\n\nAjustons maintenant une rÃ©gression simple sur ces donnÃ©es transformÃ©es.\n\nRegModele.2 &lt;- lm(log10(fklngth) ~ log10(age), data = esturgeon.male)\nsummary(RegModele.2)\n\n\nCall:\nlm(formula = log10(fklngth) ~ log10(age), data = esturgeon.male)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.082794 -0.016837 -0.000719  0.021102  0.087446 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  1.19199    0.02723   43.77   &lt;2e-16 ***\nlog10(age)   0.34086    0.02168   15.72   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.03015 on 73 degrees of freedom\n  (5 observations deleted due to missingness)\nMultiple R-squared:  0.772, Adjusted R-squared:  0.7688 \nF-statistic: 247.1 on 1 and 73 DF,  p-value: &lt; 2.2e-16\n\n\nExaminons maintenant les graphiques diagnostiques:\n\npar(mfrow = c(2, 2), las = 1)\nplot(RegModele.2)\n\n\n\n\n\n\nFigureÂ 9.9: Graphiques diagnostiques du modÃ¨le avec les donnÃ©es log-transformÃ©es.\n\n\n\n\nIl y a une certaine amÃ©lioration, mais ce nâ€™est pas encore parfait (la perfection nâ€™est pas de ce mondeâ€¦.). Le graphique des rÃ©sidus en fonction des valeurs prÃ©dites suggÃ¨re encore une certaine non linÃ©aritÃ©. Sur le graphique Q-Q les points se retrouvent plus prÃ¨s de la droite diagonale quâ€™avant, indiquant que les rÃ©sidus sont encore plus prÃ¨s de la normalitÃ© aprÃ¨s la transformation log-log. Il nâ€™y a pas dâ€™indice dâ€™hÃ©tÃ©roscÃ©dasticitÃ©. Finalement, mÃªme si il reste quelques points avec plus dâ€™influence (leverage) que les autres, aucun nâ€™a une distance de Cook au-delÃ  de 0.5. En rÃ©sumÃ©, la transformation log a amÃ©liorÃ© les choses: la relation est plus linÃ©aire, les rÃ©sidus sont plus normaux, et il y a moins de points avec une influence relativement Ã©levÃ©e. Est-ce que les tests formels supportent cette Ã©valuation ?\n\nbptest(RegModele.2)\n\n\n    studentized Breusch-Pagan test\n\ndata:  RegModele.2\nBP = 0.14282, df = 1, p-value = 0.7055\n\ndwtest(RegModele.2)\n\n\n    Durbin-Watson test\n\ndata:  RegModele.2\nDW = 2.1777, p-value = 0.6134\nalternative hypothesis: true autocorrelation is greater than 0\n\nresettest(RegModele.2)\n\n\n    RESET test\n\ndata:  RegModele.2\nRESET = 4.4413, df1 = 2, df2 = 71, p-value = 0.01523\n\nshapiro.test(residuals(RegModele.2))\n\n\n    Shapiro-Wilk normality test\n\ndata:  residuals(RegModele.2)\nW = 0.98998, p-value = 0.8246\n\n\nOui, les conclusions sont les mÃªmes: les rÃ©sidus sont encore homoscÃ©dastiques (test Breusch-Pagan), ne sont pas autocorrÃ©lÃ©s (test Durbin-Watson), sont normaux (test Shapiro-Wilk), et sont plus linÃ©aires (la valeur de P du test RESET est maintenant 0.015, au lieu de 0.000005). Donc la linÃ©aritÃ© a augmentÃ©, mais cette condition dâ€™application semble encore lÃ©gÃ¨rement violÃ©e.",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>CorrÃ©lation et rÃ©gression linÃ©aire simple</span>"
    ]
  },
  {
    "objectID": "31-reg_lin.html#traitement-des-valeurs-extrÃªmes",
    "href": "31-reg_lin.html#traitement-des-valeurs-extrÃªmes",
    "title": "\n9Â  CorrÃ©lation et rÃ©gression linÃ©aire simple\n",
    "section": "\n9.8 Traitement des valeurs extrÃªmes",
    "text": "9.8 Traitement des valeurs extrÃªmes\nDans cet exemple, il nâ€™y a pas de valeur vraiment extrÃªme. Oui, je sais, R a quand mÃªme identifiÃ© les observations 8, 24, et 112 dans le dernier graphique diagnostique. Mais ces valeurs sont encore dans la fourchette de valeurs que je juge â€œacceptablesâ€. Mais comment dÃ©terminer objectivement ce qui est acceptable ? Ã€ quel moment juge tâ€™on quâ€™une valeur extrÃªme est vraiment trop invraisemblable pour ne pas lâ€™exclure ? Il nâ€™y a malheureusement pas de rÃ¨gle absolue lÃ -dessus. Les opinions varient, mais je penche vers le conservatisme sur cette question.\nMa position est que, Ã  moins que la valeur soit biologiquement impossible ou clairement une erreur dâ€™entrÃ©e de donnÃ©es, je nâ€™Ã©limine pas les valeurs extrÃªmes et jâ€™utilise toutes mes donnÃ©es dans leur analyse. Pourquoi?\nParce que je veux que mes donnÃ©es reflÃ¨tent bien la variabilitÃ© naturelle ou rÃ©elle. Câ€™est dâ€™ailleurs parfois cette variabilitÃ© qui est intÃ©ressante.\nLâ€™approche conservatrice qui consiste Ã  conserver toutes les valeurs extrÃªmes possibles est possiblement la plus honnÃªte, mais elle peut causer certains problÃ¨mes. Ces valeurs extrÃªmes sont souvent la cause des violations des conditions dâ€™application des tests statistiques. La solution suggÃ©rÃ©e Ã  ce dilemme est de faire lâ€™analyse avec et sans les valeurs extrÃªmes et de comparer les conclusions. Dans bien des cas, les conclusions seront qualitativement les mÃªmes et les tailles dâ€™effet ne seront pas trÃ¨s diffÃ©rentes. Toutefois, dans certains cas, la prÃ©sence des valeurs extrÃªmes change complÃ¨tement les conclusions. Dans ces cas, il faut simplement accepter que les conclusions dÃ©pendent entiÃ¨rement de la prÃ©sence des valeurs extrÃªmes et sont donc peu concluantes.\nSuivant cette approche comparative, refaisons donc lâ€™analyse aprÃ¨s avoir enlevÃ© les observations 8, 24, et 112.\n\nRegModele.3 &lt;- lm(log10(fklngth) ~ log10(age), data = esturgeon.male, subset = !(rownames(esturgeon.male) %in% c(\"8\", \"24\", \"112\"))) # On enlÃ¨ve les observations 8, 24 et 112 du jeu de donnÃ©es\nsummary(RegModele.3)\n\n\nCall:\nlm(formula = log10(fklngth) ~ log10(age), data = esturgeon.male, \n    subset = !(rownames(esturgeon.male) %in% c(\"8\", \"24\", \"112\")))\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.069163 -0.017390  0.000986  0.018590  0.047647 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  1.22676    0.02431   50.46   &lt;2e-16 ***\nlog10(age)   0.31219    0.01932   16.16   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.02554 on 70 degrees of freedom\n  (5 observations deleted due to missingness)\nMultiple R-squared:  0.7885,    Adjusted R-squared:  0.7855 \nF-statistic:   261 on 1 and 70 DF,  p-value: &lt; 2.2e-16\n\n\nLâ€™ordonnÃ©e Ã  lâ€™origine (Intercept), la pente, et le R carrÃ© sont presque les mÃªmes, et la valeur de p est encore astronomiquement petite. Enlever les valeurs extrÃªmes a peu dâ€™effet dans ce cas.\nLes graphiques diagnostiques des rÃ©sidus et les tests formels des conditions dâ€™application sur ce sous-ensemble de donnÃ©es donnent :\n\npar(mfrow = c(2, 2))\nplot(RegModele.3)\nbptest(RegModele.3)\n\n\n    studentized Breusch-Pagan test\n\ndata:  RegModele.3\nBP = 0.3001, df = 1, p-value = 0.5838\n\ndwtest(RegModele.3)\n\n\n    Durbin-Watson test\n\ndata:  RegModele.3\nDW = 2.0171, p-value = 0.5074\nalternative hypothesis: true autocorrelation is greater than 0\n\nresettest(RegModele.3)\n\n\n    RESET test\n\ndata:  RegModele.3\nRESET = 3.407, df1 = 2, df2 = 68, p-value = 0.0389\n\nshapiro.test(residuals(RegModele.3))\n\n\n    Shapiro-Wilk normality test\n\ndata:  residuals(RegModele.3)\nW = 0.98318, p-value = 0.4502\n\n\n\n\n\n\n\nFigureÂ 9.10: Graphiques diagnostiques du modÃ¨le RegModele.3 excluant les donnÃ©es aberrantes.\n\n\n\n\nIl nâ€™y a pas vraiment de diffÃ©rence ici non plus avec lâ€™analyse des donnÃ©es en entier. Bref, tout pointe vers la conclusion que les valeurs les plus extrÃªmes de cet ensemble de donnÃ©e nâ€™influencent pas indÃ»ment les rÃ©sultats statistiques.",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>CorrÃ©lation et rÃ©gression linÃ©aire simple</span>"
    ]
  },
  {
    "objectID": "31-reg_lin.html#quantifier-la-taille-deffet-et-analyse-de-puissance-en-rÃ©gression",
    "href": "31-reg_lin.html#quantifier-la-taille-deffet-et-analyse-de-puissance-en-rÃ©gression",
    "title": "\n9Â  CorrÃ©lation et rÃ©gression linÃ©aire simple\n",
    "section": "\n9.9 Quantifier la taille dâ€™effet et analyse de puissance en rÃ©gression",
    "text": "9.9 Quantifier la taille dâ€™effet et analyse de puissance en rÃ©gression\nLâ€™interprÃ©tation biologique des rÃ©sultats nâ€™est pas la mÃªme chose que lâ€™interprÃ©tation statistique. Dans lâ€™analyse qui prÃ©cÃ¨de, on conclue statistiquement que la taille augmente avec lâ€™Ã¢ge (puisque la pente est positive et et \\(p&lt;0.05\\)). Mais cette augmentation â€œstatistiqueâ€ de la taille avec lâ€™Ã¢ge ne donne pas dâ€™informations sur la diffÃ©rence de taille entre les jeunes et vieux individus. La pente et un graphique sont plus informatifs Ã  ce sujet que la valeur p. La pente (dans lâ€™espace log-log) est de 0.34. Cela veut dire que pour chaque unitÃ© dâ€™accroissement de X (log10(age)), il y a une augmentation de 0.34 unitÃ©s de log10(fklngth). En dâ€™autres mots, quand lâ€™Ã¢ge est multipliÃ© par 10, la longueur est multipliÃ©e environ par 2 (100.34 = 2.19). Donc la longueur des esturgeons augmente plus lentement que leur Ã¢ge. La valeur de la pente (0.34) est un estimÃ© de la taille de lâ€™effet de lâ€™Ã¢ge sur la longueur.\nIl est aussi important dâ€™estimer lâ€™intervalle de confiance sur la pente pour pouvoir estimer si lâ€™intervalle nâ€™inclus ou non que des valeurs biologiquement importantes. Cela peut Ãªtre fait simplement avec la fonction confint().\n\nconfint(RegModele.2)\n\n                2.5 %   97.5 %\n(Intercept) 1.1377151 1.246270\nlog10(age)  0.2976433 0.384068\n\n\nLâ€™intervalle de confiance Ã  95% de la pente est 0.29-0.38. L,intervalle de confiance est assez Ã©troit et Ã©loignÃ© de zÃ©ro.\n\n9.9.1 Puissance de dÃ©tecter une pente donnÃ©e\nPour les calculs de puissance avec G*Power vous devrez cependant utiliser une autre mÃ©trique de la taille de lâ€™effet, calculÃ©e Ã  partir de la pente, de son erreur-type, et de la taille de lâ€™Ã©chantillon (ce qui facilite les calculs pour G*Power, mais malheureusement pas pour vous) La mÃ©trique (d) est calculÃ©e comme: \\[ d = \\frac{b}{s_b\\sqrt{n-k-1}} \\] oÃ¹ \\(b\\) est lâ€™estimÃ© de la pente, \\(s_b\\) est lâ€™erreur type de la pente, \\(n\\) est le nombre dâ€™observations, et \\(k\\) est le nombre de variables indÃ©pendantes (1 pour la rÃ©gression linÃ©aire simple).\nVous pouvez calculer approximativement la puissance avec G*Power pour une valeur de pente que vous jugez assez grande pour mÃ©riter dâ€™Ãªtre dÃ©tectÃ©e. Choisissez Tests: Means: One group: difference from constant, lÃ , vous devrez remplacer la valeur de \\(b\\) dans lâ€™Ã©quation pour la taille dâ€™effet (d) par la pente que vous voudriez dÃ©tecter, mais utiliser lâ€™erreur type calculÃ©e Ã  partir de vos donnÃ©es.\nPar exemple, supposons que les ichthyologues considÃ¨rent quâ€™une pente de 0.1 pour la relation entre log10(fklngth) et log10(age) est signifiante biologiquement, et quâ€™ils dÃ©sirent estimer la puissance de dÃ©tecter une telle pente Ã  partir dâ€™un Ã©chantillon de 20 esturgeons. Les rÃ©sultats de la rÃ©gression log-log nous fournissent ce dont on a besoin:\n\nsummary(RegModele.2)\n\n\nCall:\nlm(formula = log10(fklngth) ~ log10(age), data = esturgeon.male)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.082794 -0.016837 -0.000719  0.021102  0.087446 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  1.19199    0.02723   43.77   &lt;2e-16 ***\nlog10(age)   0.34086    0.02168   15.72   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.03015 on 73 degrees of freedom\n  (5 observations deleted due to missingness)\nMultiple R-squared:  0.772, Adjusted R-squared:  0.7688 \nF-statistic: 247.1 on 1 and 73 DF,  p-value: &lt; 2.2e-16\n\n\nLâ€™erreur-type de la pente est 0.02168. Il y avait 75 poissons (n=75) dans lâ€™Ã©chantillon de dÃ©part. On peut donc calculer la mÃ©trique de taille dâ€™effet pour G*Power \\[ d = \\frac{b}{s_b\\sqrt{n-k-1}} = \\frac{0.1}{0.02168\\sqrt{74-1-1}}=0.54\\]\nArmÃ©s de cette taille dâ€™effet (une pente prÃ©sumÃ©e de 0.1 et une variabilitÃ© autour de la rÃ©gression similaire Ã  la rÃ©gression de fklngth vs age), choisissez Tests: Means: One group: difference from constant, et entrez la valeur calculÃ©e de d, alpha, et lâ€™effectif de lâ€™Ã©chantillon pour calculer la puissance.\n\n\n\n\n\n\n\nFigureÂ 9.11: Analyse de puissance pour N = 20 et pente = 0.1\n\n\n\n\nDans R, il est possible de faire cette analyse avec le code suivant:\n\nlibrary(pwr)\n\n# analyse de puissance\npwr.t.test(n = 20, d = 0.54, sig.level = 0.05, type = \"one.sample\")\n\n\n     One-sample t test power calculation \n\n              n = 20\n              d = 0.54\n      sig.level = 0.05\n          power = 0.6299804\n    alternative = two.sided\n\n\nLa puissance de dÃ©tecter une pente comme Ã©tant statistiquement significative (au niveau alpha), si la pente est 0.1, que la variabilitÃ© rÃ©siduelle autour de la rÃ©gression est semblable Ã  celle de notre Ã©chantillon (ce qui revient Ã  une taille dâ€™effet de 0.54, pour un Ã©chantillon de 20 esturgeons et alpha=0.05) est de 0.629. Seulement environ 2/3 des Ã©chantillons de cette taille dÃ©tecteraient un effet significatif de lâ€™Ã¢ge sur fklngth.\n\n9.9.2 Effectif requis pour atteindre une puissance dÃ©sirÃ©e (test A-priori)\nPour estimer la taille dâ€™Ã©chantillon (effectif) requis pour avoir une puissance de 99% de dÃ©tecter un effet de lâ€™Ã¢ge si la pente est 0.1 (sur une Ã©chelle log-log), avec alpha=0.05, on utilise la mÃªme valeur de d (0.54):\n\n\n\n\n\n\n\nFigureÂ 9.12: Analyse Ã  priori pour dÃ©terminer la taille dâ€™Ã©chantillon pour une puissance de 0.99\n\n\n\n\nDans R, il est possible de faire cette analyse avec le code suivant:\n\nlibrary(pwr)\n\n# analyse de puissance\npwr.t.test(n = 65, d = 0.54, sig.level = 0.05, type = \"one.sample\")\n\n\n     One-sample t test power calculation \n\n              n = 65\n              d = 0.54\n      sig.level = 0.05\n          power = 0.9900297\n    alternative = two.sided\n\n\nEn augmentant la taille de lâ€™Ã©chantillon Ã  65, selon le mÃªme scÃ©nario que prÃ©cÃ©demment, la puissance augmente Ã  99%.",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>CorrÃ©lation et rÃ©gression linÃ©aire simple</span>"
    ]
  },
  {
    "objectID": "31-reg_lin.html#bootstrap-en-rÃ©gression-simple-avec-r",
    "href": "31-reg_lin.html#bootstrap-en-rÃ©gression-simple-avec-r",
    "title": "\n9Â  CorrÃ©lation et rÃ©gression linÃ©aire simple\n",
    "section": "\n9.10 Bootstrap en rÃ©gression simple avec R",
    "text": "9.10 Bootstrap en rÃ©gression simple avec R\nUn test non paramÃ©trique pour lâ€™ordonnÃ©e Ã  lâ€™origine et la pente dâ€™une rÃ©gression simple peut Ãªtre effectuÃ© par bootstrap.\n\n# charger le paquet boot\nlibrary(boot)\n# obtenir les poids de rÃ©gression\nbs &lt;- function(formula, data, indices) {\n  d &lt;- data[indices, ] # Permets Ã  boot de sÃ©lectionner les Ã©chantillons\n  fit &lt;- lm(formula, data = d)\n  return(coef(fit))\n}\n# bootstrap avec 1000 rÃ©plications\nresults &lt;- boot(\n  data = esturgeon.male,\n  statistic = bs,\n  R = 1000, formula = log10(fklngth) ~ log10(age)\n)\n# RÃ©sultats\nresults\n\n\nORDINARY NONPARAMETRIC BOOTSTRAP\n\n\nCall:\nboot(data = esturgeon.male, statistic = bs, R = 1000, formula = log10(fklngth) ~ \n    log10(age))\n\n\nBootstrap Statistics :\n     original        bias    std. error\nt1* 1.1919926  0.0010297189  0.03344522\nt2* 0.3408557 -0.0006201354  0.02643693\n\n\nPour chaque paramÃ¨tre du modÃ¨le (ici lâ€™ordonnÃ©e Ã  lâ€™origine est appelÃ©e t1* et la pente de la rÃ©gression t2*), R imprime :\n\n\noriginal la valeur estimÃ©e sur tout lâ€™Ã©chantillon\n\nbias la diffÃ©rence entre la valeur moyenne des estimÃ©s par bootstrap et la valeur originale sur tout lâ€™Ã©chantillon\n\nstd. error lâ€™erreur-type de lâ€™estimÃ© bootstrap\n\n\npar(mfrow = c(2, 2))\nplot(results, index = 1) # intercept\nplot(results, index = 2) # log10(age)\n\n\n\n\n\n\nFigureÂ 9.13: RÃ©sultats du test de bootstrap non paramÃ©trique\n\n\n\n\n\n\n\n\n\nFigureÂ 9.14: RÃ©sultats du test de bootstrap non paramÃ©trique\n\n\n\n\nLa distribution des estimÃ©s obtenus par bootstrap est assez normale dans cet exemple, avec de petites dÃ©viations dans les queue de la distribution (lÃ  oÃ¹ Ã§a compte pour les intervalles de confianceâ€¦). On pourrait utiliser lâ€™erreur-type des estimÃ©s bootstrap pour calculer un intervalle de confiance symÃ©trique (moyenne +- t E.T.). Cependant, comme R peut facilement calculer des intervalles de confiance qui corrigent pour le biais (BCa: â€œBias-Corrected Adjustedâ€) ou encore des intervalle empiriques Ã  partir des distributions simulÃ©es (mÃ©thode Percentile) il peut Ãªtre aussi simple de les calculer selon les 3 mÃ©thodes:\n\n# interval de confiance pour l'ordonnÃ©e Ã  l'origine\nboot.ci(results, type = \"all\", index = 1)\n\nWarning in boot.ci(results, type = \"all\", index = 1): bootstrap variances\nneeded for studentized intervals\n\n\nBOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS\nBased on 1000 bootstrap replicates\n\nCALL : \nboot.ci(boot.out = results, type = \"all\", index = 1)\n\nIntervals : \nLevel      Normal              Basic         \n95%   ( 1.125,  1.257 )   ( 1.126,  1.254 )  \n\nLevel     Percentile            BCa          \n95%   ( 1.130,  1.258 )   ( 1.123,  1.253 )  \nCalculations and Intervals on Original Scale\n\n\n\n# intervalle de confiance pour la pente\nboot.ci(results, type = \"all\", index = 2)\n\nWarning in boot.ci(results, type = \"all\", index = 2): bootstrap variances\nneeded for studentized intervals\n\n\nBOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS\nBased on 1000 bootstrap replicates\n\nCALL : \nboot.ci(boot.out = results, type = \"all\", index = 2)\n\nIntervals : \nLevel      Normal              Basic         \n95%   ( 0.2897,  0.3933 )   ( 0.2896,  0.3923 )  \n\nLevel     Percentile            BCa          \n95%   ( 0.2894,  0.3921 )   ( 0.2941,  0.3955 )  \nCalculations and Intervals on Original Scale\n\n\nIci, les 4 types dâ€™intervalles de confiance que R a calculÃ© sont essentiellement semblables. Si les donnÃ©es avaient violÃ© plus sÃ©vÃ¨rement les conditions dâ€™application de la rÃ©gression (normalitÃ©, homoscedasticitÃ©), alors les diffÃ©rentes mÃ©thodes (Normal, Basic, Percentile, et BCa) auraient divergÃ© un peu plus. Lequel choisir alors? BCa est celui qui est prÃ©fÃ©rÃ© de la majoritÃ© des praticiens, prÃ©sentement.",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>CorrÃ©lation et rÃ©gression linÃ©aire simple</span>"
    ]
  },
  {
    "objectID": "32-t_test.html",
    "href": "32-t_test.html",
    "title": "\n10Â  Comparaison de deux Ã©chantillons\n",
    "section": "",
    "text": "10.1 Paquets R et donnÃ©es requises\nPour ce laboratoire, vous aurez besoin de :\nlibrary(car)\nlibrary(lmtest)\nlibrary(boot)\nlibrary(lmPerm)\nlibrary(ggplot2)\nesturgeon &lt;- read.csv(\"data/sturgeon.csv\")\ncrane &lt;- read.csv(\"data/skulldat_2020.csv\")",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Comparaison de deux Ã©chantillons</span>"
    ]
  },
  {
    "objectID": "32-t_test.html#set-t",
    "href": "32-t_test.html#set-t",
    "title": "\n10Â  Comparaison de deux Ã©chantillons\n",
    "section": "",
    "text": "Paquets R:\n\n\ncar ğŸ“¦\n\n\nlmtest ğŸ“¦\n\n\nboot ğŸ“¦\n\n\nlmPerm ğŸ“¦\n\n\n\nJeux de donnÃ©es\n\nâ€œsturgeon.csvâ€\nâ€œskulldat_2020.csvâ€",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Comparaison de deux Ã©chantillons</span>"
    ]
  },
  {
    "objectID": "32-t_test.html#examen-visuel-des-donnÃ©es",
    "href": "32-t_test.html#examen-visuel-des-donnÃ©es",
    "title": "\n10Â  Comparaison de deux Ã©chantillons\n",
    "section": "\n10.2 Examen visuel des donnÃ©es",
    "text": "10.2 Examen visuel des donnÃ©es\nUne des premiÃ¨res Ã©tapes dans toute analyse de donnÃ©es est lâ€™examen visuel des donnÃ©es par des graphiques et statistiques sommaires pour avoir une idÃ©e des distributions sous-jacentes, des valeurs extrÃªmes et des tendances dans vos donnÃ©es. Cela commence souvent avec des graphiques de vos donnÃ©es (histogrammes, diagrammes de probabilitÃ©, boÃ®te Ã  moustache, etc.) qui vous permettent dâ€™Ã©valuer si vos donnÃ©es sont distribuÃ©es normalement (c-Ã -d, suivent une distribution normale), si elles sont corrÃ©lÃ©es les unes aux autres, ou sâ€™il y a des valeurs suspectes dans le jeu de donnÃ©es.\nSupposons que lâ€™on veuille comparer la distribution des taille des esturgeons de The Pas et Cumberland House. La variable fklngth dans le jeu de donnÃ©es sturgeon.csv reprÃ©sente la longueur (en cm) de chaque poisson (mesurÃ©e de lâ€™extrÃ©mitÃ© de la tÃªte Ã  la base de la fourche de la nageoire caudale). Pour commencer, examinons si cette variable est normalement distribuÃ©e. On ne va pas tester pour la normalitÃ© Ã  ce stade-ci ; la prÃ©somption de normalitÃ© dans les analyses paramÃ©triques sâ€™applique aux rÃ©sidus et non aux donnÃ©es brutes. Cependant, si les donnÃ©es brutes ne sont pas normales, vous avez, en gÃ©nÃ©ral, une trÃ¨s bonne raison de soupÃ§onner que les rÃ©sidus ne suivront pas non plus une distribution normale.\nUne excellente faÃ§on de comparer visuellement une distribution Ã  la distribution normale est de superposer un histogramme des donnÃ©es observÃ©es Ã  une courbe normale. Pour ce faire, il faut procÃ©der en deux Ã©tapes :\n\nIndiquer Ã  R que nous voulons crÃ©er un histogramme superposÃ© Ã  une courbe normale\nSpÃ©cifier quâ€™on veut que les graphiques soient faits pour les deux sites\n\n\nEn utilisant les donnÃ©es de sturgeon.csv, gÃ©nÃ©rez les histogrammes et les approximations des distributions normales ajustÃ©es aux donnÃ©es de fklngth Ã  The Pas et Cumberland House.\n\n\n# Utilisez le jeu de donnÃ©es \"sturgeon\" pour crÃ©er le graphique appelÃ© \"mongraph\".\n# Et dÃ©finissez l'axe x, correspondant Ã  \"fklngth\".\nmongraph &lt;- ggplot(data = esturgeon, \n                   aes(x = fklngth)) +\n  xlab(\"Longueur Ã  la fourche (cm)\")\n\n# Ajoutez des Ã©lÃ©ments au graphique (ggplot) \"mongraph\".\nmongraph &lt;- mongraph +\n  geom_density() + # Ajoutez la densitÃ© des donnÃ©es, lissÃ©e.\n  geom_rug() + # Ajoutez un \"tapis\" (barres en bas du graphe).\n  geom_histogram(aes(y = ..density..),\n                 color = \"black\", alpha = 0.3) +  # Ajoutez un histogramme noir, semi transparent.\n  stat_function(fun = dnorm,\n                args = list(mean = mean(esturgeon$fklngth),\n                            sd = sd(esturgeon$fklngth)),\n                color = \"red\") # Ajoutez une courbe normale en rouge, Ã  partir de la moyenne et Ã©cart-type de \"fklngth\".\n\nmongraph + facet_grid(. ~ location) # Affichez le graphe, par site.\n\n\n\n\n\n\nFigureÂ 10.1: Distribution de la longueur des esturgeons par site.\n\n\n\n\nExaminez ce graphique et essayez de dÃ©terminer si ces deux Ã©chantillons sont normalement distribuÃ©s. Ã€ mon avis, cette variable est approximativement normalement distribuÃ©e dans les deux Ã©chantillons.\nPuisque ce qui nous intÃ©resse est de comparer la taille des poissons de deux sites diffÃ©rents, câ€™est probablement une bonne idÃ©e de crÃ©er un graphique qui compare les deux groupes de donnÃ©es. Une boÃ®te Ã  moustache (â€œBox plotâ€) convient trÃ¨s bien pour cette tÃ¢che.\n\nTracez un boxplot de fklngth groupÃ© par location. Que concluez-vous quant Ã  la diffÃ©rence entre les deux sites?\n\n\nggplot(data = esturgeon, aes(x = location, \n                            y = fklngth)) +\n  geom_boxplot(notch = TRUE)\n\n\n\n\n\n\nFigureÂ 10.2: Boxplot de la longueur des esturgeons par site.\n\n\n\n\nIl nâ€™y a pas de grande diffÃ©rence de taille entre les deux sites, mais la taille des poissons Ã  The Pas est plus variable, ayant une plus large Ã©tendue de taille et des valeurs extrÃªmes (dÃ©finies par les valeurs qui sont &gt; 1.5 * lâ€™Ã©tendue interquartile) Ã  chaque bout de la distribution.",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Comparaison de deux Ã©chantillons</span>"
    ]
  },
  {
    "objectID": "32-t_test.html#comparer-les-moyennes-de-deux-Ã©chantillons-indÃ©pendants",
    "href": "32-t_test.html#comparer-les-moyennes-de-deux-Ã©chantillons-indÃ©pendants",
    "title": "\n10Â  Comparaison de deux Ã©chantillons\n",
    "section": "\n10.3 Comparer les moyennes de deux Ã©chantillons indÃ©pendants",
    "text": "10.3 Comparer les moyennes de deux Ã©chantillons indÃ©pendants\nÃ‰prouvez lâ€™hypothÃ¨se nulle (H0) : La longueur Ã  la fourche nâ€™est pas diffÃ©rente entre The Pas et Cumberland House de 3 maniÃ¨res diffÃ©rentes :\n\nTest paramÃ©triques supposant des variances Ã©gales\nTest paramÃ©triques supposant des variances diffÃ©rentes\nTest non-paramÃ©trique (pas de conditions dâ€™applications sur la distribution et la variance)\n\nQue concluez-vous?\n\n# Test t supposant des variances Ã©gales.\nt.test(fklngth ~ location,\n       data = esturgeon,\n       alternative = \"two.sided\",\n       var.equal = TRUE)\n\n\n    Two Sample t-test\n\ndata:  fklngth by location\nt = 2.1359, df = 184, p-value = 0.03401\nalternative hypothesis: true difference in means between group CUMBERLAND and group THE_PAS is not equal to 0\n95 percent confidence interval:\n 0.1308307 3.2982615\nsample estimates:\nmean in group CUMBERLAND    mean in group THE_PAS \n                45.08439                 43.36984 \n\n\n\n# Test t supposant des variances diffÃ©rentes.\nt.test(fklngth ~ location,\n       data = esturgeon,\n       alternative = \"two.sided\",\n       var.equal = FALSE)\n\n\n    Welch Two Sample t-test\n\ndata:  fklngth by location\nt = 2.2201, df = 169.8, p-value = 0.02774\nalternative hypothesis: true difference in means between group CUMBERLAND and group THE_PAS is not equal to 0\n95 percent confidence interval:\n 0.1900117 3.2390804\nsample estimates:\nmean in group CUMBERLAND    mean in group THE_PAS \n                45.08439                 43.36984 \n\n\n\n# Test non paramÃ©trique.\nwilcox.test(fklngth ~ location,\n            data = esturgeon,\n            alternative = \"two.sided\")\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  fklngth by location\nW = 4973, p-value = 0.06296\nalternative hypothesis: true location shift is not equal to 0\n\n\nEn se fiant au test de t, on rejette donc lâ€™hypothÃ¨se nulle. Il y a une diffÃ©rence significative entre les deux moyennes des longueurs Ã  la fourche selon le site.\nNotez que si lâ€™on se fie au test de Wilcoxon, on ne peut pas rejeter lâ€™hypothÃ¨se nulle. Les deux tests mÃ¨nent donc Ã  des conclusions contradictoires. La diffÃ©rence significative obtenue par le test de t peut provenir en partie dâ€™une violation des conditions dâ€™application du test (normalitÃ© et homoscÃ©dasticitÃ©). Dâ€™un autre cÃ´tÃ©, lâ€™absence de diffÃ©rence significative selon le test de Wilcoxon pourrait Ãªtre due au fait que, pour un effectif donnÃ©, la puissance du test non paramÃ©trique est infÃ©rieure Ã  celle du test paramÃ©trique correspondant. Compte tenu 1) des valeurs de p obtenues pour les deux tests, et 2) le fait que pour des grands Ã©chantillons (des effectifs de 84 et 101 sont considÃ©rÃ©s grands) le test de t est considÃ©rÃ© robuste, il est raisonnable de rejeter lâ€™hypothÃ¨se nulle.\nAvant dâ€™accepter les rÃ©sultats du test de t et de rejeter lâ€™hypothÃ¨se nulle quâ€™il nâ€™y a pas de diffÃ©rences de taille entre les deux sites, il est important de dÃ©terminer si les donnÃ©es remplissent les conditions de normalitÃ© des rÃ©sidus et dâ€™Ã©galitÃ© des variances. Lâ€™examen prÃ©liminaire suggÃ©rait que les donnÃ©es sont Ã  peu prÃ¨s normales mais quâ€™il y avait peut-Ãªtre des problÃ¨mes avec les variances (puisque lâ€™Ã©tendue des donnÃ©es pour The Pas Ã©tait beaucoup plus grande que celle pour Cumberland). On peut examiner ces conditions dâ€™application plus en dÃ©tail en examinant les rÃ©sidus dâ€™un modÃ¨le linÃ©aire et en utilisant les graphiques diagnostiques:\n\nm1 &lt;- lm(fklngth ~ location, data = esturgeon)\npar(mfrow = c(2, 2))\nplot(m1)\n\n\n\n\n\n\nFigureÂ 10.3: Examen visuel des conditions dâ€™application du modÃ¨le linÃ©aire.\n\n\n\n\nLe premier graphique ci-dessus montre comment les rÃ©sidus se distribuent autour des valeurs prÃ©dites (les moyennes) pour chaque site et permet de juger si il semble y avoir un problÃ¨me de normalitÃ© ou dâ€™homoscÃ©dasticitÃ©. Si les variances Ã©taient Ã©gales dans les deux sites, lâ€™Ã©tendue verticale des rÃ©sidus tendrait Ã  Ãªtre la mÃªme. Sur le graphique, on voit que lâ€™Ã©tendue des rÃ©sidus est plus grande Ã  gauche (le site oÃ¹ la taille moyenne est la plus faible), ce qui suggÃ¨re un possible problÃ¨me dâ€™homogÃ©nÃ©itÃ© des variances. On peut tester cela plus formellement en comparant la moyenne de la valeur absolue des rÃ©sidus.(on y reviendra; câ€™est le test de Levene).\nLe deuxiÃ¨me graphique est un graphique de probabilitÃ© (graphique Q-Q) des rÃ©sidus. Comme ici, les points tombent prÃ¨s de la diagonale, il ne semble pas y avoir de problÃ¨me important avec la normalitÃ©. On peut faire un test formel de la condition de normalitÃ© : le test de Shapiro-Wilk:\n\nshapiro.test(residuals(m1))\n\n\n    Shapiro-Wilk normality test\n\ndata:  residuals(m1)\nW = 0.97469, p-value = 0.001857\n\n\nHummmâ€¦ Ce test indique que les rÃ©sidus ne sont pas normaux, ce qui contredit notre Ã©valuation visuelle. Cependant, puisque (a) la distribution des rÃ©sidus ne sâ€™Ã©loigne pas beaucoup de la normalitÃ© et (b) le nombre dâ€™observations Ã  chaque site est raisonnablement grand (i.e.Â &gt;30), nul besoin dâ€™Ãªtre trop inquiet quant Ã  lâ€™impact de cette violation de normalitÃ© sur la fiabilitÃ© du test.\nQuâ€™en est-il de lâ€™Ã©galitÃ© des variances?\n\nlibrary(car)\nleveneTest(m1)\n\nWarning in leveneTest.default(y = y, group = group, ...): group coerced to\nfactor.\n\n\nLevene's Test for Homogeneity of Variance (center = median)\n       Df F value    Pr(&gt;F)    \ngroup   1  11.514 0.0008456 ***\n      184                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nbptest(m1)\n\n\n    studentized Breusch-Pagan test\n\ndata:  m1\nBP = 8.8015, df = 1, p-value = 0.00301\n\n\nLes rÃ©sultats qui prÃ©cÃ©dents proviennent de 2 des tests disponibles en R (dans les package car ğŸ“¦ et lmtest ğŸ“¦) qui Ã©prouvent lâ€™hypothÃ¨se de lâ€™Ã©galitÃ© des variances dans des tests de t ou des modÃ¨les linÃ©aires ayant uniquement des variables indÃ©pendantes discontinues ou catÃ©goriques. Il est inutile de faire les 2 tests. Si ils sont prÃ©sentÃ©s ici, câ€™est que ces 2 tests sont usuels et quâ€™il nâ€™y a pas consensus quant au meilleur des deux. Le test de Levene est le plus connu et utilisÃ©. Il compare la moyenne des valeurs absolues des rÃ©sidus dans les deux groupes. Le test Breusch-Pagan a lâ€™avantage dâ€™Ãªtre applicable Ã  une plus large gamme de modÃ¨les linÃ©aires (il peut Ãªtre utilisÃ© Ã©galement avec des variables indÃ©pendantes continues, comme en rÃ©gression). Ici, les deux tests mÃ¨nent Ã  la mÃªme conclusion: la variance diffÃ¨re entre les deux sites.\nSur la base de ces rÃ©sultats, on peut conclure quâ€™il y a des Ã©lÃ©ments (mÃªme si faibles) pour rejeter lâ€™hypothÃ¨se nulle quâ€™il nâ€™y a pas de diffÃ©rence dans la taille de poissons entre les deux sites. On a utilisÃ© une modification du test de t pour tenir compte du fait que les variances ne sont pas Ã©gales et nous sommes satisfaits que la condition de normalitÃ© des rÃ©sidus a Ã©tÃ© remplie. Alors, â€œfklngthâ€ Ã  Cumberland est plus grande que â€œfklngthâ€ Ã  The Pas.",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Comparaison de deux Ã©chantillons</span>"
    ]
  },
  {
    "objectID": "32-t_test.html#bootstrap-et-tests-de-permutation-pour-comparer-deux-moyennes",
    "href": "32-t_test.html#bootstrap-et-tests-de-permutation-pour-comparer-deux-moyennes",
    "title": "\n10Â  Comparaison de deux Ã©chantillons\n",
    "section": "\n10.4 Bootstrap et tests de permutation pour comparer deux moyennes",
    "text": "10.4 Bootstrap et tests de permutation pour comparer deux moyennes\n\n10.4.1 Bootstrap\nLe bootstrap et les tests de permutation peuvent Ãªtre utilisÃ©s pour comparer les moyennes (ou dâ€™autres statistiques). Le principe gÃ©nÃ©ral est simple et peut Ãªtre effectuÃ© de diverses faÃ§ons. Ici on utilise certains des outils disponibles et le fait quâ€™une comparaison de moyenne peut Ãªtre reprÃ©sentÃ©e par un modÃ¨le linÃ©aire. On pourra utiliser un programme similaire plus tard quand on ajustera des modÃ¨les plus complexes (mais plus amusants !).\n\nlibrary(boot)\n\nLa premiÃ¨re section sert Ã  dÃ©finir une fonction (ici appelÃ©e bs) qui extraie les coefficients dâ€™un modÃ¨le ajustÃ© :\n\n# Fonction pour extraire les coefficients d'un modÃ¨le pour chaque itÃ©rations.\nbs &lt;- function(formule, data, indices) {\n  d &lt;- data[indices, ]\n  fit &lt;- lm(formule, data = d)\n  return(coef(fit))\n}\n\nLa deuxiÃ¨me section avec la commande boot() fait le gros du travail: on prend les donnÃ©es dans â€œsturgeonâ€, on les bootstrap \\(R = 1000\\) fois, et chaque fois on ajuste le modÃ¨le fklngth vs location et on garde les valeurs calculÃ©es par la fonction bs.\n\n# bootstrap avec 1000 rÃ©plications.\nresultats &lt;- boot(data = esturgeon, statistic = bs, R = 1000,\n                formule = fklngth ~ location)\n# Affichez les rÃ©sultats.\nresultats\n\n\nORDINARY NONPARAMETRIC BOOTSTRAP\n\n\nCall:\nboot(data = esturgeon, statistic = bs, R = 1000, formule = fklngth ~ \n    location)\n\n\nBootstrap Statistics :\n     original       bias    std. error\nt1* 45.084391 -0.010974135   0.4225382\nt2* -1.714546  0.004510085   0.7645004\n\n\nOn obtient les estimÃ©s originaux pour les deux coefficients du modÃ¨le: la moyenne pour le premier (alphabÃ©tiquement) site soit Cumberland, et la diffÃ©rence entre les deux moyennes Ã  Cumberland et The Pas. Câ€™est ce second paramÃ¨tre, la diffÃ©rence entre les moyennes, qui nous intÃ©resse.\n\nplot(resultats, index = 2)\n\n\n\n\n\n\nFigureÂ 10.4: NormalitÃ© des estimÃ©s de la diffÃ©rence des moyennes par bootstrap.\n\n\n\n\n\n# Calculez l'intervalle de confiance Ã  95%.\nboot.ci(resultats, type = \"bca\", index = 2)\n\nBOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS\nBased on 1000 bootstrap replicates\n\nCALL : \nboot.ci(boot.out = resultats, type = \"bca\", index = 2)\n\nIntervals : \nLevel       BCa          \n95%   (-3.220, -0.129 )  \nCalculations and Intervals on Original Scale\n\n\nComme lâ€™intervalle de confiance nâ€™inclue pas 0, on conclue que les moyennes ne sont pas les mÃªmes.\n\n10.4.2 Permutation\nLes tests de permutation pour les modÃ¨les linÃ©aires peuvent Ãªtre effectuÃ©s Ã  lâ€™aide du package lmPerm ğŸ“¦ :\n\nm1Perm &lt;- lmp(fklngth ~ location,\n              data = esturgeon,\n              perm = \"Prob\")\n\n[1] \"Settings:  unique SS \"\n\n\nLa fonction lmp() fait tout le travail pour nous. Ici, cette fonction est effectuÃ©e avec lâ€™option perm pour choisir la rÃ¨gle utilisÃ©e pour stopper les calculs. Lâ€™option â€œProbâ€ arrÃªte les permutations quand la dÃ©viation standard estimÃ©e pour la p-valeur tombe sous un seuil dÃ©terminÃ©. Câ€™est lâ€™une des nombreuses rÃ¨gles qui peuvent possiblement Ãªtre utilisÃ©es pour ne faire les permutations que sur un sous-ensemble des permutations possibles (ce qui prendrait souvent trÃ¨Ã¨Ã¨Ã¨Ã¨s longtemps).\n\nsummary(m1Perm)\n\n\nCall:\nlmp(formula = fklngth ~ location, data = sturgeon, perm = \"Prob\")\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-18.40921  -3.75370  -0.08439   3.76598  23.48055 \n\nCoefficients:\n          Estimate Iter Pr(Prob)  \nlocation1   0.8573 3150   0.0308 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.454 on 184 degrees of freedom\nMultiple R-Squared: 0.02419,    Adjusted R-squared: 0.01889 \nF-statistic: 4.562 on 1 and 184 DF,  p-value: 0.03401 \n\n\n\n\nIter: la rÃ¨gle a limitÃ© le calcul Ã  5000 permutations. Notez que ce nombre va varier Ã  chaque fois que vous ferez tourner ce code. Ce sont des rÃ©sultats obtenus par permutations alÃ©atoires, donc vous devez vous attendre Ã  de la variabilitÃ©. .\n\nPr(Prob): La p-valeur estimÃ©e pour H0 est 0.0172. La diffÃ©rence observÃ©e pour â€œfklngthâ€ entre les deux sites Ã©tait plus grande que les valeurs permutÃ©es pour environ (1 - 0.0172= 98.3%) des 5000 permutations. Notez que 5000 permutations ce nâ€™est pas un si grand nombre de permutations que Ã§a, et donc les faibles valeurs de p ne sont pas trÃ¨s prÃ©cises. Si vous voulez des valeurs prÃ©cises de p, vous devrez faire plus de permutations. Vous pouvez ajuster 2 paramÃ¨tres: maxIter, le nombre maximal de permutations (dÃ©faut 5000) et Ca, le seuil de prÃ©cision dÃ©sirÃ© qui arrÃªte les permutations quand lâ€™erreur-type de p est plus petite que Ca*p (dÃ©faut=0.1)\n\nF-statistic: Le reste est la sortie standard pour un modÃ¨le ajustÃ© Ã  des donnÃ©es, avec le test paramÃ©trique. Ici, la p-valeur, prÃ©sumant que toutes les conditions dâ€™application sont remplies, est 0.034.",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Comparaison de deux Ã©chantillons</span>"
    ]
  },
  {
    "objectID": "32-t_test.html#comparer-les-moyennes-de-deux-Ã©chantillons-appariÃ©s",
    "href": "32-t_test.html#comparer-les-moyennes-de-deux-Ã©chantillons-appariÃ©s",
    "title": "\n10Â  Comparaison de deux Ã©chantillons\n",
    "section": "\n10.5 Comparer les moyennes de deux Ã©chantillons appariÃ©s",
    "text": "10.5 Comparer les moyennes de deux Ã©chantillons appariÃ©s\n\n\n\n\n\n\nAvertissement\n\n\n\nPour la section suivante veuillez tÃ©lÃ©charger le jeu de donnÃ©es skulldat_2020.csv qui a Ã©tÃ© rÃ©cemment ajoutÃ© sur Brightspace.\n\n\nDans certaines expÃ©riences les mÃªmes individus sont mesurÃ©s deux fois, par exemple avant et aprÃ¨s un traitement ou encore Ã  deux moments au cours de leur dÃ©veloppement. Les mesures obtenues lors de ces deux Ã©vÃ¨nements ne sont donc pas indÃ©pendantes, et des comparaisons de ces mesures appariÃ©es doivent Ãªtre faites.\nLe jeu de donnÃ©es skulldat_2020.csv contient des mesures de la partie infÃ©rieure du visage de jeunes filles dâ€™AmÃ©rique du Nord prises Ã  5 ans, puis Ã  6 ans (donnÃ©es de Newman and Meredith, 1956).\n\nPour dÃ©buter, Ã©prouvons lâ€™hypothÃ¨se que la largeur de la figure est la mÃªme Ã  5 ans et Ã  6 ans en assumant que les mesures viennent dâ€™Ã©chantillons indÃ©pendants.\n\n\ncrane &lt;- read.csv(\"data/skulldat_2020.csv\")\nt.test(width ~ age,\n       data = crane,\n       alternative = \"two.sided\")\n\n\n    Welch Two Sample t-test\n\ndata:  width by age\nt = -1.7812, df = 27.93, p-value = 0.08576\nalternative hypothesis: true difference in means between group 5 and group 6 is not equal to 0\n95 percent confidence interval:\n -0.43002624  0.03002624\nsample estimates:\nmean in group 5 mean in group 6 \n       7.461333        7.661333 \n\n\nJusquâ€™Ã  maintenant, nous avons spÃ©cifiÃ© le test de t en utilisant une notation de type formule avec y ~ x oÃ¹ y est la variable pour laquelle on souhaite comparer les moyennes et x correspond Ã  une variable dÃ©finissant les groupes. Cela marche bien lorsque les donnÃ©es ne sont pas appariÃ©es et sont prÃ©sentÃ©es dans un format de type long oÃ¹ les donnÃ©es prise dans une mÃªme catÃ©gorie ou sur une mÃªme personne sont simplement les unes en-dessous des autres avec des colonnes indiquant lâ€™appartenance des mesures aux diffÃ©rentes catÃ©gories (voir la structure de crane par exemple) Dans le jeu de donnÃ©es crane, il y a 3 colonnes:\n\n\nwidth: largeur de la tÃªte\n\nage: age lors de la mesure\n\nid: identitÃ© de la personne\n\n\nhead(crane)\n\n  width age id\n1  7.33   5  1\n2  7.53   6  1\n3  7.49   5  2\n4  7.70   6  2\n5  7.27   5  3\n6  7.46   6  3\n\n\nQuand les donnÃ©es sont appariÃ©es, il faut indiquer comment elle doivent Ãªtre associÃ©es. Dans notre exemple, elles sont appariÃ©es par individu. Le format de donnÃ©es de type long indique cet appariement via la colonne id. Cependant, la fonction t.test ne permet pas de le prendre en compte. Il faut donc transformer les donnÃ©es en format de type large ou horizontale ou il y a une colonne diffÃ©rente pour chaque catÃ©gorie. Dans notre exemple, on veut un jeu de donnÃ©es avec une colonne de mesure par age et oÃ¹ chaque ligne correspond Ã  une personne diffÃ©rente. On peut modifier le format des donnÃ©es avec le code suivant.\n\ncrane_h &lt;- data.frame(id = unique(crane$id))\ncrane_h$width5 &lt;- crane$width[match(crane_h$id, crane$id) & crane$age == 5]\ncrane_h$width6 &lt;- crane$width[match(crane_h$id, crane$id) & crane$age == 6]\nhead(crane_h)\n\n  id width5 width6\n1  1   7.33   7.53\n2  2   7.49   7.70\n3  3   7.27   7.46\n4  4   7.93   8.21\n5  5   7.56   7.81\n6  6   7.81   8.01\n\n\nMaintenant, effectuons le test appariÃ© qui est appropriÃ©: Que conclure? Comment les rÃ©sultats diffÃ¨rent-ils de la premiÃ¨re analyse? Pourquoi?\n\nt.test(crane_h$width5, crane_h$width6,\n  alternative = \"two.sided\",\n  paired = TRUE\n)\n\n\n    Paired t-test\n\ndata:  crane_h$width5 and crane_h$width6\nt = -19.72, df = 14, p-value = 1.301e-11\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n -0.2217521 -0.1782479\nsample estimates:\nmean difference \n           -0.2 \n\n\nLa premiÃ¨re analyse a comme supposition que les deux Ã©chantillons de filles de 5 et 6 ans sont indÃ©pendants, alors que la deuxiÃ¨me analyse a comme supposition que la mÃªme fille a Ã©tÃ© mesurÃ©e deux fois, une fois Ã  5 ans, et la deuxiÃ¨me fois Ã  6 ans.\nNotez que, dans le premier cas, on accepte lâ€™hypothÃ¨se nulle, mais que le test appariÃ© rejette lâ€™hypothÃ¨se nulle. Donc, le test qui est appropriÃ© (le test appariÃ©) indique un effet trÃ¨s significatif de lâ€™Ã¢ge, mais le test inappropriÃ© suggÃ¨re que lâ€™Ã¢ge nâ€™importe pas. Câ€™est parce quâ€™il y a une trÃ¨s forte corrÃ©lation entre la largeur du visage Ã  5 et 6 ans:\n\ngraphcrane &lt;- ggplot(data = crane_h, aes(x = width5, y = width6)) +\n  geom_point() +\n  labs(x = \"Largeur du visage Ã  5 ans\", y = \"Largeur du visage Ã  6 ans\") +\n  geom_smooth() +\n  scale_fill_continuous(low = \"lavenderblush\", high = \"red\")\n\ngraphcrane\n\n\n\n\n\n\nFigureÂ 10.5: Relation entre la largeur du visage Ã  5 et 6 ans.\n\n\n\n\nAvec r = 0.9930841. En prÃ©sence dâ€™une si forte corrÃ©lation, lâ€™erreur-type de la diffÃ©rence appariÃ©e de largeur du visage entre 5 et 6 ans est beaucoup plus petite que lâ€™erreur-type de la diffÃ©rence entre la largeur moyenne Ã  5 ans et la largeur moyenne Ã  6 ans. Par consÃ©quent, la statistique t associÃ©e est beaucoup plus Ã©levÃ©e pour le test appariÃ©, la puissance du test est plus grande, et la valeur de p plus petite.\n\nRÃ©pÃ©tez lâ€™analyse en utilisant lâ€™alternative non paramÃ©trique, le test Wilcoxon rang-signÃ©s (signed-rank). (Que concluez-vous?\n\n\nwilcox.test(crane_h$width5, crane_h$width6,\n  alternative = \"two.sided\",\n  paired = TRUE\n)\n\nWarning in wilcox.test.default(crane_h$width5, crane_h$width6, alternative =\n\"two.sided\", : cannot compute exact p-value with ties\n\n\n\n    Wilcoxon signed rank test with continuity correction\n\ndata:  crane_h$width5 and crane_h$width6\nV = 0, p-value = 0.0007193\nalternative hypothesis: true location shift is not equal to 0\n\n\nDonc on tire la mÃªme conclusion quâ€™avec le test de t appariÃ© et on conclue quâ€™il y a des diffÃ©rences significatives entre la taille des crÃ¢nes de filles Ã¢gÃ©es de 5 et 6 ans (quelle surprise !).\nMais, attendez une minute ! On a utilisÃ© des tests bilatÃ©raux ici mais, compte tenu des connaissances sur la croissance des enfants, une hypothÃ¨se unilatÃ©rale serait prÃ©fÃ©rable. Ceci peut Ãªtre accommodÃ© en modifiant lâ€™option â€œalternativeâ€. On utilise lâ€™hypothÃ¨se alternative pour dÃ©cider entre â€œlessâ€ ou â€œgreaterâ€. Ici, si il y a une diffÃ©rence, on sâ€™attend Ã  ce que width5 sera infÃ©rieur Ã  width6, donc on utiliserait â€œlessâ€.\n\nt.test(crane_h$width5, crane_h$width6,\n  alternative = \"less\",\n  paired = TRUE\n)\n\n\n    Paired t-test\n\ndata:  crane_h$width5 and crane_h$width6\nt = -19.72, df = 14, p-value = 6.507e-12\nalternative hypothesis: true mean difference is less than 0\n95 percent confidence interval:\n       -Inf -0.1821371\nsample estimates:\nmean difference \n           -0.2 \n\nwilcox.test(crane_h$width5, crane_h$width6,\n  alternative = \"less\",\n  paired = TRUE\n)\n\nWarning in wilcox.test.default(crane_h$width5, crane_h$width6, alternative =\n\"less\", : cannot compute exact p-value with ties\n\n\n\n    Wilcoxon signed rank test with continuity correction\n\ndata:  crane_h$width5 and crane_h$width6\nV = 0, p-value = 0.0003597\nalternative hypothesis: true location shift is less than 0\n\n\nPour estimer la puissance dâ€™un test de t avec R, il faut utiliser la fonction power.t.test(). Il faut spÃ©cifier lâ€™argument type = \"paired\", utiliser la moyenne et lâ€™Ã©cart-type de la diffÃ©rence au sein des paires dans les arguments delta et sd.\n\ncrane_h$diff &lt;- crane_h$width6 - crane_h$width5\npower.t.test(n = 15,\n             delta = mean(crane_h$diff),\n             sd = sd(crane_h$diff),\n             type = \"paired\")\n\n\n     Paired t test power calculation \n\n              n = 15\n          delta = 0.2\n             sd = 0.03927922\n      sig.level = 0.05\n          power = 1\n    alternative = two.sided\n\nNOTE: n is number of *pairs*, sd is std.dev. of *differences* within pairs",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Comparaison de deux Ã©chantillons</span>"
    ]
  },
  {
    "objectID": "32-t_test.html#rÃ©fÃ©rences",
    "href": "32-t_test.html#rÃ©fÃ©rences",
    "title": "\n10Â  Comparaison de deux Ã©chantillons\n",
    "section": "\n10.6 RÃ©fÃ©rences",
    "text": "10.6 RÃ©fÃ©rences\nBumpus, H.C. (1898) The elimination of the unfit as illustrated by the introduced sparrow, Passer domesticus. Biological Lectures, Woods Hole Biology Laboratory, Woods Hole, 11 th Lecture: 209 - 226.\nNewman, K.J. and H.V. Meredith. (1956) Individual growth in skele- tal bigonial diameter during the childhood period from 5 to 11 years of age. Amer. J. Anat. 99: 157 - 187.",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Comparaison de deux Ã©chantillons</span>"
    ]
  },
  {
    "objectID": "33-anova.html",
    "href": "33-anova.html",
    "title": "\n11Â  ANOVA Ã  un critÃ¨re de classification\n",
    "section": "",
    "text": "11.1 Paquets et donnÃ©es requises pour le labo\nCe laboratoire nÃ©cessite:\nlibrary(ggplot2)\nlibrary(car)\nlibrary(multcomp)",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>11</span>Â  <span class='chapter-title'>ANOVA Ã  un critÃ¨re de classification</span>"
    ]
  },
  {
    "objectID": "33-anova.html#set-ano",
    "href": "33-anova.html#set-ano",
    "title": "\n11Â  ANOVA Ã  un critÃ¨re de classification\n",
    "section": "",
    "text": "les paquets R:\n\nggplot2\nmultcomp\ncar\n\n\nles fichiers de donnÃ©es\n\nDam10dat.csv",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>11</span>Â  <span class='chapter-title'>ANOVA Ã  un critÃ¨re de classification</span>"
    ]
  },
  {
    "objectID": "33-anova.html#anova-Ã -un-critÃ¨re-de-classification-et-comparaisons-multiples",
    "href": "33-anova.html#anova-Ã -un-critÃ¨re-de-classification-et-comparaisons-multiples",
    "title": "\n11Â  ANOVA Ã  un critÃ¨re de classification\n",
    "section": "\n11.2 ANOVA Ã  un critÃ¨re de classification et comparaisons multiples",
    "text": "11.2 ANOVA Ã  un critÃ¨re de classification et comparaisons multiples\nLâ€™ANOVA Ã  un critÃ¨re de classification est lâ€™analogue du test de t pour des comparaisons de moyennes de plus de deux Ã©chantillons. Les conditions dâ€™application du test sont essentiellement les mÃªmes, et lorsque appliquÃ© Ã  deux Ã©chantillons ce test est mathÃ©matiquement Ã©quivalent au test de t.\nEn 1961-1962, le barrage Grand Rapids Ã©tait construit sur la riviÃ¨re Saskatchewan en amont de Cumberland House. On croit que durant la construction plusieurs gros esturgeons restÃ¨rent prisonniers dans des sections peu profondes et moururent. Des inventaires de la population dâ€™esturgeons furent faits en 1954, 1958, 1965 et 1966. Au cours de ces inventaires, la longueur Ã  la fourche (frklngth) furent mesurÃ©es (pas nÃ©cessairement sur chaque poisson cependant). Ces donnÃ©es sont dans le fichier Dam10dat.csv.\n\n11.2.1 Visualiser les donnÃ©es\n\nÃ€ partir des donnÃ©es, vous devez dâ€™abord changer le type de donnÃ©e de la variable year, pour que R traite year comme une variable discontinue (factor) plutÃ´t que continue.\n\n\nDam10dat &lt;- read.csv(\"data/Dam10dat.csv\")\nDam10dat$year &lt;- as.factor(Dam10dat$year)\nstr(Dam10dat)\n\n'data.frame':   118 obs. of  21 variables:\n $ year    : Factor w/ 4 levels \"1954\",\"1958\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ fklngth : num  45 50 39 46 54.5 49 42.5 49 56 54 ...\n $ totlngth: num  49 NA 43 50.5 NA 51.7 45.5 52 60.2 58.5 ...\n $ drlngth : logi  NA NA NA NA NA NA ...\n $ drwght  : num  16 20.5 10 17.5 19.7 21.3 9.5 23.7 31 27.3 ...\n $ rdwght  : num  24.5 33 15.5 28.5 32.5 35.5 15.3 40.5 51.5 43 ...\n $ sex     : int  1 1 1 2 1 2 1 1 1 1 ...\n $ age     : int  24 33 17 31 37 44 23 34 33 47 ...\n $ lfkl    : num  1.65 1.7 1.59 1.66 1.74 ...\n $ ltotl   : num  1.69 NA 1.63 1.7 NA ...\n $ ldrl    : logi  NA NA NA NA NA NA ...\n $ ldrwght : num  1.2 1.31 1 1.24 1.29 ...\n $ lrdwght : num  1.39 1.52 1.19 1.45 1.51 ...\n $ lage    : num  1.38 1.52 1.23 1.49 1.57 ...\n $ rage    : int  4 6 3 6 7 7 4 6 6 7 ...\n $ ryear   : int  1954 1954 1954 1954 1954 1954 1954 1954 1954 1954 ...\n $ ryear2  : int  1958 1958 1958 1958 1958 1958 1958 1958 1958 1958 ...\n $ ryear3  : int  1966 1966 1966 1966 1966 1966 1966 1966 1966 1966 ...\n $ location: int  1 1 1 1 1 1 1 1 1 1 ...\n $ girth   : logi  NA NA NA NA NA NA ...\n $ lgirth  : logi  NA NA NA NA NA NA ...\n\n\n\nEnsuite, visualisez les donnÃ©es comme dans le labo pour les tests de t. CrÃ©ez un histogramme avec ligne de densitÃ© et un Box plot par annÃ©e. Que vous rÃ©vÃ¨lent ces donnÃ©es?\n\n\nmygraph &lt;- ggplot(Dam10dat, aes(x = fklngth)) +\n  labs(x = \"Fork length (cm)\") +\n  geom_density() +\n  geom_rug() +\n  geom_histogram(aes(y = ..density..),\n    color = \"black\",\n    alpha = 0.3\n  ) +\n  stat_function(\n    fun = dnorm,\n    args = list(\n      mean = mean(Dam10dat$fklngth),\n      sd = sd(Dam10dat$fklngth)\n    ),\n    color = \"red\"\n  )\n\n# display graph, by year\nmygraph + facet_wrap(~year, ncol = 2)\n\n\n\n\n\n\nFigureÂ 11.1: Distribution de la longueur des esturgeons par annÃ©e\n\n\n\n\n\nboxplot(fklngth ~ year, data = Dam10dat)\n\n\n\n\n\n\nFigureÂ 11.2: Boxplot de la longueur pas annÃ©ee\n\n\n\n\nIl semble que la taille des esturgeons est un peu plus petite aprÃ¨s la construction du barrage, mais les donnÃ©es sont trÃ¨s variables et les effets ne sont pas parfaitement clairs. Il y a peut-Ãªtre des problÃ¨mes de normalitÃ© avec les Ã©chantillons de 1954 et 1966, et il y a probablement des valeurs extrÃªmes dans les Ã©chantillons de 1958 et 1966. On va continuer en testant les conditions dâ€™application de lâ€™ANOVA. Il faut dâ€™abord faire lâ€™analyse et examiner les rÃ©sidus.\n\n11.2.2 VÃ©rifier les conditions dâ€™application de lâ€™ANOVA paramÃ©trique\nLâ€™ANOVA paramÃ©trique a trois conditions principales dâ€™application :\n\nles rÃ©sidus sont normalement distribuÃ©s,\nla variance des rÃ©sidus est Ã©gale dans tous les traitements (homoscÃ©dasticitÃ©) et\nles rÃ©sidus sont indÃ©pendants les uns des autres.\n\nCes conditions doivent Ãªtre remplies avant quâ€™on puisse se fier aux rÃ©sultats de lâ€™ANOVA paramÃ©trique.\n\nFaites une ANOVA Ã  un critÃ¨re de classification sur fklngth par annÃ©e et produisez les graphiques diagnostiques\n\n\n# Fit anova model and plot residual diagnostics\nanova.model1 &lt;- lm(fklngth ~ year, data = Dam10dat)\npar(mfrow = c(2, 2))\nplot(anova.model1)\n\n\n\n\n\n\nFigureÂ 11.3: Conditions dâ€™applications de lâ€™ANOVA\n\n\n\n\n\n\n\n\n\n\nAvertissement\n\n\n\nFaire attention dans le cadre dâ€™une ANOVA Ã  ce que la variable indÃ©pendante soit bien un facteur factor. Si la variable indÃ©pendante est reconnu comme du texte character alors vous nâ€™obtiendrez que 3 graphiques et un message dâ€™erreur du type:\n`hat values (leverages) are all = 0.1\nand there are no factor predictors; no plot no. 5`\n\n\nDâ€™aprÃ¨s les graphiques, on peut douter de la normalitÃ© et de lâ€™homogÃ©nÃ©itÃ© des variances. Notez quâ€™il y a un point qui ressort vraiment avec une forte valeur rÃ©siduelle (cas numÃ©ro 59) et quâ€™il ne sâ€™aligne pas bien avec les autres valeurs: câ€™est la valeur extrÃªme qui avait Ã©tÃ© dÃ©tectÃ©e plus tÃ´t. Ce point fera sans doute gonfler la variance rÃ©siduelle du groupe auquel il appartient.\nDes tests formels nous confirmeront ou infirmeront nos conclusions faites Ã  partir de ces graphiques.\n\nFaites un test de normalitÃ© sur les rÃ©sidus de lâ€™ANOVA.\n\n\nshapiro.test(residuals(anova.model1))\n\n\n    Shapiro-Wilk normality test\n\ndata:  residuals(anova.model1)\nW = 0.91571, p-value = 1.63e-06\n\n\nCe test confirme nos soupÃ§ons: les rÃ©sidus ne sont pas distribuÃ©s normalement. Il faut cependant garder Ã  lâ€™esprit que la puissance est grande et que mÃªme de petites dÃ©viations de la normalitÃ© sont suffisantes pour rejeter lâ€™hypothÃ¨se nulle.\n\nEnsuite, Ã©prouvez lâ€™hypothÃ¨se dâ€™Ã©galitÃ© des variances (homoscedasticitÃ©):\n\n\nleveneTest(fklngth ~ year, data = Dam10dat)\n\nLevene's Test for Homogeneity of Variance (center = median)\n       Df F value  Pr(&gt;F)  \ngroup   3  2.8159 0.04234 *\n      114                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nLa valeur de p vous dit que vous pouvez rejeter lâ€™hypothÃ¨se nulle quâ€™il nâ€™y a aucune diffÃ©rence dans les variances entre les annÃ©es. Alors, nous concluons que les variances ne sont pas homogÃ¨nes.\n\n11.2.3 Faire lâ€™ANOVA\n\nFaites une ANOVA de fklnght en choisissant / en prÃ©sumant pour lâ€™instant que les conditions dâ€™application sont suffisamment remplies. Que concluez-vous?\n\n\nsummary(anova.model1)\n\n\nCall:\nlm(formula = fklngth ~ year, data = Dam10dat)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-11.2116  -2.6866  -0.7116   2.2103  26.7885 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  48.0243     0.8566  56.061  &lt; 2e-16 ***\nyear1958      0.1872     1.3335   0.140  0.88859    \nyear1965     -5.5077     1.7310  -3.182  0.00189 ** \nyear1966     -3.3127     1.1684  -2.835  0.00542 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.211 on 114 degrees of freedom\nMultiple R-squared:  0.1355,    Adjusted R-squared:  0.1128 \nF-statistic: 5.957 on 3 and 114 DF,  p-value: 0.0008246\n\n\n\n\nCoefficients: Estimates Les 4 coefficients peuvent Ãªtre utilisÃ©s pour obtenir les valeurs prÃ©dites par le modÃ¨le (i.e.Â les moyennes de chaque groupe). La fklngth moyenne de la premiÃ¨re annÃ©e (1954) est 48.0243. Les coefficients pour les 3 autres annÃ©es sont la diffÃ©rence entre la moyenne de lâ€™annÃ©e en question et la moyenne de 1954. La moyenne pour 1965 est 48.0243-5.5077=42.5166. Pour chaque coefficient, on a Ã©galement accÃ¨s Ã  lâ€™erreur-type, une valeur de t et la probabilitÃ© qui lui est associÃ©e (H0 que le coefficient est 0). Les poissons Ã©taient plus petits aprÃ¨s la construction du barrage quâ€™en 1954. Vous devez prendre ces p-valeurs avec un grain de sel, car elles ne sont pas corrigÃ©es pour les comparaisons multiples et. En gÃ©nÃ©ral, je porte peu dâ€™attention Ã  cette partie des rÃ©sultats imprimÃ©s et me concentre sur ce qui suit.\n\nResidual standard error: La racine carrÃ©e de la variance des rÃ©sidus (valeurs observÃ©es moins valeurs prÃ©dites) qui correspond Ã  la variabilitÃ© inexpliquÃ©e par le modÃ¨le (variation de la taille des poissons capturÃ©s la mÃªme annÃ©e).\n\nMutiple R-squared Le R-carrÃ© est la proportion de la variabilitÃ© de la variable dÃ©pendante qui peut Ãªtre expliquÃ©e par le modÃ¨le. Ici, le modÃ¨le explique 13.5% de la variabilitÃ©. Les diffÃ©rences de taille dâ€™une annÃ©e Ã  lâ€™autre sont relativement petites lorsquâ€™on les compare Ã  la variation de taille entre les poissons capturÃ©s la mÃªme annÃ©e.\n\n\n\nF-Statistic La p-valeur associÃ©e au test â€œomnibusâ€ que toutes les moyennes sont Ã©gales. Ici, p est beaucoup plus petit que 0.05 et on rejetterait H0 pour conclure que fklngth varie selon les annÃ©es.\n\nLa commande anova() produit le tableau dâ€™ANOVA standard qui contient la plupart de cette information:\n\nanova(anova.model1)\n\nAnalysis of Variance Table\n\nResponse: fklngth\n           Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \nyear        3  485.26 161.755  5.9574 0.0008246 ***\nResiduals 114 3095.30  27.152                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nLa variabilitÃ© totale de fklngth, mesurÃ©e par la somme des carrÃ©s des Ã©carts (Sum sq) est partitionnÃ©e en ce qui peut Ãªtre expliquÃ© par lâ€™annÃ©e (485.26) et la variabilitÃ© rÃ©siduelle inexpliquÃ©e (3095.30). Lâ€™annÃ©e explique bien (485.26/(3095.30+485.26)=.1355 or 13.55% de la variabilitÃ©). Le carrÃ© moyen des rÃ©sidus (Residual Mean Sq) est leur variance.\n\n11.2.4 Les comparaisons multiples\n\nLa fonction pairwise.t.test() peut Ãªtre utilisÃ©e pour comparer des moyennes et ajuster (ou non, si dÃ©sirÃ©) les probabilitÃ©s pour le nombre de comparaisons en utilisant lâ€™une des options pour p.adj:\n\nCompare toutes les moyennes sans ajuster les probabilitÃ©s\n\npairwise.t.test(Dam10dat$fklngth, Dam10dat$year,\n  p.adj = \"none\"\n)\n\n\n    Pairwise comparisons using t tests with pooled SD \n\ndata:  Dam10dat$fklngth and Dam10dat$year \n\n     1954   1958   1965  \n1958 0.8886 -      -     \n1965 0.0019 0.0022 -     \n1966 0.0054 0.0079 0.1996\n\nP value adjustment method: none \n\n\nOption bonf ajuste les p-valeurs avec la correction de Bonferroni. Ici, il y a 6 valeurs de p calculÃ©es, et la correction de Bonferroni revient Ã  simplement multiplier la p-valeur par 6 (sauf si le rÃ©sultat est supÃ©rieur Ã  1. Si tel est le cas, la p-value ajustÃ©e est 1).\n\npairwise.t.test(Dam10dat$fklngth, Dam10dat$year,\n  p.adj = \"bonf\"\n)\n\n\n    Pairwise comparisons using t tests with pooled SD \n\ndata:  Dam10dat$fklngth and Dam10dat$year \n\n     1954  1958  1965 \n1958 1.000 -     -    \n1965 0.011 0.013 -    \n1966 0.033 0.047 1.000\n\nP value adjustment method: bonferroni \n\n\nOption â€œholmâ€ is est la correction sÃ©quentielle de Bonferroni dans laquelle les p-valeurs sont ordonnÃ©es de (i=1) la plus faible Ã  (N) la plus grande. La correction pour les p-valeurs est (N-i+1). Ici, il y a N=6 paires de moyennes qui sont comparÃ©es. La plus petite valeur de p non corrigÃ©e est 0.0019 pour 1954 vs 1965. La p-valeur corrigÃ©e est donc \\(0.0019*(6-1+1)=0.011\\). La seconde plus petite p-valeur est 0.0022. Sa p-valeur corrigÃ©e est 0.0022*(6-2+1)=0.011. Pour la p-valeur la plus Ã©levÃ©e, la correction est (N-N+1)=1, donc la p-valeur corrigÃ©e est Ã©gale Ã  la p-valeur brute.\n\npairwise.t.test(Dam10dat$fklngth, Dam10dat$year,\n  p.adj = \"holm\"\n)\n\n\n    Pairwise comparisons using t tests with pooled SD \n\ndata:  Dam10dat$fklngth and Dam10dat$year \n\n     1954  1958  1965 \n1958 0.889 -     -    \n1965 0.011 0.011 -    \n1966 0.022 0.024 0.399\n\nP value adjustment method: holm \n\n\nLâ€™option â€œfdrâ€ sert Ã  contrÃ´ler le â€œfalse discovery rateâ€.\n\npairwise.t.test(Dam10dat$fklngth, Dam10dat$year,\n  p.adj = \"fdr\"\n)\n\n\n    Pairwise comparisons using t tests with pooled SD \n\ndata:  Dam10dat$fklngth and Dam10dat$year \n\n     1954   1958   1965  \n1958 0.8886 -      -     \n1965 0.0066 0.0066 -     \n1966 0.0108 0.0119 0.2395\n\nP value adjustment method: fdr \n\n\nLes quatre mÃ©thodes mÃ¨nent ici Ã  la mÃªme conclusion: les poissons sont plus gros aprÃ¨s la construction du barrage et toutes les comparaisons entre les annÃ©es 50 et 60 sont significatives alors que les diffÃ©rences entre 54 et 58 ou 65 et 66 ne le sont pas. La conclusion ne dÃ©pend pas du choix de mÃ©thode.\nDans dâ€™autres situations, vous pourriez obtenir des rÃ©sultats contradictoires. Alors, quelle mÃ©thode choisir? Les p-valeurs qui ne sont pas corrigÃ©es sont certainement suspectes lorsquâ€™il y a plusieurs comparaisons. Dâ€™un autre cotÃ©, la correction de Bonferroni est conservatrice et le devient encore plus lorsquâ€™il y a de trÃ¨s nombreuses comparaisons. Des travaux rÃ©cents suggÃ¨rent que la correction fdr est un bon compromis lorsquâ€™il y a beaucoup de comparaisons.\nLa mÃ©thode de Tukey est lâ€™une des plus populaires et est facile Ã  utiliser en R (notez cependant quâ€™il y a un petit bug qui se manifeste quand la variable indÃ©pendante peut ressembler Ã  un nombre plutÃ´t quâ€™un facteur, ce qui explique la petite pirouette avec paste0 dans le code):\n\nDam10dat$myyear &lt;- as.factor(paste0(\"m\", Dam10dat$year))\nTukeyHSD(aov(fklngth ~ myyear, data = Dam10dat))\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = fklngth ~ myyear, data = Dam10dat)\n\n$myyear\n                  diff        lwr        upr     p adj\nm1958-m1954  0.1872141  -3.289570  3.6639986 0.9990071\nm1965-m1954 -5.5076577 -10.021034 -0.9942809 0.0100528\nm1966-m1954 -3.3126964  -6.359223 -0.2661701 0.0274077\nm1965-m1958 -5.6948718 -10.436304 -0.9534397 0.0116943\nm1966-m1958 -3.4999106  -6.875104 -0.1247171 0.0390011\nm1966-m1965  2.1949612  -2.240630  6.6305526 0.5710111\n\n\n\nplot(TukeyHSD(aov(fklngth ~ myyear, data = Dam10dat)))\n\n\n\n\n\n\nFigureÂ 11.4: DiffÃ©rence anuelles dans la longueur des esturgeons\n\n\n\n\nLes intervalles de confiance, corrigÃ©s pour les comparaisons multiples par la mÃ©thode de Tukey, sont illustrÃ©s pour les diffÃ©rences entre annÃ©es. Malheureusement les lÃ©gendes ne sont pas complÃ¨tes, mais lâ€™ordre est le mÃªme que dans le tableau prÃ©cÃ©dent.\nLe package multcomp peut produire de meilleurs graphiques, mais requiert un peu plus de code:\n\n# Alternative way to compute Tukey multiple comparisons\n# set up a one-way ANOVA\nanova.fkl.vs.year &lt;- aov(aov(fklngth ~ myyear, data = Dam10dat))\n# set up all-pairs comparisons for factor `year'\n\nmeandiff &lt;- glht(anova.fkl.vs.year, linfct = mcp(\n  myyear =\n    \"Tukey\"\n))\nconfint(meandiff)\n\n\n     Simultaneous Confidence Intervals\n\nMultiple Comparisons of Means: Tukey Contrasts\n\n\nFit: aov(formula = aov(fklngth ~ myyear, data = Dam10dat))\n\nQuantile = 2.589\n95% family-wise confidence level\n \n\nLinear Hypotheses:\n                   Estimate lwr      upr     \nm1958 - m1954 == 0   0.1872  -3.2652   3.6396\nm1965 - m1954 == 0  -5.5077  -9.9894  -1.0259\nm1966 - m1954 == 0  -3.3127  -6.3378  -0.2875\nm1965 - m1958 == 0  -5.6949 -10.4030  -0.9867\nm1966 - m1958 == 0  -3.4999  -6.8514  -0.1484\nm1966 - m1965 == 0   2.1950  -2.2095   6.5994\n\nplot(meandiff)\n\n\n\n\n\n\nFigureÂ 11.5: DiffÃ©rence anuelles dans la longueur des esturgeons\n\n\n\n\nCâ€™est un peu mieux, mais ce qui le serait encore plus câ€™est un graphique des moyennes, avec leurs intervalles de confiance ajustÃ©s pour les comparaisons multiples:\n\n# Compute and plot means and Tukey CI\nmeans &lt;- glht(\n  anova.fkl.vs.year,\n  linfct = mcp(myyear = \"Tukey\")\n)\ncimeans &lt;- cld(means)\n# use sufficiently large upper margin\n# plot\nold.par &lt;- par(mai = c(1, 1, 1.25, 1))\nplot(cimeans)\n\n\n\n\n\n\nFigureÂ 11.6: DiffÃ©rence anuelles dans la longueur des esturgeons\n\n\n\n\nNotez les lettres au dessus du graphique: les annÃ©es Ã©tiquetÃ©es avec la mÃªme lettre ne diffÃ¨rent pas significativement lâ€™une de lâ€™autre.",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>11</span>Â  <span class='chapter-title'>ANOVA Ã  un critÃ¨re de classification</span>"
    ]
  },
  {
    "objectID": "33-anova.html#transformations-de-donnÃ©es-et-anova-non-paramÃ©trique",
    "href": "33-anova.html#transformations-de-donnÃ©es-et-anova-non-paramÃ©trique",
    "title": "\n11Â  ANOVA Ã  un critÃ¨re de classification\n",
    "section": "\n11.3 Transformations de donnÃ©es et ANOVA non-paramÃ©trique",
    "text": "11.3 Transformations de donnÃ©es et ANOVA non-paramÃ©trique\nDans lâ€™exemple prÃ©cÃ©dent sur les diffÃ©rences annuelles de la variable fklgnth, on a notÃ© que les conditions dâ€™application de lâ€™ANOVA nâ€™Ã©taient pas remplies. Si les donnÃ©es ne remplissent pas les conditions de lâ€™ANOVA paramÃ©trique, il y a 3 options :\n\nNe rien faire. Si les effectifs dans chaque groupe sont grands, on peut relaxer les conditions dâ€™application car lâ€™ANOVA est alors assez robuste aux violations de normalitÃ© (mais moins aux violations dâ€™homoscedasticitÃ©),\non peut transformer les donnÃ©es\non peut faire une analyse non-paramÃ©trique.\n\n\nRefaites lâ€™ANOVA de la section prÃ©cÃ©dente aprÃ¨s avoir transformÃ© en faisant le logarithme Ã  la base de 10. Avec les donnÃ©es transformÃ©es, est-ce que les problÃ¨mes qui avaient Ã©tÃ© identifiÃ©s disparaissent ?\n\n\n# Fit anova model on log10 of fklngth and plot residual diagnostics\npar(mfrow = c(2, 2))\nanova.model2 &lt;- lm(log10(fklngth) ~ year, data = Dam10dat)\nplot(anova.model2)\n\n\n\n\n\n\nFigureÂ 11.7: Conditions dâ€™application de lâ€™ANOVA\n\n\n\n\nLes graphiques diagnostiques des rÃ©sidus donnent:\nLes graphiques sont Ã  peine mieux ici. Si on fait le test Wilk-Shapiro sur les rÃ©sidus, on obtient:\n\nshapiro.test(residuals(anova.model2))\n\n\n    Shapiro-Wilk normality test\n\ndata:  residuals(anova.model2)\nW = 0.96199, p-value = 0.002048\n\n\nAlors, on a toujours des problÃ¨mes avec la normalitÃ© et on est juste sur le seuil de dÃ©cision pour lâ€™Ã©galitÃ© des variances. Vous avez le choix Ã  ce point:\n\nessayer de trouver une autre transformation pour mieux rencontrer les conditions dâ€™application\nassumer que les donnÃ©es sont rencontrent suffisamment les conditions dâ€™application\nfaire une ANOVA non-paramÃ©trique.\n\n\nLâ€™analogue non-paramÃ©trique de lâ€™ANOVA Ã  un critÃ¨re de classification le plus employÃ© est le test de Kruskall-Wallis. Faites ce test sur fklngth et comparez les rÃ©sultats Ã  ceux de lâ€™analyse paramÃ©trique. Que concluez-vous?\n\n\nkruskal.test(fklngth ~ year, data = Dam10dat)\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  fklngth by year\nKruskal-Wallis chi-squared = 15.731, df = 3, p-value = 0.001288\n\n\nLa conclusion est donc la mÃªme quâ€™avec lâ€™ANOVA paramÃ©trique: on rejette lâ€™hypothÃ¨se nulle que le rang moyen est le mÃªme pour chaque annÃ©e. Donc, mÃªme si les conditions dâ€™application de lâ€™analyse paramÃ©trique nâ€™Ã©taient pas parfaitement rencontrÃ©es, les conclusions sont les mÃªmes, ce qui illustre la robustesse de lâ€™ANOVA paramÃ©trique.",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>11</span>Â  <span class='chapter-title'>ANOVA Ã  un critÃ¨re de classification</span>"
    ]
  },
  {
    "objectID": "33-anova.html#examen-des-valeurs-extrÃªmes",
    "href": "33-anova.html#examen-des-valeurs-extrÃªmes",
    "title": "\n11Â  ANOVA Ã  un critÃ¨re de classification\n",
    "section": "\n11.4 Examen des valeurs extrÃªmes",
    "text": "11.4 Examen des valeurs extrÃªmes\nVous devriez avoir remarquÃ© au cours des analyses prÃ©cÃ©dentes quâ€™il y avait peut-Ãªtre des valeurs extrÃªmes dans les donnÃ©es. Ces points Ã©taient Ã©vidents dans le Box Plot de fklngth by year et ont Ã©tÃ© notÃ©s comme les points 59, 23, et 87 dans les diagrammes de probabilitÃ© des rÃ©sidus et dans le diagramme de dispersion des rÃ©sidus et des valeurs estimÃ©es. En gÃ©nÃ©ral, vous devez avoir de trÃ¨s bonnes raisons pour enlever des valeurs extrÃªmes de la base de donnÃ©es (i.e.Â vous savez quâ€™il y a eu une erreur avec un cas). Cependant, il est quand mÃªme toujours valable de voir comment lâ€™analyse change en enlevant des valeurs extrÃªmes de la base de donnÃ©es.\n\nRÃ©pÃ©tez lâ€™ANOVA originale sur fklngth et year mais faites le avec un sous-ensemble de donnÃ©es sans les valeurs extrÃªmes. Est-ce que les conclusions ont changÃ©?\n\n\nDamsubset &lt;- Dam10dat[-c(23, 59, 87), ] # removes obs 23, 59 and 87\naov.Damsubset &lt;- aov(fklngth ~ as.factor(year), Damsubset)\nsummary(aov.Damsubset)\n\n                 Df Sum Sq Mean Sq F value   Pr(&gt;F)    \nas.factor(year)   3  367.5  122.50   6.894 0.000267 ***\nResiduals       111 1972.4   17.77                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nshapiro.test(residuals(aov.Damsubset))\n\n\n    Shapiro-Wilk normality test\n\ndata:  residuals(aov.Damsubset)\nW = 0.98533, p-value = 0.2448\n\n\n\nleveneTest(fklngth ~ year, Damsubset)\n\nLevene's Test for Homogeneity of Variance (center = median)\n       Df F value   Pr(&gt;F)   \ngroup   3  4.6237 0.004367 **\n      111                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nLâ€™Ã©limination de trois valeurs extrÃªmes amÃ©liore un peu les choses, mais ce nâ€™est pas parfait. On a toujours une problÃ¨me avec les variances, mais les rÃ©sidus sont maintenant normaux. Cependant, le fait que la conclusion quâ€™on tire de lâ€™ANOVA originale ne change pas en enlevant les points renforce le fait quâ€™on nâ€™a pas une bonne raison pour enlever les points.",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>11</span>Â  <span class='chapter-title'>ANOVA Ã  un critÃ¨re de classification</span>"
    ]
  },
  {
    "objectID": "33-anova.html#test-de-permutation",
    "href": "33-anova.html#test-de-permutation",
    "title": "\n11Â  ANOVA Ã  un critÃ¨re de classification\n",
    "section": "\n11.5 Test de permutation",
    "text": "11.5 Test de permutation\nCommande R pour un test de permutation dâ€™une ANOVA Ã  un critÃ¨re de classification.\n\n#############################################################\n# Permutation Test for one-way ANOVA\n# modified from code written by David C. Howell\n# http://www.uvm.edu/~dhowell/StatPages/More_Stuff/Permutation%20Anova/PermTestsAnova.html\n# set desired number of permutations\nnreps &lt;- 500\n# to simplify reuse of this code, copy desired dataframe to mydata\nmydata &lt;- Dam10dat\n# copy model formula to myformula\nmyformula &lt;- as.formula(\"fklngth ~ year\")\n# copy dependent variable vector to mydep\nmydep &lt;- mydata$fklngth\n# copy independent variable vector to myindep\nmyindep &lt;- as.factor(mydata$year)\n################################################\n# You should not need to modify code chunk below\n################################################\n# Compute observed F value for original sample\nmod1 &lt;- lm(myformula, data = mydata) # Standard Anova\nANOVA &lt;- summary(aov(mod1)) # Save summary to variable\nobservedF &lt;- ANOVA[[1]]$\"F value\"[1] # Save observed F value\n# Print standard ANOVA results\ncat(\n  \" The standard ANOVA for these data follows \",\n  \"\\n\"\n)\n\nprint(ANOVA, \"\\n\")\ncat(\"\\n\")\ncat(\"\\n\")\nprint(\"Resampling as in Manly with unrestricted sampling of observations. \")\n\n# Now start resampling\nFboot &lt;- numeric(nreps) # initalize vector to receive permuted\nvalues\nFboot[1] &lt;- observedF\nfor (i in 2:nreps) {\n  newdependent &lt;- sample(mydep, length(mydep)) # randomize dep\n  var\n  mod2 &lt;- lm(newdependent ~ myindep) # refit model\n  b &lt;- summary(aov(mod2))\n  Fboot[i] &lt;- b[[1]]$\"F value\"[1] # store F stats\n}\npermprob &lt;- length(Fboot[Fboot &gt;= observedF]) / nreps\ncat(\n  \" The permutation probability value is: \", permprob,\n  \"\\n\"\n)\n# end of code chunk for permutation\n\nVersion lmPerm du test de permutation.\n\n## lmPerm version of permutation test\nlibrary(lmPerm)\n# for generality, copy desired dataframe to mydata\n# and model formula to myformula\nmydata &lt;- Dam10dat\nmyformula &lt;- as.formula(\"fklngth ~ year\")\n# Fit desired model on the desired dataframe\nmymodel &lt;- lm(myformula, data = mydata)\n# Calculate permutation p-value\nanova(lmp(myformula, data = mydata, perm = \"Prob\", center = FALSE, Ca = 0.001))",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>11</span>Â  <span class='chapter-title'>ANOVA Ã  un critÃ¨re de classification</span>"
    ]
  },
  {
    "objectID": "34-anova_mult.html",
    "href": "34-anova_mult.html",
    "title": "\n12Â  ANOVA Ã  critÃ¨res multiples : plans factoriels et hiÃ©rarchiques\n",
    "section": "",
    "text": "12.1 Paquets et donnÃ©es requises pour le labo\nCe laboratoire nÃ©cessite:\nlibrary(multcomp)\nlibrary(car)\nlibrary(tidyverse)",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>12</span>Â  <span class='chapter-title'>ANOVA Ã  critÃ¨res multiples : plans factoriels et hiÃ©rarchiques</span>"
    ]
  },
  {
    "objectID": "34-anova_mult.html#set-anomul",
    "href": "34-anova_mult.html#set-anomul",
    "title": "\n12Â  ANOVA Ã  critÃ¨res multiples : plans factoriels et hiÃ©rarchiques\n",
    "section": "",
    "text": "les paquets R:\n\nmulticomp\ncar\ntidyverse\n\n\nles fichiers de donnÃ©es\n\nStu2wdat.csv\nStu2mdat.csv\nnr2wdat.csv\nnestdat.csv\nwmcdat2.csv\nwmc2dat2.csv",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>12</span>Â  <span class='chapter-title'>ANOVA Ã  critÃ¨res multiples : plans factoriels et hiÃ©rarchiques</span>"
    ]
  },
  {
    "objectID": "34-anova_mult.html#plan-factoriel-Ã -deux-facteurs-de-classification-et-rÃ©plication",
    "href": "34-anova_mult.html#plan-factoriel-Ã -deux-facteurs-de-classification-et-rÃ©plication",
    "title": "\n12Â  ANOVA Ã  critÃ¨res multiples : plans factoriels et hiÃ©rarchiques\n",
    "section": "\n12.2 Plan factoriel Ã  deux facteurs de classification et rÃ©plication",
    "text": "12.2 Plan factoriel Ã  deux facteurs de classification et rÃ©plication\nIl est frÃ©quent de vouloir analyser lâ€™effet de plusieurs facteurs simultanÃ©ment. Lâ€™ANOVA factorielle Ã  deux critÃ¨res de classification permet dâ€™examiner deux facteurs Ã  la fois, mais la mÃªme approche peut Ãªtre utilisÃ©e pour 3, 4 ou mÃªme 5 facteurs quoique lâ€™interprÃ©tation des rÃ©sultats devienne beaucoup plus complexe.\nSupposons que vous Ãªtes intÃ©ressÃ©s par lâ€™effet de deux facteurs : site (location, Cumberland House ou The Pas) et sexe (sex, mÃ¢le ou femelle) sur la taille des esturgeons. Comme lâ€™effectif nâ€™est pas le mÃªme pour tous les groupes, câ€™est un plan qui nâ€™est pas balancÃ©. Notez aussi quâ€™il y a des valeurs manquantes pour certaines variables, ce qui veut dire que chaque mesure nâ€™a pas Ã©tÃ© effectuÃ©e sur chaque poisson.\n\n12.2.1 ANOVA Ã  effets fixes\n\nExaminez dâ€™abord les donnÃ©es en faisant des box plots de rdwght pour sex et location des donnÃ©es du fichier Stu2wdat.csv .\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nStu2wdat &lt;- read.csv(\"data/Stu2wdat.csv\")\n\nggplot(Stu2wdat, aes(x = sex, y = rdwght)) +\ngeom_boxplot(notch = TRUE) +\nfacet_grid(~location)\n\nWarning: Removed 4 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\n\n\nFigureÂ 12.1\n\n\n\n\n\n\n\nLes graphiques montrent quâ€™aux deux sites les femelles sont probablement plus grandes que les mÃ¢les, mais que les tailles ne varient pas beaucoup dâ€™un site Ã  lâ€™autre. La prÃ©sence de valeurs extrÃªmes sur ces graphiques suggÃ¨re quâ€™il y aura peut-Ãªtre des problÃ¨mes avec la condition de normalitÃ© des rÃ©sidus.\n\nGÃ©nÃ©rez les statistiques sommaires pour RDWGHT par sex et Location.\n\n\nStu2wdat %&gt;%\n  group_by(sex, location) %&gt;%\n  summarise(\n    mean = mean(rdwght, na.rm = TRUE), sd = sd(rdwght, na.rm = TRUE), n = n()\n  )\n\n`summarise()` has grouped output by 'sex'. You can override using the `.groups`\nargument.\n\n\n# A tibble: 4 Ã— 5\n# Groups:   sex [2]\n  sex            location        mean    sd     n\n  &lt;chr&gt;          &lt;chr&gt;          &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n1 \"FEMALE      \" \"CUMBERLAND  \"  27.4  9.33    51\n2 \"FEMALE      \" \"THE_PAS     \"  28.0 12.5     55\n3 \"MALE        \" \"CUMBERLAND  \"  22.1  4.79    34\n4 \"MALE        \" \"THE_PAS     \"  20.6  9.92    46\n\n\nCes rÃ©sultats supportent lâ€™interprÃ©tation des box plots: Les femelles sont plus grosses que les mÃ¢les, et la diffÃ©rence de taille entre les deuxsites sont petites.\n\nÃ€ lâ€™aide du fichier Stu2wdat.csv faites une ANOVA factorielle Ã  deux critÃ¨res de classification:\n\n\n# Fit anova model and plot residual diagnostics\n# but first, save current graphic parameters\nopar &lt;- par()\nanova.model1 &lt;- lm(rdwght ~ sex + location + sex:location,\n  contrasts = list(sex = contr.sum, location = contr.sum),\n  data = Stu2wdat\n)\nanova(anova.model1)\n\nAnalysis of Variance Table\n\nResponse: rdwght\n              Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \nsex            1  1839.6 1839.55 18.6785 2.569e-05 ***\nlocation       1     4.3    4.26  0.0433    0.8355    \nsex:location   1    48.7   48.69  0.4944    0.4829    \nResiduals    178 17530.4   98.49                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\n\n\nAvertissement\n\n\n\nAttention, R imprime les sommes des carrÃ©s sÃ©quentielles (Type I) les carrÃ©s moyens et probabilitÃ©s associÃ©s. Vous ne pouvez pas vous y fier si votre plan dâ€™expÃ©rience nâ€™est pas parfaitement balancÃ©. Dans cet exemple, le nombre de poissons capturÃ©s change selon le site et le sexe et le plan dâ€™expÃ©rience nâ€™est donc pas balancÃ©.\n\n\nVous devez extraire les sommes de carrÃ©s partielles (Type III). Le moyen le plus simple que jâ€™ai trouvÃ© est dâ€™utiliser la fonction Anova()du package car (notez la diffÃ©rence subtile, Anova() nâ€™est pas la mÃªme chose que anova(), R est impitoyable et distingue les majuscules des minuscules). Malheureusement, Anova() ne suffit pas; il faut Ã©galement spÃ©cifier le type de contraste dans le modÃ¨le aveclâ€™argument contrasts = list(sex = contr.sum,location = contr.sum)\n\nlibrary(car)\nAnova(anova.model1, type = 3)\n\nAnova Table (Type III tests)\n\nResponse: rdwght\n             Sum Sq  Df   F value    Pr(&gt;F)    \n(Intercept)  106507   1 1081.4552 &lt; 2.2e-16 ***\nsex            1745   1   17.7220 4.051e-05 ***\nlocation          9   1    0.0891    0.7656    \nsex:location     49   1    0.4944    0.4829    \nResiduals     17530 178                        \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nSuite Ã  lâ€™ANOVA, on accepte deux hypothÃ¨ses nulles: (1) que lâ€™effet du sexe ne varie pas entre les sites (pas dâ€™interaction significative) et (2) quâ€™il nâ€™y a pas de diffÃ©rence de taille des esturgeons (peu importe le sexe) entre les deux sites. Dâ€™un autre cotÃ©, on rejette lâ€™hypothÃ¨se nulle quâ€™il nâ€™y a pas de diffÃ©rence de taille entre les esturgeons mÃ¢les et les femelles, tel que suggÃ©rÃ© par les graphiques.\n\npar(mfrow = c(2, 2))\nplot(anova.model1)\n\n\n\n\n\n\nFigureÂ 12.2: Conditions dâ€™application ANOVA model1\n\n\n\n\nCependant, on ne peut se fier Ã  ces rÃ©sultats sans vÃ©rifier si les conditions dâ€™application de lâ€™ANOVA Ã©taient remplies. Un examen des graphiques des rÃ©sidus, en haut, montre que les rÃ©sidus semblent Ãªtre distribuÃ©s plus ou moins normalement, si ce nâ€™est des 3 valeurs extrÃªmes qui sont notÃ©es sur le diagramme de probabilitÃ© (cas 101, 24,& 71). Dâ€™aprÃ¨s le graphique des rÃ©sidus vs les valeurs prÃ©dites, on voit que lâ€™Ã©tendue des rÃ©sidus est plus ou moins Ã©gale pour les valeurs estimÃ©es, sauf encore pour 2 ou 3 cas. Si on Ã©prouve la normalitÃ©, on obtient:\n\nshapiro.test(residuals(anova.model1))\n\n\n    Shapiro-Wilk normality test\n\ndata:  residuals(anova.model1)\nW = 0.87213, p-value = 2.619e-11\n\n\nAlors, il y a Ã©vidence que les rÃ©sidus ne sont pas distribuÃ©s normalement.\nNous allons utiliser le test de Levene pour examiner lâ€™homoscÃ©dasticitÃ© des rÃ©sidus, de la mÃªme faÃ§on quâ€™on a fait pour lâ€™ANOVA Ã  un critÃ¨re de classification.\n\nlibrary(car)\nleveneTest(rdwght ~ sex * location, data = Stu2wdat)\n\nLevene's Test for Homogeneity of Variance (center = median)\n       Df F value  Pr(&gt;F)  \ngroup   3  3.8526 0.01055 *\n      178                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nSi les rÃ©sidus Ã©taient homoscÃ©dastiques, on accepterait lâ€™hypothÃ¨se nulle que le absres moyen ne varie pas entre les niveaux de sexe et location (i.e., sexloc). Le tableau dâ€™ANOVA ci-dessus montre que lâ€™hypothÃ¨se est rejetÃ©e. Il y a donc Ã©vidence dâ€™hÃ©tÃ©roscÃ©dasticitÃ©. En bref, nous avons donc plusieurs conditions dâ€™application qui ne sont pas respectÃ©es. La question qui reste est: ces violations sont-elles suffisantes pour invalider nos conclusions ?\n\n\n\n\n\n\nExercice\n\n\n\nRÃ©pÃ©tez la mÃªme analyse avec les donnÃ©es du fichier stu2mdat.csv . Que concluez-vous? Supposons que vous vouliez comparer la taille des mÃ¢les et des femelles. Comment cette comparaison diffÃ¨re entre les deux ensembles de donnÃ©es ?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nStu2mdat &lt;- read.csv(\"data/Stu2mdat.csv\")\nanova.model2 &lt;- lm(\n  formula = rdwght ~ sex + location + sex:location,\n  contrasts = list(sex = contr.sum, location = contr.sum),\n  data = Stu2mdat\n)\nsummary(anova.model2)\nAnova(anova.model2, type = 3)\n\n\n\n\n\n\n\nCall:\nlm(formula = rdwght ~ sex + location + sex:location, data = Stu2mdat, \n    contrasts = list(sex = contr.sum, location = contr.sum))\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.917  -6.017  -0.580   4.445  65.743 \n\nCoefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)     24.5346     0.7461  32.885  &lt; 2e-16 ***\nsex1            -0.5246     0.7461  -0.703    0.483    \nlocation1        0.2227     0.7461   0.299    0.766    \nsex1:location1   3.1407     0.7461   4.210 4.05e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 9.924 on 178 degrees of freedom\n  (4 observations deleted due to missingness)\nMultiple R-squared:  0.09744,   Adjusted R-squared:  0.08223 \nF-statistic: 6.405 on 3 and 178 DF,  p-value: 0.0003817\n\n\nNotez que cette fois les femelles sont plus grandes que les mÃ¢les Ã  Cumberland House, mais que câ€™est le contraire Ã  The Pas. Quel est le rÃ©sultat de lâ€™ANOVA (nâ€™oubliez pas quâ€™il faut des Type III sums of squares pour les rÃ©sultats)?\n\n\nAnova Table (Type III tests)\n\nResponse: rdwght\n             Sum Sq  Df   F value    Pr(&gt;F)    \n(Intercept)  106507   1 1081.4552 &lt; 2.2e-16 ***\nsex              49   1    0.4944    0.4829    \nlocation          9   1    0.0891    0.7656    \nsex:location   1745   1   17.7220 4.051e-05 ***\nResiduals     17530 178                        \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nDans ce cas, le terme de lâ€™interaction (sex:location) est maintenant significatif mais les effets principaux ne le sont pas.\n\nVous trouverez utile ici de crÃ©er des graphiques pour les deux fichiers de donnÃ©es pour comparer les interactions entre sex et location. Le graphique dâ€™interaction montre les relations entre les moyennes de chaque combinaison de facteurs (appelÃ©es aussi les moyennes des ce$lules).GÃ©nÃ©rez un graphique illustrant les intÃ©ractions en utilisant la fonction allEffects du package effects :\n\n\nlibrary(effects)\nallEffects(anova.model1)\n\n model: rdwght ~ sex + location + sex:location\n\n sex*location effect\n              location\nsex            CUMBERLAND   THE_PAS     \n  FEMALE           27.37347     27.97717\n  MALE             22.14118     20.64652\n\nplot(allEffects(anova.model1), \"sex:location\")\n\n\n\n\n\n\nFigureÂ 12.3: Effet du sexe et du lieu sur le poids des esturgeons\n\n\n\n\n\nallEffects(anova.model2)\n\n model: rdwght ~ sex + location + sex:location\n\n sex*location effect\n              location\nsex            CUMBERLAND   THE_PAS     \n  FEMALE           27.37347     20.64652\n  MALE             22.14118     27.97717\n\nplot(allEffects(anova.model2), \"sex:location\")\n\n\n\n\n\n\nFigureÂ 12.4: Effet du sexe et du lieu sur le poids des esturgeons\n\n\n\n\nIl y a une diffÃ©rence importante entre les rÃ©sultats obtenus avec stu2wdat et stu2mdat. Dans le premier cas, puisquâ€™il nâ€™y a pas dâ€™interaction, on peut regrouper les donnÃ©es des deux niveaux dâ€™un facteur (le site, par exemple) pour Ã©prouver lâ€™hypothÃ¨se dâ€™un effet de lâ€™autre facteur (le sexe). En fait, si on fait cela et que lâ€™on calcule une ANOVA Ã  un critÃ¨re de classification (sex), on obtient:\n\nAnova(aov(rdwght ~ sex, data = Stu2wdat), type = 3)\n\nAnova Table (Type III tests)\n\nResponse: rdwght\n            Sum Sq  Df F value    Pr(&gt;F)    \n(Intercept)  78191   1 800.440 &lt; 2.2e-16 ***\nsex           1840   1  18.831 2.377e-05 ***\nResiduals    17583 180                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nNotez que la somme des carrÃ©s des rÃ©sidus (17583) est presque Ã©gale Ã  celle du modÃ¨le complet (17530) de lâ€™ANOVA factorielle Ã  deux facteurs. Câ€™est parce que dans cette anova factorielle, le terme dâ€™interaction et le terme reprÃ©sentant lâ€™effet du site nâ€™expliquent quâ€™une partie infime de la variabilitÃ©. Dâ€™un autre cotÃ©, si on essaie le mÃªme truc avec stu2mdat, on obtient:\n\nAnova(aov(rdwght ~ sex, data = Stu2mdat), type = 3)\n\nAnova Table (Type III tests)\n\nResponse: rdwght\n            Sum Sq  Df  F value Pr(&gt;F)    \n(Intercept)  55251   1 515.0435 &lt;2e-16 ***\nsex            113   1   1.0571 0.3053    \nResiduals    19309 180                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nIci la somme des carrÃ©es des rÃ©sidus (19309) est beaucoup plus grande que celle de lâ€™ANOVA factorielle (175306) parce quâ€™une partie importante de la variabilitÃ© expliquÃ©e par le modÃ¨le est associÃ©e Ã  lâ€™interaction. Notez que si on nâ€™avait fait que cette analyse, on conclurait que les esturgeons mÃ¢les et femelles ont la mÃªme taille. Mais en fait leur taille diffÃ¨re; seulement la diffÃ©rence est Ã  lâ€™avantage des mÃ¢les Ã  un site et Ã  lâ€™avantage des femelles Ã  lâ€™autre. Il est donc dÃ©licat dâ€™interprÃ©ter lâ€™effet principal (sexe) en prÃ©sence dâ€™une interaction significativeâ€¦\n\n12.2.2 ANOVA Ã  effets mixtes\nLes analyses qui prÃ©cÃ¨dent nÃ©gligent un point important: location pourrait Ãªtre traitÃ© comme un facteur alÃ©atoire et sex est fixe. Par consÃ©quent le modÃ¨le appropriÃ© dâ€™ANOVA est de type mixte.\nNotez que dans toutes les analyses qui prÃ©cÃ¨dent, R a traitÃ© cette ANOVA comme si elle etait de type effet fixe seulement, et les termes principaux et celui dâ€™interaction ont Ã©tÃ© testÃ©s en utilisant le carrÃ© moyen des rÃ©sidus comme dÃ©nominateur des tests de F. Cependant, pour une ANOVA de type mixte, ces effets devraient Ãªtre testÃ©s en utilisant le carrÃ© moyen du terme dâ€™interaction, ou en combinant la somme des carrÃ©s de lâ€™erreur et de lâ€™interaction (selon le statisticien consultÃ©!).\nEn utilisant Stu2wdat, refaites un tableau dâ€™ANOVA pour RDWGHT en considÃ©rant location comme facteur alÃ©atoire et sex comme un facteur fixe. Pour ce faire, vous devrez recalculer les valeurs de F pour sex et location en utilisant le carrÃ© moyen de lâ€™interaction sex:location au lieu du carrÃ© moyen des rÃ©sidus comme dÃ©nominateur. Le mieux câ€™est de le faire Ã  la mitaine ent travaillant avec les Type III Sums of squares du tableau dâ€™ANOVA.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nAnova(anova.model1, type = 3)\n\n\n\n\n\n\nAnova Table (Type III tests)\n\nResponse: rdwght\n             Sum Sq  Df   F value    Pr(&gt;F)    \n(Intercept)  106507   1 1081.4552 &lt; 2.2e-16 ***\nsex            1745   1   17.7220 4.051e-05 ***\nlocation          9   1    0.0891    0.7656    \nsex:location     49   1    0.4944    0.4829    \nResiduals     17530 178                        \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nPour sex, la nouvelle valeur de F (le rapport des carrÃ©s moyens) est de\n\\[F = \\frac{(1745/1)}{(49/1)} = 35.6\\]\nPour obtenir la valeur de p correspondant Ã  cette statistique F, il faut utilisez la fonction de probabilitÃ© de la distribtuion de F pf(F, df1, df2, lower.tail = FALSE), oÃ¹ F est la valeur de F calculÃ©e, et df1 et df2 sont les degrÃ©s de libertÃ© du numÃ©rateur (sex) et dÃ©nominateur(SEX:location).\n\npf(35.6, 1, 1, lower.tail = FALSE)\n\n[1] 0.1057152\n\n\nNotez que maintenant la valeur de p pour sex nâ€™est plus significative. Câ€™est parce que le carrÃ© moyen de lâ€™erreur dans lâ€™ANOVA initiale est plus petit que celui associÃ© Ã  lâ€™interaction, mais surtout parce que le nombre de degrÃ©s de libertÃ© pour le dÃ©nominateur du test de F est passÃ© de 178 Ã  1 seulement. En gÃ©nÃ©ral, câ€™est beaucoup plus difficile dâ€™obtenir des rÃ©sultats significatifs quand les degrÃ©s de libertÃ© pour le dÃ©nominateur sont petits.\n\n\n\n\n\n\nNote\n\n\n\nLes modÃ¨les mixtes qui sont une gÃ©nÃ©ralisation de lâ€™ANOVA Ã  effets mixtes sont maintenant extrÃªmement bien dÃ©veloppÃ© et sont Ã  favoriser lors dâ€™analyse incluant des effets dit alÃ©atoires.",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>12</span>Â  <span class='chapter-title'>ANOVA Ã  critÃ¨res multiples : plans factoriels et hiÃ©rarchiques</span>"
    ]
  },
  {
    "objectID": "34-anova_mult.html#plan-factoriel-Ã -deux-facteurs-de-classification-sans-rÃ©plication",
    "href": "34-anova_mult.html#plan-factoriel-Ã -deux-facteurs-de-classification-sans-rÃ©plication",
    "title": "\n12Â  ANOVA Ã  critÃ¨res multiples : plans factoriels et hiÃ©rarchiques\n",
    "section": "\n12.3 Plan factoriel Ã  deux facteurs de classification sans rÃ©plication",
    "text": "12.3 Plan factoriel Ã  deux facteurs de classification sans rÃ©plication\nDans certains plans dâ€™expÃ©rience il nâ€™y a pas de rÃ©plicats pour chaque combinaison de facteurs, par exemple parce quâ€™il serait trop coÃ»teux de faire plus dâ€™une observation. Lâ€™ANOVA Ã  deux critÃ¨res de classification est quand mÃªme possible dans ces circonstances, mais il y a une limitation importante.\n\n\n\n\n\n\nAvertissement\n\n\n\nComme il nâ€™y a pas de rÃ©plicats, on ne peut estimer la variance du terme dâ€™erreur. En effet on ne peut quâ€™estimer la somme des carrÃ©s associÃ©s Ã  chacun des facteurs principaux, et la quantitÃ© de variabilitÃ© qui reste (Remainder Mean Square) reprÃ©sente la somme de la variabilitÃ© attribuable Ã  lâ€™interaction et au terme dâ€™erreur. Cela a une implication importante. Dans le cas dâ€™un modÃ¨le avec uniquement des effets fixes ou pour lâ€™effet alÃ©atoire dâ€™un modÃ¨le dâ€™ANOVA mixtes on ne peut tester les effets principaux que si on est sur quâ€™il nâ€™y a pas dâ€™interaction.\n\n\nUn limnologiste qui Ã©tudie Round Lake dans le Parc Algonquin prend une seule mesure de tempÃ©rature (temp,en degrÃ©s C) Ã  10 profondeurs diffÃ©rentes (depth, en m) Ã  quatre dates (date) au cours de lâ€™Ã©tÃ©. Ses donnÃ©es sont au fichier nr2wdat.csv.\n\nEffectuez une ANOVA Ã  deux critÃ¨res de classification en utilisant temp comme variable dÃ©pendante et date et depth comme variables indÃ©pendantes (vous devez changer le type de donnÃ©es pour DEPTH pour que R traite cette variable comme un facteur et non pas une var$able continue).\n\n\nnr2wdat &lt;- read.csv(\"data/nr2wdat.csv\")\nnr2wdat$depth &lt;- as.factor(nr2wdat$depth)\nanova.model4 &lt;- lm(temp ~ date + depth, data = nr2wdat)\nAnova(anova.model4, type = 3)\n\nAnova Table (Type III tests)\n\nResponse: temp\n             Sum Sq Df  F value    Pr(&gt;F)    \n(Intercept) 1511.99  1 125.5652 1.170e-11 ***\ndate         591.15  3  16.3641 2.935e-06 ***\ndepth       1082.82  9   9.9916 1.450e-06 ***\nResiduals    325.12 27                       \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nSi on suppose que câ€™est un modÃ¨le dâ€™ANOVA mixte (date alÃ©atoire, Depth fixe), que concluez vous? (Indice: faites un graphique dâ€™interaction tempÃ©rature en fonction de la profondeur et la date, pour voir ce qui se passe).\n\ninteraction.plot(nr2wdat$depth, nr2wdat$date, nr2wdat$temp)\n\n\n\n\n\n\nFigureÂ 12.5: Effet du mois et de la profondeur sur la tempÃ©rature\n\n\n\n\nLa tempÃ©rature diminue significativement en profondeur. Pour tester lâ€™effet du mois (le facteur alÃ©atoire), on doit prÃ©sumer quâ€™il nâ€™y a pas dâ€™interaction entre la profondeur et le mois (donc que lâ€™effet de la profondeur sur la tempÃ©rature est le mÃªme Ã  chaque mois). Câ€™est peu probable: si vous faites un graphique de la tempÃ©rature en fonction de la profondeur pour chaque mois, vous observerez que le profil de tempÃ©rature change au fur et Ã  mesure du dÃ©veloppement de la thermocline. Bref, comme le profil change au cours de lâ€™Ã©tÃ©, ce modÃ¨le ne fait pas de trÃ¨s bonnes prÃ©dictions.\nJetez un coup dâ€™oeil sur les graphiques des rÃ©sidus:\n\npar(mfrow = c(2, 2))\nplot(anova.model4)\n\n\n\n\n\n\nFigureÂ 12.6: Conditions dâ€™applications du modÃ¨le anova.model4\n\n\n\n\n\nshapiro.test(residuals(anova.model4))\n\n\n    Shapiro-Wilk normality test\n\ndata:  residuals(anova.model4)\nW = 0.95968, p-value = 0.1634\n\n\nLe test de normalitÃ© sur les rÃ©sidus donne p = 0.16, donc lâ€™hypothÃ¨se de normalitÃ© ne semble pas Ãªtre sÃ©rieusement en doute. Pour lâ€™Ã©galitÃ© des variances, on peut seulement comparer entre les mois en utilisant les profondeurs comme rÃ©plicats (ou lâ€™inverse). En utilisant les profondeurs comme rÃ©plicats, on obtient:\n\nleveneTest(temp ~ date, data = nr2wdat)\n\nWarning in leveneTest.default(y = y, group = group, ...): group coerced to\nfactor.\n\n\nLevene's Test for Homogeneity of Variance (center = median)\n      Df F value    Pr(&gt;F)    \ngroup  3  17.979 2.679e-07 ***\n      36                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nIl y a donc un problÃ¨me dâ€™hÃ©tÃ©roscÃ©dasticitÃ©, comme on peut trÃ¨s bien voir dans le graphique des rÃ©sidus vs les valeurs estimÃ©es. Cette analyse nâ€™est donc pas trÃ¨s satisfaisante: il y a des violations des conditions dâ€™application et il semble y avoir une interaction entre depth et date qui pourrait invalider lâ€™analyse.",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>12</span>Â  <span class='chapter-title'>ANOVA Ã  critÃ¨res multiples : plans factoriels et hiÃ©rarchiques</span>"
    ]
  },
  {
    "objectID": "34-anova_mult.html#plans-hiÃ©rarchiques",
    "href": "34-anova_mult.html#plans-hiÃ©rarchiques",
    "title": "\n12Â  ANOVA Ã  critÃ¨res multiples : plans factoriels et hiÃ©rarchiques\n",
    "section": "\n12.4 Plans hiÃ©rarchiques",
    "text": "12.4 Plans hiÃ©rarchiques\nUn design expÃ©rimental frÃ©quent implique la division de chaque groupe du facteur majeur en sous-groupes alÃ©atoires. Par exemple, une gÃ©nÃ©ticienne intÃ©ressÃ©e par lâ€™effet du gÃ©notype sur la rÃ©sistance Ã  la dessiccation chez la drosophile effectue une expÃ©rience. Pour chaque gÃ©notype (facteur principal) elle prÃ©pare trois chambres de croissance (sous-groupes) avec une tempÃ©rature et humiditÃ© contrÃ´lÃ©es. Dans chaque chambre de croissance, elle place cinq larves, puis mesure le nombre dâ€™heures pendant lesquelles chaque larve survit. Les donnÃ©es ont donc un structure hiÃ©rarchique. Il ya des observations rÃ©pÃ©tÃ©es dans chaque chambre au sein de chaque gÃ©notype.\n\nLe fichier nestdat.csv contient les rÃ©sultats dâ€™une expÃ©rience semblable. Il contient trois variables : genotype, chamber et survival. Effectuez une ANOVA hiÃ©rarchique avec survival comme variable dÃ©pendante et genotype et chamber/genotype comme variables indÃ©pendantes.\n\n\nnestdat &lt;- read.csv(\"data/nestdat.csv\")\nnestdat$chamber &lt;- as.factor(nestdat$chamber)\nnestdat$genotype &lt;- as.factor(nestdat$genotype)\nanova.nested &lt;- lm(survival ~ genotype / chamber, data = nestdat)\n\nQue concluez-vous de cette analyse ? Que devrait Ãªtre la prochaine Ã©tape ? (Indice: si lâ€™effet de Chamber / genotype nâ€™est pas significatif, vous pouvez augmenter la puissance des comparaisons entre gÃ©notypes en regroupant les chambres de chaque gÃ©notype.). Faites-le ! Nâ€™oubliez pas de vÃ©rifier les conditions dâ€™applications de lâ€™ANOVA!\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nanova(anova.nested)\n\nAnalysis of Variance Table\n\nResponse: survival\n                 Df  Sum Sq Mean Sq  F value Pr(&gt;F)    \ngenotype          2 2952.22 1476.11 292.6081 &lt;2e-16 ***\ngenotype:chamber  6   40.65    6.78   1.3432 0.2639    \nResiduals        36  181.61    5.04                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\npar(mfrow = c(2, 2))\nplot(anova.nested)\n\n\n\n\n\n\nFigureÂ 12.7: Conditions dâ€™applications du modÃ¨le anova.nested\n\n\n\n\n\n\n\nOn conclue de cette analyse que la variation entre les chambres de croissance nâ€™est pas significative, mais quâ€™on doit rejeter lâ€™hypothÃ¨se nulle que tous les gÃ©notypes ont la mÃªme rÃ©sistance Ã  la dessiccation.\nComme lâ€™effet hiÃ©rarchique chamber / genotype nâ€™est pas significatif, on peut regrouper les observations pour augmenter le nombre de degrÃ©s de libertÃ©:\n\nanova.simple &lt;- lm(survival ~ genotype, data = nestdat)\nanova(anova.simple)\n\nAnalysis of Variance Table\n\nResponse: survival\n          Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \ngenotype   2 2952.22 1476.11  278.93 &lt; 2.2e-16 ***\nResiduals 42  222.26    5.29                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nDonc on conclue quâ€™il y a une variation significative de rÃ©sistance Ã  la dessiccation entre les trois gÃ©notypes.\nLe graphique de survival en fonction du gÃ©notype suggÃ¨re que la rÃ©sistance Ã  la dessiccation varie entre chaque gÃ©notype. On peut combiner cela avec un test de Tukey.\n\npar(mfrow = c(1, 1))\n# Compute and plot means and Tukey CI\nmeans &lt;- glht(anova.simple, linfct = mcp(\n  genotype =\n    \"Tukey\"\n))\ncimeans &lt;- cld(means)\n# use sufficiently large upper margin\nold.par &lt;- par(mai = c(1, 1, 1.25, 1))\n# plot\nplot(cimeans, las = 1) # las option to put y-axis labels as God intended them\n\n\n\n\n\n\nFigureÂ 12.8: Effet du genotype sur la rÃ©sistance Ã  la dessication avec un test de Tukey\n\n\n\n\nOn conclue donc que la rÃ©sistance Ã  la dessiccation (R), telle que mesurÃ©e par la survie dans des conditions chaudes et sÃ¨ches, varie significativement entre les trois gÃ©notypes avec R(AA) &gt; R(Aa) &gt; R(aa).\nCependant, avant dâ€™accepter cette conclusion, il faut Ã©prouver les conditions dâ€™application du test. Voici les diagnostics des rÃ©sidus pour lâ€™ANOVA Ã  un critÃ¨re de classification (non hiÃ©rarchique):\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\npar(mfrow = c(2, 2))\nplot(anova.simple)\n\n\n\n\n\n\nFigureÂ 12.9: Conditions dâ€™applications du modÃ¨le anova.simple\n\n\n\n\n\n\n\nDonc, toutes les conditions dâ€™application semblent Ãªtre remplies, et on peut donc accepter les conclusions. Notez que si lâ€™on compare le carrÃ© moyen des rÃ©sidus de lâ€™ANOVA hiÃ©rarchique et de lâ€™ANOVA Ã  un critÃ¨re de classification (5.045 vs 5.292), ils sont presque identiques. Cela nâ€™est pas surprenant compte tenu de la faible variabilitÃ© associÃ©e aux chambres de croissance pour chaque gÃ©notype.",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>12</span>Â  <span class='chapter-title'>ANOVA Ã  critÃ¨res multiples : plans factoriels et hiÃ©rarchiques</span>"
    ]
  },
  {
    "objectID": "34-anova_mult.html#anova-non-paramÃ©trique-avec-deux-facteurs-de-classification",
    "href": "34-anova_mult.html#anova-non-paramÃ©trique-avec-deux-facteurs-de-classification",
    "title": "\n12Â  ANOVA Ã  critÃ¨res multiples : plans factoriels et hiÃ©rarchiques\n",
    "section": "\n12.5 ANOVA non paramÃ©trique avec deux facteurs de classification",
    "text": "12.5 ANOVA non paramÃ©trique avec deux facteurs de classification\nLâ€™ANOVA non paramÃ©trique Ã  deux critÃ¨res de classification est une extension de celle Ã  un critÃ¨re de classification vue prÃ©cÃ©demment. Elle dÃ©bute par une ANOVA faite sur les donnÃ©es transformÃ©es en rangs. Elle peut se faire sur des donnÃ©es avec ou sans rÃ©plicats.\nÃ€ partir du fichier stu2wdat.csv, effectuez une ANOVA non paramÃ©trique Ã  deux facteurs de classification pour examiner lâ€™effet de sex et location sur rank(rdwght).\n\naov.rank &lt;- aov(\n  rank(rdwght) ~ sex * location,\n  contrasts = list(\n    sex = contr.sum, location = contr.sum\n  ),\n  data = Stu2wdat\n)\n\nLâ€™extension de Schreirer-Ray-Hare au test de Kruskall-Wallis se fait ensuite Ã  la main. Il faut dâ€™abord calculer la statistique H Ã©gale au rapport de la somme des carrÃ©es de lâ€™effet testÃ©, divisÃ©e par le carrÃ© moyen total. On calcule la statistique H pour chacun des termes. Les statistiques H sont ensuite comparÃ©es Ã  une distribution thÃ©orique de \\(\\chi^2\\) (chi-carrÃ©) en utilisant la commande pchisq(H, df, lower.tail = FALSE), oÃ¹ H et df sont les statistiques H calculÃ©es et les degrÃ©s de libertÃ©s, respectivement.\nTestez lâ€™effet de sex et location sur rdwght. Que concluez-vous ? Comment ce rÃ©sultat se compare-t-il Ã  celui obtenu en faisant lâ€™ANOVA paramÃ©trique faite prÃ©cÃ©demment ?\n\nAnova(aov.rank, type = 3)\n\nAnova Table (Type III tests)\n\nResponse: rank(rdwght)\n              Sum Sq  Df  F value    Pr(&gt;F)    \n(Intercept)  1499862   1 577.8673 &lt; 2.2e-16 ***\nsex            58394   1  22.4979 4.237e-06 ***\nlocation        1128   1   0.4347    0.5105    \nsex:location    1230   1   0.4738    0.4921    \nResiduals     472383 182                       \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nPour calculer lâ€™extension Schreirer-Ray-Hare au test de Kruskall-Wallis, on doit dâ€™abord calculer le carrÃ© moyen total (MS), i.e.Â la variance des donnÃ©es transformÃ©es en rang. Ici, on a 186 observations, donc des rangs; 1, 2, 3, â€¦ 186. La variance de cette sÃ©rie de 186 valeurs peut Ãªtre calculÃ©e simplement par var(1:186).\nDonc on peut calculer la statistique H pour chaque terme:\n\nHsex &lt;- 58394 / var(1:186)\nHlocation &lt;- 1128 / var(1:186)\nHsexloc &lt;- 1230 / var(1:186)\n\nEt convertir ces statistiques en valeur de ps:\n\n# sex\nHsex\n\n[1] 20.14628\n\npchisq(Hsex, 1, lower.tail = FALSE)\n\n[1] 7.173954e-06\n\n# location\nHlocation\n\n[1] 0.3891668\n\npchisq(Hlocation, 1, lower.tail = FALSE)\n\n[1] 0.5327377\n\n# sex:location\nHsexloc\n\n[1] 0.4243574\n\npchisq(Hsexloc, 1, lower.tail = FALSE)\n\n[1] 0.5147707\n\n\nCes rÃ©sultats sont semblables aux rÃ©sultats de lâ€™ANOVA non-paramÃ©trique Ã  deux critÃ¨res de classification. MalgrÃ© la puissance rÃ©duite, il y a encore un effet significatif du sexe, mais ni interaction ni effet du site.\nIl y a toutefois une diffÃ©rence importante. Rappelez-vous que dans lâ€™ANOVA paramÃ©trique il y avait un effet significatif de sex en considÃ©rant le problÃ¨me comme un modÃ¨le ANOVA Ã  effet fixe. Cependant, si on traite le problÃ¨me comme un modÃ¨le dâ€™ANOVA Ã  effet mixte lâ€™effet significatif de sex peut en principe disparaÃ®tre parce que le nombre de degrÃ© de libertÃ© (dl) associÃ©s au carrÃ© moyen (CM) de lâ€™interaction est plus faible que le nombre de dl du CM de lâ€™erreur du modÃ¨le Ã  effet fixes. Dans ce cas ci, cependant, le CM de lâ€™interaction est environ la moitiÃ© du CM de lâ€™erreur. Par consÃ©quent, lâ€™effet significatif de sex pourrait devenir encore plus significatif si le problÃ¨me est analysÃ© (comme il se doit) comme une ANOVA mixte. Encore une fois on peut voir lâ€™importance de spÃ©cifier le modÃ¨le adÃ©quat en ANOVA.",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>12</span>Â  <span class='chapter-title'>ANOVA Ã  critÃ¨res multiples : plans factoriels et hiÃ©rarchiques</span>"
    ]
  },
  {
    "objectID": "34-anova_mult.html#comparaisons-multiples",
    "href": "34-anova_mult.html#comparaisons-multiples",
    "title": "\n12Â  ANOVA Ã  critÃ¨res multiples : plans factoriels et hiÃ©rarchiques\n",
    "section": "\n12.6 Comparaisons multiples",
    "text": "12.6 Comparaisons multiples\nLes Ã©preuves dâ€™hypothÃ¨ses subsÃ©quentes en ANOVA Ã  plus dâ€™un critÃ¨re de classification dÃ©pendent des rÃ©sultats initiaux de lâ€™ANOVA. Si vous Ãªtes intÃ©ressÃ©s Ã  comparer des effets moyens dâ€™un facteur pour tous les niveaux dâ€™un autre facteur (par exemple lâ€™effet du sexe sur la taille des esturgeons peu importe dâ€™oÃ¹ ils viennent), alors vous pouvez procÃ©der exactement tel que dÃ©crit dans la section sur les comparaisons multiples suivant lâ€™ANOVA Ã  un critÃ¨re de classification. Pour comparer les moyennes des cellules entre elles, il faut spÃ©cifier lâ€™interaction comme variable qui reprÃ©sente le groupe.\nLe fichier wmcdat2.csv contient des mesures de consommation dâ€™oxygÃ¨ne, o2cons, de deux espÃ¨ces, species, dâ€™un mollusque (une patelle) Ã  trois concentrations diffÃ©rentes dâ€™eau de mer, conc. Ces donnÃ©es sont prÃ©sentÃ©es Ã  la p.Â 332 de Sokal et Rohlf 1995.\n\nEffectuez une ANOVA factorielle Ã  deux critÃ¨res de classification sur ces donnÃ©es en utilisant o2cons comme variable dÃ©pendante et species et conc comme les facteurs (il va probablement falloir changer le type de donnÃ©es de variable conc Ã  facteur). Que concluez-vous ?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nwmcdat2 &lt;- read.csv(\"data/wmcdat2.csv\")\nwmcdat2$species &lt;- as.factor(wmcdat2$species)\nwmcdat2$conc &lt;- as.factor(wmcdat2$conc)\nanova.model5 &lt;- lm(o2cons ~ species * conc, data = wmcdat2)\nAnova(anova.model5, type = 3)\n\n\n\n\n\n\nAnova Table (Type III tests)\n\nResponse: o2cons\n              Sum Sq Df  F value    Pr(&gt;F)    \n(Intercept)  1185.60  1 124.0165 4.101e-14 ***\nspecies         0.09  1   0.0097   0.92189    \nconc           74.90  2   3.9172   0.02755 *  \nspecies:conc   23.93  2   1.2514   0.29656    \nResiduals     401.52 42                       \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nComme lâ€™effectif dans chaque cellule est relativement petit, il faudrait idÃ©alement refaire cette analyse avec une ANOVA non-paramÃ©trique. Pour le moment, contentons nous de la version paramÃ©trique.\nExaminons les graphiques diagnostiques:\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\npar(mfrow = c(2, 2))\nplot(anova.model5)\n\n\n\n\n\n\nFigureÂ 12.10\n\n\n\n\n\n\n\nLes variances semblent donc Ã©gales. Le test de normalitÃ© donne:\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nshapiro.test(residuals(anova.model5))\n\n\n    Shapiro-Wilk normality test\n\ndata:  residuals(anova.model5)\nW = 0.93692, p-value = 0.01238\n\n\n\n\n\nIl y a donc Ã©vidence de non-normalitÃ©, mais Ã  part Ã§a tout semble aller. Comme lâ€™ANOVA est relativement robuste Ã  la non-normalitÃ©, on va regarder de lâ€™autre cotÃ©. (Si vous voulez Ãªtre plus confiants, vous pouvez tourner une ANOVA non paramÃ©trique. Vous arriverez aux mÃªmes conclusions.)\n\nÃ€ la suite des rÃ©sultats que vous venez dâ€™obtenir, quelles moyennes voudriez-vous comparer ? Pourquoi?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\najouter une explication ici\n\n\n\nOn conclue donc quâ€™il nâ€™y a pas de diffÃ©rence entre les espÃ¨ces et que lâ€™effet de la concentration ne dÃ©pends pas de lâ€™espÃ¨ce (il nâ€™y a pas dâ€™interaction). Par consÃ©quent, les seules comparaisons justifiables sont entre les concentrations:\n\n# fit simplified model\nanova.model6 &lt;- aov(o2cons ~ conc, data = wmcdat2)\n# Make Tukey multiple comparisons\nTukeyHSD(anova.model6)\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = o2cons ~ conc, data = wmcdat2)\n\n$conc\n           diff       lwr        upr     p adj\n75-50  -4.63625 -7.321998 -1.9505018 0.0003793\n100-50 -3.25500 -5.940748 -0.5692518 0.0141313\n100-75  1.38125 -1.304498  4.0669982 0.4325855\n\npar(mfrow = c(1, 1))\n# Graph of all comparisons for conc\ntuk &lt;- glht(anova.model6, linfct = mcp(conc = \"Tukey\"))\n# extract information\ntuk.cld &lt;- cld(tuk)\n# use sufficiently large upper margin\nold.par &lt;- par(mai = c(1, 1, 1.25, 1))\n# plot\nplot(tuk.cld)\npar(old.par)\n\n\n\n\n\n\nFigureÂ 12.11: Comparaison de Tukey des moyennes de consommation dâ€™oxygÃ¨n en fonction del la concentration\n\n\n\n\nIl y a donc une diffÃ©rence de consommation dâ€™oxygÃ¨ne significative lorsque la salinitÃ© est rÃ©duite de 50%, mais pas Ã  25% de rÃ©duction.\n\nRÃ©pÃ©tez les deux analyses prÃ©cÃ©dentes sur les donnÃ©es du fichier wmc2dat2.csv. Comment les rÃ©sultats se comparent-ils Ã  ceux obt$nus prÃ©cÃ©demment ?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nwmc2dat2 &lt;- read.csv(\"data/wmc2dat2.csv\")\nwmc2dat2$species &lt;- as.factor(wmc2dat2$species)\nwmc2dat2$conc &lt;- as.factor(wmc2dat2$conc)\nanova.model7 &lt;- lm(o2cons ~ species * conc, data = wmc2dat2)\n\n\n\n\nEn utilisant wmc2dat2.csv, on obtient:\n\n\nAnova Table (Type III tests)\n\nResponse: o2cons\n             Sum Sq Df F value    Pr(&gt;F)    \n(Intercept)  343.09  1 36.2132 3.745e-07 ***\nspecies      133.52  1 14.0929 0.0005286 ***\nconc          66.76  2  3.5232 0.0385011 *  \nspecies:conc 168.15  2  8.8742 0.0006101 ***\nResiduals    397.91 42                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nDans ce cas ci, il y a une interaction significative, et il nâ€™est par consÃ©quent pas appropriÃ© de comparer les moyennes regroupÃ©es par espÃ¨ce ou concentration. Ceci est clairement visualisÃ© par un graphique dâ€™interaction:\n\nwith(wmc2dat2, interaction.plot(conc, species, o2cons))\n\n\n\n\n\n\n\n\nToujours en utilisant les donnÃ©es de wmc2dat2.csv, comparez les 6 moyennes avec lâ€™ajustement Bonferonni. Pour ce faire, il sera utile de crÃ©er une nouvelle variable qui combine species et conc:\n\n\nwmc2dat2$species.conc &lt;- as.factor(paste0(wmc2dat2$species, wmc2dat2$conc))\n\nensuite on peut faire les comparaisons de Bonferroni:\n\nwith(wmc2dat2, pairwise.t.test(o2cons, species.conc, p.adj = \"bonf\"))\n\n\n    Pairwise comparisons using t tests with pooled SD \n\ndata:  o2cons and species.conc \n\n     A100   A50    A75    B100   B50   \nA50  0.1887 -      -      -      -     \nA75  1.0000 1.0000 -      -      -     \nB100 0.7223 1.0000 1.0000 -      -     \nB50  1.0000 0.0079 0.0929 0.0412 -     \nB75  0.6340 1.0000 1.0000 1.0000 0.0350\n\nP value adjustment method: bonferroni \n\n\nCes comparaisons sont un peu plus difficiles Ã  interprÃ©ter, mais lâ€™analyse examine essentiellement les diffÃ©rences entre les concentrations de lâ€™eau dans lâ€™espÃ¨ce A (nommÃ© adj1) et pour les diffÃ©rences entre les concentrations dans lâ€™espÃ¨ce B (nommÃ© adj2). Cette analyse indique que la diffÃ©rence principale est entre la concentration de 50% pour lâ€™espÃ¨ce B et les concentrations de 75 et 100% de lâ€™espÃ¨ce B, tandis quâ€™il nâ€™y a aucunes diffÃ©rences significatives pour lâ€™espÃ¨ce A.\nJe trouve ces tableaux de rÃ©sultats peu satisfaisants parce quâ€™ils indiquent seulement les valeur de ps sans indices de la taille de lâ€™effet. On peut obtenir Ã  la fois le rÃ©sultat des tests de comparaison multiple et un indice de la taille de lâ€™effet Ã  lâ€™aide du code suivant:\n\n# fit one-way anova comparing all combinations of species.conc combinations\nanova.modelx &lt;- aov(o2cons ~ species.conc, data = wmc2dat2)\ntuk2 &lt;- glht(anova.modelx, linfct = mcp(species.conc = \"Tukey\"))\n# extract information\ntuk2.cld &lt;- cld(tuk2)\n# use sufficiently large upper margin\nold.par &lt;- par(mai = c(1, 1, 1.25, 1))\n# plot\nplot(tuk2.cld)\npar(old.par)\n\n\n\n\n\n\nFigureÂ 12.12\n\n\n\n\nDans cette analyse on a utilisÃ© le CM = 9.474 du modÃ¨le dâ€™ANOVA pour comparer les moyennes. En ce faisant, on prÃ©sume quâ€™il sâ€™agit dâ€™une situation dâ€™ANOVA Ã  effet fixes, ce qui nâ€™est peut-Ãªtre pas le cas (conc est certainement fixe, mais species peut Ãªtre fixe ou alÃ©atoire).",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>12</span>Â  <span class='chapter-title'>ANOVA Ã  critÃ¨res multiples : plans factoriels et hiÃ©rarchiques</span>"
    ]
  },
  {
    "objectID": "34-anova_mult.html#test-de-permutation-pour-lanova-Ã -deux-facteurs-de-classification",
    "href": "34-anova_mult.html#test-de-permutation-pour-lanova-Ã -deux-facteurs-de-classification",
    "title": "\n12Â  ANOVA Ã  critÃ¨res multiples : plans factoriels et hiÃ©rarchiques\n",
    "section": "\n12.7 Test de permutation pour lâ€™ANOVA Ã  deux facteurs de classification",
    "text": "12.7 Test de permutation pour lâ€™ANOVA Ã  deux facteurs de classification\nQuand les donnÃ©es ne rencontrent pas les conditions dâ€™application des tests paramÃ©triques dâ€™ANOVA Ã  un ou plusieurs facteurs de classification, il est possible dâ€™utiliser les tests de permutation comme une alternative aux tests non-paramÃ©triques pour calculer des p-valeurs. Le code suivant est pour un modÃ¨le I dâ€™une ANOVA Ã  deux facteurs de classification. Je vous laisse le soin dâ€™adapter ce code pour dâ€™autres modÃ¨les. (Jâ€™offre mÃªme des points boni pour une solution Ã©lÃ©gante pour des modÃ¨les Ã  plusieurs facteurs de classification).\n\n###########################################################\n# Permutation test for two way ANOVA\n# Ter Braak creates residuals from cell means and then permutes across\n# all cells\n# This can be accomplished by taking residuals from the full model\n# modified from code written by David C. Howell\n# http://www.uvm.edu/~dhowell/StatPages/More_Stuff/Permutation%20Anova/PermTestsAnova.html\nnreps &lt;- 500\ndependent &lt;- Stu2wdat$rdwght\nfactor1 &lt;- as.factor(Stu2wdat$sex)\nfactor2 &lt;- as.factor(Stu2wdat$location)\nmy.dataframe &lt;- data.frame(dependent, factor1, factor2)\nmy.dataframe.noNA &lt;- my.dataframe[complete.cases(my.dataframe), ]\nmod &lt;- lm(dependent ~ factor1 + factor2 + factor1:factor2,\n  data = my.dataframe.noNA\n)\nres &lt;- mod$residuals\nTBint &lt;- numeric(nreps)\nTB1 &lt;- numeric(nreps)\nTB2 &lt;- numeric(nreps)\nANOVA &lt;- summary(aov(mod))\ncat(\n  \" The standard ANOVA for these data follows \",\n  \"\\n\"\n)\nF1 &lt;- ANOVA[[1]]$\"F value\"[1]\nF2 &lt;- ANOVA[[1]]$\"F value\"[2]\nFinteract &lt;- ANOVA[[1]]$\"F value\"[3]\nprint(ANOVA)\ncat(\"\\n\")\ncat(\"\\n\")\nTBint[1] &lt;- Finteract\nfor (i in 2:nreps) {\n  newdat &lt;- sample(res, length(res), replace = FALSE)\n  modb &lt;- summary(aov(newdat ~ factor1 + factor2 +\n    factor1:factor2,\n  data = my.dataframe.noNA\n  ))\n  TBint[i] &lt;- modb[[1]]$\"F value\"[3]\n  TB1[i] &lt;- modb[[1]]$\"F value\"[1]\n  TB2[i] &lt;- modb[[1]]$\"F value\"[2]\n}\nprobInt &lt;- length(TBint[TBint &gt;= Finteract]) / nreps\nprob1 &lt;- length(TB1[TB1 &gt;= F1]) / nreps\nprob2 &lt;- length(TB2[TB1 &gt;= F2]) / nreps\ncat(\"\\n\")\ncat(\"\\n\")\nprint(\"Resampling as in ter Braak with unrestricted sampling\nof cell residuals. \")\ncat(\n  \"The probability for the effect of Interaction is \",\n  probInt, \"\\n\"\n)\ncat(\n  \"The probability for the effect of Factor 1 is \",\n  prob1, \"\\n\"\n)\ncat(\n  \"The probability for the effect of Factor 2 is \",\n  prob2, \"\\n\"\n)\n\nSi vous avez la chance dâ€™avoir accÃ¨s au package lmPerm, vous pouvez effectuer le test de permutation beaucoup plus rapidement et facilement:\n\n#######################################################################\n## lmPerm version of permutation test\nlibrary(lmPerm)\n# for generality, copy desired dataframe to mydata\n# and model formula to myformula\nmydata &lt;- Stu2wdat\nmyformula &lt;- as.formula(\"rdwght ~ sex+location+sex:location\")\n# Fit desired model on the desired dataframe\nmymodel &lt;- lm(myformula, data = mydata)\n# Calculate permutation p-value\nanova(lmp(myformula, data = mydata, perm = \"Prob\", center = FALSE, Ca = 0.001))",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>12</span>Â  <span class='chapter-title'>ANOVA Ã  critÃ¨res multiples : plans factoriels et hiÃ©rarchiques</span>"
    ]
  },
  {
    "objectID": "34-anova_mult.html#bootstrap-pour-lanova-Ã -deux-facteurs-de-classification",
    "href": "34-anova_mult.html#bootstrap-pour-lanova-Ã -deux-facteurs-de-classification",
    "title": "\n12Â  ANOVA Ã  critÃ¨res multiples : plans factoriels et hiÃ©rarchiques\n",
    "section": "\n12.8 Bootstrap pour lâ€™ANOVA Ã  deux facteurs de classification",
    "text": "12.8 Bootstrap pour lâ€™ANOVA Ã  deux facteurs de classification\nDans la plupart des cas, les tests de permutation seront plus appropriÃ©s que le bootstrap pour les designs dâ€™ANOVA. Jâ€™ai quand mÃªme un bout de code qui pourra servir si vous en avez besoin:\n\n############################################################\n###########\n# Bootstrap for two-way ANOVA\n# You possibly want to edit bootfunction.mod1 to return other values\n# Here it returns the standard coefficients of the fitted model\n# Requires boot library\n#\nnreps &lt;- 5000\ndependent &lt;- Stu2wdat$rdwght\nfactor1 &lt;- as.factor(Stu2wdat$sex)\nfactor2 &lt;- as.factor(Stu2wdat$location)\nmy.dataframe &lt;- data.frame(dependent, factor1, factor2)\nmy.dataframe.noNA &lt;- my.dataframe[complete.cases(my.dataframe), ]\nlibrary(boot)\n# Fit model on observed data\nmod1 &lt;- aov(dependent ~ factor1 + factor2 + factor1:factor2,\n  data = my.dataframe.noNA\n)\n\n\n# Bootstrap 1000 time using the residuals bootstraping methods to\n# keep the same unequal number of observations for each level of the indep. var.\nfit &lt;- fitted(mod1)\ne &lt;- residuals(mod1)\nX &lt;- model.matrix(mod1)\nbootfunction.mod1 &lt;- function(data, indices) {\n  y &lt;- fit + e[indices]\n  bootmod &lt;- lm(y ~ X)\n  coefficients(bootmod)\n}\nbootresults &lt;- boot(my.dataframe.noNA, bootfunction.mod1,\n  R = 1000\n)\nbootresults\n## Calculate 90% CI and plot bootstrap estimates separately for each model parameter\nboot.ci(bootresults, conf = 0.9, index = 1)\nplot(bootresults, index = 1)\nboot.ci(bootresults, conf = 0.9, index = 3)\nplot(bootresults, index = 3)\nboot.ci(bootresults, conf = 0.9, index = 4)\nplot(bootresults, index = 4)\nboot.ci(bootresults, conf = 0.9, index = 5)\nplot(bootresults, index = 5)",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>12</span>Â  <span class='chapter-title'>ANOVA Ã  critÃ¨res multiples : plans factoriels et hiÃ©rarchiques</span>"
    ]
  },
  {
    "objectID": "35-reg_mult.html",
    "href": "35-reg_mult.html",
    "title": "\n13Â  RÃ©gression multiple\n",
    "section": "",
    "text": "13.1 Paquets et donnÃ©es requises pour le labo\nCe laboratoire nÃ©cessite:",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>13</span>Â  <span class='chapter-title'>RÃ©gression multiple</span>"
    ]
  },
  {
    "objectID": "35-reg_mult.html#set-reg-mul",
    "href": "35-reg_mult.html#set-reg-mul",
    "title": "\n13Â  RÃ©gression multiple\n",
    "section": "",
    "text": "les paquets R:\n\nggplot2\ncar\nlmtest\nsimpleboot\nboot\nMuMIn\n\n\nles fichiers de donnÃ©es\n\nMregdat.csv",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>13</span>Â  <span class='chapter-title'>RÃ©gression multiple</span>"
    ]
  },
  {
    "objectID": "35-reg_mult.html#conseils-gÃ©nÃ©raux",
    "href": "35-reg_mult.html#conseils-gÃ©nÃ©raux",
    "title": "\n13Â  RÃ©gression multiple\n",
    "section": "\n13.2 Conseils gÃ©nÃ©raux",
    "text": "13.2 Conseils gÃ©nÃ©raux\nLes variables qui intÃ©ressent les biologistes sont gÃ©nÃ©ralement influencÃ©es par plusieurs facteurs, et une description exacte ou une prÃ©diction de la variable dÃ©pendante requiert que plus dâ€™une variable soit incluse dans le modÃ¨le. La rÃ©gression multiple permet de quantifier lâ€™effet de plusieurs variables continues sur la variable dÃ©pendante.\nIl est important de rÃ©aliser que la maÃ®trise de la rÃ©gression multiple ne sâ€™acquiert pas instantanÃ©ment. Les dÃ©butants doivent garder Ã  lâ€™esprit plusieurs points importants :\n\nUn modÃ¨le de rÃ©gression multiple peut Ãªtre hautement significatif mÃªme si aucun des termes pris isolÃ©ment ne lâ€™est (ceci est causÃ© par la multicolinÃ©aritÃ©),\nUn modÃ¨le peut ne pas Ãªtre significatif alors que lâ€™un ou plusieurs des termes le sont (ceci est un signe dâ€™un modÃ¨le trop complexe (â€œoverfittingâ€)) et,\nÃ€ moins que les variables indÃ©pendantes soient parfaitement orthogonales (câ€™est-Ã -dire quâ€™il nâ€™y ait aucune corrÃ©lation entre elles et donc pas de multicolinÃ©aritÃ©) les diverses approches de sÃ©lection des variables indÃ©pendantes peuvent mener Ã  des modÃ¨les diffÃ©rents.",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>13</span>Â  <span class='chapter-title'>RÃ©gression multiple</span>"
    ]
  },
  {
    "objectID": "35-reg_mult.html#premiÃ¨res-rÃ©gressions-multiples",
    "href": "35-reg_mult.html#premiÃ¨res-rÃ©gressions-multiples",
    "title": "\n13Â  RÃ©gression multiple\n",
    "section": "\n13.3 PremiÃ¨res rÃ©gressions multiples",
    "text": "13.3 PremiÃ¨res rÃ©gressions multiples\nLe fichier Mregdat.csv contient des donnÃ©es de richesse spÃ©cifique de quatre groupes dâ€™organismes dans 30 marais de la rÃ©gion Ottawa-Cornwall-Kingston. Les variables sont:\n\nla richesse spÃ©cifique:\n\ndes oiseaux (bird, et son logarithme base 10 logbird)\ndes mammifÃ¨res (mammal, logmam)\ndes amphibiens et reptiles (herptile, logherp)\ndes vertÃ©brÃ©s (totsp, logtot)\n\n\nles coordonnÃ©es des sites (lat, long)\nla superficie du marais (logarea)\nle pourcentage du marais inondÃ© toute lâ€™annÃ©e (swamp)\nle pourcentage des terres couvertes par des forÃªts dans un rayon de 1km du marais (cpfor2)\nla densitÃ© des routes pavÃ©es (en m/ha) dans un rayon de 1km du marais (thtden).\n\nNous allons nous concentrer sur les amphibiens et les reptiles (herptile) pour cet exemple, il est donc avisÃ© dâ€™examiner la distribution de cette variable et les corrÃ©lations avec les variables indÃ©pendantes potentielles:\n\nmydata &lt;- read.csv(\"data/Mregdat.csv\")\nscatterplotMatrix(\n  ~ logherp + logarea + cpfor2 + thtden + swamp,\n  regLine = TRUE, smooth = TRUE, diagonal = TRUE,\n  data = mydata\n)\n\n\n\n\n\n\nFigureÂ 13.1: Matrice de rÃ©lation et densitÃ© pour la richesse spÃ©cifique des amphibiens et reptiles\n\n\n\n\n\nEn utilisant les donnÃ©es de ce fichier, faites la rÃ©gression simple de logherp en fonction de logarea . Que concluez-vous Ã  partir de cette analyse?\n\n\nmodel.loga &lt;- lm(logherp ~ logarea, data = mydata)\nsummary(model.loga)\n\n\nCall:\nlm(formula = logherp ~ logarea, data = mydata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.38082 -0.09265  0.00763  0.10409  0.46977 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.18503    0.15725   1.177 0.249996    \nlogarea      0.24736    0.06536   3.784 0.000818 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1856 on 26 degrees of freedom\n  (2 observations deleted due to missingness)\nMultiple R-squared:  0.3552,    Adjusted R-squared:  0.3304 \nF-statistic: 14.32 on 1 and 26 DF,  p-value: 0.0008185\n\npar(mfrow = c(2, 2))\nplot(model.loga)\n\n\n\n\n\n\nFigureÂ 13.2: Conditions dâ€™applications de la rÃ©gression de logherp sur logarea\n\n\n\n\nIl semble donc y avoir une relation positive entre la richesse spÃ©cifique des reptiles et des amphibiens et la surface des marais. La rÃ©gression nâ€™explique cependant quâ€™environ le tiers de la variabilitÃ© (R 2 =0.355). Lâ€™analyse des rÃ©sidus indique quâ€™il nâ€™y a pas de problÃ¨me avec la normalitÃ©, lâ€™homoscÃ©dasticitÃ©, ni lâ€™indÃ©pendance.\n\nFaites ensuite la rÃ©gression de logherp en fonction de cpfor2 . Que concluez-vous?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nmodel.logcp &lt;- lm(logherp ~ cpfor2, data = mydata)\nsummary(model.logcp)\n\n\nCall:\nlm(formula = logherp ~ cpfor2, data = mydata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.49095 -0.10266  0.05881  0.16027  0.25159 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 0.609197   0.104233   5.845 3.68e-06 ***\ncpfor2      0.002706   0.001658   1.632    0.115    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2202 on 26 degrees of freedom\n  (2 observations deleted due to missingness)\nMultiple R-squared:  0.09289,   Adjusted R-squared:  0.058 \nF-statistic: 2.662 on 1 and 26 DF,  p-value: 0.1148\n\n\n\n\n\nIci, on doit accepter lâ€™hypothÃ¨se nulle et conclure quâ€™il nâ€™y a pas de relation entre la richesse spÃ©cifique dans les marais (logherp) et la proportion de forÃªts sur les terres adjacentes (cpfor2). Quâ€™est-ce qui arrive quand on fait une rÃ©gression avec les 2 variables indÃ©pendantes?\n\nRefaites la rÃ©gression de logherp enfonction de logarea et cpfor2 Ã  la fois. Que concluez-vous?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nmodel.mcp &lt;- lm(logherp ~ logarea + cpfor2, data = mydata)\nsummary(model.mcp)\n\n\nCall:\nlm(formula = logherp ~ logarea + cpfor2, data = mydata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.40438 -0.11512  0.01774  0.08187  0.36179 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 0.027058   0.166749   0.162 0.872398    \nlogarea     0.247789   0.061603   4.022 0.000468 ***\ncpfor2      0.002724   0.001318   2.067 0.049232 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.175 on 25 degrees of freedom\n  (2 observations deleted due to missingness)\nMultiple R-squared:  0.4493,    Adjusted R-squared:  0.4052 \nF-statistic:  10.2 on 2 and 25 DF,  p-value: 0.0005774\n\n\n\n\n\nOn voit donc quâ€™on peut rejeter les 2 hypothÃ¨ses nulles que la pente de la rÃ©gression de logherp sur logarea est zÃ©ro et que la pente de la rÃ©gression de logherp sur cpfor2 est zÃ©ro. Pourquoi cpfor2 devient-il un facteur significatif dans la rÃ©gression multiple alors quâ€™il nâ€™est pas significatif dans la rÃ©gression simple? Parce quâ€™il est parfois nÃ©cessaire de contrÃ´ler pour lâ€™effet dâ€™une variable pour pouvoir dÃ©tecter les effets plus subtils dâ€™autres variables. Ici, il y a une relation significative entre logherp et logarea qui masque lâ€™effet de cpfor2 sur logherp . Lorsque le modÃ¨le tient compte des deux variables explicatives, il devient possible de dÃ©tecter lâ€™effet de cpfor2 .\n\nAjustez un autre modÃ¨le, cette fois en remplaÃ§ant cpfor2 par thtden (logherp ~ logarea + thtden). Que concluez-vous?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nmodel.mden &lt;- lm(logherp ~ logarea + thtden, data = mydata)\nsummary(model.mden)\n\n\nCall:\nlm(formula = logherp ~ logarea + thtden, data = mydata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.31583 -0.12326  0.02095  0.13201  0.31674 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.37634    0.14926   2.521 0.018437 *  \nlogarea      0.22504    0.05701   3.947 0.000567 ***\nthtden      -0.04196    0.01345  -3.118 0.004535 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1606 on 25 degrees of freedom\n  (2 observations deleted due to missingness)\nMultiple R-squared:  0.5358,    Adjusted R-squared:  0.4986 \nF-statistic: 14.43 on 2 and 25 DF,  p-value: 6.829e-05\n\n\n\n\n\nOn rejette donc lâ€™hypothÃ¨se nulle que la richesse spÃ©cifique nâ€™est pas influencÃ©e par la taille des marais (logarea) ni par la densitÃ© des routes (thtden). Notez quâ€™ici il y a une relation nÃ©gative significative entre la richesse spÃ©cifique des amphibiens et reptiles et la densitÃ© des routes sur les terres adjacentes, tandis que la relation est positive pour la taille des marais et pour la densitÃ© des forÃªts (cpfor2 ; rÃ©sultat de la derniÃ¨re rÃ©gression).\nLe \\(R^2\\) de ce modÃ¨le est plus Ã©levÃ© que pour le prÃ©cÃ©dent, reflÃ©tant une corrÃ©lation plus forte entre logherp et thtden quâ€™entre logherp et cpfor2 .\nLa richesse spÃ©cifique des reptiles et amphibiens semble donc reliÃ©e Ã  la surface de marais (logarea), la densitÃ© des routes (thtden), et possiblement au couvert forestier sur les terres adjacentes aux marais (cpfor2). Cependant, les trois variables ne sont peut-Ãªtre pas nÃ©cessaires dans un modÃ¨le prÃ©dictif. Si deux des trois variables (disons cpfor2 et thtden) sont parfaitement corrÃ©lÃ©es, alors lâ€™effet de thtden ne serait rien de plus que celui de cpfor2 (et vice-versa) et un modÃ¨le incluant lâ€™une des deux variables ferait des prÃ©dictions identiques Ã  un modÃ¨le incluant ces deux variables (en plus de logarea).\n\nEstimez un modÃ¨le de rÃ©gression avec logherp comme variable dÃ©pendante et logarea, cpfor2 et thtden comme variables indÃ©pendantes. Que concluez-vous?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nmodel.mtri &lt;- lm(logherp ~ logarea + cpfor2 + thtden, data = mydata)\nsummary(model.mtri)\n\n\nCall:\nlm(formula = logherp ~ logarea + cpfor2 + thtden, data = mydata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.30729 -0.13779  0.02627  0.11441  0.29582 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.284765   0.191420   1.488 0.149867    \nlogarea      0.228490   0.057647   3.964 0.000578 ***\ncpfor2       0.001095   0.001414   0.774 0.446516    \nthtden      -0.035794   0.015726  -2.276 0.032055 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1619 on 24 degrees of freedom\n  (2 observations deleted due to missingness)\nMultiple R-squared:  0.5471,    Adjusted R-squared:  0.4904 \nF-statistic: 9.662 on 3 and 24 DF,  p-value: 0.0002291\n\n\n\n\n\nPlusieurs choses sont Ã  noter ici: 1. Tel que prÃ©dit, le coefficient de rÃ©gression pour cpfor2 nâ€™est plus significativement diffÃ©rent de 0. Une fois que la variabilitÃ© attribuable Ã  logarea et thtden est enlevÃ©e, il ne reste quâ€™une fraction nonsignificative de la variabilitÃ© attribuable Ã  cpfor2 . 2. Le \\(R^2\\) pour ce modÃ¨le(0.547) nâ€™est que lÃ©gÃ¨rement supÃ©rieur au \\(R^2\\) du modÃ¨le avec seulement logarea et thtden (.536), ce qui confirme que cpfor2 nâ€™explique pas grand-chose de plus.\nNotez aussi que mÃªme si le coefficient de rÃ©gression pour thtden nâ€™a pas beaucoup changÃ© par rapport Ã  ce qui avait Ã©tÃ© estimÃ© lorsque seul thtden et logarea Ã©taient dans le modÃ¨le (0-.036 vs -0.042), lâ€™erreur type pour lâ€™estimÃ© du coefficient est plus grand, et ce modÃ¨le plus complexe mÃ¨ne Ã  un estimÃ© moins prÃ©cis. Si la corrÃ©lation entre thtden et cpfor2 Ã©tait plus forte, la dÃ©croissance de la prÃ©cision serait encore plus grande.\nOn peut comparer les deux derniers modÃ¨les (i.e., le modÃ¨le incluant les 3 variables et celui avec seulement logarea and thtden) pour dÃ©cider lequel privilÃ©gier.\n\nanova(model.mtri, model.mden)\n\nAnalysis of Variance Table\n\nModel 1: logherp ~ logarea + cpfor2 + thtden\nModel 2: logherp ~ logarea + thtden\n  Res.Df     RSS Df Sum of Sq     F Pr(&gt;F)\n1     24 0.62937                          \n2     25 0.64508 -1 -0.015708 0.599 0.4465\n\n\nCette comparaison rÃ©vÃ¨le que le modÃ¨le Ã  3 variables ne fait pas de prÃ©dictions significativement meilleures que le modÃ¨le avec seulement Logarea et thtden . Ce rÃ©sultat nâ€™est pas surprenant puisque le test de signification pour cpfor2 dans le modÃ¨le complet indique quâ€™il faut accepter lâ€™hypothÃ¨se nulle.\nÃ€ la suite de cette analyse, on doit conclure que:\n\nLe meilleur modÃ¨le est celui incluant thtden et logarea .\nIl y a une relation nÃ©gative entre la richesse spÃ©cifique des amphibiens et reptiles et la densitÃ© des routes sur les terres adjacentes.\nIl y a une relation positive entre la richesse spÃ©cifique et la taille des marais.\n\nNotez que le â€œmeilleurâ€ modÃ¨le nâ€™est pas nÃ©cessairement le modÃ¨le parfait, seulement le meilleur nâ€™utilisant que ces trois variables indÃ©pendantes. Il est Ã©vident quâ€™il y a dâ€™autres facteurs qui contrÃ´lent la richesse spÃ©cifique dans les marais puisque, mÃªme le â€œmeilleurâ€ modÃ¨le nâ€™explique que la moitiÃ© de la variabilitÃ©.",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>13</span>Â  <span class='chapter-title'>RÃ©gression multiple</span>"
    ]
  },
  {
    "objectID": "35-reg_mult.html#rÃ©gression-multiple-pas-Ã -pas-stepwise",
    "href": "35-reg_mult.html#rÃ©gression-multiple-pas-Ã -pas-stepwise",
    "title": "\n13Â  RÃ©gression multiple\n",
    "section": "\n13.4 RÃ©gression multiple pas-Ã -pas (stepwise)",
    "text": "13.4 RÃ©gression multiple pas-Ã -pas (stepwise)\n\n\n\n\n\n\nAvertissement\n\n\n\nSection encore prÃ©sente Ã  titre dâ€™information mais Ã  ne jamais utiliser Ã  cause de lâ€™ensemble des problÃ¨mes dâ€™infÃ©rences et de bias dans lâ€™erreur de type 1 quâ€™elle gÃ©nÃ¨re.\n\n\nQuand le nombre de variables prÃ©dictives est restreint, comme dans lâ€™exemple prÃ©cÃ©dent, il est aisÃ© de comparer manuellement les modÃ¨les pour sÃ©lectionner le plus adÃ©quat. Cependant, lorsque le nombre de variables indÃ©pendantes augmente, cette approche nâ€™est rapidement plus utilisable et il est alors utile dâ€™utiliser une mÃ©thode automatisÃ©e.\nLa sÃ©lection pas Ã  pas avec R utilise le CritÃ¨re Informatif de Akaike (Akaike Information Criterion, \\(AIC = 2* ln(RSS) + 2K\\) oÃ¹ K le nombre de variables indÃ©pendantes, n est le nombre dâ€™observations, et RSS est la somme des carrÃ©s des rÃ©sidus) comme mesure de la qualitÃ© dâ€™ajustement des modÃ¨les. Cette mesure favorise la prÃ©cision des prÃ©dictions et pÃ©nalise la complexitÃ©. Lorsque lâ€™on compare des modÃ¨les par AIC, le modÃ¨le avec le plus petit AIC est le modÃ¨le Ã  prÃ©fÃ©rer.\n\nUtiliser la fonction step pour activer la sÃ©lection pas Ã  pas des variables indÃ©pendantes sur le modÃ¨les de rÃ©gression incluant logarea, cpfor2 et thtden:\n\n\n# Stepwise Regression\nstep.mtri &lt;- step(model.mtri, direction = \"both\")\n\nStart:  AIC=-98.27\nlogherp ~ logarea + cpfor2 + thtden\n\n          Df Sum of Sq     RSS     AIC\n- cpfor2   1   0.01571 0.64508 -99.576\n&lt;none&gt;                 0.62937 -98.267\n- thtden   1   0.13585 0.76522 -94.794\n- logarea  1   0.41198 1.04135 -86.167\n\nStep:  AIC=-99.58\nlogherp ~ logarea + thtden\n\n          Df Sum of Sq     RSS     AIC\n&lt;none&gt;                 0.64508 -99.576\n+ cpfor2   1   0.01571 0.62937 -98.267\n- thtden   1   0.25092 0.89600 -92.376\n- logarea  1   0.40204 1.04712 -88.013\n\nstep.mtri$anova # display results\n\n      Step Df   Deviance Resid. Df Resid. Dev       AIC\n1          NA         NA        24  0.6293717 -98.26666\n2 - cpfor2  1 0.01570813        25  0.6450798 -99.57640\n\n\nR nous donne:\n\nLâ€™ajustement (mesurÃ© par AIC) du modÃ¨le complet en premier lieu.\nLâ€™AIC des modÃ¨les dans lesquels une variable a Ã©tÃ© enlevÃ©e du modÃ¨le complet. Notez que câ€™est seulement en enlevant cpfor2 du modÃ¨le quâ€™on peut rÃ©duire lâ€™AIC\nLa valeur de AIC pour les modÃ¨les auxquels on enlÃ¨ve ou on ajoute une variable au modÃ¨le sÃ©lectionnÃ© Ã  la premiÃ¨re Ã©tape.(i.e.Â logherp ~ logarea + thtden). Notez quâ€™aucun des modÃ¨les nâ€™a un AIC infÃ©rieur Ã  ce modÃ¨le.\n\nAu lieu de dÃ©buter par le modÃ¨le complet (saturÃ©) et enlever des termes, on peut commencer par le modÃ¨le nul et ajouter des termes:\n\n# Forward selection approach\nmodel.null &lt;- lm(logherp ~ 1, data = mydata)\nstep.f &lt;- step(\n  model.null,\n  scope = ~ . + logarea + cpfor2 + thtden, direction = \"forward\"\n)\n\nStart:  AIC=-82.09\nlogherp ~ 1\n\n          Df Sum of Sq    RSS     AIC\n+ logarea  1   0.49352 0.8960 -92.376\n+ thtden   1   0.34241 1.0471 -88.013\n+ cpfor2   1   0.12907 1.2605 -82.820\n&lt;none&gt;                 1.3895 -82.091\n\nStep:  AIC=-92.38\nlogherp ~ logarea\n\n         Df Sum of Sq     RSS     AIC\n+ thtden  1   0.25093 0.64508 -99.576\n+ cpfor2  1   0.13078 0.76522 -94.794\n&lt;none&gt;                0.89600 -92.376\n\nStep:  AIC=-99.58\nlogherp ~ logarea + thtden\n\n         Df Sum of Sq     RSS     AIC\n&lt;none&gt;                0.64508 -99.576\n+ cpfor2  1  0.015708 0.62937 -98.267\n\nstep.f$anova # display results\n\n       Step Df  Deviance Resid. Df Resid. Dev       AIC\n1           NA        NA        27  1.3895281 -82.09073\n2 + logarea -1 0.4935233        26  0.8960048 -92.37639\n3  + thtden -1 0.2509250        25  0.6450798 -99.57640\n\n\nLe rÃ©sultat final est le mÃªme, mais la trajectoire est diffÃ©rente. Dans ce cas, R dÃ©bute avec le modÃ¨le le plus simple et ajoute une variable indÃ©pendante Ã  chaque Ã©tape, sÃ©lectionnant la variable minimisant AIC Ã  cette Ã©tape. Le modÃ¨le de dÃ©part a donc seulement une ordonnÃ©e Ã  lâ€™origine. Puis, logarea est ajoutÃ©, suivi de thtden. cpfor2 nâ€™est pas ajoutÃ© au modÃ¨le, car son addition fait augmenter lâ€™AIC.\nIl est recommandÃ© de comparer le rÃ©sultat final de plusieurs approches. Si le modÃ¨le retenu diffÃ¨re selon lâ€™approche utilisÃ©e, câ€™est un signe que le â€œmeilleurâ€ modÃ¨le est possiblement difficile Ã  identifier et que vous devriez Ãªtre circonspects dans vos infÃ©rences. Dans notre exemple, pas de problÃ¨me: toutes les mÃ©thodes convergent sur le mÃªme modÃ¨le final.\nPour conclure cette section, quelques conseils concernant les mÃ©thodes automatisÃ©es de sÃ©lection des variables indÃ©pendantes:\n\nLes diffÃ©rentes mÃ©thodes de sÃ©lection des variables indÃ©pendantes peuvent mener Ã  des modÃ¨les diffÃ©rents. Il est souvent utile dâ€™essayer plus dâ€™une mÃ©thode et de comparer les rÃ©sultats. Si les rÃ©sultats diffÃ¨rent, câ€™est presque toujours Ã  cause de multicolinÃ©aritÃ© entre les variables indÃ©pendantes.\nAttention Ã  la rÃ©gression pas-Ã -pas. Les auteurs de SYSTAT en disent:\n\n\nStepwise regression is probably the most abused computerized statistical technique ever devised. If you think you need automated stepwise regression to solve a particular problem, you probably donâ€™t. Professional statisticians rarely use automated stepwise regression because it does not necessarily find the â€œbestâ€ fitting model, the â€œrealâ€ model, or alternative â€œplausibleâ€ models. Furthermore, the order in which variables enter or leave a stepwise program is usually of no theoretical significance. You are always better off thinking about why a model could generate your data and then testing that model.\n\nEn bref, on abuse trop souvent de cette technique.\n\nIl faut toujours garder Ã  lâ€™esprit que lâ€™existence dâ€™une rÃ©gression significative nâ€™est pas suffisante pour prouver une relation causale.",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>13</span>Â  <span class='chapter-title'>RÃ©gression multiple</span>"
    ]
  },
  {
    "objectID": "35-reg_mult.html#dÃ©tecter-la-multicolinÃ©aritÃ©",
    "href": "35-reg_mult.html#dÃ©tecter-la-multicolinÃ©aritÃ©",
    "title": "\n13Â  RÃ©gression multiple\n",
    "section": "\n13.5 DÃ©tecter la multicolinÃ©aritÃ©",
    "text": "13.5 DÃ©tecter la multicolinÃ©aritÃ©\nLa multicolinÃ©aritÃ© est la prÃ©sence de corrÃ©lations entre les variables indÃ©pendantes. Lorsquâ€™elle est extrÃªme (multicolinÃ©aritÃ© parfaite) elle empÃªche lâ€™estimation des modÃ¨les statistiques. Lorsquâ€™elle est grande ou modÃ©rÃ©e, elle rÃ©duit la puissance de dÃ©tection de lâ€™effet des variables indÃ©pendantes individuellement, mais elle nâ€™empÃªche pas le modÃ¨le de faire des prÃ©dictions.\nUn des indices les plus utilisÃ©s pour quantifier la multicolinÃ©aritÃ© et le facteur dâ€™inflation de la variance (VIF, variance inflation factor). Le fichier dâ€™aide du package HH explique ainsi son calcul:\n\nA simple diagnostic of collinearity is the variance inflation factor, VIF one for each regression coefficient (other than the intercept). Since the condition of collinearity involves the predictors but not the response, this measure is a function of the Xâ€™s but not of Y. The VIF for predictor i is \\(1/(1-R_i^2)\\), where \\(R_i^2\\) is the \\(R^2\\) from a regression of predictor i against the remaining predictors. If \\(R_i^2\\) is close to 1, this means that predictor i is well explained by a linear function of the remaining predictors, and, therefore, the presence of predictor i in the model is redundant. Values of VIF exceeding 5 are considered evidence of collinearity: The information carried by a predictor having such a VIF is contained in a subset of the remaining predictors. If, however, all of a modelâ€™s regression coefficients differ significantly from 0 (p-value &lt; .05), a somewhat larger VIF may be tolerable.\n\nBref, les VIF indiquent de combien lâ€™incertitude de chaque coefficient de rÃ©gression est augmentÃ©e par la multicolinÃ©aritÃ©.\nAttrappe. Il y a plusieurs fonctions vif() (jâ€™en connais au moins trois dans les extensions car, HH et DAAG), et je ne sais pas en quoi elles diffÃ¨rent.\nOn peut calculer les VIF avec la fonction vif() de lâ€™extension car:\n\nlibrary(car)\nvif(model.mtri)\n\n logarea   cpfor2   thtden \n1.022127 1.344455 1.365970 \n\n\nIci, il nâ€™y a pas dâ€™Ã©vidence de multicolinÃ©aritÃ© car toutes les valeurs de VIF sont prÃ¨s de 1.",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>13</span>Â  <span class='chapter-title'>RÃ©gression multiple</span>"
    ]
  },
  {
    "objectID": "35-reg_mult.html#rÃ©gression-polynomiale",
    "href": "35-reg_mult.html#rÃ©gression-polynomiale",
    "title": "\n13Â  RÃ©gression multiple\n",
    "section": "\n13.6 RÃ©gression polynomiale",
    "text": "13.6 RÃ©gression polynomiale\nLa rÃ©gression requiert la linÃ©aritÃ© de la relation entre les variables dÃ©pendante et indÃ©pendante(s). Lorsque la relation nâ€™est pas linÃ©aire, il est parfois possible de linÃ©ariser la relation en effectuant une transformation sur une ou plusieurs variables. Cependant, dans bien des cas il est impossible de transformer les axes pour rendre la relation linÃ©aire. On doit alors utiliser une forme ou lâ€™autre de rÃ©gression nonlinÃ©aire. La forme la plus simple de rÃ©gression non-linÃ©aire est la rÃ©gression polynomiale dans laquelle les variables indÃ©pendantes sont Ã  une puissance plus grande que 1 (Ex : \\(X^2\\) ou \\(X^3\\)).\n\nFaites un diagramme de dispersion des rÃ©sidus (residual) de la rÃ©gression logherp ~ logarea en fonction de swamp .\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n# problÃ¨me avec les donnÃ©es de manquantes dans logherp\nmysub &lt;- subset(mydata, !is.na(logherp))\n# ajouter les rÃ©sidus dans les donnÃ©e\nmysub$resloga &lt;- residuals(model.loga)\nggplot(data = mysub, aes(y = resloga, x = swamp)) +\n  geom_point() +\n  geom_smooth()\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\nFigureÂ 13.3: Relation entre swamp et les rÃ©sidus de la rÃ©gression entre logherp et logarea\n\n\n\n\n\n\n\n\nLâ€™examen de ce graphique suggÃ¨re quâ€™il y a une forte relation entre les deux variables, mais quâ€™elle nâ€™est pas linÃ©aire. Essayez de faire une rÃ©gression de residual sur swamp . Quelle est votre conclusion?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nmodel.resloga &lt;- lm(resloga ~ swamp, mysub)\nsummary(model.resloga)\n\n\nCall:\nlm(formula = resloga ~ swamp, data = mysub)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.35088 -0.13819  0.00313  0.10849  0.45802 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)  0.084571   0.109265   0.774    0.446\nswamp       -0.001145   0.001403  -0.816    0.422\n\nResidual standard error: 0.1833 on 26 degrees of freedom\nMultiple R-squared:  0.02498,   Adjusted R-squared:  -0.01252 \nF-statistic: 0.666 on 1 and 26 DF,  p-value: 0.4219\n\n\n\n\n\nEn deux mots, lâ€™ajustement est Ã©pouvantable! MalgrÃ© le fait que le graphique suggÃ¨re une relation trÃ¨s forte entre les deux variables. Cependant, cette relation nâ€™est pas linÃ©aireâ€¦ (ce qui est Ã©galement apparent si vous examinez les rÃ©sidus du modÃ¨le linÃ©aire).\n\nRefaites la rÃ©gression dâ€™en haut, mais cette fois incluez un terme pour reprÃ©senter \\(swamp^2\\) . Lâ€™expression devrait apparaÃ®tre comme: \\(Y ~ X + I(X^2)\\) . Que concluez-vous? Quâ€™est-ce que lâ€™examen des rÃ©sidus de cette rÃ©gression multiple rÃ©vÃ¨le?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nmodel.resloga2 &lt;- lm(resloga ~ swamp + I(swamp^2), mysub)\nsummary(model.resloga2)\n\n\nCall:\nlm(formula = resloga ~ swamp + I(swamp^2), data = mysub)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.181185 -0.085350  0.007377  0.067327  0.242455 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -7.804e-01  1.569e-01  -4.975 3.97e-05 ***\nswamp        3.398e-02  5.767e-03   5.892 3.79e-06 ***\nI(swamp^2)  -2.852e-04  4.624e-05  -6.166 1.90e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1177 on 25 degrees of freedom\nMultiple R-squared:  0.6132,    Adjusted R-squared:  0.5823 \nF-statistic: 19.82 on 2 and 25 DF,  p-value: 6.972e-06\n\n\n\n\n\nIl devient Ã©vident que si on corrige la richesse spÃ©cifique pour la taille des marais, une fraction importante de la variabilitÃ© rÃ©siduelle peut Ãªtre associÃ©e Ã  swamp, selon une relation quadratique. Si vous examinez les rÃ©sidus, vous observerez que lâ€™ajustement est nettement meilleur quâ€™avec le modÃ¨le linÃ©aire.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\npar(mfrow = c(2, 2))\nplot(model.resloga2)\n\n\n\n\n\n\nFigureÂ 13.4: Relation\n\n\n\n\n\n\n\n\nEn vous basant sur les rÃ©sultats de la derniÃ¨re analyse, comment suggÃ©rez-vous de modifier le modÃ¨le de rÃ©gression multiple? Quel est, dâ€™aprÃ¨s vous, le meilleur modÃ¨le? Pourquoi? Ordonnez les diffÃ©rents facteurs en ordre croissant de leur effet sur la richesse spÃ©cifique des reptiles.\n\nSuite Ã  ces analyses, il semble opportun dâ€™essayer dâ€™ajuster un modÃ¨le incluant logarea, thtden, cpfor2, swamp et swamp^2 :\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nmodel.poly1 &lt;- lm(\n  logherp ~ logarea + cpfor2 + thtden + swamp + I(swamp^2),\n  data = mydata\n)\nsummary(model.poly1)\n\n\nCall:\nlm(formula = logherp ~ logarea + cpfor2 + thtden + swamp + I(swamp^2), \n    data = mydata)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.201797 -0.056170 -0.002072  0.051814  0.205626 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -3.203e-01  1.813e-01  -1.766   0.0912 .  \nlogarea      2.202e-01  3.893e-02   5.656 1.09e-05 ***\ncpfor2      -7.864e-04  9.955e-04  -0.790   0.4380    \nthtden      -2.929e-02  1.048e-02  -2.795   0.0106 *  \nswamp        3.113e-02  5.898e-03   5.277 2.70e-05 ***\nI(swamp^2)  -2.618e-04  4.727e-05  -5.538 1.45e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1072 on 22 degrees of freedom\n  (2 observations deleted due to missingness)\nMultiple R-squared:  0.8181,    Adjusted R-squared:  0.7767 \nF-statistic: 19.78 on 5 and 22 DF,  p-value: 1.774e-07\n\n\n\n\n\nLes rÃ©sultats de cette analyse suggÃ¨rent quâ€™on devrait probablement exclure cpfor2 du modÃ¨le:\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nmodel.poly2 &lt;- lm(\n  logherp ~ logarea + thtden + swamp + I(swamp^2),\n  data = mydata\n)\nsummary(model.poly2)\n\n\nCall:\nlm(formula = logherp ~ logarea + thtden + swamp + I(swamp^2), \n    data = mydata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.19621 -0.05444 -0.01202  0.07116  0.21295 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -3.461e-01  1.769e-01  -1.957   0.0626 .  \nlogarea      2.232e-01  3.842e-02   5.810 6.40e-06 ***\nthtden      -2.570e-02  9.364e-03  -2.744   0.0116 *  \nswamp        2.956e-02  5.510e-03   5.365 1.89e-05 ***\nI(swamp^2)  -2.491e-04  4.409e-05  -5.649 9.46e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1063 on 23 degrees of freedom\n  (2 observations deleted due to missingness)\nMultiple R-squared:  0.8129,    Adjusted R-squared:  0.7804 \nF-statistic: 24.98 on 4 and 23 DF,  p-value: 4.405e-08\n\n\n\n\n\nEst-ce quâ€™il y a possiblement un problÃ¨me de multicolinÃ©aritÃ©?\n\nvif(model.poly2)\n\n   logarea     thtden      swamp I(swamp^2) \n  1.053193   1.123491  45.845845  45.656453 \n\n\nLes valeurs dâ€™inflation de la variance (VIF) pour les deux termes de swamp sont beaucoup plus Ã©levÃ©s que le seuil de 5. Cependant, câ€™est la norme pour les termes polynomiaux et on ne doit pas sâ€™en prÃ©occuper outre mesure, surtout quand les deux termes sont hautement significatifs dans le modÃ¨le. Les fortes valeurs de VIF indiquent que les coefficients pour ces deux termes ne sont pas estimÃ©s prÃ©cisÃ©ment, mais leur utilisation dans le modÃ¨le permet tout de mÃªme de faire de bonnes prÃ©dictions (i.e.Â ils dÃ©crivent la rÃ©ponse Ã  swamp).",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>13</span>Â  <span class='chapter-title'>RÃ©gression multiple</span>"
    ]
  },
  {
    "objectID": "35-reg_mult.html#vÃ©rifier-les-conditions-dapplication-de-modÃ¨les-de-rÃ©gression-multiple",
    "href": "35-reg_mult.html#vÃ©rifier-les-conditions-dapplication-de-modÃ¨les-de-rÃ©gression-multiple",
    "title": "\n13Â  RÃ©gression multiple\n",
    "section": "\n13.7 VÃ©rifier les conditions dâ€™application de modÃ¨les de rÃ©gression multiple",
    "text": "13.7 VÃ©rifier les conditions dâ€™application de modÃ¨les de rÃ©gression multiple\nToutes les techniques de sÃ©lection des modÃ¨les prÃ©sument que les conditions dâ€™applications (indÃ©pendance, normalitÃ©, homoscÃ©dasticitÃ©, linÃ©aritÃ©) sont remplies. Comme il y a un grand nombre de modÃ¨les qui peuvent Ãªtre ajustÃ©s, il peut paraÃ®tre quasi impossible de vÃ©rifier si les conditions sont remplies Ã  chaque Ã©tape de construction. Cependant, il est souvent suffisant dâ€™examiner les rÃ©sidus du modÃ¨le complet (saturÃ©) puis du modÃ¨le final. Les termes qui ne contribuent pas significativement Ã  lâ€™ajustement nâ€™affectent pas beaucoup les rÃ©sidus et donc les rÃ©sidus du modÃ¨le final sont gÃ©nÃ©ralement similaires Ã  ceux du modÃ¨le complet.\nExaminons donc les graphiques diagnostiques du modÃ¨le final:\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\npar(mfrow = c(2, 2))\nplot(model.poly2)\n\n\n\n\n\n\nFigureÂ 13.5: Conditions dâ€™application du modÃ¨le model.poly2\n\n\n\n\n\n\n\nTout semble acceptable dans ce cas. Pour convaincre les sceptiques, on peut faire les tests formels des conditions dâ€™application:\n\nshapiro.test(residuals(model.poly2))\n\n\n    Shapiro-Wilk normality test\n\ndata:  residuals(model.poly2)\nW = 0.9837, p-value = 0.9278\n\n\nLes rÃ©sidus ne dÃ©vient pas significativement de la normalitÃ©. Bien.\n\nlibrary(lmtest)\nbptest(model.poly2)\n\n\n    studentized Breusch-Pagan test\n\ndata:  model.poly2\nBP = 3.8415, df = 4, p-value = 0.4279\n\n\nPas de dÃ©viation dâ€™homoscÃ©dasticitÃ© non plus. Bien.\n\ndwtest(model.poly2)\n\n\n    Durbin-Watson test\n\ndata:  model.poly2\nDW = 1.725, p-value = 0.2095\nalternative hypothesis: true autocorrelation is greater than 0\n\n\nPas de corrÃ©lation sÃ©rielle des rÃ©sidus, donc pas dâ€™Ã©vidence de nonindÃ©pendance.\n\nresettest(model.poly2, type = \"regressor\", data = mydata)\n\n\n    RESET test\n\ndata:  model.poly2\nRESET = 0.9823, df1 = 8, df2 = 15, p-value = 0.4859\n\n\nEt finalement, pas de dÃ©viation significative de la linÃ©aritÃ©. Donc tout semble acceptable.",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>13</span>Â  <span class='chapter-title'>RÃ©gression multiple</span>"
    ]
  },
  {
    "objectID": "35-reg_mult.html#visualiser-la-taille-deffet",
    "href": "35-reg_mult.html#visualiser-la-taille-deffet",
    "title": "\n13Â  RÃ©gression multiple\n",
    "section": "\n13.8 Visualiser la taille dâ€™effet",
    "text": "13.8 Visualiser la taille dâ€™effet\nLes coefficients de la rÃ©gression multiple peuvent mesurer la taille dâ€™effet, quoiquâ€™il puisse Ãªtre nÃ©cessaire de les standardiser pour quâ€™ils ne soient pas influencÃ©s par les unitÃ©s de mesure. Mais un graphique est souvent plus informatif. Dans ce contexte, les graphiques des rÃ©sidus partiels (appelÃ©s components+residual plots dans R) sont particuliÃ¨rement utiles. Ces graphique illustrent comment la variable dÃ©pendante, corrigÃ©e pour lâ€™effet des autres variables dans le modÃ¨le, varie avec chacune des variables indÃ©pendantes du modÃ¨le. Voyons voir:\n\n# Evaluate visually linearity and effect size\n# component + residual plot\ncrPlots(model.poly2)\n\n\n\n\n\n\nFigureÂ 13.6: Graphiques de rÃ©sidus partiels du modÃ¨le model.poly2\n\n\n\n\nNotez que lâ€™Ã©chelle de lâ€™axe des y varie sur chaque graphique. Pour thtden, la variable dÃ©pendante (log10(richesse des herptiles)) varie dâ€™environ 0.4 unitÃ©s entre la valeur minimum et maximum de thtden. Pour logarea, la variation est dâ€™environ 0.6 unitÃ© log. Pour swamp, lâ€™interprÃ©tation est plus compliquÃ©e parce quâ€™il y a deux termes qui quantifient son effet, et que ces termes ont des signes opposÃ©s (positif pour swamp et nÃ©gatif pour swamp^2) ce qui donne une relation curvilinÃ©aire de type parabole. Le graphique ne permet pas de bien visualiser cela. Ceci dit, ces graphique nâ€™indiquent pas vraiment de violation de linÃ©aritÃ©.\nPour illustrer ce qui serait visible sur ces graphiques si il y avait une dÃ©viation de linÃ©aritÃ©, enlevons le terme du second degrÃ© pour swamp, puis on va refaire ces graphiques et effectuer le test RESET.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nmodel.nopoly &lt;- lm(\n  logherp ~ logarea + thtden + swamp,\n  data = mydata\n)\ncrPlots(model.nopoly)\n\n\n\n\n\n\nFigureÂ 13.7: Graphiques de rÃ©sidus partiels du modÃ¨le model.nopoly\n\n\n\n\n\n\n\nLa relation non-linÃ©aire avec swamp devient Ã©vidente. Et le test RESET dÃ©tecte bien cette non-linÃ©aritÃ©:\n\nresettest(model.nopoly, type = \"regressor\")\n\n\n    RESET test\n\ndata:  model.nopoly\nRESET = 6.7588, df1 = 6, df2 = 18, p-value = 0.0007066",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>13</span>Â  <span class='chapter-title'>RÃ©gression multiple</span>"
    ]
  },
  {
    "objectID": "35-reg_mult.html#tester-la-prÃ©sence-dinteractions",
    "href": "35-reg_mult.html#tester-la-prÃ©sence-dinteractions",
    "title": "\n13Â  RÃ©gression multiple\n",
    "section": "\n13.9 Tester la prÃ©sence dâ€™interactions",
    "text": "13.9 Tester la prÃ©sence dâ€™interactions\nLorsquâ€™il y a plusieurs variables indÃ©pendantes, vous devriez toujours garder Ã  lâ€™esprit la possibilitÃ© dâ€™interactions. Dans la majoritÃ© des situations de rÃ©gression multiple cela nâ€™est pas Ã©vident parce que lâ€™addition de termes dâ€™interaction augmente la multicolinÃ©aritÃ© des termes du modÃ¨le, et parce quâ€™il nâ€™y a souvent pas assez dâ€™observations pour Ã©prouver toutes les interactions ou que les observations ne sont pas suffisamment balancÃ©es pour faire des tests puissants pour les interactions. Retournons Ã  notre modÃ¨le â€œfinalâ€ et voyons ce qui se passe si on essaie dâ€™ajuster un modÃ¨le saturÃ© avec toutes les interactions:\n\nfullmodel.withinteractions &lt;- lm(\n  logherp ~ logarea * cpfor2 * thtden * swamp * I(swamp^2),\n  data = mydata\n)\nsummary(fullmodel.withinteractions)\n\n\nCall:\nlm(formula = logherp ~ logarea * cpfor2 * thtden * swamp * I(swamp^2), \n    data = mydata)\n\nResiduals:\nALL 28 residuals are 0: no residual degrees of freedom!\n\nCoefficients: (4 not defined because of singularities)\n                                         Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)                            -5.948e+03        NaN     NaN      NaN\nlogarea                                 3.293e+03        NaN     NaN      NaN\ncpfor2                                  7.080e+01        NaN     NaN      NaN\nthtden                                  9.223e+02        NaN     NaN      NaN\nswamp                                   1.176e+02        NaN     NaN      NaN\nI(swamp^2)                             -3.517e-01        NaN     NaN      NaN\nlogarea:cpfor2                         -3.771e+01        NaN     NaN      NaN\nlogarea:thtden                         -4.781e+02        NaN     NaN      NaN\ncpfor2:thtden                          -1.115e+01        NaN     NaN      NaN\nlogarea:swamp                          -7.876e+01        NaN     NaN      NaN\ncpfor2:swamp                           -1.401e+00        NaN     NaN      NaN\nthtden:swamp                           -1.920e+01        NaN     NaN      NaN\nlogarea:I(swamp^2)                      5.105e-01        NaN     NaN      NaN\ncpfor2:I(swamp^2)                       3.825e-03        NaN     NaN      NaN\nthtden:I(swamp^2)                       7.826e-02        NaN     NaN      NaN\nswamp:I(swamp^2)                       -2.455e-03        NaN     NaN      NaN\nlogarea:cpfor2:thtden                   5.359e+00        NaN     NaN      NaN\nlogarea:cpfor2:swamp                    8.743e-01        NaN     NaN      NaN\nlogarea:thtden:swamp                    1.080e+01        NaN     NaN      NaN\ncpfor2:thtden:swamp                     2.620e-01        NaN     NaN      NaN\nlogarea:cpfor2:I(swamp^2)              -5.065e-03        NaN     NaN      NaN\nlogarea:thtden:I(swamp^2)              -6.125e-02        NaN     NaN      NaN\ncpfor2:thtden:I(swamp^2)               -1.551e-03        NaN     NaN      NaN\nlogarea:swamp:I(swamp^2)               -4.640e-04        NaN     NaN      NaN\ncpfor2:swamp:I(swamp^2)                 3.352e-05        NaN     NaN      NaN\nthtden:swamp:I(swamp^2)                 2.439e-04        NaN     NaN      NaN\nlogarea:cpfor2:thtden:swamp            -1.235e-01        NaN     NaN      NaN\nlogarea:cpfor2:thtden:I(swamp^2)        7.166e-04        NaN     NaN      NaN\nlogarea:cpfor2:swamp:I(swamp^2)                NA         NA      NA       NA\nlogarea:thtden:swamp:I(swamp^2)                NA         NA      NA       NA\ncpfor2:thtden:swamp:I(swamp^2)                 NA         NA      NA       NA\nlogarea:cpfor2:thtden:swamp:I(swamp^2)         NA         NA      NA       NA\n\nResidual standard error: NaN on 0 degrees of freedom\n  (2 observations deleted due to missingness)\nMultiple R-squared:      1, Adjusted R-squared:    NaN \nF-statistic:   NaN on 27 and 0 DF,  p-value: NA\n\n\nNotez les coefficients manquants aux derniÃ¨res lignes: on ne peut inclure les 32 termes si on a seulement 28 observations. Il manque des observations, le R carrÃ© est 1, et le modÃ¨le â€œprÃ©ditâ€ parfaitement les donnÃ©es.\nSi on essaie une mÃ©thode automatique pour identifier le â€œmeilleurâ€ modÃ¨le dans ce gÃ¢chis, R refuse:\n\nstep(fullmodel.withinteractions)\n\nError in step(fullmodel.withinteractions): AIC is -infinity for this model, so 'step' cannot proceed\n\n\nBon, est-ce quâ€™on oublie tout Ã§a et quâ€™on accepte le modÃ¨le final sans ce soucier des interactions? Non, pas encore. Il y a un compromis possible: comparer notre modÃ¨le â€œfinalâ€ Ã  un modÃ¨le qui contient au moins un sous-ensemble des interactions, par exemple toutes les interactions du second degrÃ©, pour Ã©prouver si lâ€™addition de ces interactions amÃ©liore beaucoup lâ€™ajustement du modÃ¨le.\n\nfull.model.2ndinteractions &lt;- lm(\n  logherp ~ logarea + cpfor2 + thtden + swamp + I(swamp^2)\n    + logarea:cpfor2\n    + logarea:thtden\n    + logarea:swamp\n    + cpfor2:thtden\n    + cpfor2:swamp\n    + thtden:swamp,\n  data = mydata\n)\nsummary(full.model.2ndinteractions)\n\n\nCall:\nlm(formula = logherp ~ logarea + cpfor2 + thtden + swamp + I(swamp^2) + \n    logarea:cpfor2 + logarea:thtden + logarea:swamp + cpfor2:thtden + \n    cpfor2:swamp + thtden:swamp, data = mydata)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.216880 -0.036534  0.003506  0.042990  0.175490 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)     4.339e-01  6.325e-01   0.686 0.502581    \nlogarea        -1.254e-01  2.684e-01  -0.467 0.646654    \ncpfor2         -9.344e-03  7.205e-03  -1.297 0.213032    \nthtden         -1.833e-01  9.035e-02  -2.028 0.059504 .  \nswamp           3.569e-02  7.861e-03   4.540 0.000334 ***\nI(swamp^2)     -3.090e-04  7.109e-05  -4.347 0.000500 ***\nlogarea:cpfor2  2.582e-03  2.577e-03   1.002 0.331132    \nlogarea:thtden  7.017e-02  3.359e-02   2.089 0.053036 .  \nlogarea:swamp  -5.290e-04  2.249e-03  -0.235 0.816981    \ncpfor2:thtden  -2.095e-04  6.120e-04  -0.342 0.736544    \ncpfor2:swamp    4.651e-05  5.431e-05   0.856 0.404390    \nthtden:swamp    2.248e-04  4.764e-04   0.472 0.643336    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.108 on 16 degrees of freedom\n  (2 observations deleted due to missingness)\nMultiple R-squared:  0.8658,    Adjusted R-squared:  0.7735 \nF-statistic: 9.382 on 11 and 16 DF,  p-value: 4.829e-05\n\n\nCe modÃ¨le sâ€™ajuste un peu mieux aux donnÃ©es que les modÃ¨le â€œfinalâ€ (il explique 86.6% de la variance de logherp, comparÃ© Ã  81.2% pour le modÃ¨le â€œfinalâ€ sans interactions), mais il compte deux fois plus de paramÃ¨tres. De plus, si vous examinez les coefficients, il se passe dâ€™Ã©tranges choses: le signe pour logare a changÃ© par exemple. Câ€™est un des symptÃ´mes de la multicolinÃ©aritÃ©. Allons voir les facteurs dâ€™inflation de la variance:\n\nvif(full.model.2ndinteractions)\n\nthere are higher-order terms (interactions) in this model\nconsider setting type = 'predictor'; see ?vif\n\n\n       logarea         cpfor2         thtden          swamp     I(swamp^2) \n      49.86060       78.49622      101.42437       90.47389      115.08457 \nlogarea:cpfor2 logarea:thtden  logarea:swamp  cpfor2:thtden   cpfor2:swamp \n      66.97792       71.69894       67.27034       14.66814       29.41422 \n  thtden:swamp \n      20.04410 \n\n\nAie! tous les VIF sont plus grands que 5, pas seulement les termes incluant swamp. Cette forte multicolinÃ©aritÃ© empÃªche de quantifier avec prÃ©cision lâ€™effet de ces interactions. De plus, ce modÃ¨le avec interactions nâ€™est pas plus informatif que le modÃ¨le â€œfinalâ€ puisque son AIC est plus Ã©levÃ© (souvenez-vous quâ€™on privilÃ©gie le modÃ¨le avec la valeur dâ€™AIC la plus basse):\n\nAIC(model.poly1)\n\n[1] -38.3433\n\nAIC(full.model.2ndinteractions)\n\n[1] -34.86123\n\n\nOn peut Ã©galement utiliser la fonction anova() pour comparer lâ€™ajustement des deux modÃ¨les et vÃ©rifier si lâ€™addition des termes dâ€™intÃ©ration amÃ©liore significativement lâ€™ajustement:\n\nanova(model.poly1, full.model.2ndinteractions)\n\nAnalysis of Variance Table\n\nModel 1: logherp ~ logarea + cpfor2 + thtden + swamp + I(swamp^2)\nModel 2: logherp ~ logarea + cpfor2 + thtden + swamp + I(swamp^2) + logarea:cpfor2 + \n    logarea:thtden + logarea:swamp + cpfor2:thtden + cpfor2:swamp + \n    thtden:swamp\n  Res.Df     RSS Df Sum of Sq      F Pr(&gt;F)\n1     22 0.25282                           \n2     16 0.18651  6  0.066314 0.9481  0.489\n\n\nIci, lâ€™addition des termes dâ€™interaction ne rÃ©duit pas significativement la variabilitÃ© rÃ©siduelle du modÃ¨le â€œcompletâ€. Quâ€™en est-il de la si on compare le modÃ¨le avec interaction et notre modÃ¨le â€œfinalâ€?\n\nanova(model.poly2, full.model.2ndinteractions)\n\nAnalysis of Variance Table\n\nModel 1: logherp ~ logarea + thtden + swamp + I(swamp^2)\nModel 2: logherp ~ logarea + cpfor2 + thtden + swamp + I(swamp^2) + logarea:cpfor2 + \n    logarea:thtden + logarea:swamp + cpfor2:thtden + cpfor2:swamp + \n    thtden:swamp\n  Res.Df     RSS Df Sum of Sq      F Pr(&gt;F)\n1     23 0.25999                           \n2     16 0.18651  7  0.073486 0.9006 0.5294\n\n\nLe test indique que ces deux modÃ¨les ont des variances rÃ©siduelles comparables, et donc que lâ€™addition des termes dâ€™interaction et de cpfor2 au modÃ¨le final nâ€™apporte pas grand chose.",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>13</span>Â  <span class='chapter-title'>RÃ©gression multiple</span>"
    ]
  },
  {
    "objectID": "35-reg_mult.html#recherche-du-meilleur-modÃ¨le-fondÃ©e-sur-la-thÃ©orie-de-linformation",
    "href": "35-reg_mult.html#recherche-du-meilleur-modÃ¨le-fondÃ©e-sur-la-thÃ©orie-de-linformation",
    "title": "\n13Â  RÃ©gression multiple\n",
    "section": "\n13.10 Recherche du meilleur modÃ¨le fondÃ©e sur la thÃ©orie de lâ€™information",
    "text": "13.10 Recherche du meilleur modÃ¨le fondÃ©e sur la thÃ©orie de lâ€™information\nUne des principales critiques des mÃ©thodes pas-Ã -pas (stepwise) est que les valeurs de p ne sont pas strictement interprÃ©tables Ã  cause du grand nombre de tests qui sont implicites dans le processus. Câ€™est le problÃ¨me des comparaisons ou tests multiples: en construisant un modÃ¨le linÃ©aire (comme une rÃ©gression multiple) Ã  partir dâ€™un grand nombre de variables et de leurs interactions, il y a tellement de combinaisons possibles quâ€™un ajustement de Bonferroni rendrait les tests trop conservateurs.\nUne alternative, dÃ©fendue par Burnham et Anderson (2002, Model selection and multimodel inference: a practical information-theoretic approach. 2nd ed), est dâ€™utiliser lâ€™AIC (ou mieux encore AICc qui est plus appropriÃ© quand le nombre dâ€™observations est infÃ©rieur Ã  40 fois le nombre de variables indÃ©pendantes) pour ordonner les modÃ¨les et identifier un sousensemble de modÃ¨les qui sont les meilleurs. On peut ensuite calculer les moyennes des coefficients pondÃ©rÃ©es par la probabilitÃ© que chacun des modÃ¨les soit le meilleur pour obtenir des coefficients qui sont plus robustes et moins sensibles Ã  la multicolinÃ©aritÃ©.\nLâ€™approche de comparaison par AIC a dâ€™abord Ã©tÃ© dÃ©veloppÃ© pour comparer un ensemble de modÃ¨le prÃ©alablement dÃ©fini basÃ© sur les connaissance du sytÃ¨me et les hypothÃ¨ses biologiques. Cependant, certains ont dÃ©veloppÃ© une approche plutÃ´t brutale et sans scrupule de faire tous les modÃ¨les possibles et de les comparer par AIC. Cette approche a Ã©tÃ© suivie dans le package MuMIn. Les comparaisons de modÃ¨le par AICdoivent Ãªtre faites en utilisant exactement le mÃªme jeu de donnÃ©es pour chaque modÃ¨le. Il faut donc sâ€™arrurer dâ€™enlever les donnÃ©es manquantes et de spÃ©cifier dans la fonction lm de ne pas marcher sâ€™il y a des donnÃ©es manquantes.\n\n\n\n\n\n\nNote\n\n\n\nJe ne supporte pas lâ€™approche stepwise ni lâ€™approche par AIC. Je dÃ©teste lâ€™approche par la fonction dredge() qui selon moi va Ã  lâ€™encontre de la philosophie des AIC et de la parsimonie. Je soutiens de dÃ©velooper un modÃ¨le basÃ© sur des hypothÃ¨ses biologiques et de reporter ce modÃ¨le avec tous les effets significatifs ou non.\n\n\n\n# refaire le modÃ¨le en s'assurant qu'il n'y a pas de \"NA\" et en spÃ©cificant na.action\nfull.model.2ndinteractions &lt;- update(\n  full.model.2ndinteractions,\n  . ~ .,\n  data = mysub,\n  na.action = \"na.fail\"\n)\n\nlibrary(MuMIn)\ndd &lt;- dredge(full.model.2ndinteractions)\n\nFixed term is \"(Intercept)\"\n\n\nLâ€™objet dd contient tous les modÃ¨les possibles (i.e.Â ceux qui ont toutes les combinaisons possibles) en utilisant les termes du modÃ¨le full.model.2ndinteractions ajustÃ© prÃ©cÃ©demment. On peut ensuite extraire de lâ€™objet dd le sous-ensemble de modÃ¨les qui ont un AICc semblable au meilleur modÃ¨le (Burnham et Anderson suggÃ¨rent que les modÃ¨les qui dÃ©vient par plus de 7 unitÃ©s dâ€™AICc du meilleur modÃ¨le ont peu de support empirique).\n\n# get models within 2 units of AICc from the best model\ntop.models.1 &lt;- get.models(dd, subset = delta &lt; 2)\navgmodel1 &lt;- model.avg(top.models.1) # compute average parameters\nsummary(avgmodel1) # display averaged model\n\n\nCall:\nmodel.avg(object = top.models.1)\n\nComponent model call: \nlm(formula = logherp ~ &lt;2 unique rhs&gt;, data = mysub, na.action = \n     na.fail)\n\nComponent models: \n      df logLik   AICc delta weight\n12345  7  27.78 -35.95  0.00   0.55\n1234   6  25.78 -35.56  0.39   0.45\n\nTerm codes: \n    I(swamp^2)        logarea          swamp         thtden logarea:thtden \n             1              2              3              4              5 \n\nModel-averaged coefficients:  \n(full average) \n                 Estimate Std. Error Adjusted SE z value Pr(&gt;|z|)    \n(Intercept)    -2.145e-01  2.308e-01   2.406e-01   0.891    0.373    \nlogarea         1.356e-01  1.089e-01   1.119e-01   1.213    0.225    \nswamp           3.180e-02  5.971e-03   6.273e-03   5.070    4e-07 ***\nI(swamp^2)     -2.669e-04  4.770e-05   5.011e-05   5.326    1e-07 ***\nthtden         -6.985e-02  5.233e-02   5.361e-02   1.303    0.193    \nlogarea:thtden  2.131e-02  2.487e-02   2.545e-02   0.837    0.403    \n \n(conditional average) \n                 Estimate Std. Error Adjusted SE z value Pr(&gt;|z|)    \n(Intercept)    -2.145e-01  2.308e-01   2.406e-01   0.891   0.3727    \nlogarea         1.356e-01  1.089e-01   1.119e-01   1.213   0.2253    \nswamp           3.180e-02  5.971e-03   6.273e-03   5.070    4e-07 ***\nI(swamp^2)     -2.669e-04  4.770e-05   5.011e-05   5.326    1e-07 ***\nthtden         -6.985e-02  5.233e-02   5.361e-02   1.303   0.1927    \nlogarea:thtden  3.882e-02  2.114e-02   2.237e-02   1.735   0.0827 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nconfint(avgmodel1) # display CI for averaged coefficients\n\n                       2.5 %       97.5 %\n(Intercept)    -0.6860022996  0.257064603\nlogarea        -0.0836067896  0.354883299\nswamp           0.0195105703  0.044099316\nI(swamp^2)     -0.0003650809 -0.000168656\nthtden         -0.1749296690  0.035236794\nlogarea:thtden -0.0050266778  0.082666701\n\n\n\nLa liste des modÃ¨les qui sont Ã  4 unitÃ©s ou moins de lâ€™AICc du meilleur modÃ¨le. Les variables dans chaque modÃ¨le sont codÃ©es et on retrouve la clÃ© en dessous du tableau.\nPour chaque modÃ¨le, en plus de lâ€™AICc, le poids Akaike est calculÃ©. Câ€™est un estimÃ© de la probabilitÃ© que ce modÃ¨le est le meilleur. Ici on voit que le premier modÃ¨le (le meilleur) a seulement 34% des chance dâ€™Ãªtre vraiment le meilleur.\nÃ€ partir de ce sous-ensemble de modÃ¨les, la moyenne pondÃ©rÃ©e des coefficients (en utilisant les poids Akaike) est calculÃ©e, avec in IC Ã  95%. Notez que les termes absents dâ€™un modÃ¨le sont considÃ©rÃ©s avoir un coefficient de 0 pour ce terme.",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>13</span>Â  <span class='chapter-title'>RÃ©gression multiple</span>"
    ]
  },
  {
    "objectID": "35-reg_mult.html#bootstrap-et-rÃ©gression-multiple",
    "href": "35-reg_mult.html#bootstrap-et-rÃ©gression-multiple",
    "title": "\n13Â  RÃ©gression multiple\n",
    "section": "\n13.11 Bootstrap et rÃ©gression multiple",
    "text": "13.11 Bootstrap et rÃ©gression multiple\nQuand les donnÃ©es ne rencontrent pas les conditions dâ€™application de normalitÃ© et dâ€™homoscÃ©dasticitÃ© et que les transformations nâ€™arrivent pas Ã  corriger ces violations, le bootstrap peut Ãªtre utilisÃ© pour calculer des intervalles de confiance pour les coefficients. Si la distribution des coefficients bootstrappÃ©s est symÃ©trique et approximativement normale, on peut utiliser les percentiles empiriques pour calculer les limites de confiance.\nLe code qui suit, utilisant le package simpleboot, a Ã©tÃ© conÃ§u pour Ãªtre facilement modifiable et calcule les limites des IC Ã  partir des percentiles empiriques.\n\n############################################################\n#######\n# Bootstrap analysis the simple way with library simpleboot\n# Define model to be bootstrapped and the data source used\nmymodel &lt;- lm(logherp ~ logarea + thtden + swamp + I(swamp^2), data = mydata)\n# Set the number of bootstrap iterations\nnboot &lt;- 1000\nlibrary(simpleboot)\n# R is the number of bootstrap iterations\n# Setting rows to FALSE indicates resampling of residuals\nmysimpleboot &lt;- lm.boot(mymodel, R = nboot, rows = FALSE)\n# Extract bootstrap coefficients\nmyresults &lt;- sapply(mysimpleboot$boot.list, function(x) x$coef)\n# Transpose matrix so that lines are bootstrap iterations and columns are coefficients\ntmyresults &lt;- t(myresults)\n\nVous pouvez ensuite faire des graphiques pour voir les rÃ©sultats. Lorsque vous tournerez ce code, il y aura une pause pour vous permettre dâ€™examiner la distribution pour chaque coefficient du modÃ¨le sur des graphiques:\n\n# Plot histograms of bootstrapped coefficients\nncoefs &lt;- length(data.frame(tmyresults))\npar(mfrow = c(1, 2), mai = c(0.5, 0.5, 0.5, 0.5), ask = TRUE)\nfor (i in 1:ncoefs) {\n  lab &lt;- colnames(tmyresults)[i]\n  x &lt;- tmyresults[, i]\n  plot(density(x), main = lab, xlab = \"\")\n  abline(v = mymodel$coef[i], col = \"red\")\n  abline(v = quantile(x, c(0.025, 0.975)))\n  hist(x, main = lab, xlab = \"\")\n  abline(v = quantile(x, c(0.025, 0.975)))\n  abline(v = mymodel$coef[i], col = \"red\")\n}\n\n\n\n\n\n\n\n\nFigureÂ 13.8: Distribution des estimÃ© par bootstrap pour logarea\n\n\n\n\nLe graphique de droite illustre la densitÃ© lissÃ©e (kernel density) et celui de gauche est lâ€™histogramme des estimÃ©s bootstrap du coefficient. La ligne rouge sur le graphique indique la valeur du coefficient ordinaire (pas bootstrap) et les deux lignes verticales noires marquent les limites de lâ€™intervalle de confiance Ã  95%. Ici lâ€™IC ne contient pas 0, et donc on peut conclure que lâ€™effet de logarea sur logherp est significativement positif.\nLes limites prÃ©cises peuvent Ãªtre obtenues par:\n\n# Display empirical bootstrap quantiles (not corrected for bias)\np &lt;- c(0.005, 0.01, 0.025, 0.05, 0.95, 0.975, 0.99, 0.995)\napply(tmyresults, 2, quantile, p)\n\n      (Intercept)   logarea       thtden      swamp    I(swamp^2)\n0.5%  -0.72015691 0.1408549 -0.049532934 0.01782288 -0.0003426127\n1%    -0.68763485 0.1458417 -0.045999063 0.01857755 -0.0003383352\n2.5%  -0.65598177 0.1547219 -0.042789810 0.02047106 -0.0003257695\n5%    -0.60369685 0.1662327 -0.040001926 0.02173747 -0.0003131280\n95%   -0.09267750 0.2790818 -0.012366646 0.03772895 -0.0001875184\n97.5% -0.01799830 0.2902973 -0.009936534 0.03888219 -0.0001738278\n99%    0.02846165 0.2979800 -0.006783287 0.04065709 -0.0001599040\n99.5%  0.05167335 0.3027551 -0.005732742 0.04121435 -0.0001542944\n\n\nCes intervalles de confiances ne sont pas fiables si la distribution des estimÃ©s bootstrap nâ€™est pas Gaussienne. Dans ce cas, il vaut mieux calculer des coefficients non-biaisÃ©s (bias-corrected accelerated confidence limits, BCa):\n\n################################################\n# Bootstrap analysis in multiple regression with BCa confidence intervals\n# Preferable when parameter distribution is far from normal\n# Bootstrap 95% BCa CI for regression coefficients\n\nlibrary(boot)\n# function to obtain regression coefficients for each iteration\nbs &lt;- function(formula, data, indices) {\n  d &lt;- data[indices, ] # allows boot to select sample\n  fit &lt;- lm(formula, data = d)\n  return(coef(fit))\n}\n# bootstrapping with 1000 replications\nresults &lt;- boot(\n  data = mydata, statistic = bs, R = 1000,\n  formula = logherp ~ logarea + thtden + swamp + I(swamp^2)\n)\n# view results\n\nPour obtenir les rÃ©sultats, le code suivant va produire le graphique standard pour chaque coefficient, et les estimÃ©s BCa pour lâ€™intervalle de confiance\n\nplot(results, index = 1) # intercept\nplot(results, index = 2) # logarea\nplot(results, index = 3) # thtden\nplot(results, index = 4) # swamp\nplot(results, index = 5) # swamp^2\n\n# get 95% confidence intervals\nboot.ci(results, type = \"bca\", index = 1)\nboot.ci(results, type = \"bca\", index = 2)\nboot.ci(results, type = \"bca\", index = 3)\nboot.ci(results, type = \"bca\", index = 4)\nboot.ci(results, type = \"bca\", index = 5)\n\nPour logarea, cela donne:\n\n\nBOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS\nBased on 1000 bootstrap replicates\n\nCALL : \nboot.ci(boot.out = results, type = \"bca\", index = 2)\n\nIntervals : \nLevel       BCa          \n95%   ( 0.1159,  0.3260 )  \nCalculations and Intervals on Original Scale\n\n\n\n\n\n\n\nFigureÂ 13.9\n\n\n\n\nNotez que lâ€™intervalle BCa va de 0.12 Ã  0.32, alors que lâ€™intervalle standard Ã©tait de 0.16 Ã  0.29. Lâ€™intervalle BCa est ici plus grand du cÃ´tÃ© infÃ©rieur et plus petit du cÃ´tÃ© supÃ©rieur comme il se doit compte tenu de la distribution non-Gaussienne et asymÃ©trique des estimÃ©s bootstrap.",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>13</span>Â  <span class='chapter-title'>RÃ©gression multiple</span>"
    ]
  },
  {
    "objectID": "35-reg_mult.html#perm_reg_mult",
    "href": "35-reg_mult.html#perm_reg_mult",
    "title": "\n13Â  RÃ©gression multiple\n",
    "section": "\n13.12 Test de permutation",
    "text": "13.12 Test de permutation\nLes tests de permutations sont plus rarement effectuÃ©s en rÃ©gression multiple que le bootstrap. Voici un fragment de code pour le faire tout de mÃªme.\n\n############################################################\n##########\n# Permutation in multiple regression\n#\n# using lmperm library\nlibrary(lmPerm)\n# Fit desired model on the desired dataframe\nmymodel &lt;- lm(logherp ~ logarea + thtden + swamp + I(swamp^2),\n  data = mydata\n)\nmymodelProb &lt;- lmp(\n  logherp ~ logarea + thtden + swamp + I(swamp^2),\n  data = mydata, perm = \"Prob\"\n)\nsummary(mymodel)\nsummary(mymodelProb)",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>13</span>Â  <span class='chapter-title'>RÃ©gression multiple</span>"
    ]
  },
  {
    "objectID": "36-ancova_glm.html",
    "href": "36-ancova_glm.html",
    "title": "\n14Â  ANCOVA et modÃ¨le linÃ©aire gÃ©nÃ©ral\n",
    "section": "",
    "text": "14.1 Paquets et donnÃ©es requises pour le labo\nCe laboratoire nÃ©cessite:",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>14</span>Â  <span class='chapter-title'>ANCOVA et modÃ¨le linÃ©aire gÃ©nÃ©ral</span>"
    ]
  },
  {
    "objectID": "36-ancova_glm.html#set-anco",
    "href": "36-ancova_glm.html#set-anco",
    "title": "\n14Â  ANCOVA et modÃ¨le linÃ©aire gÃ©nÃ©ral\n",
    "section": "",
    "text": "les paquets R:\n\nggplot2\ncar\nlmtest\n\n\nles fichiers de donnÃ©es\n\nanc1dat.csv\nanc3dat.csv",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>14</span>Â  <span class='chapter-title'>ANCOVA et modÃ¨le linÃ©aire gÃ©nÃ©ral</span>"
    ]
  },
  {
    "objectID": "36-ancova_glm.html#modÃ¨le-linÃ©aire-gÃ©nÃ©ral",
    "href": "36-ancova_glm.html#modÃ¨le-linÃ©aire-gÃ©nÃ©ral",
    "title": "\n14Â  ANCOVA et modÃ¨le linÃ©aire gÃ©nÃ©ral\n",
    "section": "\n14.2 ModÃ¨le linÃ©aire gÃ©nÃ©ral",
    "text": "14.2 ModÃ¨le linÃ©aire gÃ©nÃ©ral\nLes modÃ¨les linÃ©aires gÃ©nÃ©raux ou General Linear Model en anglais sont diffÃ©rent des modÃ¨les linÃ©aires gÃ©nÃ©ralisÃ©s (ou generalized linear model, GLM). Les modÃ¨les linÃ©aires gÃ©nÃ©raux sont des modÃ¨les statistiques de la forme \\(Y = B \\mathbf{X} + E\\), ou Y est un vecteur contenant la variable dÃ©pendante continue, B est un vecteur des paramÃ¨tres estimÃ©s, \\(\\mathbf{X}\\) et la matrice des diffÃ©rents variables indÃ©pendantes et E est un vecteur de rÃ©sidus homoscÃ©dastiques et normalement distribuÃ©s. Tous les tests que nous avons Ã©tudiÃ©s Ã  date (test de t, rÃ©gression linÃ©aire simple, ANOVA Ã  un facteur de classification, ANOVA Ã  plusieurs facteurs de classification et rÃ©gression multiple) sont formulÃ©s ainsi. Notez que tous les modÃ¨les que nous avons rencontrÃ©s Ã  ce jour ne contiennent quâ€™un type de variable indÃ©pendante (soit continue ou discontinue). Dans cet exercice de laboratoire, vous allez ajuster des modÃ¨les qui ont les deux types de variables indÃ©pendantes.",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>14</span>Â  <span class='chapter-title'>ANCOVA et modÃ¨le linÃ©aire gÃ©nÃ©ral</span>"
    ]
  },
  {
    "objectID": "36-ancova_glm.html#ancova",
    "href": "36-ancova_glm.html#ancova",
    "title": "\n14Â  ANCOVA et modÃ¨le linÃ©aire gÃ©nÃ©ral\n",
    "section": "\n14.3 ANCOVA",
    "text": "14.3 ANCOVA\nANCOVA est lâ€™abrÃ©viation pour lâ€™analyse de covariance. Câ€™est un type de modÃ¨le linÃ©aire gÃ©nÃ©ral dans lequel il y a une (ou plusieurs) variable indÃ©pendante continue (parfois appelÃ© la covariable) et une (ou plusieurs) variable indÃ©pendante discontinue. Dans la prÃ©sentation traditionnelle de lâ€™ANCOVA dans les manuels de biostatistique, le modÃ¨le ANCOVA ne contient pas de termes dâ€™interaction entre les variables continues et discontinues. Par consÃ©quent, on doit prÃ©cÃ©der lâ€™ajustement de ce modÃ¨le (rÃ©duit parce que sans terme dâ€™interaction), par un test de signification de lâ€™interaction qui correspond Ã  Ã©prouver lâ€™Ã©galitÃ© des pentes (coefficients pour la ou les variables continues) entre les diffÃ©rents niveaux de la ou les variables discontinues (i.e un test dâ€™homogÃ©nÃ©itÃ© des pentes).",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>14</span>Â  <span class='chapter-title'>ANCOVA et modÃ¨le linÃ©aire gÃ©nÃ©ral</span>"
    ]
  },
  {
    "objectID": "36-ancova_glm.html#homogÃ©nÃ©itÃ©-des-pentes",
    "href": "36-ancova_glm.html#homogÃ©nÃ©itÃ©-des-pentes",
    "title": "\n14Â  ANCOVA et modÃ¨le linÃ©aire gÃ©nÃ©ral\n",
    "section": "\n14.4 HomogÃ©nÃ©itÃ© des pentes",
    "text": "14.4 HomogÃ©nÃ©itÃ© des pentes\nPour rÃ©pondre Ã  de nombreuses questions biologiques, il est nÃ©cessaire de dÃ©terminer si deux (ou plus de deux) rÃ©gressions diffÃ¨rent significativement. Par exemple, pour comparer lâ€™efficacitÃ© de deux insecticides on doit comparer la relation entre leur dose et la mortalitÃ©. Ou encore, pour comparer le taux de croissance des mÃ¢les et des femelles on doit comparer la relation entre la taille et lâ€™Ã¢ge des mÃ¢les et des femelles.\nComme chaque rÃ©gression linÃ©aire est dÃ©crite par deux paramÃ¨tres, la pente et lâ€™ordonnÃ©e Ã  lâ€™origine, on doit considÃ©rer les deux dans la comparaison. Le modÃ¨le dâ€™ANCOVA, Ã  strictement parler, nâ€™Ã©prouve que lâ€™hypothÃ¨se dâ€™Ã©galitÃ© des ordonnÃ©es Ã  lâ€™origine. Cependant, avant dâ€™ajuster ce modÃ¨le, il faut Ã©prouver lâ€™hypothÃ¨se dâ€™Ã©galitÃ© des pentes (homogÃ©nÃ©itÃ© des pentes).\n\n14.4.1 Cas 1 - La taille en fonction de lâ€™Ã¢ge (exemple avec pente commune)\n\n\n\n\n\n\nExercice\n\n\n\nEn utilisant les donnÃ©es du fichier anc1dat.csv, Ã©prouvez lâ€™hypothÃ¨se que le taux de croissance des esturgeons mÃ¢les et femelles de The Pas est le mÃªme (donnÃ©es de 1978-1980). Comme mesure du taux de croissance, nous allons utiliser la pente de la rÃ©gression du log 10 de la longueur Ã  la fourche, lfkl, sur le log 10 de lâ€™Ã¢ge, lâ€™age.\n\n\nCommenÃ§ons par examiner les donnÃ©es. Pour faciliter la comparaison, il serait utile de tracer la droite de rÃ©gression et la trace lowess pour ainsi plus facilement Ã©valuer la linÃ©aritÃ©. On peut aussi ajouter un peu de trucs R pour obtenir des lÃ©gendes plus complÃ¨tes (remarquez lâ€™utilisation de la commande expression() pour obtenir des indices):\n\nanc1dat &lt;- read.csv(\"data/anc1dat.csv\")\nanc1dat$sex &lt;- as.factor(anc1dat$sex)\nmyplot &lt;- ggplot(data = anc1dat, aes(x=lage,    y=log10(fklngth)))+facet_grid(.~sex)+geom_point()\nmyplot &lt;- myplot+\n  stat_smooth(method = lm, se=FALSE)+\n  stat_smooth(se=FALSE, color=\"red\") +\n  labs(\n    y = expression(log[10]~(Fork~length)),\n    x = expression(log[10]~(Age))\n)\nmyplot\n\n\n\n\n\n\nFigureÂ 14.1: Longueur des esturgeons en fonction de lâ€™age\n\n\n\n\nLa transformation log-log rend la relation linÃ©aire et, Ã  premiÃ¨re vue, il ne semble pas y avoir de problÃ¨me Ã©vident avec les conditions dâ€™application. Ajustons donc le modÃ¨le complet avec lâ€™interaction:\n\nmodel.full1&lt;-lm(lfkl ~ sex + lage + sex:lage, data = anc1dat)\nAnova(model.full1, type = 3)\n\nAnova Table (Type III tests)\n\nResponse: lfkl\n             Sum Sq Df  F value    Pr(&gt;F)    \n(Intercept) 0.64444  1 794.8182 &lt; 2.2e-16 ***\nsex         0.00041  1   0.5043    0.4795    \nlage        0.07259  1  89.5312 4.588e-15 ***\nsex:lage    0.00027  1   0.3367    0.5632    \nResiduals   0.07135 88                       \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nProbabilitÃ© que le terme lage*sex nâ€™affecte pas la longueur Ã  la fourche (i.e.Â que la pente ne diffÃ¨re pas entre les sexes, et que la diffÃ©rence de taille entre les mÃ¢les et femelles ne varie pas avec lâ€™Ã¢ge)\nAttrape. Notez que jâ€™ai utilisÃ© la fonction Anova() du package car avec un â€œaâ€ majuscule au lieu de la fonction native anova() (avec un â€œaâ€ minusculeâ€) associÃ©e aux objets produits par lm() pour obtenir les sommes de carrÃ©s de type III. Ces sommes des carrÃ©s des Ã©carts de type III (partiels) sont calculÃ©es comme si la variable Ã©tait entrÃ©e la derniÃ¨re dans le modÃ¨le et correspondent Ã  la diffÃ©rence entre la variance expliquÃ©e par le modÃ¨le complet et par le modÃ¨le dans lequel seule cette variable est omise. La fonction native anova() donne les sommes des carrÃ©s sÃ©quentielles, calculÃ©es au fur et Ã  mesure que chaque variable est ajoutÃ©e au modÃ¨le nul avec seulement une ordonnÃ©e Ã  lâ€™origine. Dans de rares cas, les sommes des carrÃ©s de type I et III sont Ã©gales (quand le design est parfaitement orthogonal ou balancÃ©). Dans la vaste majoritÃ© des cas, les sommes des carrÃ©s de type I et III sont diffÃ©rentes et je vous conseille de toujours utiliser les sommes des carrÃ©s de type III dans vos analyses.\nÃ€ partir de cette analyse, on devrait accepter les hypothÃ¨ses nulles (1) dâ€™Ã©galitÃ© des pentes pour les deux sexes, et (2) que les ordonnÃ©es Ã  lâ€™origine sont les mÃªmes pour les deux sexes. Mais, avant dâ€™accepter ces conclusions, il faut vÃ©rifier si les donnÃ©es rencontrent les conditions dâ€™application, comme dâ€™habitudeâ€¦\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\npar(mfrow = c(2, 2))\nplot(model.full1)\n\n\n\n\n\n\nFigureÂ 14.2: Conditions dâ€™applications du modÃ¨le model.full1\n\n\n\n\n\n\n\nEn ce qui concerne la normalitÃ©, Ã§a a lâ€™air dâ€™aller quoiquâ€™il y a quelques points, en haut Ã  droite, qui dÃ©vient de la droite. Si on effectue le test de Wilk-Shapiro (W = .9764, p = 0.09329), on confirme que les rÃ©sidus ne dÃ©vient pas significativement de la normalitÃ©. Les rÃ©sidus semblent homoscÃ©dastiques, mais si vous voulez vous en assurer, vous pouvez lâ€™Ã©prouver par un des tests formels. Ici jâ€™utilise le test Breusch-Pagan, qui est appropriÃ© quand certaines des variables indÃ©pendantes sont continues (Le test de Levene nâ€™est appropriÃ© que lorsquâ€™il nâ€™y a que des variables discontinues).\n\nbptest(model.full1)\n\n\n    studentized Breusch-Pagan test\n\ndata:  model.full1\nBP = 0.99979, df = 3, p-value = 0.8013\n\n\nComme lâ€™hypothÃ¨se nulle de ce test est que les rÃ©sidus sont homoscÃ©dastiques, et que p est relativement Ã©levÃ©, le test confirme lâ€™Ã©valuation visuelle. De plus, il nâ€™y a pas de tendance Ã©vidente dans les rÃ©sidus, suggÃ©rant quâ€™il nâ€™y a pas de problÃ¨me de linÃ©aritÃ©. Ce qui peut Ã©galement Ãªtre Ã©prouvÃ© formellement:\n\nresettest(model.full1, power = 2:3, type = \"regressor\", data = anc1dat)\n\n\n    RESET test\n\ndata:  model.full1\nRESET = 0.59861, df1 = 2, df2 = 86, p-value = 0.5519\n\n\nLa derniÃ¨re condition dâ€™application est quâ€™il nâ€™y a pas dâ€™erreur de mesure sur la variable indÃ©pendante continue. On ne peut vraiment Ã©prouver cette condition,, mais on sait que des estimÃ©s indÃ©pendants de lâ€™Ã¢ge des poissons obtenus par diffÃ©rents chercheurs donnent des Ã¢ges qui concordent avec moins de 1-2 ans dâ€™Ã©cart., ce qui est infÃ©rieur au 10% de la fourchette observÃ©e des Ã¢ges et donc acceptable pour des analyses de modÃ¨les de type I (attention ici on ne parle pas des SC de type I, je sais, câ€™est facile de confondreâ€¦)\nVous noterez quâ€™il y a une observation qui a un rÃ©sidu normalisÃ© (studentized residual) qui est Ã©levÃ©, i.e.Â une valeur extrÃªme (cas numÃ©ro 49). Ã‰liminez-la de lâ€™ensemble de donnÃ©es et refaites lâ€™analyse. Vos conclusions changent-elles?\n\nmodel.full.no49&lt;-lm(lfkl ~ sex + lage + sex:lage, data = anc1dat[c(-49),])\nAnova(model.full.no49, type=3)\n\nAnova Table (Type III tests)\n\nResponse: lfkl\n             Sum Sq Df  F value Pr(&gt;F)    \n(Intercept) 0.64255  1 895.9394 &lt;2e-16 ***\nsex         0.00038  1   0.5273 0.4697    \nlage        0.07378  1 102.8746 &lt;2e-16 ***\nsex:lage    0.00022  1   0.3135 0.5770    \nResiduals   0.06239 87                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nLa conclusion ne change pas aprÃ¨s avoir enlevÃ© la valeur extrÃªme. Comme on nâ€™a pas de bonne raison dâ€™Ã©liminer cette valeur, il est probablement mieux de la conserver. Un examen des conditions dâ€™application aprÃ¨s avoir enlevÃ© cette valeur rÃ©vÃ¨le quâ€™elles sont toutes rencontrÃ©es.\n\n14.4.2 Cas 2 - Taille en fonction de lâ€™Ã¢ge (exemple avec des pentes diffÃ©rentes)\n\n\n\n\n\n\nExercice\n\n\n\nLe fichier anc3dat.csv contient des donnÃ©es sur des esturgeons mÃ¢les de deux sites (locate) : Lake of the Woods dans le Nord-Ouest de lâ€™Ontario et Chruchill River dans le Nord du Manitoba. En utilisant la mÃªme procÃ©dure, Ã©prouvez lâ€™hypothÃ¨se que la pente de la rÃ©gression de lfkl sur lage est la mÃªme aux deux sites (alors Locate est la variable en catÃ©gories et non pas sex). Que concluez-vous?\n\n\n\nanc3dat &lt;- read.csv(\"data/anc3dat.csv\")\nmyplot &lt;- ggplot(data = anc3dat, aes(x = lage, y = log10(fklngth))) +\n  facet_grid(. ~ locate) +\n  geom_point() +\n  stat_smooth(method = lm, se = FALSE) +\n  stat_smooth(se = FALSE, color = \"red\") +\n  labs(\n    y = expression(log[10] ~ (Fork ~ length)),\n    x = expression(log[10] ~ (Age))\n  )\nmyplot\nmodel.full2 &lt;- lm(lfkl ~ lage + locate + lage:locate, data = anc3dat)\nAnova(model.full2, type = 3)\n\nAnova Table (Type III tests)\n\nResponse: lfkl\n             Sum Sq Df  F value    Pr(&gt;F)    \n(Intercept) 0.62951  1 1078.632 &lt; 2.2e-16 ***\nlage        0.07773  1  133.185 &lt; 2.2e-16 ***\nlocate      0.00968  1   16.591 0.0001012 ***\nlage:locate 0.00909  1   15.575 0.0001592 ***\nResiduals   0.05136 88                       \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\n\nFigureÂ 14.3: Longueur des esturgeons en fonction de lâ€™age dâ€™aprÃ¨s anc3dat\n\n\n\n\nIci, on rejette les hypothÃ¨ses nulles (1) que les pentes sont les mÃªmes dans les deux sites et (2) que les ordonnÃ©es Ã  lâ€™origine sont Ã©gales. En dâ€™autres mots, si on veut prÃ©dire la longueur Ã  la fourche dâ€™un esturgeon Ã  un Ã¢ge donnÃ© prÃ©cisÃ©ment, il faut savoir de quel site il provient. Puisque les pentes diffÃ¨rent, il faut estimer des rÃ©gressions sÃ©parÃ©es.\nMais avant dâ€™accepter ces conclusions, on doit se convaincre que les conditions dâ€™application sont rencontrÃ©es:\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\npar(mfrow = c(2,2))\nplot(model.full2)\n\n\n\n\n\n\nFigureÂ 14.4: Conditions dâ€™applications du modÃ¨le model.full2\n\n\n\n\n\n\n\nSi on examine les rÃ©sidus selon les mÃ©thodes habituelles, on voit quâ€™il nâ€™y a pas de problÃ¨me de linÃ©aritÃ©, ni dâ€™homoscÃ©dasticitÃ© (BP = 2.8721, p = 0.4118). Cependant, le test de Wilk-Shapiro est significatif (W=0.97, p = 0.03). Ã‰tant donnÃ© la taille assez grande de lâ€™Ã©chantillon (N=92), ce test a beaucoup de puissance, mÃªme si la dÃ©viation de normalitÃ© ne semble pas trÃ¨s grande. Compte-tenu de la robustesse relative des LM, de la taille de lâ€™Ã©chantillon, on ne devrait pas ^tre trop inquiet de cette dÃ©viation de normalitÃ©.\nDonc, comme les conditions des LM sont suffisamment remplies, on peut accepter les rÃ©sultats donnÃ©s par R. Tous les termes sont significatifs (location, lage, interaction). Ce modÃ¨le complet est Ã©quivalent Ã  ajuster des rÃ©gressions sÃ©parÃ©es pour chaque site. Pour obtenir les coefficients, on peut ajuster des rÃ©gressions simples sur chaque sous-ensemble, ou extraire les coefficients ajustÃ©s du modÃ¨le complet:\n\nmodel.full2\n\n\nCall:\nlm(formula = lfkl ~ lage + locate + lage:locate, data = anc3dat)\n\nCoefficients:\n            (Intercept)                     lage       locateNELSON        \n                 1.2284                   0.3253                   0.2207  \nlage:locateNELSON        \n                -0.1656  \n\n\nPar dÃ©faut, la variable locate est encodÃ©e comme 0 pour le site qui vient le premier en ordre alphabÃ©tique (LofW) et 1 pour lâ€™autre (Nelson). Les rÃ©gressions pour chaque site deviennent donc:\nPour LofW: \\[\\begin{aligned}\nlfkl &= 1.2284 + 0.3253 \\times lage + 0.2207 \\times 0 - 0.1656 \\times 0 \\times lage \\\\\n&= 1.2284 + 0.3253 \\times lage\n\\end{aligned}\\]\nPour Nelson: \\[\\begin{aligned}\nlfkl &= 1.2284 + 0.3253 \\times lage + 0.2207 \\times 1 - 0.1656 \\times 1 \\times lage \\\\\n&= 1.4491 + 0.1597 \\times lage\n\\end{aligned}\\]\nVous pouvez vÃ©rifier en ajustant sÃ©parÃ©ment les rÃ©gressions pour chaque site:\n\nby(anc3dat, anc3dat$locate,function(x) lm(lfkl~lage, data=x))\n\nanc3dat$locate: LOFW        \n\nCall:\nlm(formula = lfkl ~ lage, data = x)\n\nCoefficients:\n(Intercept)         lage  \n     1.2284       0.3253  \n\n------------------------------------------------------------ \nanc3dat$locate: NELSON      \n\nCall:\nlm(formula = lfkl ~ lage, data = x)\n\nCoefficients:\n(Intercept)         lage  \n     1.4491       0.1597",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>14</span>Â  <span class='chapter-title'>ANCOVA et modÃ¨le linÃ©aire gÃ©nÃ©ral</span>"
    ]
  },
  {
    "objectID": "36-ancova_glm.html#le-modÃ¨le-dancova",
    "href": "36-ancova_glm.html#le-modÃ¨le-dancova",
    "title": "\n14Â  ANCOVA et modÃ¨le linÃ©aire gÃ©nÃ©ral\n",
    "section": "\n14.5 Le modÃ¨le dâ€™ANCOVA",
    "text": "14.5 Le modÃ¨le dâ€™ANCOVA\nSi le test dâ€™homogÃ©nÃ©itÃ© des pentes indique quâ€™elles diffÃ¨rent, alors on devrait estimer des rÃ©gressions individuelles pour chaque niveau des variables discontinues. Cependant, si on accepte lâ€™hypothÃ¨se dâ€™Ã©galitÃ© des pentes, lâ€™Ã©tape suivante est de comparer les ordonnÃ©es Ã  lâ€™origine. Selon la â€œvieille Ã©coleâ€ i.e.Â lâ€™approche traditionnelle, on ajuste un modÃ¨le avec la variable catÃ©gorique et la variable continue, mais sans interaction (le modÃ¨le ANCOVA sensus stricto) et on utilise la somme des carrÃ©s des Ã©carts de type III, disons avec la fonction Anova(). Câ€™est ce que la majoritÃ© des manuels de biostatistiques prÃ©sentent.\nLâ€™autre approche consiste Ã  utiliser les rÃ©sultats de lâ€™analyse du modÃ¨le complet, et tester la signification de chaque terme Ã  partir des sommes des carrÃ©s partiels. Câ€™est plus rapide, mais moins puissant. Dans la plupart des cas, cette perte de puissance nâ€™est pas trop prÃ©occupante, sauf lorsque le modÃ¨le est trÃ¨s complexe et contient de nombreuses interactions non-significatives. Je vous suggÃ¨re dâ€™utiliser lâ€™approche simplifiÃ©e, et de nâ€™utiliser lâ€™approche traditionnelle que lorsque vous acceptez lâ€™hypothÃ¨se dâ€™Ã©galitÃ© des ordonnÃ©es Ã  lâ€™origine. Pourquoi?\nPuisque lâ€™approche simplifiÃ©e est moins puissante, si vous rejetez quand mÃªme H0, alors votre conclusion ne changera pas, mais sera seulement renforcÃ©e, en utilisant lâ€™approche traditionnelle.\nIci, je vais comparer lâ€™approche traditionnelle et lâ€™approche simplifiÃ©e. Rappelez-vous que vous voulez Ã©valuer lâ€™Ã©galitÃ© des ordonnÃ©es Ã  lâ€™origine aprÃ¨s avoir dÃ©terminÃ© que les pentes Ã©taient Ã©gales. Ã‰prouver lâ€™Ã©galitÃ© des ordonnÃ©es Ã  lâ€™origine quand les pentes diffÃ¨rent (ou, si vous prÃ©fÃ©rez, quand il y a une interaction) est rarement sensÃ©, peut facilement Ãªtre mal interprÃ©tÃ©, et ne devrait Ãªtre effectuÃ© que rarement.\nDe retour aux donnÃ©es de anc1dat.csv, en comparant la relation entre lfkl et lage entre les sexes, nous avions obtenu les rÃ©sultats suivants pour le modÃ¨le complet avec interactions:\n\nAnova(model.full1, type = 3)\n\nAnova Table (Type III tests)\n\nResponse: lfkl\n             Sum Sq Df  F value    Pr(&gt;F)    \n(Intercept) 0.64444  1 794.8182 &lt; 2.2e-16 ***\nsex         0.00041  1   0.5043    0.4795    \nlage        0.07259  1  89.5312 4.588e-15 ***\nsex:lage    0.00027  1   0.3367    0.5632    \nResiduals   0.07135 88                       \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nOn avait dÃ©jÃ  conclu que la pente ne varie pas entre les sexes (i.e.Â lâ€™interaction nâ€™est pas significative). Notez que la p-valeur associÃ©e au sexe (0.4795) nâ€™est pas significative non plus.\nDe lâ€™autre cÃ´tÃ©, selon lâ€™approche traditionnelle, lâ€™infÃ©rence quand Ã  lâ€™effet du sexe se fait Ã  partir du modÃ¨le rÃ©duit (le modÃ¨le ANCOVA sensus stricto):\n\nmodel.ancova &lt;- lm(lfkl ~ sex + lage, data = anc1dat)\nAnova(model.ancova, type = 3)\n\nAnova Table (Type III tests)\n\nResponse: lfkl\n             Sum Sq Df   F value Pr(&gt;F)    \n(Intercept) 1.13480  1 1410.1232 &lt;2e-16 ***\nsex         0.00149  1    1.8513 0.1771    \nlage        0.14338  1  178.1627 &lt;2e-16 ***\nResiduals   0.07162 89                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(model.ancova)\n\n\nCall:\nlm(formula = lfkl ~ sex + lage, data = anc1dat)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.093992 -0.018457 -0.000876  0.022491  0.081161 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)      1.225533   0.032636  37.552   &lt;2e-16 ***\nsexMALE         -0.008473   0.006228  -1.361    0.177    \nlage             0.327253   0.024517  13.348   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.02837 on 89 degrees of freedom\nMultiple R-squared:  0.696, Adjusted R-squared:  0.6892 \nF-statistic: 101.9 on 2 and 89 DF,  p-value: &lt; 2.2e-16\n\n\nDans ce modÃ¨le, sex nâ€™est pas significatif et on conclue donc que lâ€™ordonnÃ©e Ã  lâ€™origine ne diffÃ¨re pas entre les sexes. Notez que la pvaleur est plus petite (0.1771 vs 0.4795), ce qui reflÃ¨te la puissance accrue de lâ€™approche traditionnelle. Toutefois, les conclusions sont les mÃªmes: les ordonnÃ©es Ã  lâ€™origine ne diffÃ¨rent pas.\n\n\n\n\n\n\nExercice\n\n\n\nEn examinant les graphiques diagnostiques, vous noterez quâ€™il y a trois observations dont la valeur absolue du rÃ©sidu est grande (cas 19, 49, et 50). Ces observations pourraient avoir un effet disproportionnÃ© sur les rÃ©sultats de lâ€™analyse. Ã‰liminez-les et refaites lâ€™analyse. Les conclusions changent-elles ?\n\n\n\nmodel.ancova.nooutliers &lt;- lm(lfkl ~ sex + lage, data = anc1dat[c(-49, -50, -19),])\nAnova(model.ancova.nooutliers, type = 3)\n\nAnova Table (Type III tests)\n\nResponse: lfkl\n             Sum Sq Df   F value  Pr(&gt;F)    \n(Intercept) 1.09160  1 1896.5204 &lt; 2e-16 ***\nsex         0.00232  1    4.0374 0.04764 *  \nlage        0.13992  1  243.0946 &lt; 2e-16 ***\nResiduals   0.04950 86                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(model.ancova.nooutliers)\n\n\nCall:\nlm(formula = lfkl ~ sex + lage, data = anc1dat[c(-49, -50, -19), \n    ])\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.058397 -0.018469 -0.000976  0.020696  0.040288 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)      1.224000   0.028106  43.549   &lt;2e-16 ***\nsexMALE         -0.010823   0.005386  -2.009   0.0476 *  \nlage             0.328604   0.021076  15.591   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.02399 on 86 degrees of freedom\nMultiple R-squared:  0.7706,    Adjusted R-squared:  0.7653 \nF-statistic: 144.4 on 2 and 86 DF,  p-value: &lt; 2.2e-16\n\n\nOuch! Les rÃ©sultats changent. Il faudrait donc rejeter lâ€™hypothÃ¨se nulle et conclure que les ordonnÃ©es Ã  lâ€™origine diffÃ¨rent! Une conclusion qualitativement diffÃ©rente de celle obtenue en considÃ©rant toutes les donnÃ©es. Pourquoi? Il y a deux raisons possibles : (1) les valeurs extrÃªmes influencent beaucoup les rÃ©gressions ou (2) lâ€™exclusion des valeurs extrÃªmes permet dâ€™augmenter la puissance de dÃ©tection dâ€™une diffÃ©rence. La premiÃ¨re explication est moins plausible parce que les valeurs extrÃªmes nâ€™avaient pas une grande influence (leverage faible). Alors, la deuxiÃ¨me explication est plus plausible et vous pouvez le vÃ©rifier en faisant des rÃ©gressions pour chaque sexe sans et avec les valeurs extrÃªmes. Si vous le faites, vous noterez que les ordonnÃ©es Ã  lâ€™origine pour chaque sexe ne changent presque pas alors que leurs erreurs-types changent beaucoup.\n\n\n\n\n\n\nExercice\n\n\n\nAjustez une rÃ©gression simple entre lfkl et lage pour lâ€™ensemble complet de donnÃ©es et aussi pour le sous-ensemble sans les 3 valeurs dÃ©viantes. Comparez ces modÃ¨les avec les modÃ¨les dâ€™ANCOVA ajustÃ©s prÃ©cÃ©demment. Que concluez-vous ? Quel modÃ¨le, dâ€™aprÃ¨s vous, a le meilleur ajustement aux donnÃ©es ? Pourquoi ?\n\n\nLe modÃ¨le en excluant les valeurs extrÃªmes:\n\nmodel.linear.nooutliers&lt;-lm(lfkl ~ lage,data = anc1dat[c(-49, -50, -19),])\nsummary(model.linear.nooutliers)\n\n\nCall:\nlm(formula = lfkl ~ lage, data = anc1dat[c(-49, -50, -19), ])\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.055567 -0.017809 -0.002944  0.021272  0.044972 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  1.20378    0.02670   45.09   &lt;2e-16 ***\nlage         0.34075    0.02054   16.59   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.02441 on 87 degrees of freedom\nMultiple R-squared:  0.7598,    Adjusted R-squared:  0.7571 \nF-statistic: 275.2 on 1 and 87 DF,  p-value: &lt; 2.2e-16\n\n\nPour la rÃ©gression simple (sans les valeurs extrÃªmes) on obtient un R 2 de 0.76 et une erreur-type des rÃ©sidus de 0.02441, En comparant Ã  lâ€™erreur-type des rÃ©sidus du modÃ¨le dâ€™ANCOVA (0.02399) on rÃ©alise que la qualitÃ© des prÃ©dictions est essentiellement la mÃªme, mÃªme en ajustant des ordonnÃ©es Ã  lâ€™origine diffÃ©rentes pour chaque groupe. Par consÃ©quent, les bÃ©nÃ©fices de lâ€™inclusion dâ€™un terme pour les diffÃ©rentes ordonnÃ©es Ã  lâ€™origine sont faibles alors que le coÃ»t, en terme de complexitÃ© du modÃ¨le, est Ã©levÃ© (33% dâ€™augmentation du nombre de termes pour un trÃ¨s faible amÃ©lioration de la qualitÃ© dâ€™ajustement). Si vous examinez les rÃ©sidus de ce modÃ¨le, vous trouverez quâ€™ils sont Ã  peu prÃ¨s O.K.)\nSi on ajuste une rÃ©gression simple sur toutes les donnÃ©es, on obtient:\n\nmodel.linear&lt;-lm(lfkl ~ lage, data = anc1dat)\nsummary(model.linear)\n\n\nCall:\nlm(formula = lfkl ~ lage, data = anc1dat)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.090915 -0.018975 -0.002587  0.021270  0.085273 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  1.21064    0.03089   39.19   &lt;2e-16 ***\nlage         0.33606    0.02376   14.14   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.0285 on 90 degrees of freedom\nMultiple R-squared:  0.6897,    Adjusted R-squared:  0.6863 \nF-statistic: 200.1 on 1 and 90 DF,  p-value: &lt; 2.2e-16\n\n\nEncore une fois, lâ€™erreur-type des rÃ©sidus (0.0285) pour cette rÃ©gression unique est semblable Ã  la variance du modÃ¨le dâ€™ANCOVA (0.02837) et le modÃ¨le simplifiÃ© prÃ©dit presque aussi bien que le modÃ¨le plus complexe. (Ici encore, toutes les conditions dâ€™application semblent remplies, si ce nâ€™est de la valeur extrÃªme).\nDonc, dans les deux cas (avec ou sans les valeurs extrÃªmes), lâ€™addition dâ€™un terme supplÃ©mentaire pour le sexe nâ€™ajoute pas grand-chose. Il semble donc que le meilleur modÃ¨le soit celui de la rÃ©gression simple. Un estimÃ© raisonnablement prÃ©cis de la taille des esturgeons peut Ãªtre obtenu de la rÃ©gression commune sur lâ€™ensemble des rÃ©sultats.\nNote: Il est frÃ©quent que lâ€™Ã©limination de valeurs extrÃªmes en fasse apparaÃ®tre dâ€™autres. Câ€™est parce que ces valeurs extrÃªmes dÃ©pendent de la variabilitÃ© rÃ©siduelle. Si on Ã©limine les valeurs les plus dÃ©viantes, la variabilitÃ© rÃ©siduelle diminue, et certaines observations qui nâ€™Ã©taient pas si dÃ©viantes que cela deviennent proportionnellement plus dÃ©viantes. Notez aussi quâ€™en Ã©liminant des valeurs extrÃªmes, lâ€™effectif diminue et que la puissance dÃ©croÃ®t. Il faut donc Ãªtre prudent.",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>14</span>Â  <span class='chapter-title'>ANCOVA et modÃ¨le linÃ©aire gÃ©nÃ©ral</span>"
    ]
  },
  {
    "objectID": "36-ancova_glm.html#comparer-lajustement-de-modÃ¨les",
    "href": "36-ancova_glm.html#comparer-lajustement-de-modÃ¨les",
    "title": "\n14Â  ANCOVA et modÃ¨le linÃ©aire gÃ©nÃ©ral\n",
    "section": "\n14.6 Comparer lâ€™ajustement de modÃ¨les",
    "text": "14.6 Comparer lâ€™ajustement de modÃ¨les\nComme vous venez de le voir, le processus dâ€™ajustement de modÃ¨les est itÃ©ratif. La plupart du temps il y a plus dâ€™un modÃ¨le qui peut Ãªtre ajustÃ© aux donnÃ©es et câ€™est Ã  vous de choisir celui qui est le meilleur compromis entre la qualitÃ© dâ€™ajustement (quâ€™on essaie de maximiser) et la complexitÃ© (quâ€™on essaie de minimiser). La stratÃ©gie de base en ajustant des modÃ¨les linÃ©aires (ANOVA, rÃ©gression, ANCOVA) est de privilÃ©gier le modÃ¨le le plus simple si la qualitÃ© dâ€™ajustement nâ€™est pas significativement plus mauvaise. R peut calculer une statistique F vous permettant de comparer lâ€™ajustement de deux modÃ¨les. Dans ce cas, lâ€™hypothÃ¨se nulle est que la qualitÃ© dâ€™ajustement ne diffÃ¨re pas entre les deux modÃ¨les.\n\n\n\n\n\n\nExercice\n\n\n\nEn utilisant les donnÃ©es de anc1dat comparez lâ€™ajustement du modÃ¨le ANCOVA et de la rÃ©gression commune:\n\n\n\nanova(model.ancova,model.linear)\n\nAnalysis of Variance Table\n\nModel 1: lfkl ~ sex + lage\nModel 2: lfkl ~ lage\n  Res.Df      RSS Df  Sum of Sq      F Pr(&gt;F)\n1     89 0.071623                            \n2     90 0.073113 -1 -0.0014899 1.8513 0.1771\n\n\nLa fonction anova() utilise la diffÃ©rence entre la somme des carrÃ©s des deux modÃ¨les et la divise par la diffÃ©rence entre le nombre de degrÃ©s de libertÃ© pour obtenir un carrÃ© moyen. Ce carrÃ© moyen est utilisÃ© au numÃ©rateur et est divisÃ© par la variance rÃ©siduelle du modÃ¨le le plus complexe pour obtenir la statistique F. Dans ce cas-ci, le test de F nâ€™est pas significatif, et on conclut que les deux modÃ¨les ont une qualitÃ© dâ€™ajustement Ã©quivalente, et quâ€™on devrait donc privilÃ©gier le modÃ¨le le plus simple, la rÃ©gression linÃ©aire simple.\n\n\n\n\n\n\nExercice\n\n\n\nRefaites le mÃªme processus avec le donnÃ©es de anc3dat, ajustez le modÃ¨le complet avec interaction (LFKL~LAGE+LOCATE+LAGE:LOCATE) et sans interaction (LFKL~LAGE+LOCATE), Comparez lâ€™ajustement des deux modÃ¨les, que concluez vous?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nmodel.full.anc3dat&lt;-lm(lfkl ~ lage + locate + lage:locate, data = anc3dat)\nmodel.ancova.anc3dat&lt;-lm(lfkl ~ lage + locate, data = anc3dat)\nanova(model.full.anc3dat,model.ancova.anc3dat)\n\nAnalysis of Variance Table\n\nModel 1: lfkl ~ lage + locate + lage:locate\nModel 2: lfkl ~ lage + locate\n  Res.Df      RSS Df  Sum of Sq      F    Pr(&gt;F)    \n1     88 0.051358                                   \n2     89 0.060448 -1 -0.0090901 15.575 0.0001592 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nCette fois-ci, le modÃ¨le plus complexe sâ€™ajuste significativement mieux aux donnÃ©es. (Pas surprenant puisque nous avions prÃ©cÃ©demment conclu que lâ€™interaction est significative avec ces donnÃ©es.)",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>14</span>Â  <span class='chapter-title'>ANCOVA et modÃ¨le linÃ©aire gÃ©nÃ©ral</span>"
    ]
  },
  {
    "objectID": "36-ancova_glm.html#bootstrap",
    "href": "36-ancova_glm.html#bootstrap",
    "title": "\n14Â  ANCOVA et modÃ¨le linÃ©aire gÃ©nÃ©ral\n",
    "section": "\n14.7 Bootstrap",
    "text": "14.7 Bootstrap\n\n############################################################\n######\n# Bootstrap analysis\n# Bootstrap analysis BCa confidence intervals\n# Preferable when parameter distribution is far from normal\n# Bootstrap 95% BCa CI for regression coefficients\nlibrary(boot)\n\n# To simplify future modifications of the code in this file,\n# copy the data to a generic mydata dataframe\nmydata &lt;- anc3dat\n\n# create a myformula variable containing the formula for the model to be fitted\nmyformula &lt;- as.formula(lfkl ~ lage + locate + lage:locate)\n\n# function to obtain regression coefficients for each iteration\nbs &lt;- function(formula, data, indices) {\n  d &lt;- data[indices, ]\n  fit &lt;- lm(formula, data = d)\n  return(coef(fit))\n}\n# bootstrapping with 1000 replications\nresults &lt;- boot(data = mydata, statistic = bs, R = 1000, formula = myformula)\n\n# view results\nresults\nboot_res &lt;- summary(results)\nrownames(boot_res) &lt;- names(results$t0)\nboot_res\n\nop &lt;- par(ask = TRUE)\nfor (i in 1:length(results$t0)) {\n  plot(results, index = i)\n  title(names(results$t0)[i])\n}\npar(op)\n\n# get 95% confidence intervals\nfor (i in 1:length(results$t0)) {\n  cat(\"\\n\", names(results$t0)[i],\"\\n\")\n  print(boot.ci(results, type = \"bca\", index = i))\n}",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>14</span>Â  <span class='chapter-title'>ANCOVA et modÃ¨le linÃ©aire gÃ©nÃ©ral</span>"
    ]
  },
  {
    "objectID": "36-ancova_glm.html#permutation-test",
    "href": "36-ancova_glm.html#permutation-test",
    "title": "\n14Â  ANCOVA et modÃ¨le linÃ©aire gÃ©nÃ©ral\n",
    "section": "\n14.8 Permutation test",
    "text": "14.8 Permutation test\n\n############################################################\n##########\n# Permutation test\n#\n# using lmperm library\n# To simplify future modifications of the code in this file,\n# copy the data to a generic mydata dataframe\nmydata&lt;-anc3dat\n# create a myformula variable containing the formula for the\n# model to be fitted\nmyformula&lt;-as.formula(lfkl ~ lage + locate + lage:locate)\nrequire(lmPerm2)\n# Fit desired model on the desired dataframe\nmymodel &lt;- lm(myformula, data = mydata)\n# Calculate p-values for each term by permutation\n# Note that lmp centers numeric variable by default, so to\n# get results that are\n# consistent with standard models, it is necessary to set\ncenter=FALSE\nmymodelProb &lt;- lmp(myformula, data = mydata, center=FALSE,\nperm = \"Prob\")\nsummary(mymodel)\nsummary(mymodelProb)",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>14</span>Â  <span class='chapter-title'>ANCOVA et modÃ¨le linÃ©aire gÃ©nÃ©ral</span>"
    ]
  },
  {
    "objectID": "42-model_freq.html",
    "href": "42-model_freq.html",
    "title": "\n15Â  Analyse de donnÃ©es de frÃ©quence: Tableaux de contingence, modÃ¨les log-linÃ©aires et rÃ©gression de Poisson\n",
    "section": "",
    "text": "15.1 Paquets et donnÃ©es requises pour le labo\nCe laboratoire nÃ©cessite:",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires gÃ©nÃ©ralisÃ©s",
      "<span class='chapter-number'>15</span>Â  <span class='chapter-title'>Analyse de donnÃ©es de frÃ©quence: Tableaux de contingence, modÃ¨les log-linÃ©aires et rÃ©gression de Poisson</span>"
    ]
  },
  {
    "objectID": "42-model_freq.html#set-freq",
    "href": "42-model_freq.html#set-freq",
    "title": "\n15Â  Analyse de donnÃ©es de frÃ©quence: Tableaux de contingence, modÃ¨les log-linÃ©aires et rÃ©gression de Poisson\n",
    "section": "",
    "text": "les paquets R:\n\nvcd\nvcdExtra\ncar\n\n\nles fichiers de donnÃ©es\n\nUSPopSurvey.csv\nloglin.csv\nsturgdat.csv",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires gÃ©nÃ©ralisÃ©s",
      "<span class='chapter-number'>15</span>Â  <span class='chapter-title'>Analyse de donnÃ©es de frÃ©quence: Tableaux de contingence, modÃ¨les log-linÃ©aires et rÃ©gression de Poisson</span>"
    ]
  },
  {
    "objectID": "42-model_freq.html#organisation-des-donnÃ©es-3-formats",
    "href": "42-model_freq.html#organisation-des-donnÃ©es-3-formats",
    "title": "\n15Â  Analyse de donnÃ©es de frÃ©quence: Tableaux de contingence, modÃ¨les log-linÃ©aires et rÃ©gression de Poisson\n",
    "section": "\n15.2 Organisation des donnÃ©es: 3 formats",
    "text": "15.2 Organisation des donnÃ©es: 3 formats\nLes rÃ©sultats de certaines expÃ©riences sont sous forme de frÃ©quences, par exemple le nombre de plantes infectÃ©es par un pathogÃ¨ne sous diffÃ©rents rÃ©gimes dâ€™infection, ou le nombre de tortues mÃ¢les et femelles qui Ã©closent Ã  diffÃ©rentes tempÃ©ratures (oui, chez les tortues le sexe dÃ©pends de la tempÃ©rature!), etc. La question statistique qui se pose gÃ©nÃ©ralement est de savoir si la proportion des observations dans chaque catÃ©gorie (infectÃ© vs non infectÃ©, mÃ¢le vs femelle, etc) diffÃ¨re significativement entre les traitements (rÃ©gime dâ€™infection ou tempÃ©rature dans les deux exemples). Pour rÃ©pondre Ã  cette question, on peut organiser les donnÃ©es de maniÃ¨re Ã  reflÃ©ter comment les observations se retrouvent dans chaque catÃ©gorie. Il existe 3 faÃ§ons dâ€™organiser ces donnÃ©es. Vous devriez Ãªtre capable de choisir la maniÃ¨re appropriÃ©e pour votre analyse, et savoir convertir entre elles avec R.\nLe fichier USPopSurvey.csv contient les donnÃ©e de recensement dâ€™une ville du midwest amÃ©ricain en 1980:\n\nUSPopSurvey &lt;- read.csv(\"data/USPopSurvey.csv\")\nUSPopSurvey\n\n   ageclass    sex frequency\n1       0-9 female     17619\n2     10-19 female     17947\n3     20-29 female     21344\n4     30-39 female     19138\n5     40-49 female     13135\n6     50-59 female     11617\n7     60-69 female     11053\n8     70-79 female      7712\n9       80+ female      4114\n10      0-9   male     17538\n11    10-19   male     18207\n12    20-29   male     21401\n13    30-39   male     18837\n14    40-49   male     12568\n15    50-59   male     10661\n16    60-69   male      9374\n17    70-79   male      5348\n18      80+   male      1926\n\n\nNotez quâ€™il y a 18 lignes et 3 colonnes dans ce fichier. Chaque ligne donne le nombre de personnes (frequency) pour un sexe et une classe dâ€™Ã¢ge. Il y a 239539 individus qui ont Ã©tÃ© classifiÃ©s selon les 18 catÃ©gories (2 sexes x 9 classes dâ€™Ã¢ge). Cette maniÃ¨re de reprÃ©senter les donnÃ©es est sous le format de frÃ©quences (frequency form). Câ€™est un format compact permettant dâ€™enregistrer les donnÃ©es quand il y a seulement des variables catÃ©goriques Ã  reprÃ©senter.\nLorsquâ€™il y a des variables continues, ce format ne peut Ãªtre utilisÃ©. Les donnÃ©es doivent Ãªtre enregistrÃ©e sous le format de cas (case form) dans laquelle chaque observation (individu) est reprÃ©sentÃ© par une ligne dans le fichier, et oÃ¹ chaque variable est reprÃ©sentÃ©e par une colonne. Le package vcdExtra contient la fonction expand.dft() qui permet de convertir de la forme de frÃ©quence Ã  la forme de cas. Par exemple, pour crÃ©er un data frame avec 239439 lignes et 2 colonnes (sex et ageclass) Ã  partir du data frame USPopSurvey:\n\nUSPopSurvey.caseform &lt;- expand.dft(USPopSurvey, freq = \"frequency\")\nhead(USPopSurvey.caseform)\n\n  ageclass    sex\n1      0-9 female\n2      0-9 female\n3      0-9 female\n4      0-9 female\n5      0-9 female\n6      0-9 female\n\ntail(USPopSurvey.caseform)\n\n       ageclass  sex\n239534      80+ male\n239535      80+ male\n239536      80+ male\n239537      80+ male\n239538      80+ male\n239539      80+ male\n\n\nCes donnÃ©es peuvent finalement Ãªtre organisÃ©es sous le format de tableau (table form) de contingence oÃ¹ chacune des n variables est reprÃ©sentÃ©e par une dimension dâ€™un tableau n-dimensionnel (dans notre exemple on a 2 variables, sexe et classe dâ€™Ã¢ge, et les rangÃ©es pourraient reprÃ©senter les classes dâ€™Ã¢ge et les colonnes chaque sexe). Les cellules de ce tableau contiennent les frÃ©quences. Le format tableau peut Ãªtre obtenu du format de frÃ©quence ou de cas par la commande xtabs() :\n\n# convert case form to table form\nxtabs(~ ageclass + sex, USPopSurvey.caseform)\n\n        sex\nageclass female  male\n   0-9    17619 17538\n   10-19  17947 18207\n   20-29  21344 21401\n   30-39  19138 18837\n   40-49  13135 12568\n   50-59  11617 10661\n   60-69  11053  9374\n   70-79   7712  5348\n   80+     4114  1926\n\n# convert frequency form to table form\nxtabs(frequency ~ ageclass + sex, data = USPopSurvey)\n\n        sex\nageclass female  male\n   0-9    17619 17538\n   10-19  17947 18207\n   20-29  21344 21401\n   30-39  19138 18837\n   40-49  13135 12568\n   50-59  11617 10661\n   60-69  11053  9374\n   70-79   7712  5348\n   80+     4114  1926\n\n\n\n(#tab:unnamed-chunk-1)Fonctions permettant la conversion de donnÃ©es de frÃ©quences entre les diffÃ©rents formats.\n\n\n\n\n\n\n\nDe (ligne) \\ Vers (colonne)\nCas\nFrÃ©quence\nTableau\n\n\n\nCas\n\nxtabs(~ A + B)\ntable(A, B)\n\n\nFrÃ©quence\nexpand.dft(X)\n\nxtabs(count ~ A + B)\n\n\nTableau\nexpand.dft(X)\nas.data.frame(X)",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires gÃ©nÃ©ralisÃ©s",
      "<span class='chapter-number'>15</span>Â  <span class='chapter-title'>Analyse de donnÃ©es de frÃ©quence: Tableaux de contingence, modÃ¨les log-linÃ©aires et rÃ©gression de Poisson</span>"
    ]
  },
  {
    "objectID": "42-model_freq.html#visualiser-graphiquement-les-tableaux-de-contingence-et-test-dindÃ©pendance",
    "href": "42-model_freq.html#visualiser-graphiquement-les-tableaux-de-contingence-et-test-dindÃ©pendance",
    "title": "\n15Â  Analyse de donnÃ©es de frÃ©quence: Tableaux de contingence, modÃ¨les log-linÃ©aires et rÃ©gression de Poisson\n",
    "section": "\n15.3 Visualiser graphiquement les tableaux de contingence et test dâ€™indÃ©pendance",
    "text": "15.3 Visualiser graphiquement les tableaux de contingence et test dâ€™indÃ©pendance\nLes tableaux de contingence peuvent servir Ã  Ã©prouver lâ€™hypothÃ¨se dâ€™indÃ©pendance des observations. Ceci Ã©quivaut Ã  rÃ©pondre Ã  la question: est-ce que la classification des observations selon une variable (par exemple sex) indÃ©pendante de la classification par une autre variable (par exemple ageclass). En autres mots, est-ce que la proportion des mÃ¢les et femelles indÃ©pendante de lâ€™Ã¢ge ou varie avec lâ€™Ã¢ge?\nLe package vcd inclut la fonction mosaic() qui permet de reprÃ©senter graphiquement le contenu dâ€™un tableau de contingence:\n\nlibrary(vcd)\nUSTable &lt;- xtabs(frequency ~ ageclass + sex, data = USPopSurvey) # save the table form as USTable dataframe\n# Mosaic plot of the contingency table\nmosaic(USTable)\n\n\n\n\n\n\nFigureÂ 15.1: ReprÃ©sentation mosaique de la proportion des sexes par classe dâ€™age\n\n\n\n\nCette mosaÃ¯que reprÃ©sente la proportion des observations dans chaque combinaison de catÃ©gories (ici il y a 18 catÃ©gories, 2 sexes x 9 classes dâ€™Ã¢ge). Les catÃ©gories contenant une plus grande proportion dâ€™observations sont reprÃ©sentÃ©es par de plus grands rectangles. Visuellement, on peut voir que la proportion des mÃ¢les et femelles est approximativement Ã©gale chez les jeunes, mais que la proportion des femelles augmente chez les personnes Ã¢gÃ©es.\nLe test de Chi carrÃ© permet dâ€™Ã©prouver lâ€™hypothÃ¨se nulle que la proportion des mÃ¢les et femelles ne change pas avec lâ€™Ã¢ge (est indÃ©pendante de lâ€™Ã¢ge):\n\n# Test of independence\nchisq.test(USTable) # runs chi square test of independence of sex and age class\n\n\n    Pearson's Chi-squared test\n\ndata:  USTable\nX-squared = 1162.6, df = 8, p-value &lt; 2.2e-16\n\n\nLa valeur p Ã©tant trÃ¨s faible, on rejette donc lâ€™hypothÃ¨se nulle que Ã¢ge et sexe sont indÃ©pendants. Ces graphiques mosaÃ¯ques peuvent Ãªtres colorÃ©s pour souligner les catÃ©gories qui contribuent le plus Ã  cette dÃ©pendance:\n\n# Mosaic plot of the contingency table with shading\nmosaic(USTable, shade = TRUE)\n\n\n\n\n\n\nFigureÂ 15.2: ReprÃ©sentation mosaique de la proportion des sexes par classe dâ€™age avec Ã©chelle de couleur\n\n\n\n\nLa couleur de chaque rectangle est proportionnelle Ã  la dÃ©viation des frÃ©quences observÃ©es de ce qui serait attendu si lâ€™Ã¢ge et le sexe Ã©taient indÃ©pendants. Les classes dâ€™Ã¢ge 40-49 et 50-59 ont un rapport des sexe approximativement Ã©gal Ã  celui de toutes les classes dâ€™Ã¢ge rÃ©unies. Il y a plus de jeunes mÃ¢les et de femelles Ã¢gÃ©es que si le rapport des sexe ne variait pas avec lâ€™Ã¢ge.et ces rectangles sont colorÃ©s en bleu. De lâ€™autre cÃ´tÃ©, il y a moins de jeunes femelles et de mÃ¢les Ã¢gÃ©s que si le rapport des sexe Ã©tait indÃ©pendant de lâ€™Ã¢ge, et ces rectangles sont en rouge. La valeur p Ã  la droite de la figure est pour le test de Chi carrÃ© qui Ã©prouve lâ€™hypothÃ¨se nulle dâ€™indÃ©pendance pour lâ€™ensemble des observations, toutes classes dâ€™Ã¢ge confondues.\nLâ€™estimation de la valeur p associÃ©e Ã  la statistique du Chi carrÃ© est approximative lorsque les frÃ©quences attendues sont faibles dans certaines cellules, et ce particuliÃ¨rement pour les tableaux de contingence 2x2. Deux options permettant des valeurs p plus exactes sont prÃ©fÃ©rÃ©es dans ce cas, et le choix dÃ©pends du nombre total dâ€™observations. Pour de grands Ã©chantillons (comme ici avec plus de 200,000 observations!), une approche par simulation de type Monte Carlo est suggÃ©rÃ©e et peut Ãªtre obtenue en ajoutant simulate.p.value=TRUE comme argument Ã  la fonction chisq.test() :\n\n# Monte-carlo estimation of p value (better for small n)\nchisq.test(USTable, simulate.p.value = TRUE, B = 10000)\n\n\n    Pearson's Chi-squared test with simulated p-value (based on 10000\n    replicates)\n\ndata:  USTable\nX-squared = 1162.6, df = NA, p-value = 9.999e-05\n\n\nIci, la simulation a Ã©tÃ© faite B=10000 fois, et la valeur de Chi carrÃ© observÃ©e avec les donnÃ©es rÃ©elles nâ€™a jamais Ã©tÃ© observÃ©e. Par consÃ©quent, p a Ã©tÃ© estimÃ© Ã  1/10001=9.999e-05, qui est beaucoup plus Ã©levÃ© que la valeur p estimÃ©e Ã  partir de la distribution thÃ©orique de Chi carrÃ© (p&lt; 2.2e-16). Cette diffÃ©rence est due au moins en partie Ã  un artÃ©facts de la simulation. Pour obtenir des valeurs p de lâ€™ordre de 1e-16, il faut effectuer au moins 10 16 simulations. Et je ne suis pas aussi patient que Ã§a!\nPour de petits tableaux de contingence avec des frÃ©quences attendues petites, le test exact de Fisher peut servir Ã  estimer la valeur p associÃ©e Ã  lâ€™hypothÃ¨se dâ€™indÃ©pendance. Mais ce test ne peut Ãªtre effectuÃ© avec de grands Ã©chantillons, comme ici:\n\n# Fisher exact test for contingency tables (small samples and small tables)\nfisher.test(USTable) # fails here because too many observations\n\nError in fisher.test(USTable): FEXACT error 40.\nOut of workspace.\n\nfisher.test(USTable, simulate.p.value = TRUE, B = 10000)\n\n\n    Fisher's Exact Test for Count Data with simulated p-value (based on\n    10000 replicates)\n\ndata:  USTable\np-value = 9.999e-05\nalternative hypothesis: two.sided",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires gÃ©nÃ©ralisÃ©s",
      "<span class='chapter-number'>15</span>Â  <span class='chapter-title'>Analyse de donnÃ©es de frÃ©quence: Tableaux de contingence, modÃ¨les log-linÃ©aires et rÃ©gression de Poisson</span>"
    ]
  },
  {
    "objectID": "42-model_freq.html#rÃ©gression-de-poisson-une-alternative-au-test-de-chi-carrÃ©-pour-les-tableaux-de-contingence",
    "href": "42-model_freq.html#rÃ©gression-de-poisson-une-alternative-au-test-de-chi-carrÃ©-pour-les-tableaux-de-contingence",
    "title": "\n15Â  Analyse de donnÃ©es de frÃ©quence: Tableaux de contingence, modÃ¨les log-linÃ©aires et rÃ©gression de Poisson\n",
    "section": "\n15.4 RÃ©gression de Poisson: une alternative au test de Chi carrÃ© pour les tableaux de contingence",
    "text": "15.4 RÃ©gression de Poisson: une alternative au test de Chi carrÃ© pour les tableaux de contingence\nRendu Ã  ce stade, vous devriez avoir appris Ã  apprÃ©cier la flexibilitÃ© et la gÃ©nÃ©ralitÃ© des modÃ¨les linÃ©aires, et rÃ©aliser que le test de t est un cas spÃ©cial dâ€™un modÃ¨le linÃ©aire avec une variable indÃ©pendante catÃ©gorique. Lâ€™analyse des tableaux de contingence par le test du Chi carrÃ© peut Ã©galement Ãªtre gÃ©nÃ©ralisÃ©. Un modÃ¨le linÃ©aire gÃ©nÃ©ralisÃ© pour une distribution de Poisson peut Ãªtre utilisÃ© quand la variable dÃ©pendante est une frÃ©quence dâ€™observations et les variables indÃ©pendantes sont catÃ©gorique (comme pour les tableaux de contingence, on parle alors de modÃ¨les log-linÃ©aires), continue (rÃ©gression Poisson), ou une combinaison de variables indÃ©pendante continues et catÃ©goriques (aussi appelÃ© rÃ©gression de Poisson, mais avec des variables catÃ©goriques en plus, analogue Ã  lâ€™ANCOVA sensu largo).\nCes modÃ¨les prÃ©disent le logarithme naturel de la frÃ©quence des observations en fonction des variables indÃ©pendantes. Comme pour les modÃ¨les linÃ©aires qui prÃ©sument de la normalitÃ© des rÃ©sidus, on peut Ã©valuer la qualitÃ© dâ€™ajustement du modÃ¨le (par AICc par exemple) et la signification statistique des termes du modÃ¨le (par exemple en comparant lâ€™ajustement dâ€™un modÃ¨le â€œcompletâ€ et celui dâ€™un modÃ¨le qui exclue un terme Ã  tester). On peut Ã©galement obtenir des estimÃ©s des paramÃ¨tre pour chaque terme dans le modÃ¨le, avec des intervalles de confiance et des valeur p pour lâ€™hypothÃ¨se nulle que ce terme nâ€™a pas dâ€™influence sur la frÃ©quence.\nLa fonction glm() avec lâ€™option family=poisson() permet lâ€™estimation, par la mÃ©thode du maximum de vraisemblance, de modÃ¨les linÃ©aires pour des frÃ©quences. Comparativement aux modÃ¨les linÃ©aires vus prÃ©cÃ©demment, une des particularitÃ© de ces modÃ¨les est que seuls les termes dâ€™interaction sont dâ€™intÃ©rÃªt. En partant des donnÃ©es de recensement en forme tableau, on peut ajuster un glm aux frÃ©quences observÃ©es par sexe et classe dâ€™Ã¢ge par:\n\nmymodel &lt;- glm(frequency ~ sex * ageclass, family = poisson(), data = USPopSurvey)\nsummary(mymodel)\n\n\nCall:\nglm(formula = frequency ~ sex * ageclass, family = poisson(), \n    data = USPopSurvey)\n\nCoefficients:\n                       Estimate Std. Error  z value Pr(&gt;|z|)    \n(Intercept)            9.776733   0.007534 1297.730  &lt; 2e-16 ***\nsexmale               -0.004608   0.010667   -0.432   0.6657    \nageclass10-19          0.018445   0.010605    1.739   0.0820 .  \nageclass20-29          0.191793   0.010179   18.842  &lt; 2e-16 ***\nageclass30-39          0.082698   0.010441    7.921 2.36e-15 ***\nageclass40-49         -0.293697   0.011528  -25.477  &lt; 2e-16 ***\nageclass50-59         -0.416508   0.011951  -34.850  &lt; 2e-16 ***\nageclass60-69         -0.466276   0.012134  -38.428  &lt; 2e-16 ***\nageclass70-79         -0.826200   0.013654  -60.511  &lt; 2e-16 ***\nageclass80+           -1.454582   0.017316  -84.004  &lt; 2e-16 ***\nsexmale:ageclass10-19  0.018991   0.014981    1.268   0.2049    \nsexmale:ageclass20-29  0.007275   0.014400    0.505   0.6134    \nsexmale:ageclass30-39 -0.011245   0.014803   -0.760   0.4475    \nsexmale:ageclass40-49 -0.039519   0.016416   -2.407   0.0161 *  \nsexmale:ageclass50-59 -0.081269   0.017136   -4.742 2.11e-06 ***\nsexmale:ageclass60-69 -0.160154   0.017633   -9.083  &lt; 2e-16 ***\nsexmale:ageclass70-79 -0.361447   0.020747  -17.422  &lt; 2e-16 ***\nsexmale:ageclass80+   -0.754343   0.029598  -25.486  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 5.3611e+04  on 17  degrees of freedom\nResidual deviance: 6.5463e-12  on  0  degrees of freedom\nAIC: 237.31\n\nNumber of Fisher Scoring iterations: 2\n\n\nLâ€™ajustement du modÃ¨le complet, avec Lâ€™interaction triple sex:ageclass interaction, permet Ã  la proportion des mÃ¢les et femelles de changer entre les classes dâ€™Ã¢ge, et donc dâ€™estimer exactement les frÃ©quences observÃ©es pour chaque combinaison de sexe et classe dâ€™Ã¢ge (notez que les rÃ©sidus (deviance residuals) sont tous 0, et que lâ€™estimÃ© de dÃ©viance rÃ©siduelle est Ã©galement approximativement zÃ©ro).\nUn masochiste peut utiliser le tableau des coefficients pour obtenir la frÃ©quence prÃ©dite pour les diffÃ©rentes catÃ©gories. Les frÃ©quences prÃ©dites, comme pour lâ€™ANOVA Ã  critÃ¨res multiple, sont obtenus en additionnant les coefficients appropriÃ©s. Puisque, en R, le premier niveau dâ€™une variable catÃ©gorique (facteur) en ordre alphabÃ©tique) est utilisÃ© comme rÃ©fÃ©rence, lâ€™ordonnÃ©e Ã  lâ€™origine (9.776733) est la valeur prÃ©dite pour le logarithme naturel de la frÃ©quence des femelles dans la premiÃ¨re classe dâ€™Ã¢ge (0 to 9). En effet, 9.776733 est approximativement Ã©gal Ã  17619, le nombre observÃ© de femelles dans cette classe dâ€™Ã¢ge.\nPour les mÃ¢les dans la classe dâ€™Ã¢ge 80+, il faut calcule lâ€™antilog du coefficient pour lâ€™ordonnÃ©e Ã  lâ€™origine (pour les femelles dans la premiÃ¨re classe dâ€™Ã¢ge), plus le coefficient pour sexmale (Ã©gal Ã  la diffÃ©rence du log de la frÃ©quence entre les femelles et les mÃ¢les), plus le coefficient pour la classe dâ€™Ã¢ge 80+ qui corresponds Ã  la diffÃ©rence de frÃ©quence entre cette classe dâ€™Ã¢ge et la classe dâ€™Ã¢ge de rÃ©fÃ©rence, plus le coefficient pour lâ€™interaction sexmale:ageclass80+ (qui corresponds Ã  la diffÃ©rence de proportion de mÃ¢les dans cette classe dâ€™Ã¢ge par rapport Ã  la classe dâ€™Ã¢ge de rÃ©fÃ©rence). Ceci donne: ln(frequency)=9.776733-0.004608-1.454582-0.754343=7.5632, et la frÃ©quence est Ã©gale Ã  e 7.5632 =1926\nIl y a de nombreuses valeur p dans ce tableau, mais elle ne sont en gÃ©nÃ©ral pas trÃ¨s utiles. Pour Ã©prouver lâ€™hypothÃ¨se que lâ€™effet du sexe sur la frÃ©quence est identique dans chaque classe dâ€™Ã¢ge (i.e.Â que sexe et Ã¢ge sont indÃ©pendants), vous devez ajuster un modÃ¨le qui exclut cette interaction (sex:ageclass) et dÃ©terminer comment lâ€™ajustement du modÃ¨le est affectÃ©.\nLa fonction Anova() du package car permet de prendre un raccourci:\n\nAnova(mymodel, type = 3, test = \"LR\")\n\nAnalysis of Deviance Table (Type III tests)\n\nResponse: frequency\n             LR Chisq Df Pr(&gt;Chisq)    \nsex               0.2  1     0.6657    \nageclass      21074.6  8     &lt;2e-16 ***\nsex:ageclass   1182.2  8     &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nLes arguments type=3 and test=\"LR\" font en sorte que le test effectuÃ© pour comparer le modÃ¨le complet aux modÃ¨les rÃ©duits est les test de Chi carrÃ© sur le rapport de vraisemblance (Likelihood Ratio Chi-Square) Ã  partir de la variance rÃ©siduelle, et que câ€™est un test partiel, et non sÃ©quentiel.\nSelon ces tests, il nâ€™y a pas dâ€™effet principal de sex (p=0.667) mais il y a un effet principal de ageclass et une interaction significative sex:ageclass. Lâ€™interaction significative signifie que lâ€™effet du sexe sur la frÃ©quence varie selon les classes dâ€™Ã¢ge, bref que le rapport des sexe varie avec lâ€™Ã¢ge. Lâ€™effet principal de ageclass signifie que la frÃ©quence des individus varie avec lâ€™Ã¢ge dans la population recensÃ©e (i.e.Â que certaines classes dâ€™Ã¢ge sont plus populeuses que dâ€™autres). Lâ€™absence dâ€™un effet principal du sexe suggÃ¨re quâ€™il y a approximativement le mÃªme nombre de mÃ¢les et femelles dans lâ€™Ã©chantillon (quoique, puisquâ€™il y a une interaction, vous devez Ãªtre prudents en faisant cette dÃ©claration. Câ€™est â€œvraiâ€ au total, mais semble incorrect pour certaines classes dâ€™Ã¢ge).",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires gÃ©nÃ©ralisÃ©s",
      "<span class='chapter-number'>15</span>Â  <span class='chapter-title'>Analyse de donnÃ©es de frÃ©quence: Tableaux de contingence, modÃ¨les log-linÃ©aires et rÃ©gression de Poisson</span>"
    ]
  },
  {
    "objectID": "42-model_freq.html#tester-une-hypothÃ¨se-extrinsÃ¨que",
    "href": "42-model_freq.html#tester-une-hypothÃ¨se-extrinsÃ¨que",
    "title": "\n15Â  Analyse de donnÃ©es de frÃ©quence: Tableaux de contingence, modÃ¨les log-linÃ©aires et rÃ©gression de Poisson\n",
    "section": "\n15.5 Tester une hypothÃ¨se extrinsÃ¨que",
    "text": "15.5 Tester une hypothÃ¨se extrinsÃ¨que\nLe test dâ€™indÃ©pendance ci-dessus Ã©prouve une hypothÃ¨se intrinsÃ¨que parce que les proportions utilisÃ©es pour calculer les valeurs attendues et tester lâ€™indÃ©pendance sont celles observÃ©es (i.e.Â la proportion des mÃ¢les et femelles dans tout lâ€™Ã©chantillon, et la proportion des individus dans chaque classe dâ€™Ã¢ge).\nPour Ã©prouver lâ€™hypothÃ¨se (extrinsÃ¨que) que le rapport des sexes est 1:1 pour les individus les plus jeunes (ageclass 0-9), on doit produire le tableau 2X2 des frÃ©quences observÃ©es et attendues. Les frÃ©quences attendues sont obtenues simplement en divisant le total des mÃ¢les et femelles par 2.\nCode R pour crÃ©er et analyser un tableau de contingence 2X2 et Ã©prouver une hypothÃ¨se extrinsÃ¨que\n\n### Produce a table of obs vs exp for 0-9 age class\nPopn0.9 &lt;- rbind(c(17578, 17578), c(17619, 17538))\n### Run X2 test on above table\nchisq.test(Popn0.9, correct = F) ### X2 without Yates\nchisq.test(Popn0.9) ### X2 with Yates\n\n\n\n\n\n\n\nExercice\n\n\n\nÃ‰prouvez lâ€™hypothÃ¨se nulle que la proportion de mÃ¢les et femelles Ã  la naissance est Ã©gale. Que concluez-vous? Croyez-vous que ces donnÃ©es sont appropriÃ©es pour tester cette hypothÃ¨se?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nchisq.test(Popn0.9, correct = F)\n\n\n    Pearson's Chi-squared test\n\ndata:  Popn0.9\nX-squared = 0.093309, df = 1, p-value = 0.76\n\nchisq.test(Popn0.9)\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  Popn0.9\nX-squared = 0.088758, df = 1, p-value = 0.7658\n\n\n\n\n\nNotez que pour un tableau 2X2, on devrait utiliser une correction de Yates ou un test de Fisher. Le test de Fisher ne pouvant Ãªtre utilisÃ© lorsque lâ€™Ã©chantillon dÃ©passe 200, on utilise la correction de Yates. Selon cette analyse, on accepte lâ€™hypothÃ¨se nulle que le rapport des sexes est 1:1Ã  la naissance. Ceci dit, ces donnÃ©es ne sont pas trÃ¨s appropriÃ©es pour Ã©prouver lâ€™hypothÃ¨se car la premiÃ¨re classe dâ€™Ã¢ge est trop grossiÃ¨re. Il est possible que le rapport des sexes Ã  la naissance soit diffÃ©rent de 1:1 mais que la mortalitÃ© diffÃ©rentielle des deux sexes compense au cours des 9 premiÃ¨res annÃ©es (par exemple si il y a plus de mÃ¢les Ã  la naissance, mais que les jeunes garÃ§ons ont une survie plus faible au cours de leurs 9 premiÃ¨res annÃ©es). Dans un tel cas, le rapport des sexes nâ€™est PAS de 1:1 Ã  la naissance, mais on accepte lâ€™hypothÃ¨se nulle Ã  partir des donnÃ©es dans la classe dâ€™Ã¢ge 0-9.",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires gÃ©nÃ©ralisÃ©s",
      "<span class='chapter-number'>15</span>Â  <span class='chapter-title'>Analyse de donnÃ©es de frÃ©quence: Tableaux de contingence, modÃ¨les log-linÃ©aires et rÃ©gression de Poisson</span>"
    ]
  },
  {
    "objectID": "42-model_freq.html#rÃ©gression-de-poisson-pour-lanalyse-de-tableaux-de-contingence-Ã -plusieurs-critÃ¨res",
    "href": "42-model_freq.html#rÃ©gression-de-poisson-pour-lanalyse-de-tableaux-de-contingence-Ã -plusieurs-critÃ¨res",
    "title": "\n15Â  Analyse de donnÃ©es de frÃ©quence: Tableaux de contingence, modÃ¨les log-linÃ©aires et rÃ©gression de Poisson\n",
    "section": "\n15.6 RÃ©gression de Poisson pour lâ€™analyse de tableaux de contingence Ã  plusieurs critÃ¨res",
    "text": "15.6 RÃ©gression de Poisson pour lâ€™analyse de tableaux de contingence Ã  plusieurs critÃ¨res\nLe principe dâ€™Ã©prouver lâ€™indÃ©pendance en examinant les interactions peut Ãªtre utilisÃ© avec les tableaux de contingence Ã  plusieurs critÃ¨res. Par exemple, examinons si la tempÃ©rature (2 niveaux: base et haute) et lâ€™Ã©clairage (2 niveaux: bas et haut) affectent si des plantes sont infectÃ©es (2 niveaux: infectÃ© et non-infectÃ©) par un pathogÃ¨ne. On peut reprÃ©senter ces donnÃ©es par un tableau de contingence Ã  3 critÃ¨res (tempÃ©rature, lumiÃ¨re, statut dâ€™infection).\nLâ€™ajustement de modÃ¨les log-linÃ©aires Ã  des donnÃ©es de frÃ©quence implique que lâ€™on Ã©prouve plusieurs modÃ¨les en les comparant au modÃ¨le complet (saturÃ©). Une sÃ©rie de modÃ¨les contenant tous les termes sauf une des interactions qui nous intÃ©ressent est produite, et lâ€™ajustement de chaque modÃ¨le est comparÃ© Ã  celui du modÃ¨le complet. Si la rÃ©duction de la qualitÃ© dâ€™ajustement nâ€™est pas significative, cela implique que lâ€™interaction manquante contribue peu Ã  la qualitÃ© de lâ€™ajustement. Par contre, si le modÃ¨le rÃ©duit sâ€™ajuste nettement moins bien aux donnÃ©es, alors lâ€™interaction manquante contribue beaucoup Ã  lâ€™ajustement du modÃ¨le complet. Comme pour les tableaux de contingence 2X2, les termes qui nous intÃ©ressent le plus sont les interactions, pas les effets principaux, si lâ€™on teste pour lâ€™indÃ©pendance des diffÃ©rents facteurs.\nLe fichier loglin.csv contient les frÃ©quences (frequency) des plantes infectÃ©es ou non infectÃ©es (infected) Ã  basse et haute tempÃ©rature (temperature) Ã  basse et haute lumiÃ¨re (light). Pour visualiser ces donnÃ©es et dÃ©terminer si le taux dâ€™infection dÃ©pends de la lumiÃ¨re et de la tempÃ©rature, on peut faire une figure mosaÃ¯que et ajuster un modÃ¨le log-linÃ©aire:\n\nloglin &lt;- read.csv(\"data/loglin.csv\")\n# Convert from frequency form to table form for mosaic plot\nloglinTable &lt;- xtabs(frequency ~ temperature + light + infected, data = loglin)\n# Create mosaic plot to look at data\nmosaic(loglinTable, shade = TRUE)\n\n\n\n\n\n\nFigureÂ 15.3: Proportion de plantes infectÃ©es en fonction de la tempÃ©rature er la lumiÃ¨re\n\n\n\n\nCette expÃ©rience contrÃ´lÃ©e avec le mÃªme nombre de plantes Ã  chaque niveau de lumiÃ¨re et de tempÃ©rature produit une mosaÃ¯que oÃ¹ la surface occupÃ©e par les observations dans les quatre quadrants est Ã©gale. Ce qui nous intÃ©resse, le taux dâ€™infection par le pathogÃ¨ne, semble varier entre les quadrants (i.e.Â les niveaux de tempÃ©rature et de lumiÃ¨re). Le rectangle rouge dans le coin en bas Ã  gauche indique que le nombre de plantes infectÃ©es Ã  basse tempÃ©rature et haute lumiÃ¨re est plus faible quâ€™attendu si ces deux facteurs nâ€™influencent pas le taux dâ€™infection. MÃªme chose pour les conditions de basse lumiÃ¨re et de haute tempÃ©rature (coin supÃ©rieur droit). La valeur p au bas de lâ€™Ã©chelle reprÃ©sente un test dâ€™indÃ©pendance Ã©quivalent Ã  comparer le modÃ¨le complet au modÃ¨le excluant toutes les interactions et ne contenant que les effets principaux de la tempÃ©rature, la lumiÃ¨re, et le statut dâ€™infection sur le logarithme naturel du nombre dâ€™observations.\n\n# Fit full model\nfull.model &lt;- glm(frequency ~ temperature * light * infected, family = poisson(), data = loglin)\n# Test partial effect of terms in full model\nAnova(full.model, type = 3, test = \"LR\")\n\nAnalysis of Deviance Table (Type III tests)\n\nResponse: frequency\n                           LR Chisq Df Pr(&gt;Chisq)    \ntemperature                  9.1786  1  0.0024487 ** \nlight                       13.2829  1  0.0002678 ***\ninfected                     0.0000  1  0.9999999    \ntemperature:light            5.6758  1  0.0172008 *  \ntemperature:infected        29.0612  1  7.013e-08 ***\nlight:infected              20.2687  1  6.729e-06 ***\ntemperature:light:infected   1.0840  1  0.2978126    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nLes probabilitÃ©s associÃ©es Ã  chaque terme sont ici calculÃ©es en comparant lâ€™ajustement du modÃ¨le complet Ã  un modÃ¨le qui exclue seulement le terme dâ€™intÃ©rÃªt. Plusieurs des termes sont ici sans vÃ©ritable intÃ©rÃªt puisque les frÃ©quences sont partiellement contrÃ´lÃ©es dans notre expÃ©rience. Puisque la question biologique porte sur le taux dâ€™infection, les seuls termes dâ€™intÃ©rÃªt sont les termes dâ€™interactions qui incluent le statut dâ€™infection (temperature:infected, light:infected et temperature:light:infected.\n\nLâ€™interation significative temperature:infected implique que le taux dâ€™infection nâ€™est pas indÃ©pendant de la tempÃ©rature. Dâ€™ailleurs il est apparent dans la mosaÃ¯que que le taux dâ€™infection (le nombre relatif de plantes infectÃ©es) est supÃ©rieur Ã  haute tempÃ©rature.\nLâ€™interaction significative light:infected implique que le taux dâ€™infection dÃ©pends de la lumiÃ¨re. La mosaÃ¯que illustre que la proportion des plantes infectÃ©es est plus Ã©levÃ©e en basse lumiÃ¨re.\nLâ€™interaction temperature:light:infected nâ€™est pas significative. Cela implique que lâ€™effet de la tempÃ©rature et de la lumiÃ¨re sur le taux dâ€™infection sont indÃ©pendants. Autrement dit, lâ€™effet de la lumiÃ¨re sur le taux dâ€™infection ne dÃ©pends pas de la tempÃ©rature, et vice versa.",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires gÃ©nÃ©ralisÃ©s",
      "<span class='chapter-number'>15</span>Â  <span class='chapter-title'>Analyse de donnÃ©es de frÃ©quence: Tableaux de contingence, modÃ¨les log-linÃ©aires et rÃ©gression de Poisson</span>"
    ]
  },
  {
    "objectID": "42-model_freq.html#ex-glm",
    "href": "42-model_freq.html#ex-glm",
    "title": "\n15Â  Analyse de donnÃ©es de frÃ©quence: Tableaux de contingence, modÃ¨les log-linÃ©aires et rÃ©gression de Poisson\n",
    "section": "\n15.7 Exercice",
    "text": "15.7 Exercice\nLe fichier Sturgdat contient les donnÃ©es qui vous permettront dâ€™Ã©prouver lâ€™hypothÃ¨se que le nombre dâ€™esturgeons capturÃ© est indÃ©pendants du site, de lâ€™annÃ©e, et du sexe. Avant de commencer lâ€™analyse, les donnÃ©es devront Ãªtre rÃ©organisÃ©es pour pouvoir ajuster un modÃ¨le log-linÃ©aire:\n\n\n\n\n\n\nExercice\n\n\n\nOuvrez sturgdat.csv, puis utilisez la fonction table() pour obtenir les frÃ©quence dâ€™individus capturÃ©s par sex, location, et year . Sauvegardez ce tableau comme strugdat.table . Faites une figure mosaÃ¯que de ces donnÃ©es.\n\n\n\nsturgdat &lt;- read.csv(\"data/sturgdat.csv\")\n# Reorganize data from case form to table form\nsturgdat.table &lt;- with(sturgdat, table(sex, year, location))\n# display the table\nsturgdat.table\n\n, , location = CUMBERLAND  \n\n              year\nsex            1978 1979 1980\n  FEMALE         10   30   11\n  MALE           14   14    6\n\n, , location = THE_PAS     \n\n              year\nsex            1978 1979 1980\n  FEMALE          5   12   38\n  MALE           16   12   18\n\n# Create data frame while converting from table form to frequency form\nsturgdat.freq &lt;- as.data.frame(sturgdat.table)\n# display data frame\nsturgdat.freq\n\n            sex year     location Freq\n1  FEMALE       1978 CUMBERLAND     10\n2  MALE         1978 CUMBERLAND     14\n3  FEMALE       1979 CUMBERLAND     30\n4  MALE         1979 CUMBERLAND     14\n5  FEMALE       1980 CUMBERLAND     11\n6  MALE         1980 CUMBERLAND      6\n7  FEMALE       1978 THE_PAS         5\n8  MALE         1978 THE_PAS        16\n9  FEMALE       1979 THE_PAS        12\n10 MALE         1979 THE_PAS        12\n11 FEMALE       1980 THE_PAS        38\n12 MALE         1980 THE_PAS        18\n\n# Look at the data as mosaic plot\n# mosaic using the table created above\nmosaic(sturgdat.table, shade = TRUE)\n\n\n\n\n\n\nFigureÂ 15.4: FrÃ©quence de femelles et males en fonction de lâ€™annÃ©e et du lieu\n\n\n\n\n\n\n\n\n\n\nExercice\n\n\n\nÃ€ partir de ces donnÃ©es en format de frÃ©quence, ajustez le modÃ¨le loglinÃ©aire complet et le tableau dâ€™anova avec les statistique de Chi carrÃ© pour les termes du modÃ¨les. Est-ce que lâ€™interaction triple (location:year:sex) est significative? Est-ce que le rapport des sexes varien entre les sites ou dâ€™une annÃ©e Ã  lâ€™autre?.\n\n\n\n# Fit full model\nfull.model &lt;- glm(Freq ~ sex * year * location, data = sturgdat.freq, family = \"poisson\")\nsummary(full.model)\n\n\nCall:\nglm(formula = Freq ~ sex * year * location, family = \"poisson\", \n    data = sturgdat.freq)\n\nCoefficients:\n                                              Estimate Std. Error z value\n(Intercept)                                    2.30259    0.31623   7.281\nsexMALE                                        0.33647    0.41404   0.813\nyear1979                                       1.09861    0.36515   3.009\nyear1980                                       0.09531    0.43693   0.218\nlocationTHE_PAS                               -0.69315    0.54772  -1.266\nsexMALE        :year1979                      -1.09861    0.52554  -2.090\nsexMALE        :year1980                      -0.94261    0.65498  -1.439\nsexMALE        :locationTHE_PAS                0.82668    0.65873   1.255\nyear1979:locationTHE_PAS                      -0.22314    0.64550  -0.346\nyear1980:locationTHE_PAS                       1.93284    0.64593   2.992\nsexMALE        :year1979:locationTHE_PAS      -0.06454    0.83986  -0.077\nsexMALE        :year1980:locationTHE_PAS      -0.96776    0.87942  -1.100\n                                              Pr(&gt;|z|)    \n(Intercept)                                    3.3e-13 ***\nsexMALE                                        0.41641    \nyear1979                                       0.00262 ** \nyear1980                                       0.82732    \nlocationTHE_PAS                                0.20569    \nsexMALE        :year1979                       0.03658 *  \nsexMALE        :year1980                       0.15011    \nsexMALE        :locationTHE_PAS                0.20950    \nyear1979:locationTHE_PAS                       0.72957    \nyear1980:locationTHE_PAS                       0.00277 ** \nsexMALE        :year1979:locationTHE_PAS       0.93875    \nsexMALE        :year1980:locationTHE_PAS       0.27114    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance:  5.7176e+01  on 11  degrees of freedom\nResidual deviance: -2.6645e-15  on  0  degrees of freedom\nAIC: 77.28\n\nNumber of Fisher Scoring iterations: 3\n\nAnova(full.model, type = 3)\n\nAnalysis of Deviance Table (Type III tests)\n\nResponse: Freq\n                  LR Chisq Df Pr(&gt;Chisq)    \nsex                 0.6698  1  0.4131256    \nyear               13.8895  2  0.0009637 ***\nlocation            1.6990  1  0.1924201    \nsex:year            4.6930  2  0.0957024 .  \nsex:location        1.6323  1  0.2013888    \nyear:location      25.2580  2  3.276e-06 ***\nsex:year:location   1.6677  2  0.4343666    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nCe tableau a trois critÃ¨res: sex, location et year . Donc le modÃ¨les compelt (saturÃ©) contient 7 termes: trois effets principaux (sex, location et year), trois interactions du second degrÃ© (double) (sex:year, sex:location et year: location) et une interaction du troisiÃ¨me degrÃ© (triple)(sex:year:location). La dÃ©viance nulle est 57.17574, la dÃ©viance rÃ©siduelle du modÃ¨le complet est, sans surprise, 0. La dÃ©viance pouvant Ãªtre attribuÃ©e Ã  lâ€™interaction triple est 1.6677, non significative.\nQuâ€™est ce que cela implique? Sâ€™il y a des interactions doubles, alors elles ne dÃ©pendent pas de la troisiÃ¨me variable. Par exemple, si le rapport des sexe des esturgeons varie dâ€™une annÃ©e Ã  lâ€™autre (une interaction sex:year), alors cette tendance est la mÃªme aux 2 stations.\nPuisquâ€™il nâ€™y a pas dâ€™interaction triple, il est (statistiquement) justifiÃ© de combiner les donnÃ©es pour Ã©prouver les interactions du second degrÃ©. Par exemple, pour tester lâ€™effet sex:location, on peut combiner les annÃ©es. Pour tester lâ€™effet sex:year, on peut combiner les sites. Cette aggrÃ©gation a pour effet dâ€™augmenter la puissance, et est analogue Ã  la stratÃ©gie en ANOVA Ã  critÃ¨res multiples. Lâ€™approche de la rÃ©gression de Poisson permet de faire lâ€™Ã©quivalent simplement en ajustant le modÃ¨le sans lâ€™interaction du troisiÃ¨me degrÃ©.\n\nAjustez le modÃ¨le en excluant lâ€™interaction du troisiÃ¨me degrÃ©:\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\no2int.model &lt;- glm(Freq ~ sex + year + location + sex:year + sex:location + year:location, data = sturgdat.freq, family = \"poisson\")\nAnova(o2int.model, type = 3)\n\nAnalysis of Deviance Table (Type III tests)\n\nResponse: Freq\n              LR Chisq Df Pr(&gt;Chisq)    \nsex             1.8691  1  0.1715807    \nyear           15.1289  2  0.0005186 ***\nlocation        1.5444  1  0.2139568    \nsex:year       15.5847  2  0.0004129 ***\nsex:location    2.1762  1  0.1401583    \nyear:location  28.3499  2  6.981e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\nLâ€™interaction sex:location nâ€™explique pas une portion significative de la dÃ©viance, alors que les deux autres sont significatives. Le rapport des sexes ne varie pas entre les sites, mais il varie selon les annÃ©es. Lâ€™interaction year:location est aussi significative (voir plus pas pour son interprÃ©tation).\nDevriez vous tenter de simplifier le modÃ¨le encore plus? Les vrais statisticiens sont divisÃ©s sur cette question. Tous sâ€™entendent cependant sur le fait que conserver des interactions non significatives dans un modÃ¨le peut rÃ©duire la puissance. De lâ€™autre cÃ´tÃ©, le retrait des interactions non significatives peut rendre lâ€™interprÃ©tation plus dÃ©licate lorsque les observations ne sont pas bien balancÃ©es (i.e.Â il y a de la colinÃ©aritÃ© entre les termes du modÃ¨le).\n\nAjustez le modÃ¨le sans lâ€™interaction sex:location :\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\no2int.model2 &lt;- glm(Freq ~ sex + year + location + sex:year + year:location, data = sturgdat.freq, family = \"poisson\")\nAnova(o2int.model2, type = 3)\n\nAnalysis of Deviance Table (Type III tests)\n\nResponse: Freq\n              LR Chisq Df Pr(&gt;Chisq)    \nsex             5.0970  1  0.0239677 *  \nyear           16.1226  2  0.0003155 ***\nlocation        0.2001  1  0.6546011    \nsex:year       13.9883  2  0.0009173 ***\nyear:location  26.7534  2  1.551e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\nLes deux interactions sont significatives et ce modÃ¨le semble le meilleur. Ce modÃ¨le est:\n\\[ln[f_{(ijk)} ] = location + sex + year + sex:year + location:year\\]\nComment ces effets peuvent-ils Ãªtre interprÃ©tÃ©s biologiquement? Souvenez vous que, comme dans les test dâ€™indÃ©pendance, on nâ€™est pas vraiment intÃ©ressÃ© aux effets principaux, seulement par les interactions. Par exemple, lâ€™effet principal de location tnous dit que le nombre total dâ€™esturgeons capturÃ© (le total des 2 sexes pendant les 3 annÃ©es dâ€™Ã©chantillonnage) diffÃ¨re entre les 2 sites. Cela nâ€™est pas vraiment surprenant et peu intÃ©ressant en lâ€™absence dâ€™information sur lâ€™effort de pÃªche. Cependant, lâ€™interaction sex:year nous dit que le rapport des sexes a changÃ© dâ€™une annÃ©e Ã  lâ€™autre. Et puisque lâ€™interaction du troisiÃ¨me degrÃ© nâ€™est pas significative, on sait que ce changement dans le temps est approximativement le mÃªme dans les deux sites. Un rÃ©sultat possiblement intÃ©ressant. Pourquoi? Comme lâ€™expliquer?\nLâ€™interaction location:year nous dit que le nombre dâ€™esturgeons nâ€™a pas seulementt variÃ© dâ€™une annÃ©e Ã  lâ€™autre, mais que la tendance dans le temps diffÃ¨re entre les deux sites. Ceci pourrait reflÃ©ter une diffÃ©rence dâ€™effort de pÃªche Ã  un des sites durant lâ€™une des campagnes dâ€™Ã©chantillonnage, ou un impact Ã  seulement un des deux sites la derniÃ¨re annÃ©e par exemple. Mais cette tendance est la mÃªme pour les mÃ¢les et les femelles (donc nâ€™a pas affectÃ© le rapport des sexes) puisque lâ€™interaction triple nâ€™est pas significative.",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires gÃ©nÃ©ralisÃ©s",
      "<span class='chapter-number'>15</span>Â  <span class='chapter-title'>Analyse de donnÃ©es de frÃ©quence: Tableaux de contingence, modÃ¨les log-linÃ©aires et rÃ©gression de Poisson</span>"
    ]
  },
  {
    "objectID": "901-bibliographie.html",
    "href": "901-bibliographie.html",
    "title": "RÃ©fÃ©rences",
    "section": "",
    "text": "Paquets R\nCe livre a utilisÃ© les paquets R (excluant leurs dÃ©pendances) listÃ© dans le tableau TableÂ 1. Comme recommandÃ© par lâ€™Ã©quipe de de dÃ©veloppement de â€˜tidyverseâ€™, seul le paquets â€˜tidyverseâ€™ est citÃ© et non pas chacun de ses composants.\nA large number of files (6573 in total) have been discovered.\nIt may take renv a long time to crawl these files for dependencies.\nConsider using .renvignore to ignore irrelevant files.\nSee `?renv::dependencies` for more information.\nSet `options(renv.config.dependencies.limit = Inf)` to disable this warning.\n\n\n\nTableÂ 1: Paquets utilisÃ©s dans le livre\n\n\n\n\n\n\n\n\n\nPaquets\nVersion\nCitation\n\n\n\nbase\n4.4.1\nR Core Team (2024)\n\n\nboot\n1.3.31\n\nA. C. Davison et D. V. Hinkley (1997); Angelo Canty et B. D. Ripley (2024)\n\n\n\ncar\n3.1.2\nFox et Weisberg (2019a)\n\n\neffects\n4.2.2\n\nFox (2003); Fox et Hong (2009); Fox et Weisberg (2018); Fox et Weisberg (2019b)\n\n\n\nemoji\n15.0\nHvitfeldt (2022)\n\n\nGGally\n2.2.1\nSchloerke et al. (2024)\n\n\nggcleveland\n0.1.0\nPrunello et Mari (2021)\n\n\nggpubr\n0.6.0\nKassambara (2023)\n\n\ngrateful\n0.2.10\nRodriguez-Sanchez et Jackson (2023)\n\n\ngt\n0.11.0\nIannone et al. (2024)\n\n\nkableExtra\n1.4.0\nZhu (2024)\n\n\nknitr\n1.48\n\nXie (2014); Xie (2015); Xie (2024)\n\n\n\nlme4\n1.1.35.5\nBates et al. (2015)\n\n\nlmPerm\n2.1.0\nWheeler et Torchiano (2016)\n\n\nlmtest\n0.9.40\nZeileis et Hothorn (2002)\n\n\nmultcomp\n1.4.26\nHothorn et al. (2008)\n\n\nMuMIn\n1.48.4\nBartoÅ„ (2024)\n\n\npalmerpenguins\n0.1.1\nHorst et al. (2020)\n\n\npatchwork\n1.2.0\nPedersen (2024)\n\n\nperformance\n0.12.3\nLÃ¼decke et al. (2021)\n\n\npwr\n1.3.0\nChampely (2020)\n\n\nreshape2\n1.4.4\nWickham (2007)\n\n\nrmarkdown\n2.28\n\nXie et al. (2018); Xie et al. (2020); Allaire et al. (2024)\n\n\n\nsimpleboot\n1.1.8\nPeng (2024)\n\n\ntidyverse\n2.0.0\nWickham et al. (2019)\n\n\nvcd\n1.4.12\n\nMeyer et al. (2006); Zeileis et al. (2007); (vcd2023?)\n\n\n\nvcdExtra\n0.8.5\nFriendly (2023)\n\n\nvioplot\n0.5.0\nAdler et al. (2024)",
    "crumbs": [
      "DonnÃ©es",
      "RÃ©fÃ©rences"
    ]
  },
  {
    "objectID": "901-bibliographie.html#bibliographie",
    "href": "901-bibliographie.html#bibliographie",
    "title": "RÃ©fÃ©rences",
    "section": "Bibliographie",
    "text": "Bibliographie\n\n\nA. C. Davison, et D. V. Hinkley. 1997. Bootstrap Methods and Their Applications. Cambridge University Press, Cambridge.\n\n\nAdler, D., S. T. Kelly, T. Elliott, et J. Adamson. 2024. vioplot: violin plot.\n\n\nAllaire, J., Y. Xie, C. Dervieux, J. McPherson, J. Luraschi, K. Ushey, A. Atkins, H. Wickham, J. Cheng, W. Chang, et R. Iannone. 2024. rmarkdown: Dynamic Documents for R.\n\n\nAngelo Canty, et B. D. Ripley. 2024. boot: Bootstrap R (S-Plus) Functions.\n\n\nBartoÅ„, K. 2024. MuMIn: Multi-Model Inference.\n\n\nBates, D., M. MÃ¤chler, B. Bolker, et S. Walker. 2015. Fitting Linear Mixed-Effects Models Using lme4. Journal of Statistical Software 67:1â€‘48.\n\n\nChampely, S. 2020. pwr: Basic Functions for Power Analysis.\n\n\nFox, J. 2003. Effect Displays in R for Generalised Linear Models. Journal of Statistical Software 8:1â€‘27.\n\n\nFox, J., et J. Hong. 2009. Effect Displays in R for Multinomial and Proportional-Odds Logit Models: Extensions to the effects Package. Journal of Statistical Software 32:1â€‘24.\n\n\nFox, J., et S. Weisberg. 2018. Visualizing Fit and Lack of Fit in Complex Regression Models with Predictor Effect Plots and Partial Residuals. Journal of Statistical Software 87:1â€‘27.\n\n\nFox, J., et S. Weisberg. 2019a. An R Companion to Applied Regression. Third. Sage, Thousand Oaks CA.\n\n\nFox, J., et S. Weisberg. 2019b. An R Companion to Applied Regression. 3rd Ã©dition. Sage, Thousand Oaks CA.\n\n\nFriendly, M. 2023. vcdExtra: Â«Â vcdÂ Â» Extensions and Additions.\n\n\nHorst, A. M., A. P. Hill, et K. B. Gorman. 2020. palmerpenguins: Palmer Archipelago (Antarctica) penguin data.\n\n\nHothorn, T., F. Bretz, et P. Westfall. 2008. Simultaneous Inference in General Parametric Models. Biometrical Journal 50:346â€‘363.\n\n\nHvitfeldt, E. 2022. emoji: Data and Function to Work with Emojis.\n\n\nIannone, R., J. Cheng, B. Schloerke, E. Hughes, A. Lauer, J. Seo, K. Brevoort, et O. Roy. 2024. gt: Easily Create Presentation-Ready Display Tables.\n\n\nKassambara, A. 2023. ggpubr: Â«Â ggplot2Â Â» Based Publication Ready Plots.\n\n\nLÃ¼decke, D., M. S. Ben-Shachar, I. Patil, P. Waggoner, et D. Makowski. 2021. performance: An R Package for Assessment, Comparison and Testing of Statistical Models. Journal of Open Source Software 6:3139.\n\n\nMeyer, D., A. Zeileis, et K. Hornik. 2006. The Strucplot Framework: Visualizing Multi-Way Contingency Tables with vcd. Journal of Statistical Software 17:1â€‘48.\n\n\nPedersen, T. L. 2024. patchwork: The Composer of Plots.\n\n\nPeng, R. D. 2024. simpleboot: Simple Bootstrap Routines.\n\n\nPrunello, M., et G. Mari. 2021. ggcleveland: Implementation of Plots from Clevelandâ€™s Visualizing Data Book.\n\n\nR Core Team. 2024. R: A Language and Environment for Statistical Computing. R Foundation for Statistical Computing, Vienna, Austria.\n\n\nRodriguez-Sanchez, F., et C. P. Jackson. 2023. grateful: Facilitate citation of R packages.\n\n\nSchloerke, B., D. Cook, J. Larmarange, F. Briatte, M. Marbach, E. Thoen, A. Elberg, et J. Crowley. 2024. GGally: Extension to Â«Â ggplot2Â Â».\n\n\nWheeler, B., et M. Torchiano. 2016. lmPerm: Permutation Tests for Linear Models.\n\n\nWickham, H. 2007. Reshaping Data with the reshape Package. Journal of Statistical Software 21:1â€‘20.\n\n\nWickham, H., M. Averick, J. Bryan, W. Chang, L. D. McGowan, R. FranÃ§ois, G. Grolemund, A. Hayes, L. Henry, J. Hester, M. Kuhn, T. L. Pedersen, E. Miller, S. M. Bache, K. MÃ¼ller, J. Ooms, D. Robinson, D. P. Seidel, V. Spinu, K. Takahashi, D. Vaughan, C. Wilke, K. Woo, et H. Yutani. 2019. Welcome to the tidyverse. Journal of Open Source Software 4:1686.\n\n\nXie, Y. 2014. knitr: A Comprehensive Tool for Reproducible Research in R. in V. Stodden, F. Leisch, et R. D. Peng, Ã©diteurs. Implementing Reproducible Computational Research. Chapman; Hall/CRC.\n\n\nXie, Y. 2015. Dynamic Documents with R and knitr. 2nd Ã©dition. Chapman; Hall/CRC, Boca Raton, Florida.\n\n\nXie, Y. 2024. knitr: A General-Purpose Package for Dynamic Report Generation in R.\n\n\nXie, Y., J. J. Allaire, et G. Grolemund. 2018. R Markdown: The Definitive Guide. Chapman; Hall/CRC, Boca Raton, Florida.\n\n\nXie, Y., C. Dervieux, et E. Riederer. 2020. R Markdown Cookbook. Chapman; Hall/CRC, Boca Raton, Florida.\n\n\nZeileis, A., et T. Hothorn. 2002. Diagnostic Checking in Regression Relationships. R News 2:7â€‘10.\n\n\nZeileis, A., D. Meyer, et K. Hornik. 2007. Residual-based Shadings for Visualizing (Conditional) Independence. Journal of Computational and Graphical Statistics 16:507â€‘525.\n\n\nZhu, H. 2024. kableExtra: Construct Complex Table with Â«Â kableÂ Â» and Pipe Syntax.",
    "crumbs": [
      "DonnÃ©es",
      "RÃ©fÃ©rences"
    ]
  },
  {
    "objectID": "902-donnees.html",
    "href": "902-donnees.html",
    "title": "Annexe A â€” DonnÃ©es utilisÃ©es dans le livre",
    "section": "",
    "text": "A.1 Fichier compressÃ© tout-inclus\nTous les fichiers de donnÃ©es et de code dans un fichier zip",
    "crumbs": [
      "DonnÃ©es",
      "Annexes",
      "<span class='chapter-number'>A</span>Â  <span class='chapter-title'>DonnÃ©es utilisÃ©es dans le livre</span>"
    ]
  },
  {
    "objectID": "902-donnees.html#tous-les-fichiers-sÃ©parÃ©s",
    "href": "902-donnees.html#tous-les-fichiers-sÃ©parÃ©s",
    "title": "Annexe A â€” DonnÃ©es utilisÃ©es dans le livre",
    "section": "\nA.2 Tous les fichiers sÃ©parÃ©s",
    "text": "A.2 Tous les fichiers sÃ©parÃ©s\n\nage.csv\nanc1dat.csv\nanc3dat.csv\natmosphere.txt\nBanta_TotalFruits.csv\nBiston_pd_1.csv\nBiston_pd_2.csv\nBiston_student.csv\nBiston.postdoc.csv\nBiston.prof.csv\nDam10dat.csv\ndragons.csv\nErablesGatineau.csv\ngala.txt\nhypoxia.uottawa.csv\nJacobsenDangles_1.csv\nJacobsenDangles_2.csv\nloglin.csv\nmouflon.csv\nMregdat.csv\nnematodes.csv\nnestdat.csv\nnr2wdat.csv\npollution.txt\nsalmonella.csv\nsimulies.csv\nsimuliidae.csv\nskulldat_2020.csv\nskulldat-rm.csv\nsmoking.txt\nStu2mdat.csv\nStu2wdat.csv\nsturgdat.csv\nsturgeon.csv\nunicorns_aggression.csv\nunicorns.csv\nunicorns.txt\nunicorns.xlsx\nUSPopSurvey.csv\nwmc2dat2.csv\nwmcdat2.csv",
    "crumbs": [
      "DonnÃ©es",
      "Annexes",
      "<span class='chapter-number'>A</span>Â  <span class='chapter-title'>DonnÃ©es utilisÃ©es dans le livre</span>"
    ]
  },
  {
    "objectID": "902-donnees.html#code-r-et-fonctions-utilisÃ©es-dans-les-diapositives",
    "href": "902-donnees.html#code-r-et-fonctions-utilisÃ©es-dans-les-diapositives",
    "title": "Annexe A â€” DonnÃ©es utilisÃ©es dans le livre",
    "section": "\nA.3 Code R et fonctions utilisÃ©es dans les diapositives",
    "text": "A.3 Code R et fonctions utilisÃ©es dans les diapositives\n\nbook-fnc.R\nextra_funs.R\nglmm_simdev.rda",
    "crumbs": [
      "DonnÃ©es",
      "Annexes",
      "<span class='chapter-number'>A</span>Â  <span class='chapter-title'>DonnÃ©es utilisÃ©es dans le livre</span>"
    ]
  }
]